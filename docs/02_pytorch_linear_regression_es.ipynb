{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Redes Neuronales en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "En este capítulo, se presentarán los fundamentos de las redes neuronales y cómo se implementan en PyTorch. Se presentarán los conceptos de redes neuronales, funciones de activación, funciones de pérdida, optimizadores y cómo se implementan en PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Desarrollando la primera red neuronal en PyTorch\n",
    "\n",
    "Una red neuronal se compone de un elemento fundamental llamado *neurona*. Cada neurona de una red neuronal realiza tres operaciones básicas:\n",
    "\n",
    "1. Multiplica cada entrada que recibe por un peso.\n",
    "2. Suma todas las entradas ponderadas añadiendo un sesgo (constante). \n",
    "3. Aplica una función no lineal a la salida. Esta función se denomina función de activación.\n",
    "\n",
    "Los pesos y el sesgo son parámetros de la neurona que se aprenden durante el entrenamiento. La función de activación es una función no lineal que se aplica a la salida de la neurona. Gracias a la función de activación no lineal, la red neuronal puede aprender relaciones no lienales entre las entradas y las salidas.\n",
    "\n",
    "Las operaciones de una neurona se puede describir en forma matemática de la siguiente manera:\n",
    "\n",
    "```\n",
    "y = f(w*x + b)\n",
    "```\n",
    "\n",
    "Siendo, `x` es un vector de entrada de tamaño `n`, `w` es un vector de pesos de tamaño `n`, `b` es el sesgo (un solo número) y `f` es la función de activación.\n",
    "Si no se utiliza función de activación, la salida `y` es simplemente una suma ponderada de las entradas (más el sesgo), es decir, una regresión lineal:\n",
    "\n",
    "```\n",
    "y = w1x1 + w2x2 + ... + wnxn + b\n",
    "```\n",
    "\n",
    "Para entender cómo se implementa una arquitectura de *deep learning* en PyTorch, se comenzará desarrollando un modelo de regresión lineal. Este modelo es el más simple de todos los modelos de redes neuronales, pero es un buen punto de partida para entender cómo se implementan las redes neuronales en PyTorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando un conjunto de datos sintético: predicción de producción de manzanas y naranjas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema que se va a resolver es el siguiente: se tiene información sobre el clima en ciertas localidades y se desea predecir la producción de manzanas y naranjas en esas localidades en base a los datos climáticos. \n",
    "\n",
    "Es interesante recalcar que se dispone de dos columnas que se quieren predecir, por lo que este ejemplo consiste en de dos modelos de regresión lineal. Cada modelo de regresión lineal predice una columna distinta.\n",
    "\n",
    "\n",
    "| Region   | Temperatura | Lluvia | Humedad | **Manzanas** (target 1) | **Naranjas** (target 2)|\n",
    "|----------|-------------|--------|---------|--------------|--------------|\n",
    "| España   | 73          | 67     | 43      | **56**       | **70**       |\n",
    "| Italia   | 91          | 88     | 64      | **81**       | **101**      |\n",
    "| Alemania | 87          | 134    | 58      | **119**      | **133**      |\n",
    "| Portugal | 102         | 43     | 37      | **22**       | **37**       |\n",
    "| Francia  | 69          | 96     | 70      | **103**      | **119**      |\n",
    "\n",
    "En un modelo de regresión lineal, cada variable objetivo se estima como una suma ponderada (también llamados weights) de las variables de entrada, sumando una constante o bias:\n",
    "\n",
    "```\n",
    "produccion_manzana = w11 * temperatura + w12 * lluvia + w13 * humedad + b1\n",
    "produccion_naranja = w21 * temperatura + w22 * lluvia + w23 * humedad + b2\n",
    "```\n",
    "\n",
    "Ahora implementaremos un modelo de regresión lineal para predecir con PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pKkEAjw2C5TC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Datos de entrenamiento\n",
    "\n",
    "Podemos representar los datos de entrenamiento usando dos matrices: `entradas` y `objetivos`, cada una con una fila por observación y una columna por variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "2bKYApSpC5TD"
   },
   "outputs": [],
   "source": [
    "# Entrada (tempertura, precipitación, humedad)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FwudGF5JC5TF"
   },
   "outputs": [],
   "source": [
    "# Salida (manzanas, naranjas)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "NOTA:\n",
    "\n",
    "Se convierten las matrices en tensores PyTorch. Si quieres saber más sobre tensores y operaciones con ellos, puedes consultar el post de [Introducción a PyTorch](xxxxx).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1636713447875,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "NvP3c6dJC5TG",
    "outputId": "d354faa3-1418-4b40-8f09-d3b30773547f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Se transforman las matrices a tensores\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Modelo de regresión lineal\n",
    "\n",
    "Los pesos y sesgos (`w11, w12,... w23, b1 y b2`) también se pueden representar como matrices, inicializadas como valores aleatorios. La primera fila de `w` y el primer elemento de `b` se utilizan para predecir la primera variable objetivo, es decir, el rendimiento de las manzanas y, de manera similar, el segundo para las naranjas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1636713924627,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "07EjOQHPC5TJ",
    "outputId": "f77510cd-3b9d-4c64-dab9-cf29b2888395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7679,  1.1114, -0.2267],\n",
      "        [ 0.0614, -1.4329,  2.0267]], requires_grad=True)\n",
      "tensor([ 1.7997, -2.2624], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Pesos y sesgos\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "`torch.randn` crea un tensor con la forma dada, con elementos elegidos aleatoriamente de una [distribución normal](https://en.wikipedia.org/wiki/Normal_distribution) con media 0 y desviación estándar 1.\n",
    "\n",
    "El *modelo* que se va a crear es simplemente una función que realiza una multiplicación matricial de las `entradas` y los pesos `w` (transpuestos) y agrega el sesgo `b` (replicado para cada observación).\n",
    "\n",
    "![matriz-mult](https://i.imgur.com/WGXLFvA.png)\n",
    "\n",
    "Podemos definir el modelo de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1vnr8H2vC5TK"
   },
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "`@` representa la multiplicación de matrices en PyTorch, y el método `.t` devuelve la transposición de un tensor.\n",
    "\n",
    "La matriz obtenida al pasar los datos de entrada al modelo es un conjunto de predicciones para las variables objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1636713928170,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "rY4M5l6QC5TL",
    "outputId": "f8f81848-1eda-48a7-ae63-9791934e5408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -62.5404,   -6.6384],\n",
      "        [ -75.7836,    6.9362],\n",
      "        [ -16.2256,  -71.3851],\n",
      "        [-139.1242,   17.3723],\n",
      "        [ -29.3582,    6.2823]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generar predicciones\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Comparemos las predicciones de nuestro modelo con los objetivos reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1636713929893,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "Od2MBNXxC5TM",
    "outputId": "1c9b2b8d-bcac-47c8-8726-f093f2432fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Comparar con los targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Como se podía esperar, existe una gran diferencia entre las predicciones de nuestro modelo y los valores reales de las variables a predecir. Como todavía no hemos entrenado el modelo, los pesos y sesgos son números aleatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Función de pérdida\n",
    "\n",
    "El entrenamiento de una red neuronal consiste en determinar los pesos y sesgos que hacen que la predicción sea lo más parecida al conjunto de valores reales (observaciones). Este proceso es en realidad un problema de optimización, en concreto de minización. La minimización de una función $y=f(x)$ consiste en determinar los parámetros $x$ que minimizan el valor de la función $f(x)$. \n",
    "\n",
    "En el caso de la función $y=x^2$ el valor que minimiza la función es $x=0$. Calcular la derivada de una función, y despejar el valor de la $x$ para determinar el valor mínimo es muy costoso computacionalmente, y en ocasiones no es posible. Por ello, la optimización de los parámetros se realiza con un proceso numérico denominado *back-propagation*. En la siguiente referencia se puede encontrar más información al respecto [REFERENCE999].\n",
    "\n",
    "Es necesario por tanto, definir cuál es la función que se quiere minimizar en el entrenamiento de nuestra red neuronal. Esta función se denomina *función de pérdidad*.\n",
    "\n",
    "Las funciones de pérdida más utilizadas son:\n",
    "* Problemas de regresión: Error cuadrático medio (MSE) y error cuadrático absoluto (MAE).\n",
    "* Problemas de clasificación: Entropía cruzada.\n",
    "\n",
    "*Calcula la diferencia entre las dos matrices (`preds` y `targets`).* Cuadre todos los elementos de la matriz de diferencias para eliminar los valores negativos.\n",
    "*Calcular el promedio de los elementos de la matriz resultante.\n",
    "\n",
    "En el problema planteado, se utilizará como función de pérdida el **error cuadrático medio** (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0meT5miC5TO"
   },
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "`torch.sum` devuelve la suma de todos los elementos en un tensor. El método `.numel` de un tensor devuelve el número de elementos en un tensor. Calculemos el error cuadrático medio de las predicciones actuales de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1636713933477,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "MQKwxvg-C5TO",
    "outputId": "665f8c61-c8aa-49a1-ea8c-5e9679a9da94"
   },
   "outputs": [],
   "source": [
    "# Computar loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Así es como podemos interpretar el resultado: *En promedio, cada elemento en la predicción difiere del objetivo real por la raíz cuadrada de la pérdida*. Y eso es bastante malo, considerando que los números que estamos tratando de predecir están en el rango de 50 a 200. El resultado se llama *pérdida* porque indica qué tan malo es el modelo para predecir las variables de destino. Representa la pérdida de información en el modelo: cuanto menor es la pérdida, mejor es el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Calcular gradientes\n",
    "\n",
    "Con PyTorch, podemos calcular automáticamente el gradiente o la derivada de la pérdida w.r.t. a los pesos y sesgos porque tienen `requires_grad` establecido en `True`. Veremos cómo esto es útil en un momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZlCJRL_C5TS"
   },
   "outputs": [],
   "source": [
    "# Computar gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Los gradientes se almacenan en la propiedad `.grad` de los respectivos tensores. Tenga en cuenta que la derivada de la pérdida w.r.t. la matriz de pesos es en sí misma una matriz con las mismas dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Ajuste pesos y sesgos para reducir la pérdida\n",
    "\n",
    "La pérdida es una [función cuadrática](https://en.wikipedia.org/wiki/Quadratic_function) de nuestros pesos y sesgos, y nuestro objetivo es encontrar el conjunto de pesos donde la pérdida es la más baja. Si trazamos un gráfico de la pérdida con cualquier elemento de peso o sesgo individual, se verá como la figura que se muestra a continuación. Una idea importante del cálculo es que el gradiente indica la tasa de cambio de la pérdida, es decir, la [pendiente] (https://en.wikipedia.org/wiki/Slope) de la función de pérdida w.r.t. los pesos y sesgos.\n",
    "\n",
    "Si un elemento degradado es **positivo**:\n",
    "\n",
    "* **aumentar** el valor del elemento de peso ligeramente **aumentará** la pérdida\n",
    "* **disminuir** el valor del elemento de peso ligeramente **disminuirá** la pérdida\n",
    "\n",
    "![gradiente-positivo](https://i.imgur.com/WLzJ4xP.png)\n",
    "\n",
    "Si un elemento degradado es **negativo**:\n",
    "\n",
    "* **aumentar** el valor del elemento de peso ligeramente **disminuirá** la pérdida\n",
    "* **disminuir** el valor del elemento de peso ligeramente **aumentará** la pérdida\n",
    "\n",
    "![negativo=gradiente](https://i.imgur.com/dvG2fxU.png)\n",
    "\n",
    "El aumento o disminución de la pérdida al cambiar un elemento de peso es proporcional al gradiente de la pérdida w.r.t. ese elemento Esta observación forma la base del_descenso de gradiente_algoritmo de optimización que usaremos para mejorar nuestro modelo (_descendiendo_a lo largo del_gradiente_).\n",
    "\n",
    "Podemos restar de cada elemento de peso una pequeña cantidad proporcional a la derivada de la pérdida w.r.t. ese elemento para reducir ligeramente la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1636713940121,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "_ggYbnKZC5TT",
    "outputId": "ecb3b11b-d567-4cb0-a322-343e634f73a6"
   },
   "outputs": [],
   "source": [
    "w\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2NS9wgOC5TU"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Multiplicamos los gradientes con un número muy pequeño (`10^-5` en este caso) para asegurarnos de no modificar los pesos en una cantidad muy grande. Queremos dar un pequeño paso en la dirección cuesta abajo de la pendiente, no un salto gigante. Este número se denomina *tasa de aprendizaje* del algoritmo.\n",
    "\n",
    "Usamos `torch.no_grad` para indicarle a PyTorch que no debemos rastrear, calcular o modificar gradientes mientras actualizamos los pesos y sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1636713945447,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "9RlhEqSMC5TU",
    "outputId": "cb893286-3376-4527-b1e1-1738d2797c4b"
   },
   "outputs": [],
   "source": [
    "# Let's verify that the loss is actually lower\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Antes de continuar, restablecemos los gradientes a cero invocando el método `.zero_()`. Necesitamos hacer esto porque PyTorch acumula gradientes. De lo contrario, la próxima vez que invocamos `.backward` en la pérdida, los nuevos valores de gradiente se agregan a los gradientes existentes, lo que puede generar resultados inesperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1636713949375,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "v4kx1rJZC5TV",
    "outputId": "96b84c1d-9314-4543-cbdd-67a791d05fb5"
   },
   "outputs": [],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Entrena el modelo usando descenso de gradiente\n",
    "\n",
    "Como se vio anteriormente, reducimos la pérdida y mejoramos nuestro modelo utilizando el algoritmo de optimización de descenso de gradiente. Por lo tanto, podemos _entrenar_ el modelo usando los siguientes pasos:\n",
    "\n",
    "1. Genera predicciones\n",
    "\n",
    "2. Calcular la pérdida\n",
    "\n",
    "3. Calcular gradientes con los pesos y sesgos\n",
    "\n",
    "4. Ajuste los pesos restando una pequeña cantidad proporcional al gradiente\n",
    "\n",
    "5. Restablecer los gradientes a cero\n",
    "\n",
    "Implementemos lo anterior paso a paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1636713961830,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "0_zqzITiHRbm",
    "outputId": "4b949ffa-9f09-482e-dcfc-f59bc552680c"
   },
   "outputs": [],
   "source": [
    "p = model(inputs)\n",
    "loss = mse(p, targets)\n",
    "loss.backward()\n",
    "with torch.no_grad():\n",
    "  w -= w.grad * 1e-4\n",
    "  b -= b.grad * 1e-4\n",
    "  w.grad.zero_()\n",
    "  b.grad.zero_()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1636713976072,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "3afvYPwXC5TW",
    "outputId": "47d27d13-2ddb-4e27-cc14-2d7f88e8eed5"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1636713982334,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "kZBFf1dCC5TW",
    "outputId": "488d92e0-5c16-4ade-b853-c77d8eb3ff95"
   },
   "outputs": [],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1636713987329,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "pZG9pSejC5TW",
    "outputId": "658eca86-cf3e-4917-e9fc-9e01e874caff"
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Actualicemos los pesos y sesgos usando los gradientes calculados arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4SOMcWNC5TX"
   },
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-4\n",
    "    b -= b.grad * 1e-4\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Echemos un vistazo a los nuevos pesos y sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1636713994145,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "GYTY5xbFC5TY",
    "outputId": "08a495da-7df9-4dff-8e27-3c7acf60cf08"
   },
   "outputs": [],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Con los nuevos pesos y sesgos, el modelo debería tener una pérdida menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1636713996969,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "mwde3z8kC5TY",
    "outputId": "b01755c2-33f9-4477-da82-b64433d00cc0"
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1636713999889,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "da9rJy-KZWX2",
    "outputId": "00689f02-7807-450b-e1ea-7f1bf4f377a3"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-4\n",
    "    b -= b.grad * 1e-4\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    " \n",
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(targets)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Ya hemos logrado una reducción significativa en la pérdida simplemente ajustando los pesos y sesgos ligeramente mediante el descenso de gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Tren para múltiples épocas\n",
    "\n",
    "Para reducir aún más la pérdida, podemos repetir el proceso de ajustar los pesos y sesgos utilizando los gradientes varias veces. Cada iteración se denomina _época_. Entrenemos el modelo para 100 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1824,
     "status": "ok",
     "timestamp": 1636714045564,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "jRqF7UhSC5TZ",
    "outputId": "8d421f8e-3bb4-4c48-dc06-0cd9730aac6e"
   },
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Una vez más, comprobemos que la pérdida ahora es menor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1636714051228,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "i4jpfkl2C5Ta",
    "outputId": "5375828e-13c1-43ff-d1b9-663e03d9261d"
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "La pérdida es ahora mucho menor que su valor inicial. Veamos las predicciones del modelo y comparémoslas con los objetivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1636714054009,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "ETxuseujC5Tb",
    "outputId": "270e49e6-ec3b-4ab2-d267-610a8d31e8f5"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1636714058532,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "ba-VbwibC5Tb",
    "outputId": "a2bea914-a96a-4ecc-8a7d-141ebf2e45fa"
   },
   "outputs": [],
   "source": [
    "# Targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Las predicciones ahora están bastante cerca de las variables objetivo. Podemos obtener resultados aún mejores si entrenamos durante algunas épocas más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Regresión lineal usando las funciones incorporadas de PyTorch\n",
    "\n",
    "Hemos implementado un modelo de regresión lineal y descenso de gradiente utilizando algunas operaciones básicas de tensor. Sin embargo, dado que este es un patrón común en el aprendizaje profundo, PyTorch proporciona varias funciones y clases integradas para facilitar la creación y el entrenamiento de modelos con solo unas pocas líneas de código.\n",
    "\n",
    "Comencemos importando el paquete `torch.nn` de PyTorch, que contiene clases de utilidad para construir redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqf3eV2XC5Td"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Como antes, representamos las entradas, los objetivos y las matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfUtzoIoC5Te"
   },
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70], \n",
    "                   [74, 66, 43], \n",
    "                   [91, 87, 65], \n",
    "                   [88, 134, 59], \n",
    "                   [101, 44, 37], \n",
    "                   [68, 96, 71], \n",
    "                   [73, 66, 44], \n",
    "                   [92, 87, 64], \n",
    "                   [87, 135, 57], \n",
    "                   [103, 43, 36], \n",
    "                   [68, 97, 70]], \n",
    "                  dtype='float32')\n",
    " \n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119],\n",
    "                    [57, 69], \n",
    "                    [80, 102], \n",
    "                    [118, 132], \n",
    "                    [21, 38], \n",
    "                    [104, 118], \n",
    "                    [57, 69], \n",
    "                    [82, 100], \n",
    "                    [118, 134], \n",
    "                    [20, 38], \n",
    "                    [102, 120]], \n",
    "                   dtype='float32')\n",
    " \n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1636714125022,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "PwpXluFPC5Te",
    "outputId": "844955c8-d411-46c0-fe1e-ff5e06cbff43"
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Usamos 15 ejemplos de capacitación para ilustrar cómo trabajar con grandes conjuntos de datos en lotes pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Conjunto de datos y cargador de datos\n",
    "\n",
    "Crearemos un `TensorDataset`, que permite el acceso a filas desde `inputs` y `targets` como tuplas, y proporciona API estándar para trabajar con muchos tipos diferentes de conjuntos de datos en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ck3oF48C5Tf"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdahO3UoJjVJ"
   },
   "outputs": [],
   "source": [
    "TensorDataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1636714143264,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "xmPZmTooC5Tf",
    "outputId": "e0589683-e9bb-4868-a059-782978519f7e"
   },
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 185,
     "status": "ok",
     "timestamp": 1636714155835,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "SOK1Zrbaa1Dh",
    "outputId": "c9cdc307-6df5-41c1-8cf4-d01e849dd0b2"
   },
   "outputs": [],
   "source": [
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "El `TensorDataset` nos permite acceder a una pequeña sección de los datos de entrenamiento utilizando la notación de indexación de matriz (`[0:3]` en el código anterior). Devuelve una tupla con dos elementos. El primer elemento contiene las variables de entrada para las filas seleccionadas y el segundo contiene los objetivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "También crearemos un `DataLoader`, que puede dividir los datos en lotes de un tamaño predefinido durante el entrenamiento. También proporciona otras utilidades como la reproducción aleatoria y el muestreo aleatorio de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ik4UN9h2C5Tg"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQlb0PAuKJtT"
   },
   "outputs": [],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58QemNKzC5Th"
   },
   "outputs": [],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1636714193554,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "zDUE5IkYbah8",
    "outputId": "c6daf9a4-07d1-42bd-c565-6f0628e3bdfb"
   },
   "outputs": [],
   "source": [
    "print(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Podemos usar el cargador de datos en un bucle `for`. Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1636714202476,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "Dv8yMBM7C5Th",
    "outputId": "99a9ab09-7da3-4f66-f4c8-c28d09cf6aa1"
   },
   "outputs": [],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "En cada iteración, el cargador de datos devuelve un lote de datos con el tamaño de lote dado. Si `shuffle` se establece en `True`, mezcla los datos de entrenamiento antes de crear lotes. El barajado ayuda a aleatorizar la entrada al algoritmo de optimización, lo que conduce a una reducción más rápida de la pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## nn.Lineal\n",
    "\n",
    "En lugar de inicializar manualmente los pesos y sesgos, podemos definir el modelo usando la clase `nn.Linear` de PyTorch, que lo hace automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1636714235300,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "Dx7oYU9wLInB",
    "outputId": "b5b224ba-2697-4d0b-87e0-a4210af2458b"
   },
   "outputs": [],
   "source": [
    "mod = nn.Linear(10, 20)\n",
    "x = torch.randn(120, 10)\n",
    "mod(x).shape\n",
    "mod.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1636714248313,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "9CK5d1y4C5Ti",
    "outputId": "c3cb75af-9375-4dc6-850a-67faf5829cb2"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Los modelos de PyTorch también tienen un útil método `.parameters`, que devuelve una lista que contiene todas las matrices de ponderación y sesgo presentes en el modelo. Para nuestro modelo de regresión lineal, tenemos una matriz de ponderación y una matriz de sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1636714269028,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "ZlgknCbWC5Ti",
    "outputId": "120b481b-f54e-4a23-af6f-0eaf43002201"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1636714524188,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "n6jPC4Uuxd-O",
    "outputId": "8492a712-a1b6-4e2c-8761-76717e120c8f"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Podemos usar el modelo para generar predicciones de la misma manera que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1636714544869,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "1f31G8UMC5Tj",
    "outputId": "594e2b63-6b43-4e63-be89-3a6c8ec1a10b"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Función de pérdida\n",
    "\n",
    "En lugar de definir una función de pérdida manualmente, podemos usar la función de pérdida integrada `mse_loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-pd8HlWC5Tj"
   },
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "El paquete `nn.function` contiene muchas funciones de pérdida útiles y varias otras utilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmXwCuUXC5Tk"
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Calculemos la pérdida para las predicciones actuales de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1636714558862,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "ICPygA8LC5Tk",
    "outputId": "67deb1f1-41b9-4f89-b3ba-82847fe62daf"
   },
   "outputs": [],
   "source": [
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Optimizador\n",
    "\n",
    "En lugar de manipular manualmente los pesos y sesgos del modelo usando gradientes, podemos usar el optimizador `optim.SGD`. SGD es la abreviatura de \"descenso de gradiente estocástico\". El término _estocástico_ indica que las muestras se seleccionan en lotes aleatorios en lugar de como un solo grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIjmecFsSzSv"
   },
   "outputs": [],
   "source": [
    "torch.optim.SGD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwn4uYmwC5Tk"
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Tenga en cuenta que `model.parameters()` se pasa como argumento a `optim.SGD` para que el optimizador sepa qué matrices deben modificarse durante el paso de actualización. Además, podemos especificar una tasa de aprendizaje que controle la cantidad en la que se modifican los parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Entrenar al modelo\n",
    "\n",
    "Ahora estamos listos para entrenar el modelo. Seguiremos el mismo proceso para implementar el descenso de gradiente:\n",
    "\n",
    "1. Genera predicciones\n",
    "\n",
    "2. Calcular la pérdida\n",
    "\n",
    "3. Calcular gradientes con los pesos y sesgos\n",
    "\n",
    "4. Ajuste los pesos restando una pequeña cantidad proporcional al gradiente\n",
    "\n",
    "5. Restablecer los gradientes a cero\n",
    "\n",
    "El único cambio es que trabajaremos con lotes de datos en lugar de procesar todos los datos de entrenamiento en cada iteración. Definamos una función de utilidad `fit` que entrene el modelo para un número determinado de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdDX3hZKC5Tl"
   },
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Algunas cosas a tener en cuenta arriba:\n",
    "\n",
    "*Usamos el cargador de datos definido anteriormente para obtener lotes de datos para cada iteración.* En lugar de actualizar los parámetros (pesos y sesgos) manualmente, usamos `opt.step` para realizar la actualización y `opt.zero_grad` para restablecer los gradientes a cero.\n",
    "\n",
    "* También agregamos una declaración de registro que imprime la pérdida del último lote de datos para cada décima época para realizar un seguimiento del progreso del entrenamiento. `loss.item` devuelve el valor real almacenado en el tensor de pérdida.\n",
    "\n",
    "Entrenemos el modelo para 100 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1636714623736,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "_wkm3D5uC5Tl",
    "outputId": "5512705c-1dd4-483c-b600-bf19e7325fc0"
   },
   "outputs": [],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Generemos predicciones usando nuestro modelo y verifiquemos que estén cerca de nuestros objetivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1636714628510,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "IaKZpbc9C5Tm",
    "outputId": "fcd6ad70-fe51-4706-a259-fb3f4a03022f"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1636714630984,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "-3WKg8JqC5Tm",
    "outputId": "810ff360-b865-40ea-aa0f-6e87dc8db374"
   },
   "outputs": [],
   "source": [
    "# Compare with targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "De hecho, las predicciones están bastante cerca de nuestros objetivos. Hemos entrenado un modelo razonablemente bueno para predecir el rendimiento de los cultivos de manzanas y naranjas al observar la temperatura promedio, las precipitaciones y la humedad en una región. Podemos usarlo para hacer predicciones de rendimiento de cultivos para nuevas regiones pasando un lote que contiene una sola fila de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1636714643976,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "2nXBJo6UC5Tn",
    "outputId": "4a8fd129-5a05-49b1-985a-78aaef7afbe3"
   },
   "outputs": [],
   "source": [
    "model(torch.tensor([[75, 63, 44.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "El rendimiento previsto de manzanas es de 54,3 toneladas por hectárea y el de naranjas de 68,3 toneladas por hectárea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1636714657232,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "Xa3htPbBt7h5",
    "outputId": "fa6e75dd-dd7d-49bc-fac4-6ebfac07a27c"
   },
   "outputs": [],
   "source": [
    "F.mse_loss(model(inputs),targets)**0.5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uVVB1K-BC5To",
    "533gf6PcC5Tp"
   ],
   "name": "02-linear-regression_FC_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
