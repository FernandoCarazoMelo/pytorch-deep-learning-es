{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344d1138",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/07_pytorch_experiment_tracking.ipynb\" target=\"_parent\"><img src=\"https:// colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\"/></a>\n",
    "\n",
    "[Ver código fuente](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/07_pytorch_experiment_tracking.ipynb) | [Ver diapositivas](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/07_pytorch_experiment_tracking.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141b6e73",
   "metadata": {},
   "source": [
    "# 07. Seguimiento del experimento de PyTorch\n",
    "\n",
    "> **Nota:** Este cuaderno utiliza la nueva [API de soporte multipeso de `torchvision` (disponible en `torchvision` v0.13+)](https://pytorch.org/blog/introtaining-torchvision-new -api-soporte-multi-peso/). \n",
    "\n",
    "Hemos entrenado a unos cuantos modelos en el camino hacia la creación de FoodVision Mini (un modelo de clasificación de imágenes para clasificar imágenes de pizza, bistec o sushi).\n",
    "\n",
    "Y hasta ahora los hemos rastreado a través de diccionarios de Python.\n",
    "\n",
    "O simplemente compararlos según las impresiones métricas durante el entrenamiento.\n",
    "\n",
    "¿Qué pasaría si quisieras ejecutar una docena (o más) de modelos diferentes a la vez?\n",
    "\n",
    "Seguramente hay una mejor manera...\n",
    "\n",
    "Hay.\n",
    "\n",
    "**Seguimiento del experimento.**\n",
    "\n",
    "Y dado que el seguimiento de experimentos es tan importante e integral para el aprendizaje automático, puede considerar este cuaderno como su primer proyecto importante.\n",
    "\n",
    "Bienvenido al Proyecto Milestone 1: Seguimiento del mini experimento de FoodVision.\n",
    "\n",
    "Responderemos la pregunta: **¿cómo hago un seguimiento de mis experimentos de aprendizaje automático?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefc0a0",
   "metadata": {},
   "source": [
    "## ¿Qué es el seguimiento de experimentos?\n",
    "\n",
    "El aprendizaje automático y el aprendizaje profundo son muy experimentales.\n",
    "\n",
    "Tendrás que ponerte tu boina de artista/gorro de chef para cocinar muchos modelos diferentes.\n",
    "\n",
    "Y hay que ponerse la bata de científico para seguir los resultados de diversas combinaciones de datos, arquitecturas de modelos y regímenes de entrenamiento.\n",
    "\n",
    "Ahí es donde entra en juego el **seguimiento de experimentos**.\n",
    "\n",
    "Si está ejecutando muchos experimentos diferentes, **el seguimiento de experimentos le ayudará a descubrir qué funciona y qué no**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401d8fc",
   "metadata": {},
   "source": [
    "## ¿Por qué realizar un seguimiento de los experimentos?\n",
    "\n",
    "Si sólo está ejecutando un puñado de modelos (como lo hemos hecho hasta ahora), podría estar bien simplemente realizar un seguimiento de sus resultados en impresiones y algunos diccionarios.\n",
    "\n",
    "Sin embargo, a medida que la cantidad de experimentos que realiza comienza a aumentar, esta forma ingenua de seguimiento podría salirse de control.\n",
    "\n",
    "Entonces, si sigues el lema de los profesionales del aprendizaje automático de *¡experimenta, experimenta, experimenta!*, querrás una forma de rastrearlos.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-experiment-tracking-can-get-out-of-hand.png\" alt=\"seguimiento de experimentos puede salirse de control, muchos experimentos diferentes con diferentes nombres\" width=900/>\n",
    "\n",
    "*Después de crear algunos modelos y realizar un seguimiento de sus resultados, comenzarás a notar lo rápido que se puede salir de control.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e25a1",
   "metadata": {},
   "source": [
    "## Diferentes formas de realizar un seguimiento de los experimentos de aprendizaje automático \n",
    "\n",
    "Hay tantas formas diferentes de realizar un seguimiento de los experimentos de aprendizaje automático como experimentos para ejecutar.\n",
    "\n",
    "Esta tabla cubre algunos.\n",
    "\n",
    "| **Método** | **Configuración** | **Ventajas** | **Desventajas** | **Costo** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Diccionarios Python, archivos CSV, impresiones | Ninguno | Fácil de configurar, se ejecuta en Python puro | Es difícil realizar un seguimiento de un gran número de experimentos | Gratis |\n",
    "| [TensorBoard](https://www.tensorflow.org/tensorboard/get_started) | Mínimo, instale [`tensorboard`](https://pypi.org/project/tensorboard/) | Las extensiones integradas en PyTorch, ampliamente reconocidas y utilizadas, se escalan fácilmente. | La experiencia del usuario no es tan agradable como la de otras opciones. | Gratis |\n",
    "| [Seguimiento de experimentos de pesos y sesgos](https://wandb.ai/site/experiment-tracking) | Mínimo, instale [`wandb`](https://docs.wandb.ai/quickstart), cree una cuenta | Increíble experiencia de usuario, hacer públicos los experimentos, rastrear casi cualquier cosa. | Requiere recursos externos fuera de PyTorch. | Gratis para uso personal | \n",
    "| [MLFlow](https://mlflow.org/) | Mínimo, instale `mlflow` e inicie el seguimiento | Gestión del ciclo de vida de MLOps totalmente de código abierto, muchas integraciones. | Es un poco más difícil configurar un servidor de seguimiento remoto que otros servicios. | Gratis | \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07- Different-places-to-track-experiments.png\" alt=\"varios lugares para realizar un seguimiento del aprendizaje automático experimentos\" ancho=900/>\n",
    "\n",
    "*Varios lugares y técnicas que puede utilizar para realizar un seguimiento de sus experimentos de aprendizaje automático. **Nota:** Hay varias otras opciones similares a Weights & Biases y opciones de código abierto similares a MLflow, pero las omití por brevedad. Puede encontrar más información buscando \"seguimiento de experimentos de aprendizaje automático\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc128b",
   "metadata": {},
   "source": [
    "## Qué vamos a cubrir\n",
    "\n",
    "Realizaremos varios experimentos de modelado diferentes con varios niveles de datos, tamaño del modelo y tiempo de entrenamiento para intentar mejorar FoodVision Mini.\n",
    "\n",
    "Y debido a su estrecha integración con PyTorch y su uso generalizado, este cuaderno se centra en el uso de TensorBoard para realizar un seguimiento de nuestros experimentos.\n",
    "\n",
    "Sin embargo, los principios que vamos a cubrir son similares en todas las demás herramientas para el seguimiento de experimentos.\n",
    "\n",
    "| **Tema** | **Contenido** |\n",
    "| ----- | ----- |\n",
    "| **0. Obteniendo configuración** | Hemos escrito bastante código útil en las últimas secciones, descarguémoslo y asegurémonos de poder usarlo nuevamente. |\n",
    "| **1. Obtener datos** | Obtengamos el conjunto de datos de clasificación de imágenes de pizza, bistec y sushi que hemos estado usando para intentar mejorar los resultados de nuestro modelo FoodVision Mini. |\n",
    "| **2. Crear conjuntos de datos y cargadores de datos** | Usaremos el script `data_setup.py` que escribimos en el capítulo 05. PyTorch se vuelve modular para configurar nuestros DataLoaders. |\n",
    "| **3. Obtenga y personalice un modelo previamente entrenado** | Al igual que en la última sección, 06. PyTorch Transfer Learning, descargaremos un modelo previamente entrenado de `torchvision.models` y lo personalizaremos según nuestro propio problema. | \n",
    "| **4. Modelo de tren y resultados de vía** | Veamos cómo es entrenar y rastrear los resultados del entrenamiento de un solo modelo usando TensorBoard. |\n",
    "| **5. Vea los resultados de nuestro modelo en TensorBoard** | Anteriormente visualizamos las curvas de pérdida de nuestro modelo con una función auxiliar, ahora veamos cómo se ven en TensorBoard. |\n",
    "| **6. Creando una función auxiliar para rastrear experimentos** | Si vamos a seguir el lema del practicante de aprendizaje automático de *¡experimentar, experimentar, experimentar!*, lo mejor será que creemos una función que nos ayude a guardar los resultados de nuestro experimento de modelado. |\n",
    "| **7. Configuración de una serie de experimentos de modelado** | En lugar de ejecutar experimentos uno por uno, ¿qué tal si escribimos código para ejecutar varios experimentos a la vez, con diferentes modelos, diferentes cantidades de datos y diferentes tiempos de entrenamiento? | \n",
    "| **8. Ver experimentos de modelado en TensorBoard** | En esta etapa habremos realizado ocho experimentos de modelado de una sola vez, bastante para realizar un seguimiento; veamos cómo se ven sus resultados en TensorBoard. | \n",
    "| **9. Cargue el mejor modelo y haga predicciones con él** | El objetivo del seguimiento del experimento es descubrir qué modelo funciona mejor, carguemos el modelo con mejor rendimiento y hagamos algunas predicciones con él para *¡visualizar, visualizar, visualizar!*. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b83f6b",
   "metadata": {},
   "source": [
    "## ¿Dónde puedes obtener ayuda?\n",
    "\n",
    "Todos los materiales de este curso [están disponibles en GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
    "\n",
    "Si tiene problemas, puede hacer una pregunta en el curso [página de debates de GitHub] (https://github.com/mrdbourke/pytorch-deep-learning/discussions).\n",
    "\n",
    "Y, por supuesto, está la [documentación de PyTorch](https://pytorch.org/docs/stable/index.html) y los [foros de desarrolladores de PyTorch](https://discuss.pytorch.org/), un lugar muy útil para todo lo relacionado con PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f266577c",
   "metadata": {},
   "source": [
    "## 0. Configuración \n",
    "\n",
    "Comencemos descargando todos los módulos que necesitaremos para esta sección.\n",
    "\n",
    "Para ahorrarnos escribir código adicional, aprovecharemos algunos de los scripts de Python (como `data_setup.py` y `engine.py`) que creamos en la sección [05. PyTorch se vuelve modular](https://www.learnpytorch.io/05_pytorch_going_modular/).\n",
    "\n",
    "Específicamente, vamos a descargar el directorio [`going_modular`](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular) del repositorio `pytorch-deep-learning` (si aún no lo tenemos).\n",
    "\n",
    "También obtendremos el paquete [`torchinfo`](https://github.com/TylerYep/torchinfo) si no está disponible. \n",
    "\n",
    "`torchinfo` nos ayudará más adelante a brindarnos resúmenes visuales de nuestro(s) modelo(s).\n",
    "\n",
    "Y dado que estamos usando una versión más nueva del paquete `torchvision` (v0.13 a partir de junio de 2022), nos aseguraremos de tener las últimas versiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7122af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que este portátil se ejecute con API actualizadas, necesitamos torch 1.12+ y torchvision 0.13+.\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef740de",
   "metadata": {},
   "source": [
    "> **Nota:** Si está utilizando Google Colab, es posible que deba reiniciar su tiempo de ejecución después de ejecutar la celda anterior. Después de reiniciar, puede ejecutar la celda nuevamente y verificar que tiene las versiones correctas de `torch` (0.12+) y `torchvision` (0.13+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1283e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuar con las importaciones regulares\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Intente obtener torchinfo, instálelo si no funciona\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "# Intente importar el directorio going_modular, descárguelo de GitHub si no funciona\n",
    "try:\n",
    "    from going_modular.going_modular import data_setup, engine\n",
    "except:\n",
    "    # Get the going_modular scripts\n",
    "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular .\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    from going_modular.going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a025a2",
   "metadata": {},
   "source": [
    "Ahora configuremos el código independiente del dispositivo.\n",
    "\n",
    "> **Nota:** Si estás usando Google Colab y aún no tienes una GPU activada, ahora es el momento de activar una a través de `Runtime -> Cambiar tipo de tiempo de ejecución -> Acelerador de hardware -> GPU` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35468828",
   "metadata": {},
   "source": [
    "### Crear una función auxiliar para establecer semillas\n",
    "\n",
    "Dado que hemos estado configurando muchas semillas aleatorias en las secciones anteriores, ¿qué tal si las funcionalizamos?\n",
    "\n",
    "Creemos una función para \"establecer las semillas\" llamada `set_seeds()`.\n",
    "\n",
    "> **Nota:** Recuerde que una [semilla aleatoria](https://en.wikipedia.org/wiki/Random_seed) es una forma de darle sabor a la aleatoriedad generada por una computadora. No es necesario configurarlos siempre cuando se ejecuta código de aprendizaje automático; sin embargo, ayudan a garantizar que haya un elemento de reproducibilidad (los números que obtengo con mi código son similares a los números que obtienes con tu código). Fuera de un entorno educativo o experimental, generalmente no se requieren semillas aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer semillas\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d22c8",
   "metadata": {},
   "source": [
    "## 1. Obtener datos\n",
    "\n",
    "Como siempre, antes de que podamos ejecutar experimentos de aprendizaje automático, necesitaremos un conjunto de datos.\n",
    "\n",
    "Continuaremos intentando mejorar los resultados que hemos obtenido con FoodVision Mini.\n",
    "\n",
    "En el apartado anterior, [06. PyTorch Transfer Learning](https://www.learnpytorch.io/06_pytorch_transfer_learning/), vimos lo poderoso que puede ser el uso de un modelo previamente entrenado y el aprendizaje por transferencia al clasificar imágenes de pizza, bistec y sushi.\n",
    "\n",
    "Entonces, ¿qué tal si realizamos algunos experimentos e intentamos mejorar aún más nuestros resultados?\n",
    "\n",
    "Para hacerlo, usaremos un código similar al de la sección anterior para descargar [`pizza_steak_sushi.zip`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi.zip ) (si los datos aún no existen) excepto que esta vez se ha funcionalizado.\n",
    "\n",
    "Esto nos permitirá volver a utilizarlo más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "def download_data(source: str, \n",
    "                  destination: str,\n",
    "                  remove_source: bool = True) -> Path:\n",
    "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
    "\n",
    "    Args:\n",
    "        source (str): A link to a zipped file containing data.\n",
    "        destination (str): A target directory to unzip data to.\n",
    "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
    "    \n",
    "    Returns:\n",
    "        pathlib.Path to downloaded data.\n",
    "    \n",
    "    Example usage:\n",
    "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                      destination=\"pizza_steak_sushi\")\n",
    "    \"\"\"\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / destination\n",
    "\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download pizza, steak, sushi data\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path / target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "\n",
    "        # Unzip pizza, steak, sushi data\n",
    "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\") \n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "        # Remove .zip file\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "    \n",
    "    return image_path\n",
    "\n",
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                           destination=\"pizza_steak_sushi\")\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25130a7e",
   "metadata": {},
   "source": [
    "¡Excelente! Parece que tenemos nuestras imágenes de pizza, bistec y sushi en formato de clasificación de imágenes estándar listas para usar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b46dd2",
   "metadata": {},
   "source": [
    "## 2. Crear conjuntos de datos y cargadores de datos\n",
    "\n",
    "Ahora que tenemos algunos datos, convirtámoslos en PyTorch DataLoaders.\n",
    "\n",
    "Podemos hacerlo usando la función `create_dataloaders()` que creamos en [05. PyTorch se vuelve modular, parte 2](https://www.learnpytorch.io/05_pytorch_going_modular/#2-create-datasets-and-dataloaders-data_setuppy).\n",
    "\n",
    "Y dado que usaremos aprendizaje por transferencia y modelos específicamente entrenados previamente de [`torchvision.models`](https://pytorch.org/vision/stable/models.html), crearemos una transformación para preparar nuestras imágenes correctamente. .\n",
    "\n",
    "Para transformar nuestras imágenes en tensores, podemos usar:\n",
    "1. Transformaciones creadas manualmente usando `torchvision.transforms`.\n",
    "2. Transformaciones creadas automáticamente usando `torchvision.models.MODEL_NAME.MODEL_WEIGHTS.DEFAULT.transforms()`.\n",
    "    * Donde `MODEL_NAME` es una arquitectura específica de `torchvision.models`, `MODEL_WEIGHTS` es un conjunto específico de pesos previamente entrenados y `DEFAULT` significa los \"mejores pesos disponibles\".\n",
    "    \n",
    "Vimos un ejemplo de cada uno de estos en [06. Sección 2 del aprendizaje por transferencia de PyTorch] (https://www.learnpytorch.io/06_pytorch_transfer_learning/#2-create-datasets-and-dataloaders).\n",
    "\n",
    "Veamos primero un ejemplo de creación manual de una canalización `torchvision.transforms` (crear una canalización de transformaciones de esta manera brinda la mayor personalización, pero puede resultar potencialmente en una degradación del rendimiento si las transformaciones no coinciden con el modelo previamente entrenado).\n",
    "\n",
    "La principal transformación manual de la que debemos estar seguros es que todas nuestras imágenes estén normalizadas en formato ImageNet (esto se debe a que los `torchvision.models` previamente entrenados están todos preentrenados en [ImageNet] (https://www.image-net.org /)).\n",
    "\n",
    "Podemos hacer esto con:\n",
    "\n",
    "```pitón\n",
    "normalizar = transforma.Normalizar(media=[0.485, 0.456, 0.406],\n",
    "                                 estándar=[0,229, 0,224, 0,225])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38770b8e",
   "metadata": {},
   "source": [
    "### 2.1 Crear cargadores de datos utilizando transformaciones creadas manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a049b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios de configuración\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "# Configurar los niveles de normalización de ImageNet (convierte todas las imágenes en una distribución similar a la de ImageNet)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Crear canalización de transformación manualmente\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])           \n",
    "print(f\"Manually created transforms: {manual_transforms}\")\n",
    "\n",
    "# Crear cargadores de datos\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=manual_transforms, # use manually created transforms\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24003453",
   "metadata": {},
   "source": [
    "### 2.2 Crear cargadores de datos utilizando transformaciones creadas automáticamente\n",
    "\n",
    "¡Datos transformados y DataLoaders creados!\n",
    "\n",
    "Veamos ahora cómo se ve el mismo proceso de transformación, pero esta vez mediante transformaciones automáticas.\n",
    "\n",
    "Podemos hacer esto creando primero una instancia de un conjunto de pesos previamente entrenados (por ejemplo, `weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT`) que nos gustaría usar y llamando al método `transforms()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a05a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios de configuración\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "# Configure pesas previamente entrenadas (muchas de ellas disponibles en torchvision.models)\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Obtener transformaciones a partir de pesos (estas son las transformaciones que se utilizaron para obtener los pesos)\n",
    "automatic_transforms = weights.transforms() \n",
    "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
    "\n",
    "# Crear cargadores de datos\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=automatic_transforms, # use automatic created transforms\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef55bbe",
   "metadata": {},
   "source": [
    "## 3. Obtener un modelo previamente entrenado, congelar las capas base y cambiar el cabezal clasificador\n",
    "\n",
    "Antes de ejecutar y realizar un seguimiento de varios experimentos de modelado, veamos cómo es ejecutar y realizar un seguimiento de uno solo.\n",
    "\n",
    "Y como nuestros datos están listos, lo siguiente que necesitaremos es un modelo.\n",
    "\n",
    "Descarguemos los pesos previamente entrenados para un modelo `torchvision.models.ficientnet_b0()` y preparémoslo para usarlo con nuestros propios datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ada10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: Así es como se crearía un modelo previamente entrenado en torchvision > 0.13; quedará obsoleto en versiones futuras.\n",
    "# modelo = torchvision.models.ficientnet_b0(preentrenado=True).to(dispositivo) # ANTIGUO\n",
    "\n",
    "# Descargue los pesos previamente entrenados para EfficientNet_B0\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # NEW in torchvision 0.13, \"DEFAULT\" means \"best weights available\"\n",
    "\n",
    "# Configure el modelo con los pesos previamente entrenados y envíelo al dispositivo de destino.\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "# Ver el resultado del modelo.\n",
    "# modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d69513",
   "metadata": {},
   "source": [
    "¡Maravilloso!\n",
    "\n",
    "Ahora que tenemos un modelo previamente entrenado, convirtámoslo en un modelo de extracción de características.\n",
    "\n",
    "En esencia, congelaremos las capas base del modelo (las usaremos para extraer características de nuestras imágenes de entrada) y cambiaremos el encabezado del clasificador (capa de salida) para adaptarlo a la cantidad de clases con las que estamos trabajando. (tenemos 3 clases: pizza, bistec, sushi).\n",
    "\n",
    "> **Nota:** La idea de crear un modelo de extracción de características (lo que estamos haciendo aquí) se cubrió con más profundidad en [06. Sección 3.2 de PyTorch Transfer Learning: Configuración de un modelo previamente entrenado] (https://www.learnpytorch.io/06_pytorch_transfer_learning/#32-setting-up-a-pretrained-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a1ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Congele todas las capas base estableciendo el atributo require_grad en Falso\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Dado que estamos creando una nueva capa con pesos aleatorios (torch.nn.Linear),\n",
    "# vamos a poner las semillas\n",
    "set_seeds() \n",
    "\n",
    "# Actualice el cabezal clasificador para adaptarlo a nuestro problema.\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, \n",
    "              out_features=len(class_names),\n",
    "              bias=True).to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6aa15c",
   "metadata": {},
   "source": [
    "Capas base congeladas, cabezal clasificador cambiado, obtengamos un resumen de nuestro modelo con `torchinfo.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1126d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "# # Obtener un resumen del modelo (descomentar para obtener un resultado completo)\n",
    "# resumen (modelo,\n",
    "# input_size=(32, 3, 224, 224), # asegúrese de que sea \"input_size\", no \"input_shape\" (batch_size, color_channels, alto, ancho)\n",
    "# detallado = 0,\n",
    "# col_names=[\"input_size\", \"output_size\", \"num_params\", \"entrenable\"],\n",
    "# ancho_columna=20,\n",
    "# row_settings=[\"var_names\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8747e66",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-output-of-torchinfo-summary.png\" alt=\"salida de torchinfo.summary() cuando pasó nuestro modelo cuando las capas base están congeladas y el cabezal del clasificador se actualiza\" width=900/>\n",
    "\n",
    "*Salida de `torchinfo.summary()` con nuestro modelo de extractor de características EffNetB0, observe cómo las capas base están congeladas (no entrenables) y las capas de salida se personalizan según nuestro propio problema.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7e864",
   "metadata": {},
   "source": [
    "## 4. Entrenar el modelo y realizar un seguimiento de los resultados.\n",
    "\n",
    "¡Modelo listo para funcionar!\n",
    "\n",
    "Preparémonos para entrenarlo creando una función de pérdida y un optimizador.\n",
    "\n",
    "Como estamos trabajando con varias clases, usaremos [`torch.nn.CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) como pérdida función.\n",
    "\n",
    "Y nos quedaremos con [`torch.optim.Adam()`](https://pytorch.org/docs/stable/optim.html) con una tasa de aprendizaje de `0,001` para el optimizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33715842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir pérdida y optimizador\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf9b0b",
   "metadata": {},
   "source": [
    "### Ajuste la función `train()` para realizar un seguimiento de los resultados con `SummaryWriter()`\n",
    "\n",
    "¡Hermoso!\n",
    "\n",
    "Todas las piezas de nuestro código de formación están empezando a encajar.\n",
    "\n",
    "Agreguemos ahora la pieza final para realizar un seguimiento de nuestros experimentos.\n",
    "\n",
    "Anteriormente, hemos realizado un seguimiento de nuestros experimentos de modelado utilizando varios diccionarios de Python (uno para cada modelo).\n",
    "\n",
    "Pero puedes imaginar que esto podría salirse de control si estuviéramos realizando algo más que unos pocos experimentos.\n",
    "\n",
    "¡No te preocupes, hay una mejor opción!\n",
    "\n",
    "Podemos usar la clase [`torch.utils.tensorboard.SummaryWriter()`](https://pytorch.org/docs/stable/tensorboard.html) de PyTorch para guardar varias partes del progreso del entrenamiento de nuestro modelo en un archivo.\n",
    "\n",
    "De forma predeterminada, la clase `SummaryWriter()` guarda diversa información sobre nuestro modelo en un archivo establecido por el parámetro `log_dir`. \n",
    "\n",
    "La ubicación predeterminada para `log_dir` está en `runs/CURRENT_DATETIME_HOSTNAME`, donde `HOSTNAME` es el nombre de su computadora.\n",
    "\n",
    "Pero, por supuesto, puedes cambiar dónde se realiza el seguimiento de tus experimentos (el nombre del archivo es tan personalizable como quieras).\n",
    "\n",
    "Las salidas de `SummaryWriter()` se guardan en [formato TensorBoard] (https://www.tensorflow.org/tensorboard/).\n",
    "\n",
    "TensorBoard es parte de la biblioteca de aprendizaje profundo de TensorFlow y es una excelente manera de visualizar diferentes partes de su modelo.\n",
    "\n",
    "Para comenzar a rastrear nuestros experimentos de modelado, creemos una instancia predeterminada `SummaryWriter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Crea un escritor con todas las configuraciones predeterminadas\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc7c38",
   "metadata": {},
   "source": [
    "Ahora, para usar el escritor, podríamos escribir un nuevo bucle de entrenamiento o podríamos ajustar la función `train()` existente que creamos en [05. PyTorch Going Modular sección 4](https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them).\n",
    "\n",
    "Tomemos la última opción.\n",
    "\n",
    "Obtendremos la función `train()` de [`engine.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py) y ajustaremos utilizar \"escritor\".\n",
    "\n",
    "Específicamente, agregaremos la capacidad de nuestra función `train()` para registrar el entrenamiento de nuestro modelo y probar los valores de pérdida y precisión.\n",
    "\n",
    "Podemos hacer esto con [`writer.add_scalars(main_tag, tag_scalar_dict)`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars), donde:\n",
    "* `main_tag` (cadena): el nombre de los escalares que se rastrean (por ejemplo, \"Precisión\")\n",
    "* `tag_scalar_dict` (dict): un diccionario de los valores que se están rastreando (por ejemplo, `{\"train_loss\": 0.3454}`)\n",
    "    * > **Nota:** El método se llama `add_scalars()` porque nuestros valores de pérdida y precisión son generalmente escalares (valores únicos).\n",
    "\n",
    "Una vez que hayamos terminado de rastrear los valores, llamaremos a `writer.close()` para decirle al `writer` que deje de buscar valores para rastrear.\n",
    "\n",
    "Para comenzar a modificar `train()` también importaremos `train_step()` y `test_step()` desde [`engine.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob /main/going_modular/going_modular/engine.py).\n",
    "\n",
    "> **Nota:** Puede realizar un seguimiento de la información sobre su modelo casi en cualquier parte de su código. Pero muy a menudo se realizará un seguimiento de los experimentos *mientras* se entrena un modelo (dentro de un ciclo de entrenamiento/prueba).\n",
    ">\n",
    "> La clase `torch.utils.tensorboard.SummaryWriter()` también tiene muchos métodos diferentes para rastrear diferentes cosas sobre su modelo/datos, como [`add_graph()`](https://pytorch.org/docs/stable /tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph) que rastrea el gráfico de cálculo de su modelo. Para obtener más opciones, [consulte la documentación `SummaryWriter()`](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5acb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from going_modular.going_modular.engine import train_step, test_step\n",
    "\n",
    "# Importar función train() desde:\n",
    "# https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "      model: A PyTorch model to be trained and tested.\n",
    "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "      epochs: An integer indicating how many epochs to train for.\n",
    "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "      \n",
    "    Returns:\n",
    "      A dictionary of training and testing loss as well as training and\n",
    "      testing accuracy metrics. Each metric has a value in a list for \n",
    "      each epoch.\n",
    "      In the form: {train_loss: [...],\n",
    "                train_acc: [...],\n",
    "                test_loss: [...],\n",
    "                test_acc: [...]} \n",
    "      For example if training for epochs=2: \n",
    "              {train_loss: [2.0616, 1.0537],\n",
    "                train_acc: [0.3945, 0.3945],\n",
    "                test_loss: [1.2641, 1.5706],\n",
    "                test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        ### New: Experiment tracking ###\n",
    "        # Add loss results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Loss\", \n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"test_loss\": test_loss},\n",
    "                           global_step=epoch)\n",
    "\n",
    "        # Add accuracy results to SummaryWriter\n",
    "        writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc}, \n",
    "                           global_step=epoch)\n",
    "        \n",
    "        # Track the PyTorch model architecture\n",
    "        writer.add_graph(model=model, \n",
    "                         # Pass in an example input\n",
    "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "    \n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "    \n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65fa6f",
   "metadata": {},
   "source": [
    "¡Guau!\n",
    "\n",
    "Nuestra función `train()` ahora está actualizada para usar una instancia `SummaryWriter()` para rastrear los resultados de nuestro modelo.\n",
    "\n",
    "¿Qué tal si lo probamos durante 5 épocas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df36828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo de tren\n",
    "# Nota: No usar Engine.train() ya que el script original no está actualizado para usar Writer.\n",
    "set_seeds()\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=5,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb4ff2",
   "metadata": {},
   "source": [
    "> **Nota:** Es posible que observe que los resultados aquí son ligeramente diferentes a los que obtuvo nuestro modelo en 06. Aprendizaje por transferencia de PyTorch. La diferencia proviene del uso de `engine.train()` y nuestra función `train()` modificada. ¿Puedes adivinar por qué? La [documentación de PyTorch sobre aleatoriedad](https://pytorch.org/docs/stable/notes/randomness.html) puede ayudar más.\n",
    "\n",
    "Al ejecutar la celda de arriba obtenemos resultados similares a los que obtuvimos en [06. PyTorch Transfer Learning sección 4: Entrenar modelo](https://www.learnpytorch.io/06_pytorch_transfer_learning/#4-train-model) pero la diferencia está detrás de escena, nuestra instancia `writer` ha creado un directorio `runs/` que almacena los resultados de nuestro modelo.\n",
    "\n",
    "Por ejemplo, la ubicación para guardar podría verse así:\n",
    "\n",
    "```\n",
    "carreras/Jun21_00-46-03_daniels_macbook_pro\n",
    "```\n",
    "\n",
    "Donde el [formato predeterminado](https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter) es `runs/CURRENT_DATETIME_HOSTNAME`. \n",
    "\n",
    "Los comprobaremos en un segundo, pero solo como recordatorio, anteriormente estábamos rastreando los resultados de nuestro modelo en un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed90bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mira los resultados del modelo.\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374f712",
   "metadata": {},
   "source": [
    "Hmmm, podríamos formatear esto para que sea una buena trama, pero ¿te imaginas hacer un seguimiento de varios de estos diccionarios?\n",
    "\n",
    "Tiene que haber una mejor manera..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5978a",
   "metadata": {},
   "source": [
    "## 5. Ver los resultados de nuestro modelo en TensorBoard\n",
    "\n",
    "La clase `SummaryWriter()` almacena los resultados de nuestro modelo en un directorio llamado `runs/` en formato TensorBoard de forma predeterminada.\n",
    "\n",
    "TensorBoard es un programa de visualización creado por el equipo de TensorFlow para ver e inspeccionar información sobre modelos y datos.\n",
    "\n",
    "¿Sabes lo que significa?\n",
    "\n",
    "Es hora de seguir el lema del visualizador de datos y *¡visualizar, visualizar, visualizar!* \n",
    "\n",
    "Puedes ver TensorBoard de varias maneras:\n",
    "\n",
    "| Entorno de código | Cómo ver TensorBoard | Recurso |\n",
    "| ----- | ----- | ----- |\n",
    "| VS Code (cuadernos o scripts de Python) | Presione `SHIFT + CMD + P` para abrir la paleta de comandos y busque el comando \"Python: Iniciar TensorBoard\". | [Guía de código VS en TensorBoard y PyTorch](https://code.visualstudio.com/docs/datascience/pytorch-support#_tensorboard-integration) |\n",
    "| Cuadernos Jupyter y Colab | Asegúrese de que [TensorBoard esté instalado] (https://pypi.org/project/tensorboard/), cárguelo con `%load_ext tensorboard` y luego vea los resultados con `%tensorboard --logdir DIR_WITH_LOGS`. | [`torch.utils.tensorboard`](https://pytorch.org/docs/stable/tensorboard.html) y [Comenzar con TensorBoard](https://www.tensorflow.org/tensorboard/get_started) |\n",
    "\n",
    "También puedes subir tus experimentos a [tensorboard.dev](https://tensorboard.dev/) para compartirlos públicamente con otros.\n",
    "\n",
    "Al ejecutar el siguiente código en Google Colab o Jupyter Notebook se iniciará una sesión interactiva de TensorBoard para ver los archivos de TensorBoard en el directorio `runs/`.\n",
    "\n",
    "```pitón\n",
    "%load_ext tensorboard # línea mágica para cargar TensorBoard\n",
    "%tensorboard --logdir ejecuta # ejecuta la sesión de TensorBoard con el directorio \"ejecuta/\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0718e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código de ejemplo para ejecutar en Jupyter o Google Colab Notebook (descoméntalo para probarlo)\n",
    "# %load_ext tensorboard\n",
    "# % tensorboard --logdir se ejecuta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090696d",
   "metadata": {},
   "source": [
    "Si todo salió correctamente, deberías ver algo como lo siguiente:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-tensorboard-single-experiment.png\" alt=\"salida de visualización de un solo experimento en tensorboard\" ancho =900/>\n",
    "\n",
    "*Ver los resultados de un único experimento de modelado para determinar la precisión y la pérdida en TensorBoard.*\n",
    "\n",
    "> **Nota:** Para obtener más información sobre cómo ejecutar TensorBoard en notebooks o en otras ubicaciones, consulte lo siguiente:\n",
    "> * [Guía de uso de TensorBoard en Notebooks de TensorFlow](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)\n",
    "> * [Comience con TensorBoard.dev](https://tensorboard.dev/#get-started) (útil para cargar sus registros de TensorBoard en un enlace para compartir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c4dff",
   "metadata": {},
   "source": [
    "## 6. Cree una función auxiliar para crear instancias `SummaryWriter()`\n",
    "\n",
    "La clase `SummaryWriter()` registra diversa información en un directorio especificado por el parámetro `log_dir`.\n",
    "\n",
    "¿Qué tal si creamos una función auxiliar para crear un directorio personalizado por experimento?\n",
    "\n",
    "En esencia, cada experimento tiene su propio directorio de registros.\n",
    "\n",
    "Por ejemplo, digamos que nos gustaría realizar un seguimiento de cosas como:\n",
    "* **Fecha/marca de tiempo del experimento**: ¿cuándo tuvo lugar el experimento?\n",
    "* **Nombre del experimento**: ¿hay algo que nos gustaría llamar al experimento?\n",
    "* **Nombre del modelo**: ¿qué modelo se utilizó?\n",
    "* **Extra**: ¿se debe realizar un seguimiento de algo más?\n",
    "\n",
    "Puedes rastrear casi cualquier cosa aquí y ser tan creativo como quieras, pero esto debería ser suficiente para comenzar.\n",
    "\n",
    "Creemos una función auxiliar llamada `create_writer()` que produzca un seguimiento de instancia `SummaryWriter()` a un `log_dir` personalizado.\n",
    "\n",
    "Idealmente, nos gustaría que `log_dir` fuera algo como: \n",
    "\n",
    "`ejecuta/AAAA-MM-DD/nombre_experimento/nombre_modelo/extra` \n",
    "\n",
    "Donde \"AAAA-MM-DD\" es la fecha en que se ejecutó el experimento (también puede agregar la hora si lo desea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514f1365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_writer(experiment_name: str, \n",
    "                  model_name: str, \n",
    "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
    "\n",
    "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
    "\n",
    "    Where timestamp is the current date in YYYY-MM-DD format.\n",
    "\n",
    "    Args:\n",
    "        experiment_name (str): Name of experiment.\n",
    "        model_name (str): Name of model.\n",
    "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
    "\n",
    "    Example usage:\n",
    "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
    "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb2\",\n",
    "                               extra=\"5_epochs\")\n",
    "        # The above is the same as:\n",
    "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "\n",
    "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
    "\n",
    "    if extra:\n",
    "        # Create log directory path\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "        \n",
    "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
    "    return SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38f2d6",
   "metadata": {},
   "source": [
    "¡Hermoso!\n",
    "\n",
    "Ahora que tenemos una función `create_writer()`, probémosla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un escritor de ejemplo\n",
    "example_writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb0\",\n",
    "                               extra=\"5_epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd3218",
   "metadata": {},
   "source": [
    "Viendo bien, ahora tenemos una manera de registrar y rastrear nuestros diversos experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671645b",
   "metadata": {},
   "source": [
    "### 6.1 Actualice la función `train()` para incluir un parámetro `writer`\n",
    "\n",
    "Nuestra función `create_writer()` funciona fantástico.\n",
    "\n",
    "¿Qué tal si le damos a nuestra función `train()` la capacidad de aceptar un parámetro `writer` para que actualicemos activamente la instancia `SummaryWriter()` que estamos usando cada vez que llamamos a `train()`?\n",
    "\n",
    "Por ejemplo, digamos que estamos ejecutando una serie de experimentos, llamando a \"train()\" varias veces para múltiples modelos diferentes, sería bueno si cada experimento usara un \"escritor\" diferente.\n",
    "\n",
    "Un \"escritor\" por experimento = un directorio de registros por experimento.\n",
    "\n",
    "Para ajustar la función `train()` agregaremos un parámetro `writer` a la función y luego agregaremos algo de código para ver si hay un `writer` y, de ser así, rastrearemos nuestra información allí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbeeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Agregar parámetro de escritor a entrenar()\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device, \n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
    "          ) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Stores metrics to specified writer log_dir if present.\n",
    "\n",
    "    Args:\n",
    "      model: A PyTorch model to be trained and tested.\n",
    "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "      epochs: An integer indicating how many epochs to train for.\n",
    "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "      writer: A SummaryWriter() instance to log model results to.\n",
    "\n",
    "    Returns:\n",
    "      A dictionary of training and testing loss as well as training and\n",
    "      testing accuracy metrics. Each metric has a value in a list for \n",
    "      each epoch.\n",
    "      In the form: {train_loss: [...],\n",
    "                train_acc: [...],\n",
    "                test_loss: [...],\n",
    "                test_acc: [...]} \n",
    "      For example if training for epochs=2: \n",
    "              {train_loss: [2.0616, 1.0537],\n",
    "                train_acc: [0.3945, 0.3945],\n",
    "                test_loss: [1.2641, 1.5706],\n",
    "                test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "\n",
    "        ### New: Use the writer parameter to track experiments ###\n",
    "        # See if there's a writer, if so, log to it\n",
    "        if writer:\n",
    "            # Add results to SummaryWriter\n",
    "            writer.add_scalars(main_tag=\"Loss\", \n",
    "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                                \"test_loss\": test_loss},\n",
    "                               global_step=epoch)\n",
    "            writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                                \"test_acc\": test_acc}, \n",
    "                               global_step=epoch)\n",
    "\n",
    "            # Close the writer\n",
    "            writer.close()\n",
    "        else:\n",
    "            pass\n",
    "    ### End new ###\n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978748e8",
   "metadata": {},
   "source": [
    "## 7. Configuración de una serie de experimentos de modelado.\n",
    "\n",
    "Es para dar un paso más en las cosas.\n",
    "\n",
    "Anteriormente hemos realizado varios experimentos e inspeccionado los resultados uno por uno.\n",
    "\n",
    "Pero, ¿qué pasaría si pudiéramos realizar varios experimentos y luego inspeccionar todos los resultados juntos?\n",
    "\n",
    "¿Te unes?\n",
    "\n",
    "Vamos, vámonos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94760ce4",
   "metadata": {},
   "source": [
    "### 7.1 ¿Qué tipo de experimentos debería realizar?\n",
    "\n",
    "Esa es la pregunta del millón en el aprendizaje automático.\n",
    "\n",
    "Porque realmente no hay límite para los experimentos que puedes realizar.\n",
    "\n",
    "Esta libertad es la razón por la que el aprendizaje automático es tan emocionante y aterrador al mismo tiempo.\n",
    "\n",
    "Aquí es donde tendrás que ponerte tu bata de científico y recordar el lema de los profesionales del aprendizaje automático: *¡experimenta, experimenta, experimenta!*\n",
    "\n",
    "Cada hiperparámetro constituye un punto de partida para un experimento diferente: \n",
    "* Cambiar el número de **épocas**.\n",
    "* Cambiar el número de **capas/unidades ocultas**.\n",
    "* Cambiar la cantidad de **datos**.\n",
    "* Cambiar la **tasa de aprendizaje**.\n",
    "* Pruebe diferentes tipos de **aumento de datos**.\n",
    "* Elija una **arquitectura de modelo** diferente. \n",
    "\n",
    "Con práctica y realizando muchos experimentos diferentes, comenzarás a desarrollar una intuición de lo que *podría* ayudar a tu modelo.\n",
    "\n",
    "Digo *podría* a propósito porque no hay garantías.\n",
    "\n",
    "Pero en general, a la luz de [*The Bitter Lesson*](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) (lo he mencionado dos veces porque es un ensayo importante en el mundo de la IA), En general, cuanto más grande sea su modelo (más parámetros que se pueden aprender) y más datos tenga (más oportunidades de aprender), mejor será el rendimiento.\n",
    "\n",
    "Sin embargo, cuando se acerque por primera vez a un problema de aprendizaje automático: comience poco a poco y, si algo funciona, amplíelo.\n",
    "\n",
    "Su primer lote de experimentos no debería tardar más de unos segundos o unos minutos en ejecutarse.\n",
    "\n",
    "Cuanto más rápido puedas experimentar, más rápido podrás descubrir lo que *no* funciona y, a su vez, más rápido podrás descubrir lo que *sí* funciona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb4deb",
   "metadata": {},
   "source": [
    "### 7.2 ¿Qué experimentos vamos a realizar?\n",
    "\n",
    "Nuestro objetivo es mejorar el modelo que impulsa FoodVision Mini sin que crezca demasiado.\n",
    "\n",
    "En esencia, nuestro modelo ideal logra un alto nivel de precisión del conjunto de pruebas (más del 90 %), pero no lleva demasiado tiempo entrenar/realizar inferencias (hacer predicciones).\n",
    "\n",
    "Tenemos muchas opciones, pero ¿qué tal si mantenemos las cosas simples?\n",
    "\n",
    "Probemos una combinación de:\n",
    "1. Una cantidad de datos diferente (10 % de pizza, bistec y sushi frente a 20 %)\n",
    "2. Un modelo diferente ([`torchvision.models.ficientnet_b0`](https://pytorch.org/vision/stable/generated/torchvision.models.ficientnet_b0.html#torchvision.models.ficientnet_b0) vs. [`torchvision. modelos.eficientenet_b2`](https://pytorch.org/vision/stable/generated/torchvision.models.ficientnet_b2.html#torchvision.models.ficientnet_b2))\n",
    "3. Un tiempo de entrenamiento diferente (5 épocas frente a 10 épocas)\n",
    "\n",
    "Desglosándolos obtenemos: \n",
    "\n",
    "| Número de experimento | Conjunto de datos de entrenamiento | Modelo (preentrenado en ImageNet) | Número de épocas |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| 1 | Pizza, bistec, sushi 10% por ciento | EfficientNetB0 | 5 |\n",
    "| 2 | Pizza, bistec, sushi 10% por ciento | EfficientNetB2 | 5 | \n",
    "| 3 | Pizza, bistec, sushi 10% por ciento | EfficientNetB0 | 10 | \n",
    "| 4 | Pizza, bistec, sushi 10% por ciento | EfficientNetB2 | 10 |\n",
    "| 5 | Pizza, bistec, sushi 20% por ciento | EfficientNetB0 | 5 |\n",
    "| 6 | Pizza, bistec, sushi 20% por ciento | EfficientNetB2 | 5 |\n",
    "| 7 | Pizza, bistec, sushi 20% por ciento | EfficientNetB0 | 10 |\n",
    "| 8 | Pizza, bistec, sushi 20% por ciento | EfficientNetB2 | 10 |\n",
    "\n",
    "Observe cómo poco a poco estamos ampliando las cosas. \n",
    "\n",
    "Con cada experimento aumentamos lentamente la cantidad de datos, el tamaño del modelo y la duración del entrenamiento.\n",
    "\n",
    "Al final, el experimento 8 utilizará el doble de datos, el doble del tamaño del modelo y el doble de duración del entrenamiento en comparación con el experimento 1.\n",
    "\n",
    "> **Nota:** Quiero dejar claro que realmente no hay límite para la cantidad de experimentos que puedes ejecutar. Lo que hemos diseñado aquí es sólo un subconjunto muy pequeño de opciones. Sin embargo, no puedes probar *todo* así que es mejor probar algunas cosas para empezar y luego seguir las que funcionan mejor.\n",
    ">\n",
    "> Y como recordatorio, los conjuntos de datos que estamos usando son un subconjunto del [conjunto de datos Food101](https://pytorch.org/vision/stable/generated/torchvision.datasets.Food101.html#torchvision.datasets.Food101) (3 clases, pizza, bistec, sushi, en lugar de 101) y 10% y 20% de las imágenes en lugar de 100%. Si nuestros experimentos funcionan, podríamos comenzar a ejecutar más con más datos (aunque esto llevará más tiempo calcularlo). Puede ver cómo se crearon los conjuntos de datos a través del [cuaderno `04_custom_data_creation.ipynb`] (https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea5e5b",
   "metadata": {},
   "source": [
    "### 7.3 Descargar diferentes conjuntos de datos\n",
    "\n",
    "Antes de comenzar a ejecutar nuestra serie de experimentos, debemos asegurarnos de que nuestros conjuntos de datos estén listos.\n",
    "\n",
    "Necesitaremos dos formas de conjunto de entrenamiento:\n",
    "1. Un conjunto de entrenamiento con **10% de los datos** de imágenes de pizza, bistec y sushi de Food101 (ya hemos creado esto arriba, pero lo haremos nuevamente para que esté completo).\n",
    "2. Un conjunto de entrenamiento con **20% de los datos** de imágenes de pizza, bistec y sushi de Food101.\n",
    "\n",
    "Para mantener la coherencia, todos los experimentos utilizarán el mismo conjunto de datos de prueba (el de la división de datos del 10%).\n",
    "\n",
    "Comenzaremos descargando los diversos conjuntos de datos que necesitamos usando la función `download_data()` que creamos anteriormente.\n",
    "\n",
    "Ambos conjuntos de datos están disponibles en el curso GitHub:\n",
    "1. [Pizza, bistec, sushi 10% de datos de entrenamiento](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip).\n",
    "2. [Pizza, bistec, sushi 20% de datos de entrenamiento](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargue datos de entrenamiento del 10 por ciento y del 20 por ciento (si es necesario)\n",
    "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                                     destination=\"pizza_steak_sushi\")\n",
    "\n",
    "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                     destination=\"pizza_steak_sushi_20_percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc28bfc9",
   "metadata": {},
   "source": [
    "¡Datos descargados!\n",
    "\n",
    "Ahora configuremos las rutas de archivo de los datos que usaremos para los diferentes experimentos.\n",
    "\n",
    "Crearemos diferentes rutas de directorio de entrenamiento, pero solo necesitaremos una ruta de directorio de prueba, ya que todos los experimentos utilizarán el mismo conjunto de datos de prueba (el conjunto de datos de prueba de pizza, bistec y sushi 10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f700e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar rutas del directorio de capacitación\n",
    "train_dir_10_percent = data_10_percent_path / \"train\"\n",
    "train_dir_20_percent = data_20_percent_path / \"train\"\n",
    "\n",
    "# Configure las rutas del directorio de prueba (nota: use el mismo conjunto de datos de prueba para ambos para comparar los resultados)\n",
    "test_dir = data_10_percent_path / \"test\"\n",
    "\n",
    "# Consulta los directorios\n",
    "print(f\"Training directory 10%: {train_dir_10_percent}\")\n",
    "print(f\"Training directory 20%: {train_dir_20_percent}\")\n",
    "print(f\"Testing directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554c942",
   "metadata": {},
   "source": [
    "### 7.4 Transformar conjuntos de datos y crear cargadores de datos\n",
    "\n",
    "A continuación, crearemos una serie de transformaciones para preparar nuestras imágenes para nuestro(s) modelo(s).\n",
    "\n",
    "Para mantener la coherencia, crearemos manualmente una transformación (tal como lo hicimos anteriormente) y usaremos la misma transformación en todos los conjuntos de datos.\n",
    "\n",
    "La transformación: \n",
    "1. Cambie el tamaño de todas las imágenes (comenzaremos con 224, 224 pero esto podría cambiarse).\n",
    "2. Conviértelos en tensores con valores entre 0 y 1. \n",
    "3. Normalícelos de manera que sus distribuciones estén alineadas con el conjunto de datos de ImageNet (hacemos esto porque nuestros modelos de [`torchvision.models`](https://pytorch.org/vision/stable/models.html) han sido entrenados previamente en ImageNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Cree una transformación para normalizar la distribución de datos para que esté en línea con ImageNet\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
    "                                 std=[0.229, 0.224, 0.225]) # values per colour channel [red, green, blue]\n",
    "\n",
    "# Compose se transforma en una canalización\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 1. Resize the images\n",
    "    transforms.ToTensor(), # 2. Turn the images into tensors with values between 0 & 1\n",
    "    normalize # 3. Normalize the images so their distributions match the ImageNet dataset \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53cf2e",
   "metadata": {},
   "source": [
    "¡Transfórmate listo!\n",
    "\n",
    "Ahora creemos nuestros DataLoaders usando la función `create_dataloaders()` de `data_setup.py` que creamos en [05. PyTorch Going Modular sección 2](https://www.learnpytorch.io/05_pytorch_going_modular/#2-create-datasets-and-dataloaders-data_setuppy). \n",
    "\n",
    "Crearemos los DataLoaders con un tamaño de lote de 32.\n",
    "\n",
    "Para todos nuestros experimentos usaremos el mismo `test_dataloader` (para mantener las comparaciones consistentes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac54346",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Cree un 10% de capacitación y pruebe DataLoaders\n",
    "train_dataloader_10_percent, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_10_percent,\n",
    "    test_dir=test_dir, \n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Cree un 20 % de datos de prueba y entrenamiento DataLoders\n",
    "train_dataloader_20_percent, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Encuentre la cantidad de muestras/lotes por cargador de datos (usando el mismo test_dataloader para ambos experimentos)\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(train_dataloader_10_percent)} (all experiments will use the same test set)\")\n",
    "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee76236f",
   "metadata": {},
   "source": [
    "### 7.5 Crear modelos de extracción de características\n",
    "\n",
    "Es hora de empezar a construir nuestros modelos.\n",
    "\n",
    "Vamos a crear dos modelos de extractor de funciones: \n",
    "\n",
    "1. [`torchvision.models.ficientnet_b0()`](https://pytorch.org/vision/main/models/generated/torchvision.models.ficientnet_b0.html) columna vertebral previamente entrenada + cabezal clasificador personalizado (EffNetB0 para abreviar).\n",
    "2. [`torchvision.models.ficientnet_b2()`](https://pytorch.org/vision/main/models/generated/torchvision.models.ficientnet_b2.html) columna vertebral previamente entrenada + cabezal clasificador personalizado (EffNetB2 para abreviar).\n",
    "\n",
    "Para hacer esto, congelaremos las capas base (las capas de características) y actualizaremos los cabezales clasificadores del modelo (capas de salida) para adaptarnos a nuestro problema tal como lo hicimos en [06. Sección 3.4 de aprendizaje por transferencia de PyTorch] (https://www.learnpytorch.io/06_pytorch_transfer_learning/#34-freezing-the-base-model-and-changing-the-output-layer-to-suit-our-needs).\n",
    "\n",
    "Vimos en el capítulo anterior que el parámetro `in_features` para el cabezal clasificador de EffNetB0 es `1280` (la columna vertebral convierte la imagen de entrada en un vector de características de tamaño `1280`).\n",
    "\n",
    "Dado que EffNetB2 tiene un número diferente de capas y parámetros, necesitaremos adaptarlo en consecuencia.\n",
    "\n",
    "> **Nota:** Siempre que utilices un modelo diferente, una de las primeras cosas que debes inspeccionar son las formas de entrada y salida. De esa manera sabrá cómo tendrá que preparar sus datos de entrada/actualizar el modelo para tener la forma de salida correcta.\n",
    "\n",
    "Podemos encontrar las formas de entrada y salida de EffNetB2 usando [`torchinfo.summary()`](https://github.com/TylerYep/torchinfo) y pasando `input_size=(32, 3, 224, 224)` El parámetro (`(32, 3, 224, 224)` es equivalente a `(batch_size, color_channels, height, width)`, es decir, pasamos un ejemplo de lo que sería un solo lote de datos a nuestro modelo).\n",
    "\n",
    "> **Nota:** Muchos modelos modernos pueden manejar imágenes de entrada de diferentes tamaños gracias a [`torch.nn.AdaptiveAvgPool2d()`](https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d .html), esta capa ajusta de forma adaptativa el `output_size` de una entrada determinada según sea necesario. Puede probar esto pasando imágenes de entrada de diferentes tamaños a `torchinfo.summary()` o a sus propios modelos usando la capa.\n",
    "\n",
    "Para encontrar la forma de entrada requerida para la capa final de EffNetB2, hagamos lo siguiente:\n",
    "1. Cree una instancia de `torchvision.models.ficientnet_b2(pretrained=True)`.\n",
    "2. Vea las diversas formas de entrada y salida ejecutando `torchinfo.summary()`.\n",
    "3. Imprima el número de `in_features` inspeccionando `state_dict()` de la parte del clasificador de EffNetB2 e imprimiendo la longitud de la matriz de peso.\n",
    "    * **Nota:** También puedes simplemente inspeccionar la salida de `effnetb2.classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchinfo import summary\n",
    "\n",
    "# 1. Cree una instancia de EffNetB2 con pesos previamente entrenados.\n",
    "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT # \"DEFAULT\" means best available weights\n",
    "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights)\n",
    "\n",
    "# # 2. Obtenga un resumen del EffNetB2 estándar de torchvision.models (descomente el comentario para obtener un resultado completo)\n",
    "# resumen (modelo = effnetb2,\n",
    "# input_size=(32, 3, 224, 224), # asegúrese de que sea \"input_size\", no \"input_shape\"\n",
    "# # col_names=[\"input_size\"], # descomentar para resultados más pequeños\n",
    "# col_names=[\"input_size\", \"output_size\", \"num_params\", \"entrenable\"],\n",
    "# ancho_columna=20,\n",
    "# row_settings=[\"var_names\"]\n",
    "# )\n",
    "\n",
    "# 3. Obtenga el número de características internas de la capa clasificadora EfficientNetB2.\n",
    "print(f\"Number of in_features to final layer of EfficientNetB2: {len(effnetb2.classifier.state_dict()['1.weight'][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1bbe0",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-effnetb2-unfrozen-summary-output.png\" alt=\"salida de torchinfo.summary() cuando Pasó nuestro modelo effnetb2 con todas las capas entrenables y el cabezal clasificador predeterminado\" width=900/>\n",
    "\n",
    "*Resumen del modelo de extracción de características de EffNetB2 con todas las capas descongeladas (entrenables) y el cabezal clasificador predeterminado del preentrenamiento de ImageNet.*\n",
    "\n",
    "Ahora que sabemos la cantidad requerida de `in_features` para el modelo EffNetB2, creemos un par de funciones auxiliares para configurar nuestros modelos de extracción de características EffNetB0 y EffNetB2.\n",
    "\n",
    "Queremos que estas funciones:\n",
    "1. Obtenga el modelo base de `torchvision.models`\n",
    "2. Congele las capas base en el modelo (establezca `requires_grad=False`)\n",
    "3. Establezca las semillas aleatorias (no *necesitamos* hacer esto, pero como estamos ejecutando una serie de experimentos e inicializando una nueva capa con pesos aleatorios, queremos que la aleatoriedad sea similar para cada experimento)\n",
    "4. Cambiar el cabezal clasificador (para adaptarlo a nuestro problema)\n",
    "5. Asigne un nombre al modelo (por ejemplo, \"effnetb0\" para EffNetB0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "# Obtenga funciones numéricas (una para cada clase de pizza, bistec y sushi)\n",
    "OUT_FEATURES = len(class_names)\n",
    "\n",
    "# Cree un extractor de funciones EffNetB0\n",
    "def create_effnetb0():\n",
    "    # 1. Get the base mdoel with pretrained weights and send to target device\n",
    "    weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "    # 2. Freeze the base model layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 3. Set the seeds\n",
    "    set_seeds()\n",
    "\n",
    "    # 4. Change the classifier head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(in_features=1280, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    # 5. Give the model a name\n",
    "    model.name = \"effnetb0\"\n",
    "    print(f\"[INFO] Created new {model.name} model.\")\n",
    "    return model\n",
    "\n",
    "# Cree un extractor de funciones EffNetB2\n",
    "def create_effnetb2():\n",
    "    # 1. Get the base model with pretrained weights and send to target device\n",
    "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
    "    model = torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
    "\n",
    "    # 2. Freeze the base model layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # 3. Set the seeds\n",
    "    set_seeds()\n",
    "\n",
    "    # 4. Change the classifier head\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(in_features=1408, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    # 5. Give the model a name\n",
    "    model.name = \"effnetb2\"\n",
    "    print(f\"[INFO] Created new {model.name} model.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66693d8f",
   "metadata": {},
   "source": [
    "¡Esas son algunas funciones bonitas!\n",
    "\n",
    "Probemoslos creando una instancia de EffNetB0 y EffNetB2 y revisando su `resumen()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19b37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb0 = create_effnetb0() \n",
    "\n",
    "# Obtenga un resumen de salida de las capas en nuestro modelo de extracción de características EffNetB0 (descomente el comentario para ver el resultado completo)\n",
    "# resumen (modelo = effnetb0,\n",
    "# input_size=(32, 3, 224, 224), # asegúrese de que sea \"input_size\", no \"input_shape\"\n",
    "# # col_names=[\"input_size\"], # descomentar para resultados más pequeños\n",
    "# col_names=[\"input_size\", \"output_size\", \"num_params\", \"entrenable\"],\n",
    "# ancho_columna=20,\n",
    "# row_settings=[\"var_names\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02397b89",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-effnetb0-frozen-summary-output.png\" alt=\"salida de torchinfo.summary() cuando pasó nuestro modelo effnetb0 con las capas base congeladas y el cabezal clasificador actualizado\" width=900/>\n",
    "\n",
    "*Resumen del modelo EffNetB0 con capas base congeladas (no entrenables) y cabezal clasificador actualizado (adecuado para clasificación de imágenes de pizza, bistec y sushi).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "effnetb2 = create_effnetb2()\n",
    "\n",
    "# Obtenga un resumen de salida de las capas en nuestro modelo de extracción de características EffNetB2 (elimine el comentario para ver la salida completa)\n",
    "# resumen (modelo = effnetb2,\n",
    "# input_size=(32, 3, 224, 224), # asegúrese de que sea \"input_size\", no \"input_shape\"\n",
    "# # col_names=[\"input_size\"], # descomentar para resultados más pequeños\n",
    "# col_names=[\"input_size\", \"output_size\", \"num_params\", \"entrenable\"],\n",
    "# ancho_columna=20,\n",
    "# row_settings=[\"var_names\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5e159",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-effnetb2-frozen-summary-output.png\" alt=\"salida de torchinfo.summary() cuando pasó nuestro modelo effnetb2 con las capas base congeladas y el cabezal clasificador actualizado\" width=900/>\n",
    "\n",
    "*Resumen del modelo EffNetB2 con capas base congeladas (no entrenables) y cabezal clasificador actualizado (adecuado para clasificación de imágenes de pizza, bistec y sushi).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c12bad",
   "metadata": {},
   "source": [
    "Al observar los resultados de los resúmenes, parece que la columna vertebral de EffNetB2 tiene casi el doble de parámetros que EffNetB0.\n",
    "\n",
    "| Modelo | Parámetros totales (antes de congelar/cambiar cabezal) | Parámetros totales (después de congelar/cambiar cabezal) | Parámetros totales entrenables (después de congelar/cambiar el cabezal) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| EfficientNetB0 | 5.288.548 | 4.011.391 | 3.843 |  \n",
    "| EfficientNetB2 | 9.109.994 | 7.705.221 | 4.227 |\n",
    "\n",
    "Esto le da a la columna vertebral del modelo EffNetB2 más oportunidades para formar una representación de nuestros datos de pizza, bistec y sushi.\n",
    "\n",
    "Sin embargo, los parámetros entrenables para cada modelo (los cabezales clasificadores) no son muy diferentes.\n",
    "\n",
    "¿Estos parámetros adicionales conducirán a mejores resultados?\n",
    "\n",
    "Tendremos que esperar y ver... \n",
    "\n",
    "> **Nota:** Con el ánimo de experimentar, realmente podrías probar casi cualquier modelo de `torchvision.models` de manera similar a lo que estamos haciendo aquí. Solo elegí EffNetB0 y EffNetB2 como ejemplos. Quizás quieras incluir algo como `torchvision.models.convnext_tiny()` o `torchvision.models.convnext_small()` en la mezcla."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a10eba",
   "metadata": {},
   "source": [
    "### 7.6 Crear experimentos y configurar código de entrenamiento\n",
    "\n",
    "Hemos preparado nuestros datos y nuestros modelos, ¡ha llegado el momento de configurar algunos experimentos!\n",
    "\n",
    "Comenzaremos creando dos listas y un diccionario:\n",
    "1. Una lista del número de épocas que nos gustaría probar (`[5, 10]`)\n",
    "2. Una lista de los modelos que nos gustaría probar (`[\"effnetb0\", \"effnetb2\"]`)\n",
    "3. Un diccionario de los diferentes DataLoaders de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear lista de épocas\n",
    "num_epochs = [5, 10]\n",
    "\n",
    "# 2. Crear lista de modelos (es necesario crear un nuevo modelo para cada experimento)\n",
    "models = [\"effnetb0\", \"effnetb2\"]\n",
    "\n",
    "# 3. Cree un diccionario de cargadores de datos para varios cargadores de datos.\n",
    "train_dataloaders = {\"data_10_percent\": train_dataloader_10_percent,\n",
    "                     \"data_20_percent\": train_dataloader_20_percent}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c1add",
   "metadata": {},
   "source": [
    "¡Listas y diccionario creados!\n",
    "\n",
    "Ahora podemos escribir código para recorrer cada una de las diferentes opciones y probar cada una de las diferentes combinaciones.\n",
    "\n",
    "También guardaremos el modelo al final de cada experimento para que luego podamos volver a cargarlo en el mejor modelo y usarlo para hacer predicciones.\n",
    "\n",
    "Específicamente, sigamos los siguientes pasos: \n",
    "1. Establezca las semillas aleatorias (para que los resultados de nuestro experimento sean reproducibles; en la práctica, puede ejecutar el mismo experimento en ~3 semillas diferentes y promediar los resultados).\n",
    "2. Mantenga un registro de los diferentes números de experimentos (esto es principalmente para impresiones bonitas).\n",
    "3. Recorra los elementos del diccionario `train_dataloaders` para cada uno de los diferentes DataLoaders de entrenamiento.\n",
    "4. Recorra la lista de números de época.\n",
    "5. Recorra la lista de diferentes nombres de modelos.\n",
    "6. Cree impresiones de información para el experimento en ejecución actual (para que sepamos qué está sucediendo).\n",
    "7. Verifique qué modelo es el modelo objetivo y cree una nueva instancia de EffNetB0 o EffNetB2 (creamos una nueva instancia de modelo en cada experimento para que todos los modelos comiencen desde el mismo punto de vista).\n",
    "8. Cree una nueva función de pérdida (`torch.nn.CrossEntropyLoss()`) y un optimizador (`torch.optim.Adam(params=model.parameters(), lr=0.001)`) para cada nuevo experimento.\n",
    "9. Entrene el modelo con la función `train()` modificada pasando los detalles apropiados al parámetro `writer`.\n",
    "10. Guarde el modelo entrenado con un nombre de archivo apropiado en el archivo `save_model()` de [`utils.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/ Going_modular/utils.py). \n",
    "\n",
    "También podemos usar la magia `%%time` para ver cuánto tiempo toman todos nuestros experimentos juntos en una sola celda de Jupyter/Google Colab.\n",
    "\n",
    "¡Vamos a hacerlo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0955d131",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from going_modular.going_modular.utils import save_model\n",
    "\n",
    "# 1. Establece las semillas aleatorias\n",
    "set_seeds(seed=42)\n",
    "\n",
    "# 2. Realice un seguimiento de los números de los experimentos\n",
    "experiment_number = 0\n",
    "\n",
    "# 3. Recorra cada DataLoader\n",
    "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
    "\n",
    "    # 4. Loop through each number of epochs\n",
    "    for epochs in num_epochs: \n",
    "\n",
    "        # 5. Loop through each model name and create a new model based on the name\n",
    "        for model_name in models:\n",
    "\n",
    "            # 6. Create information print outs\n",
    "            experiment_number += 1\n",
    "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
    "            print(f\"[INFO] Model: {model_name}\")\n",
    "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
    "            print(f\"[INFO] Number of epochs: {epochs}\")  \n",
    "\n",
    "            # 7. Select the model\n",
    "            if model_name == \"effnetb0\":\n",
    "                model = create_effnetb0() # creates a new model each time (important because we want each experiment to start from scratch)\n",
    "            else:\n",
    "                model = create_effnetb2() # creates a new model each time (important because we want each experiment to start from scratch)\n",
    "            \n",
    "            # 8. Create a new loss and optimizer for every model\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "            # 9. Train target model with target dataloaders and track experiments\n",
    "            train(model=model,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader, \n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  epochs=epochs,\n",
    "                  device=device,\n",
    "                  writer=create_writer(experiment_name=dataloader_name,\n",
    "                                       model_name=model_name,\n",
    "                                       extra=f\"{epochs}_epochs\"))\n",
    "            \n",
    "            # 10. Save the model to file so we can get back the best model\n",
    "            save_filepath = f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
    "            save_model(model=model,\n",
    "                       target_dir=\"models\",\n",
    "                       model_name=save_filepath)\n",
    "            print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be47a930",
   "metadata": {},
   "source": [
    "## 8. Ver experimentos en TensorBoard\n",
    "\n",
    "¡Ho, ho!\n",
    "\n",
    "¡Míranos ir!\n",
    "\n",
    "¿Entrenar ocho modelos de una sola vez?\n",
    "\n",
    "¡Eso sí que está a la altura del lema!\n",
    "\n",
    "*¡Experimenta, experimenta, experimenta!*\n",
    "\n",
    "¿Qué tal si comprobamos los resultados en TensorBoard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de TensorBoard en Jupyter y Google Colab Notebooks (elimine el comentario para ver la instancia completa de TensorBoard)\n",
    "# %load_ext tensorboard\n",
    "# % tensorboard --logdir se ejecuta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f705792",
   "metadata": {},
   "source": [
    "Al ejecutar la celda de arriba deberíamos obtener un resultado similar al siguiente.\n",
    "\n",
    "> **Nota:** Dependiendo de las semillas aleatorias que usaste/el hardware que usaste, existe la posibilidad de que tus números no sean exactamente los mismos que los que aparecen aquí. Esto está bien. Se debe a la aleatoriedad inherente del aprendizaje profundo. Lo que más importa es la tendencia. Hacia dónde se dirigen tus números. Si están muy desviados, tal vez haya algún problema y sea mejor volver atrás y verificar el código. Pero si están ligeramente desviados (digamos un par de decimales más o menos), está bien. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/07-tensorboard-lowest-test-loss.png\" alt=\"varios experimentos de modelado visualizados en tensorboard con modelo que tiene la pérdida de prueba más baja resaltada\" width=900/>\n",
    "\n",
    "*Al visualizar los valores de pérdida de prueba para los diferentes experimentos de modelado en TensorBoard, se puede ver que el modelo EffNetB0 entrenado durante 10 épocas y con el 20% de los datos logra la pérdida más baja. Esto se mantiene con la tendencia general de los experimentos de que: más datos, un modelo más grande y un tiempo de entrenamiento más largo es generalmente mejor.*\n",
    "\n",
    "También puede cargar los resultados de su experimento de TensorBoard en [tensorboard.dev](https://tensorboard.dev) para alojarlos públicamente de forma gratuita.\n",
    "\n",
    "Por ejemplo, ejecutando código similar al siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f21969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sube los resultados a TensorBoard.dev (descomenta para probarlo)\n",
    "# !tensorboard dev upload --logdir se ejecuta \\\n",
    "# --name \"07. Seguimiento de experimentos de PyTorch: resultados del modelo FoodVision Mini\" \\\n",
    "# --description \"Comparación de resultados de diferentes tamaños de modelo, cantidad de datos de entrenamiento y tiempo de entrenamiento\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b02aa",
   "metadata": {},
   "source": [
    "Al ejecutar la celda anterior, los experimentos de este cuaderno se pueden ver públicamente en: https://tensorboard.dev/experiment/VySxUYY7Rje0xREYvCvZXA/\n",
    "\n",
    "> **Nota:** Tenga en cuenta que todo lo que cargue en tensorboard.dev estará disponible públicamente para que cualquiera lo vea. Entonces, si carga sus experimentos, tenga cuidado de que no contengan información confidencial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeaf329",
   "metadata": {},
   "source": [
    "## 9. Cargue el mejor modelo y haga predicciones con él.\n",
    "\n",
    "Al observar los registros de TensorBoard para nuestros ocho experimentos, parece que el experimento número ocho logró los mejores resultados generales (mayor precisión de prueba, segunda pérdida de prueba más baja).\n",
    "\n",
    "Este es el experimento que utilizó:\n",
    "* EffNetB2 (duplica los parámetros de EffNetB0)\n",
    "* 20% de datos de entrenamiento de pizza, bistec y sushi (el doble de los datos de entrenamiento originales)\n",
    "* 10 épocas (el doble del tiempo de entrenamiento original)\n",
    "\n",
    "En esencia, nuestro modelo más grande logró los mejores resultados.\n",
    "\n",
    "Aunque no es que estos resultados fueran mucho mejores que los de otros modelos.\n",
    "\n",
    "El mismo modelo con los mismos datos logró resultados similares en la mitad del tiempo de entrenamiento (experimento número 6).\n",
    "\n",
    "Esto sugiere que potencialmente las partes más influyentes de nuestros experimentos fueron la cantidad de parámetros y la cantidad de datos.\n",
    "\n",
    "Al inspeccionar más a fondo los resultados, parece que, en general, un modelo con más parámetros (EffNetB2) y más datos (20% de datos de entrenamiento de pizza, bistec y sushi) funciona mejor (menor pérdida de prueba y mayor precisión de la prueba).\n",
    "\n",
    "Se podrían realizar más experimentos para probar esto más a fondo, pero por ahora, importemos nuestro modelo de mejor rendimiento del experimento ocho (guardado en: `models/07_effnetb2_data_20_percent_10_epochs.pth`, puede [descargar este modelo del curso GitHub](https:// github.com/mrdbourke/pytorch-deep-learning/blob/main/models/07_effnetb2_data_20_percent_10_epochs.pth)) y realice algunas evaluaciones cualitativas.\n",
    "\n",
    "En otras palabras, ¡visualicemos, visualicemos, visualicemos!*\n",
    "\n",
    "Podemos importar el mejor modelo guardado creando una nueva instancia de EffNetB2 usando la función `create_effnetb2()` y luego cargar el `state_dict()` guardado con `torch.load()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b49c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure la mejor ruta de archivo del modelo\n",
    "best_model_path = \"models/07_effnetb2_data_20_percent_10_epochs.pth\"\n",
    "\n",
    "# Crear una nueva instancia de EffNetB2 (para cargar el state_dict() guardado en)\n",
    "best_model = create_effnetb2()\n",
    "\n",
    "# Cargue el mejor modelo guardado state_dict()\n",
    "best_model.load_state_dict(torch.load(best_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2f815",
   "metadata": {},
   "source": [
    "¡El mejor modelo cargado!\n",
    "\n",
    "Mientras estamos aquí, revisemos su tamaño de archivo.\n",
    "\n",
    "Esta es una consideración importante más adelante al implementar el modelo (incorporarlo a una aplicación).\n",
    "\n",
    "Si el modelo es demasiado grande, puede resultar difícil implementarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd36602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique el tamaño del archivo del modelo\n",
    "from pathlib import Path\n",
    "\n",
    "# Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes\n",
    "effnetb2_model_size = Path(best_model_path).stat().st_size // (1024*1024)\n",
    "print(f\"EfficientNetB2 feature extractor model size: {effnetb2_model_size} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f143ab",
   "metadata": {},
   "source": [
    "Parece que nuestro mejor modelo hasta ahora tiene un tamaño de 29 MB. Tendremos esto en cuenta si quisiéramos implementarlo más adelante.\n",
    "\n",
    "Es hora de hacer y visualizar algunas predicciones.\n",
    "\n",
    "Creamos una función `pred_and_plot_image()` para usar un modelo entrenado para hacer predicciones sobre una imagen en [06. Sección 6 del aprendizaje por transferencia de PyTorch] (https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set).\n",
    "\n",
    "Y podemos reutilizar esta función importándola desde [`going_modular.going_modular.predictions.py`](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/predictions.py) (Puse la función `pred_and_plot_image()` en un script para poder reutilizarla).\n",
    "\n",
    "Entonces, para hacer predicciones sobre varias imágenes que el modelo no ha visto antes, primero obtendremos una lista de todas las rutas de archivos de imágenes del conjunto de datos de prueba de 20% de pizza, bistec y sushi y luego seleccionaremos aleatoriamente un subconjunto de estas rutas de archivos. para pasar a nuestra función `pred_and_plot_image()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6203e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de importación para hacer predicciones sobre imágenes y trazarlas.\n",
    "# Consulte la función creada anteriormente en la sección: https://www.learnpytorch.io/06_pytorch_transfer_learning/#6-make-predictions-on-images-from-the-test-set\n",
    "from going_modular.going_modular.predictions import pred_and_plot_image\n",
    "\n",
    "# Obtenga una lista aleatoria de 3 imágenes del 20 % del conjunto de prueba\n",
    "import random\n",
    "num_images_to_plot = 3\n",
    "test_image_path_list = list(Path(data_20_percent_path / \"test\").glob(\"*/*.jpg\")) # get all test image paths from 20% dataset\n",
    "test_image_path_sample = random.sample(population=test_image_path_list,\n",
    "                                       k=num_images_to_plot) # randomly select k number of images\n",
    "\n",
    "# Iterar a través de rutas de imágenes de prueba aleatorias, hacer predicciones sobre ellas y trazarlas\n",
    "for image_path in test_image_path_sample:\n",
    "    pred_and_plot_image(model=best_model,\n",
    "                        image_path=image_path,\n",
    "                        class_names=class_names,\n",
    "                        image_size=(224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b671075",
   "metadata": {},
   "source": [
    "¡Lindo!\n",
    "\n",
    "Al ejecutar la celda de arriba varias veces, podemos ver que nuestro modelo funciona bastante bien y, a menudo, tiene mayores probabilidades de predicción que los modelos anteriores que hemos creado.\n",
    "\n",
    "Esto sugiere que el modelo tiene más confianza en las decisiones que toma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34109961",
   "metadata": {},
   "source": [
    "### 9.1 Predecir en una imagen personalizada con el mejor modelo\n",
    "\n",
    "Hacer predicciones sobre el conjunto de datos de prueba es genial, pero la verdadera magia del aprendizaje automático es hacer predicciones sobre sus propias imágenes personalizadas.\n",
    "\n",
    "Entonces, importemos la confiable [imagen del papá de la pizza](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg) (una foto de mi papá frente a una pizza) que hemos estado usando durante las últimas secciones y ver cómo funciona nuestro modelo en ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar imagen personalizada\n",
    "import requests\n",
    "\n",
    "# Configurar ruta de imagen personalizada\n",
    "custom_image_path = Path(\"data/04-pizza-dad.jpeg\")\n",
    "\n",
    "# Descarga la imagen si aún no existe\n",
    "if not custom_image_path.is_file():\n",
    "    with open(custom_image_path, \"wb\") as f:\n",
    "        # When downloading from GitHub, need to use the \"raw\" file link\n",
    "        request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
    "        print(f\"Downloading {custom_image_path}...\")\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print(f\"{custom_image_path} already exists, skipping download.\")\n",
    "\n",
    "# Predecir en imagen personalizada\n",
    "pred_and_plot_image(model=model,\n",
    "                    image_path=custom_image_path,\n",
    "                    class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9152c8f",
   "metadata": {},
   "source": [
    "¡Guau!\n",
    "\n",
    "¡Dos pulgares otra vez!\n",
    "\n",
    "Nuestro mejor modelo predice \"pizza\" correctamente y esta vez con una probabilidad de predicción aún mayor (0,978) que el primer modelo de extracción de características que entrenamos y utilizamos en [06. Sección 6.1 de aprendizaje por transferencia de PyTorch] (https://www.learnpytorch.io/06_pytorch_transfer_learning/#61-making-predictions-on-a-custom-image).\n",
    "\n",
    "Esto nuevamente sugiere que nuestro mejor modelo actual (el extractor de características EffNetB2 entrenado en el 20% de los datos de entrenamiento de pizza, bistec y sushi y durante 10 épocas) ha aprendido patrones para que tenga más confianza en su decisión de predecir la pizza.\n",
    "\n",
    "Me pregunto qué podría mejorar aún más el rendimiento de nuestro modelo. \n",
    "\n",
    "Te lo dejaré como un desafío para que investigues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e8208",
   "metadata": {},
   "source": [
    "## Principales conclusiones\n",
    "\n",
    "Ahora hemos completado el círculo en el flujo de trabajo de PyTorch introducido en [01. Fundamentos del flujo de trabajo de PyTorch] (https://www.learnpytorch.io/01_pytorch_workflow/), preparamos los datos, creamos y elegimos un modelo previamente entrenado, utilizamos nuestras diversas funciones auxiliares para entrenar y evaluar el modelo. y en este cuaderno hemos mejorado nuestro modelo FoodVision Mini ejecutando y rastreando una serie de experimentos.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/01_a_pytorch_workflow.png\" width=900 alt=\"un chat de flujo de flujo de trabajo de pytorch\"/>\n",
    "\n",
    "Deberías estar orgulloso de ti mismo, ¡esto no es poca cosa!\n",
    "\n",
    "Las ideas principales que debes extraer de este Proyecto Hito 1 son:\n",
    "\n",
    "* El lema del profesional del aprendizaje automático: *¡experimenta, experimenta, experimenta!* (aunque ya hemos estado haciendo mucho de esto).\n",
    "* Al principio, mantenga sus experimentos pequeños para que pueda trabajar rápido; sus primeros experimentos no deberían tardar más de unos segundos o unos minutos en ejecutarse.\n",
    "* Cuantos más experimentos hagas, más rápido podrás descubrir qué *no* funciona.\n",
    "* Aumente la escala cuando encuentre algo que funcione. Por ejemplo, dado que hemos encontrado un modelo con un rendimiento bastante bueno con EffNetB2 como extractor de funciones, tal vez ahora le gustaría ver qué sucede cuando lo amplía a todo el [conjunto de datos de Food101](https://pytorch.org /vision/main/generated/torchvision.datasets.Food101.html) de `torchvision.datasets`.\n",
    "* El seguimiento programático de sus experimentos requiere algunos pasos para configurarlo, pero a la larga vale la pena para que pueda descubrir qué funciona y qué no.\n",
    "    * Existen muchos rastreadores de experimentos de aprendizaje automático diferentes, así que explore algunos y pruébelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ffcf2b",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "> **Nota:** Estos ejercicios requieren el uso de `torchvision` v0.13+ (lanzado en julio de 2022); las versiones anteriores pueden funcionar, pero probablemente tendrán errores.\n",
    "\n",
    "Todos los ejercicios se centran en practicar el código anterior.\n",
    "\n",
    "Debería poder completarlos haciendo referencia a cada sección o siguiendo los recursos vinculados.\n",
    "\n",
    "Todos los ejercicios deben completarse utilizando [código independiente del dispositivo](https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code).\n",
    "\n",
    "**Recursos:**\n",
    "* [Cuaderno de plantilla de ejercicios para 07](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/07_pytorch_experiment_tracking_exercise_template.ipynb)\n",
    "* [Cuaderno de soluciones de ejemplo para 07](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/07_pytorch_experiment_tracking_exercise_solutions.ipynb) (pruebe los ejercicios *antes* de mirar esto)\n",
    "    * Vea un [video tutorial de las soluciones en YouTube] en vivo (https://youtu.be/cO_r2FYcAjU) (errores y todo)\n",
    "\n",
    "\n",
    "1. Elija un modelo más grande de [`torchvision.models`](https://pytorch.org/vision/main/models.html) para agregarlo a la lista de experimentos (por ejemplo, EffNetB3 o superior). \n",
    "    * ¿Cómo funciona en comparación con nuestros modelos existentes?\n",
    "2. Introduzca el aumento de datos en la lista de experimentos que utilizan conjuntos de datos de prueba y entrenamiento de pizza, bistec y sushi al 20%. ¿Esto cambia algo?\n",
    "    * Por ejemplo, podría tener un DataLoader de entrenamiento que utilice aumento de datos (por ejemplo, `train_dataloader_20_percent_aug` y `train_dataloader_20_percent_no_aug`) y luego comparar los resultados de dos tipos de modelos iguales entrenando en estos dos DataLoaders.\n",
    "    * **Nota:** Es posible que necesite modificar la función `create_dataloaders()` para poder realizar una transformación para los datos de entrenamiento y los datos de prueba (porque no necesita realizar un aumento de datos en los datos de prueba) . Ver [04. Sección 6 de conjuntos de datos personalizados de PyTorch] (https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation) para ver ejemplos de uso del aumento de datos o el siguiente script para ver un ejemplo:\n",
    "\n",
    "```pitón\n",
    "# Nota: Una transformación de aumento de datos como esta solo debe realizarse en datos de entrenamiento\n",
    "train_transform_data_aug = transforma.Compose([\n",
    "    transforma.Resize((224, 224)),\n",
    "    transforma.TrivialAugmentWide(),\n",
    "    transforma.ToTensor(),\n",
    "    normalizar\n",
    "])\n",
    "\n",
    "# Función auxiliar para ver imágenes en un DataLoader (funciona con transformaciones de aumento de datos o no) \n",
    "def view_dataloader_images(cargador de datos, n=10):\n",
    "    si norte > 10:\n",
    "        print(f\"Tener n mayor que 10 creará gráficos desordenados, reduciéndolos a 10.\")\n",
    "        norte = 10\n",
    "    imgs, etiquetas = siguiente (iter (cargador de datos))\n",
    "    plt.figura(tamaño de figura=(16, 8))\n",
    "    para i en el rango (n):\n",
    "        # Escala mínima máxima de la imagen para fines de visualización\n",
    "        targ_image = imágenes[i]\n",
    "        sample_min, sample_max = targ_image.min(), targ_image.max()\n",
    "        sample_scaled = (targ_image - sample_min)/(sample_max - sample_min)\n",
    "\n",
    "        # Trazar imágenes con información de ejes apropiada\n",
    "        plt.subtrama(1, 10, i+1)\n",
    "        plt.imshow(sample_scaled.permute(1, 2, 0)) # cambiar el tamaño para los requisitos de Matplotlib\n",
    "        plt.title(nombres_clase[etiquetas[i]])\n",
    "        eje.plt(Falso)\n",
    "\n",
    "# Tenemos que actualizar `create_dataloaders()` para manejar diferentes aumentos\n",
    "importar sistema operativo\n",
    "desde torch.utils.data importar DataLoader\n",
    "desde conjuntos de datos de importación de torchvision\n",
    "\n",
    "NUM_WORKERS = os.cpu_count() # usa el número máximo de CPU para que los trabajadores carguen datos \n",
    "\n",
    "# Nota: esta es una versión actualizada de data_setup.create_dataloaders para manejar\n",
    "# diferentes transformaciones de tren y prueba.\n",
    "def crear_cargadores de datos (\n",
    "    tren_dir, \n",
    "    dir_prueba, \n",
    "    train_transform, # agrega parámetro para la transformación del tren (transformaciones en el conjunto de datos del tren)\n",
    "    test_transform, # agrega parámetro para la transformación de prueba (transformaciones en el conjunto de datos de prueba)\n",
    "    tamaño_lote=32, num_trabajadores=NUM_TRABAJADORES\n",
    "):\n",
    "    # Utilice ImageFolder para crear conjuntos de datos\n",
    "    train_data = conjuntos de datos.ImageFolder(train_dir, transform=train_transform)\n",
    "    test_data = conjuntos de datos.ImageFolder(test_dir, transform=test_transform)\n",
    "\n",
    "    # Obtener nombres de clases\n",
    "    nombres_clase = datos_tren.clases\n",
    "\n",
    "    # Convertir imágenes en cargadores de datos\n",
    "    train_dataloader = Cargador de datos(\n",
    "        datos_tren,\n",
    "        tamaño_lote = tamaño_lote,\n",
    "        barajar = Verdadero,\n",
    "        num_trabajadores=num_trabajadores,\n",
    "        pin_memory=Verdadero,\n",
    "    )\n",
    "    test_dataloader = Cargador de datos(\n",
    "        datos de prueba,\n",
    "        tamaño_lote = tamaño_lote,\n",
    "        barajar = Verdadero,\n",
    "        num_trabajadores=num_trabajadores,\n",
    "        pin_memory=Verdadero,\n",
    "    )\n",
    "\n",
    "    devolver train_dataloader, test_dataloader, class_names\n",
    "```\n",
    "\n",
    "3. Amplíe el conjunto de datos para convertir FoodVision Mini en FoodVision Big utilizando todo el [conjunto de datos Food101 de `torchvision.models`](https://pytorch.org/vision/stable/generated/torchvision.datasets.Food101.html#torchvision .conjuntos de datos.Food101)\n",
    "    * Podría tomar el modelo de mejor rendimiento de sus diversos experimentos o incluso el extractor de funciones EffNetB2 que creamos en este cuaderno y ver cómo se adapta durante 5 épocas en todo Food101.\n",
    "    * Si prueba más de un modelo, sería bueno realizar un seguimiento de los resultados del modelo.\n",
    "    * Si carga el conjunto de datos Food101 desde `torchvision.models`, deberá crear PyTorch DataLoaders para usarlo en el entrenamiento.\n",
    "    * **Nota:** Debido a la mayor cantidad de datos en Food101 en comparación con nuestro conjunto de datos de pizza, bistec y sushi, este modelo tardará más en entrenarse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d525e07",
   "metadata": {},
   "source": [
    "## Extracurricular\n",
    "\n",
    "* Lea la publicación del blog [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html) de Richard Sutton para tener una idea de cuántos de los últimos avances en IA provienen de una mayor escala (conjuntos de datos más grandes). y modelos más grandes) y métodos más generales (menos meticulosamente elaborados).\n",
    "* Consulte el [tutorial de código/YouTube de PyTorch](https://pytorch.org/tutorials/beginner/introyt/tensorboardyt_tutorial.html) para TensorBoard durante 20 minutos y vea cómo se compara con el código que hemos escrito en este computadora portátil.\n",
    "* Quizás quieras ver y reorganizar los registros de TensorBoard de tu modelo con un DataFrame (para que puedas ordenar los resultados por menor pérdida o mayor precisión), hay una guía para esto [en la documentación de TensorBoard] (https://www.tensorflow .org/tensorboard/dataframe_api). \n",
    "* Si desea usar VSCode para el desarrollo usando scripts o cuadernos (VSCode ahora puede usar Jupyter Notebooks de forma nativa), puede configurar TensorBoard directamente dentro de VSCode usando la [Guía de desarrollo de PyTorch en VSCode] (https://code.visualstudio.com/ documentos/datascience/pytorch-support).\n",
    "* Para ir más allá con el seguimiento de experimentos y ver cómo se está desempeñando su modelo PyTorch desde una perspectiva de velocidad (¿hay algún cuello de botella que podría mejorarse para acelerar el entrenamiento?), consulte la [documentación de PyTorch para el generador de perfiles de PyTorch](https:// pytorch.org/blog/introduciendo-pytorch-profiler-the-new-and-improved-rendimiento-herramienta/).\n",
    "* Made With ML es un excelente recurso para todo lo relacionado con el aprendizaje automático de Goku Mohandas y su [guía sobre seguimiento de experimentos](https://madewithml.com/courses/mlops/experiment-tracking/) contiene una fantástica introducción al seguimiento del aprendizaje automático. experimentos con MLflow."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
