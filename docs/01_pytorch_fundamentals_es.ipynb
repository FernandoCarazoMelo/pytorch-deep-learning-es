{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Introducción a PyTorch. Tensores y Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Este primer tutorial cubre los siguientes temas:\n",
    "\n",
    "* Introducciones a los tensores PyTorch\n",
    "* Operaciones con tensores\n",
    "* Introducción a los gradientes tensoriales\n",
    "* Interoperabilidad entre PyTorch y Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de PyTorch\n",
    "<br>\n",
    "\n",
    "> **Nota:** Antes de ejecutar cualquier código en este cuaderno, deberías haber pasado por los [pasos de instalación de PyTorch](https://pytorch.org/get-started/locally/).\n",
    ">\n",
    "> **Si estás ejecutando en Google Colab**, no es necesario instalar ninguna librería (Google Colab tiene PyTorch y otras bibliotecas preinstaladas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Como alternativa, también se puede instalar directamente el requirments.txt localizado el repositorio de este notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instalado, se importa PyTorch y se comprueba la versión utilizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Yu40N6s6G3hC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a los tensores con Pytorch\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "### Tensores\n",
    "<br>\n",
    "En esencia, PyTorch es una biblioteca para procesar tensores. Un tensor es un número, vector, matriz o cualquier array de n dimensiones (también denominados simplemente tensores). \n",
    "\n",
    "Para empezar de forma sencilla, se creará un tensor con un solo número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1636709970149,
     "user": {
      "displayName": "Fernando Carazo Melo",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07036149080487308581"
     },
     "user_tz": -60
    },
    "id": "I6pas8ojG3hD",
    "outputId": "60bc4421-429b-4d1e-c079-db5773fff147"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escalares en PyTorch\n",
    "# ======================================================================================\n",
    "t1 = torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "`4.` es una abreviatura de `4.0`. Se utiliza para indicar a Python (y PyTorch) que desea crear un número de coma flotante. Se puede verificar esto comprobando el atributo `dtype` de nuestro tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42795,
     "status": "ok",
     "timestamp": 1619706528250,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "7pGtb7yMG3hG",
    "outputId": "8f5fc137-2e6d-4a66-a4ba-eb8ab47f4315"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de dato de un tensor\n",
    "# ======================================================================================\n",
    "t1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Creación de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39711,
     "status": "ok",
     "timestamp": 1619706528250,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "Z1ACleEUG3hJ",
    "outputId": "1547381d-372d-4296-c976-a4078dc93bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.])\n",
      "torch.float32\n",
      "tensor([1, 2, 3, 4])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Vector de 1 dimensión\n",
    "# ======================================================================================\n",
    "t2 = torch.tensor([1., 2, 3, 4])\n",
    "t2_int = torch.tensor([1, 2, 3, 4])\n",
    "print(t2)\n",
    "print(t2.dtype)\n",
    "print(t2_int)\n",
    "print(t2_int.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede ver, todos los números del tensor tienen el mismo tipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dimensión ahora es 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20183,
     "status": "ok",
     "timestamp": 1619706528251,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "_igxt7hAG3hK",
    "outputId": "5dcfa126-112a-42df-a676-188532fb6af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrices \n",
    "# ======================================================================================\n",
    "t3 = torch.tensor([[5., 6], \n",
    "                   [7, 8], \n",
    "                   [9, 10]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tensores propiamente dichos son aquellos arrays de 3 dimensiones o más, aunque se suele hablar de tensores siempre que son de objeto tensor. Los tensores son la estructura de datos básica en PyTorch.\n",
    "\n",
    "Los tensores son similares a los arrays de NumPy, pero pueden ser usados en GPUs para acelerar los cálculos, como se verá más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1619706592421,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "Wrf7xvhrG3hL",
    "outputId": "f33b110b-4148-4072-deac-77d1457e045b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11., 12., 13., 10.],\n",
       "         [11., 12., 13., 10.],\n",
       "         [13., 14., 15., 10.]],\n",
       "\n",
       "        [[15., 16., 17., 10.],\n",
       "         [11., 12., 13., 10.],\n",
       "         [17., 18., 19., 10.]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor tridimensional\n",
    "# ======================================================================================\n",
    "t4 = torch.tensor([\n",
    "    [[11, 12, 13, 10],\n",
    "     [11, 12, 13, 10], \n",
    "     [13, 14, 15, 10]], \n",
    "    [[15, 16, 17, 10], \n",
    "     [11, 12, 13, 10],\n",
    "     [17, 18, 19., 10]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Los tensores pueden tener cualquier número de dimensiones y diferentes longitudes a lo largo de cada dimensión. Se puede inspeccionar la longitud a lo largo de cada dimensión usando la propiedad `.shape` de un tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Al igual que pasa con numpy, no es posible crear tensores con una dimensionalidad incompatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "executionInfo": {
     "elapsed": 819,
     "status": "error",
     "timestamp": 1619706661132,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "C2XWpjiUG3hR",
    "outputId": "c7f2cab3-a69f-4bc2-87c7-ad55e5157440"
   },
   "outputs": [],
   "source": [
    "# Tensor con dimensiones imcompatibles\n",
    "# ======================================================================================\n",
    "# t5 = torch.tensor([[5., 6, 11], \n",
    "#                    [7, 8], \n",
    "#                    [9, 10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "El `ValueError` se debe a que las longitudes de las filas `[5., 6, 11]` y `[7, 8]` no coinciden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores aleatorios\n",
    "<br>\n",
    "Los modelos de aprendizaje automático como las redes neuronales manipulan y buscan patrones dentro de los tensores. Cuando se construyen modelos de aprendizaje automático con PyTorch, es raro que se creen tensores a mano.\n",
    "\n",
    "Sin embargo, un modelo de aprendizaje automático a menudo comienza con grandes tensores de números aleatorios (weights and biases) que posteriormente se ajustan estos números aleatorios a medida que trabaja a través de los datos para representarlos mejor.\n",
    "\n",
    "Para crear tensores con números aleatorios entre [0,1] se utiliza la funicón [`torch.rand ()`](https://pytorch.org/docs/stable/generated/torch.rand.html) pasando el parámetro `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8955, 0.7819, 0.9867, 0.6980],\n",
       "         [0.8123, 0.1524, 0.3739, 0.8194],\n",
       "         [0.0155, 0.1711, 0.2164, 0.8552]]),\n",
       " torch.float32,\n",
       " torch.Size([3, 4]),\n",
       " 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor con valores aleatorios de dimensiones (3, 4)\n",
    "# ======================================================================================\n",
    "tensor_aleatorio = torch.rand(size=(3, 4))\n",
    "# Se imprime por pantalla\n",
    "tensor_aleatorio, tensor_aleatorio.dtype, tensor_aleatorio.shape, tensor_aleatorio.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones con tensores\n",
    "<br>\n",
    "En el aprendizaje profundo, los datos (imágenes, texto, video, audio, estructuras de proteínas, etc.) se representan como tensores.\n",
    "\n",
    "Para codificar una red neuronal, es necesario realizar operaciones básicas entre tensores:\n",
    "* Suma\n",
    "* Resta\n",
    "* Multiplicación (elemento a elemento)\n",
    "* División\n",
    "* Multiplicación de matrices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comencemos con algunas de las operaciones fundamentales, suma (`+`), resta (`-`), multiplicación (`*`).\n",
    "\n",
    "Funcionan tal como piensas que lo harían, como en numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suma\n",
    "# ======================================================================================\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación por un escalar\n",
    "# ======================================================================================\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resta\n",
    "# ======================================================================================\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicación de matrices\n",
    "<br>\n",
    "Una de las operaciones más comunes en los algoritmos de aprendizaje automático y aprendizaje profundo (como las redes neuronales) es la [multiplicación de matrices](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "PyTorch implementa la funcionalidad de multiplicación de matrices en el método [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Las dos reglas principales para la multiplicación de matrices a recordar son:\n",
    "1. Las **dimensiones internas** deben coincidir:\n",
    "  * `(3, 2) @ (3, 2)` no funcionará\n",
    "  * `(2, 3) @ (3, 2)` funcionará\n",
    "  * `(3, 2) @ (2, 3)` funcionará\n",
    "2. La matriz resultante tiene la forma de las **dimensiones externas**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **Nota:** \"`@`\" en Python es el símbolo para la multiplicación de matrices.\n",
    ">\n",
    "> **Recurso:** Puede ver todas las reglas para la multiplicación de matrices usando `torch.matmul()` [en la documentación de PyTorch](https://pytorch.org/docs/stable/generated/torch.matmul.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia entre la multiplicación elemento a elemento y la multiplicación de matrices es la adición de valores.\n",
    "\n",
    "Para nuestra variable `tensor` con valores `[1, 2, 3]`:\n",
    "\n",
    "| Operación | Cálculo | Código |\n",
    "| ----- | ----- | ----- |\n",
    "| **Multiplicación elemento a elemento** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **Multiplicación de matrices** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación elemento a elemento de tensores\n",
    "# ======================================================================================\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación matricial con el operador @\n",
    "# ======================================================================================\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación matricial con el método matmul\n",
    "# ======================================================================================\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de los valores maximo, minimo, media y suma de un tensor\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se crea un tensor\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 1.0\n",
      "Max: 3.0\n",
      "Media: 1.6666666269302368\n",
      "Suma: 10.0\n"
     ]
    }
   ],
   "source": [
    "# Cálculo de los valores maximo, minimo, media y suma de un tensor\n",
    "# ======================================================================================\n",
    "x = torch.tensor([1,2,1,3,1,2], dtype=torch.float32)  # para calcular la media hay que convertir a float\n",
    "print(f\"Min: {x.min()}\")\n",
    "print(f\"Max: {x.max()}\")\n",
    "print(f\"Media: {x.mean()}\")\n",
    "print(f\"Suma: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min/Max posicional\n",
    "<br>\n",
    "También se puede encontrar el índice de un tensor donde ocurre el máximo o el mínimo con [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) y [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectivamente.\n",
    "\n",
    "Esto es útil en caso de que sólo se quiera la posición donde está el valor más alto (o más bajo) y no el valor en sí (lo veremos en una sección posterior cuando usemos la [función de activación softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Obtención del índice del valor máximo y mínimo de un tensor\n",
    "# ======================================================================================\n",
    "# Se crea un tensor secuencial\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Se devuelve el índice del valor máximo y mínimo\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ejercicio** Hasta ahora se han cubierto algunos métodos de tensor, pero hay muchos más en la documentación de [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html), se recomienda revisar la web y repasar  cualquier función o método que llame la atención."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras funciones tensoriales\n",
    "<br>\n",
    "El módulo `torch` también contiene muchas funciones para crear y manipular tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[42, 42],\n",
       "        [42, 42],\n",
       "        [42, 42]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Crear un tensor con un valor fijo para cada elemento\n",
    "# ======================================================================================\n",
    "tensor = torch.full((3, 2), 42)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar funciones matemáticas a un tensor, hay que realizarlo a través de una función de torch. En la [documentación](https://pytorch.org/docs/stable/index.html) de PyTorch, se pueden encontrar muchas otras funciones matematicas. Se recomienda dedicar un tiempo a revisar la documentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165],\n",
       "        [-0.9165, -0.9165]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seno de un tensor\n",
    "# ======================================================================================\n",
    "tensor_sin = torch.sin(tensor)\n",
    "tensor_sin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganización, apilamiento y permutación\n",
    "<br>\n",
    "Frecuentemente se quiere reorganizar o cambiar las dimensiones de los tensores sin cambiar los valores que contienen.\n",
    "\n",
    "Para hacerlo, algunos métodos populares son:\n",
    "\n",
    "| Método | Descripción |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reorganiza `input` a `shape` (si es compatible), también se puede usar `torch.Tensor.reshape()`. |\n",
    "| [`torch.Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Devuelve una vista del tensor original en una `shape` diferente pero comparte los mismos datos que el tensor original. |\n",
    "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatena una secuencia de `tensors` a lo largo de una nueva dimensión (`dim`), todos los `tensors` deben tener el mismo tamaño. |\n",
    "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Devuelve una *vista* del `input` original con sus dimensiones permutadas (reorganizadas) a `dims`. |\n",
    "\n",
    "redes neuronales) se tratan de manipular tensores de alguna manera. Y debido a las reglas de la multiplicación de matrices, si hay incompatibilidades de forma, se producirán errores. Estos métodos te ayudan a asegurarte de que los elementos correctos de tus tensores se mezclan con los elementos correctos de otros tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se crea un tensor de 1 dimensión con los valores del 1 al 7\n",
    "# ======================================================================================\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadimos una dimensión extra con `torch.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se añade una dimension extra al tensor x\n",
    "# ======================================================================================\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con view se puede hacer lo mismo, pero sin crear una copia del tensor original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con el método view\n",
    "# ======================================================================================\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiamos un elemento y se cambia en los dos tensores\n",
    "# ======================================================================================\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tensores pueden ser cambiados de dimensiones, pero la cantidad de elementos debe ser la misma. Y, por lo tanto, las dimensiones deben de ser compatibles.\n",
    "\n",
    "Por ejemplo, un tensor de dimensión (10, 10, 3) tiene 300 elementos. Lo podríamos cambiár a la diemensión (30, 10), pero no a otra incompatible como (4, 10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 3])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se crea un tensor\n",
    "# ======================================================================================\n",
    "x = torch.randn(10, 10, 3)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 10])\n",
      "torch.Size([3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Cambiamos la dimesión de un tensor\n",
    "# ======================================================================================\n",
    "y = x.reshape(30,10)\n",
    "print(y.shape)\n",
    "y = x.reshape(3,10,10)\n",
    "print(y.shape)\n",
    "# Dimensiones incompatibles\n",
    "# y = x.reshape(4,10,10)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Si se utiliza el -1 como valor de una dimensión, esta se calculará automáticamente para que la cantidad de elementos sea la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Equivale a poner -1 en la dimensión que se quiere calcular automáticamente\n",
    "y = x.reshape(3,-1,10)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueede obtener más información sobre las operaciones de tensor aquí: https://pytorch.org/docs/stable/torch.html. Se recomienda experimentar 5-10 funciones y operaciones de tensor para familiarizarse con la librería."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para apilar tensores se utiliza la función `torch.stack()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [1, 2, 3, 4],\n",
       "        [1, 2, 3, 4],\n",
       "        [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apilar tensores - horizontalmente\n",
    "# ======================================================================================\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) \n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3],\n",
       "        [4, 4, 4, 4]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apilar tensores - verticalmente\n",
    "# ======================================================================================\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se puede reordenar el orden de los valores de los ejes con `torch.permute(input, dims)`, donde el `input` se convierte en una *vista* con nuevos `dims`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicial: torch.Size([224, 224, 3])\n",
      "Final: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Permutar tensor\n",
    "\n",
    "# Se crea un tensor con una forma específica\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Se permuta el tensor\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Inicial: {x_original.shape}\")\n",
    "print(f\"Final: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Debido a que permutar devuelve una *vista* (comparte los mismos datos que el original), los valores en el tensor permutado serán los mismos que el tensor original y si cambias los valores en la vista, cambiará los valores del original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Tensores y Gradientes\n",
    "<br>\n",
    "\n",
    "Una de las propiedades más importantes de PyTorch es que se pueden calcular los gradientes, o derivadas, de los tensores. Esto es muy útil para el entrenamiento de redes neuronales, ya que se puede calcular el error de la red y ajustar los pesos para minimizar el error con el algoritmo del descenso del gradiente.\n",
    "\n",
    "\n",
    "Como se verá más adelante, el algoritmo del descenso del gradiente es el que se utiliza para ajustar los pesos de la red. Este algoritmo consiste en calcular el gradiente de la función de error con respecto a los pesos, y actualizar los pesos en la dirección opuesta al gradiente, ya que en esa dirección la función de error decrece más rápidamente.\n",
    "\n",
    "\n",
    "Por este motivo, es muy importante que la librería utilizada permita calcular de forma eficiente los gradientes de un tensor. A continuación mostramos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1619706864184,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "98zxma0XG3hV",
    "outputId": "4848d6fd-1719-4939-cd8a-80e0199d2094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de tensores\n",
    "# ======================================================================================\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)\n",
    "x, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Se han creado tres tensores: `x`, `w` y `b`, todos son simplemente números. `w` y `b` tienen un parámetro adicional `requires_grad` establecido en `True`. Ahora se verá su importante función.\n",
    "\n",
    "Ahora se creará un nuevo tensor `y` combinando estos tensores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1619706865124,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "JNYP-YVNG3hb",
    "outputId": "f47b5bbc-adff-40ea-bc1f-76d5dd740030"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Operación aritmetica\n",
    "# ======================================================================================\n",
    "y = w * x**2 + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Como era de esperar, `y` es un tensor con el valor $4 * 3^2 + 5 = 41$. \n",
    "\n",
    "Lo que hace único a PyTorch es que podemos calcular automáticamente la derivada de `y`!\n",
    "\n",
    "Los tensores que tienen `requires_grad` establecido en `True`, es decir, w y b. Esta característica de PyTorch se llama_autograd_ (gradientes automáticos).\n",
    "\n",
    "Para calcular las derivadas, podemos invocar el método `.backward` en nuestro resultado `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "jcaBi_oJG3hc",
    "lang": "en"
   },
   "outputs": [],
   "source": [
    "# Calculamos las derivadas\n",
    "# ======================================================================================\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Las derivadas de `y` con respecto a los tensores de entrada se almacenan en la propiedad `.grad` de los respectivos tensores. Se puede observar que `x` tiene una derivada igual a `None` porque no se ha incluido el parámetro `requires_grad` en su definición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1619706868509,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "DhSsONL3G3hc",
    "outputId": "bb9887ee-c328-4c3a-b3d8-aaf503ffa6e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: None\n",
      "dy/dw: tensor(9.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Obtención de las derivadas\n",
    "# ======================================================================================\n",
    "print('dy/dx:', x.grad)\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Como era de esperar, `dy/dw` tiene el mismo valor que `x`, es decir, `3`, y `dy/db` tiene el valor `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presenta a continuación un segundo ejemplo:   \n",
    "\n",
    "$y=2*x^2$\n",
    "\n",
    "Donde,\n",
    "\n",
    "+ dy/dx = 4x\n",
    "+ como x=3, dy/dx = 4*3 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1619706992129,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "Dhw3QHOqIjbQ",
    "outputId": "d734fd17-9755-4f19-c441-2a92ef5b5a2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otro ejemplo\n",
    "# ======================================================================================\n",
    "x = torch.tensor(3., requires_grad=True)\n",
    "y = 2*x**2\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta propiedad de los tensores es muy útil para la implementación de redes neuronales, ya que permite definir el tamaño de las capas de forma dinámica, en función de los datos de entrada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "## Interoperabilidad con Numpy\n",
    "<br>\n",
    "\n",
    "[Numpy](http://www.numpy.org/) es una popular biblioteca de código abierto que se utiliza para la computación matemática y científica en Python. Permite operaciones eficientes en grandes arrays multidimensionales y tiene un vasto ecosistema de bibliotecas de soporte, que incluyen:\n",
    "\n",
    "*[Pandas](https://pandas.pydata.org/) para E/S de archivos y análisis de datos* [Matplotlib](https://matplotlib.org/) para trazado y visualización\n",
    "* [OpenCV](https://opencv.org/) para procesamiento de imágenes y videos\n",
    "\n",
    "Una pregunta que surge a menudo es por qué necesitamos una biblioteca como PyTorch, ya que Numpy ya proporciona estructuras de datos y utilidades para trabajar con datos numéricos multidimensionales. \n",
    "\n",
    "Hay dos razones principales:\n",
    "\n",
    "1. **Autograd**: la capacidad de calcular gradientes automáticamente para operaciones de tensor es esencial para entrenar modelos de aprendizaje profundo.\n",
    "2. **Compatibilidad con GPU**: al trabajar con conjuntos de datos masivos y modelos grandes, las operaciones de tensor de PyTorch se pueden realizar de manera eficiente utilizando una Unidad de procesamiento de gráficos (GPU). Los cálculos que normalmente pueden llevar horas se pueden completar en minutos usando GPU.\n",
    "\n",
    "Aprovecharemos ampliamente estas dos funciones de PyTorch en esta serie de tutoriales.\n",
    "\n",
    "\n",
    "En lugar de reinventar la rueda, PyTorch interactúa bien con Numpy para aprovechar su ecosistema existente de herramientas y bibliotecas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Así es como se crea una matriz en Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1317,
     "status": "ok",
     "timestamp": 1619707167562,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "GvB7afRdG3hm",
    "outputId": "c32fcf86-290d-479b-aa14-37ccdd256db8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación de un array de numpy\n",
    "# ======================================================================================\n",
    "x = np.array([[1, 2], [3, 4.]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Se puede convertir una matriz Numpy en un tensor PyTorch de forma muy sencilla usando `torch.from_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1619707171984,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "buH3Wmc6G3hn",
    "outputId": "01a8e01b-baaa-4467-9378-e2c63a6e9644"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambio de numpy a tensor\n",
    "# ======================================================================================\n",
    "y = torch.from_numpy(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Se verifica que la matriz numpy y el tensor de antorcha tengan tipos de datos similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1619707174572,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "hruhtXbdG3ho",
    "outputId": "e5227d3c-b0d6-4464-b3e5-3ee3bc12f2a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype, y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "También se pueda hacer el paso contrario: convertir un tensor PyTorch en una matriz Numpy. Para ello se utiliza el método `.numpy` de un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1619707188514,
     "user": {
      "displayName": "Fer C",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gji1zaID25-JE2zk84bsFruB1qAgYhl3sENYORs2aI=s64",
      "userId": "11587814752720571700"
     },
     "user_tz": -120
    },
    "id": "n83IfEtjG3hq",
    "outputId": "ed49a206-f631-4b2f-f0d0-ea29be1e45e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [3., 4.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir un tensor de torch a un array de numpy\n",
    "# ======================================================================================\n",
    "z = y.numpy()\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "La interoperabilidad entre PyTorch y Numpy es esencial porque la mayoría de los conjuntos de datos con los que trabajará probablemente se leerán y preprocesarán como matrices de Numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de sesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "numpy               1.25.2\n",
      "session_info        1.0.0\n",
      "torch               2.0.1\n",
      "-----\n",
      "IPython             8.14.0\n",
      "jupyter_client      8.3.0\n",
      "jupyter_core        5.3.1\n",
      "jupyterlab          4.0.5\n",
      "notebook            7.0.3\n",
      "-----\n",
      "Python 3.10.12 (main, Jul  5 2023, 15:34:07) [Clang 14.0.6 ]\n",
      "macOS-10.16-x86_64-i386-64bit\n",
      "-----\n",
      "Session information updated at 2023-09-02 11:33\n"
     ]
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show(html=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía y recursos\n",
    "<br>\n",
    "\n",
    "Recursos y bibliografia de Deep Learning con PyToch\n",
    "\n",
    "+ [PyTorch Tutorials](https://pytorch.org/tutorials/)\n",
    "+ [PyTorch API](https://pytorch.org/docs/stable/index.html)\n",
    "+ [Redes Neuronales y Deep Learning](https://www.deeplearningbook.org/)\n",
    "+ [Jovian.ai](https://jovian.ai/)\n",
    "+ [Daniel Bourke](https://www.mrdbourke.com/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "zVTQttAAG3hv",
    "VWPi6ltzG3hx",
    "FQ0QpiMGG3hz"
   ],
   "name": "01-pytorch-basics_FC_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
