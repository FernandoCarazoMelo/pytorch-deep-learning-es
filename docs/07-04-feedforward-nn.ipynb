{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c6a83f",
   "metadata": {},
   "source": [
    "# Entrenamiento de redes neuronales profundas en una GPU con PyTorch\n",
    "\n",
    "### Parte 4 de \"Aprendizaje profundo con Pytorch: de cero a GAN\"\n",
    "\n",
    "Esta serie de tutoriales es una introducción práctica y sencilla para principiantes al aprendizaje profundo utilizando [PyTorch](https://pytorch.org), una biblioteca de redes neuronales de código abierto. Estos tutoriales adoptan un enfoque práctico y centrado en la codificación. La mejor manera de aprender el material es ejecutar el código y experimentar con él usted mismo. Mira la serie completa aquí:\n",
    "\n",
    "1. [Conceptos básicos de PyTorch: tensores y degradados] (https://jovian.ai/aakashns/01-pytorch-basics)\n",
    "2. [Descenso de gradiente y regresión lineal](https://jovian.ai/aakashns/02-linear-regression)\n",
    "3. [Trabajar con imágenes y regresión logística](https://jovian.ai/aakashns/03-logistic-regression) \n",
    "4. [Entrenamiento de redes neuronales profundas en una GPU](https://jovian.ai/aakashns/04-feedforward-nn)\n",
    "5. [Clasificación de imágenes mediante redes neuronales convolucionales] (https://jovian.ai/aakashns/05-cifar10-cnn)\n",
    "6. [Aumento de datos, regularización y ResNets](https://jovian.ai/aakashns/05b-cifar10-resnet)\n",
    "7. [Generación de imágenes mediante redes generativas adversarias](https://jovian.ai/aakashns/06b-anime-dcgan/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c88ab7",
   "metadata": {},
   "source": [
    "Este tutorial cubre los siguientes temas:\n",
    " \n",
    " * Creando una red neuronal profunda con capas ocultas.\n",
    " * Usando una función de activación no lineal\n",
    " * Usar una GPU (cuando esté disponible) para acelerar el entrenamiento\n",
    " * Experimentar con hiperparámetros para mejorar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f552da6",
   "metadata": {},
   "source": [
    "### Cómo ejecutar el código\n",
    "\n",
    "Este tutorial es un ejecutable [Jupyter notebook](https://jupyter.org) alojado en [Jovian](https://www.jovian.ai). Puede _ejecutar_ este tutorial y experimentar con los ejemplos de código de dos maneras: *usando recursos gratuitos en línea* (recomendado) o *en su computadora*.\n",
    "\n",
    "#### Opción 1: Ejecutar usando recursos en línea gratuitos (1 clic, recomendado)\n",
    "\n",
    "La forma más sencilla de comenzar a ejecutar el código es hacer clic en el botón **Ejecutar** en la parte superior de esta página y seleccionar **Ejecutar en Colab**. [Google Colab](https://colab.research.google.com) es una plataforma en línea gratuita para ejecutar portátiles Jupyter utilizando la infraestructura en la nube de Google. También puede seleccionar \"Ejecutar en Binder\" o \"Ejecutar en Kaggle\" si tiene problemas al ejecutar el cuaderno en Google Colab. \n",
    "\n",
    "\n",
    "#### Opción 2: ejecutar en su computadora localmente\n",
    "\n",
    "Para ejecutar el código en su computadora localmente, deberá configurar [Python](https://www.python.org), descargar el cuaderno e instalar las bibliotecas necesarias. Recomendamos utilizar la distribución [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) de Python. Haga clic en el botón **Ejecutar** en la parte superior de esta página, seleccione la opción **Ejecutar localmente** y siga las instrucciones.\n",
    "\n",
    "> **Jupyter Notebooks**: este tutorial es un [Jupyter notebook](https://jupyter.org): un documento compuesto de _celdas_. Cada celda puede contener código escrito en Python o explicaciones en inglés sencillo. Puede ejecutar celdas de código y ver los resultados, por ejemplo, números, mensajes, gráficos, tablas, archivos, etc., instantáneamente dentro del cuaderno. Jupyter es una poderosa plataforma para la experimentación y el análisis. No tengas miedo de trastear con el código y romper cosas: aprenderás mucho encontrando y corrigiendo errores. Puede utilizar la opción de menú \"Kernel > Reiniciar y borrar salida\" o \"Editar > Borrar salidas\" para borrar todas las salidas y comenzar de nuevo desde arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641549e7",
   "metadata": {},
   "source": [
    "### Usando una GPU para un entrenamiento más rápido\n",
    "\n",
    "Puede utilizar una [Unidad de procesamiento de gráficos](https://en.wikipedia.org/wiki/Graphics_processing_unit) (GPU) para entrenar sus modelos más rápido si su plataforma de ejecución está conectada a una GPU fabricada por NVIDIA. Siga estas instrucciones para usar una GPU en la plataforma de su elección:\n",
    "\n",
    "* _Google Colab_: utilice la opción de menú \"Tiempo de ejecución > Cambiar tipo de tiempo de ejecución\" y seleccione \"GPU\" en el menú desplegable \"Acelerador de hardware\".\n",
    "* _Kaggle_: En la sección \"Configuración\" de la barra lateral, seleccione \"GPU\" en el menú desplegable \"Acelerador\". Utilice el botón en la parte superior derecha para abrir la barra lateral.\n",
    "* _Binder_: Las computadoras portátiles que ejecutan Binder no pueden usar una GPU, ya que las máquinas que alimentan Binder no están conectadas a ninguna GPU.\n",
    "* _Linux_: Si su computadora portátil/escritorio tiene una GPU (tarjeta gráfica) NVIDIA, asegúrese de haber instalado los [controladores NVIDIA CUDA] (https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index .html).\n",
    "* _Windows_: si su computadora portátil/escritorio tiene una GPU (tarjeta gráfica) NVIDIA, asegúrese de haber instalado los [controladores NVIDIA CUDA] (https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows /index.html).\n",
    "* _macOS_: macOS no es compatible con las GPU NVIDIA\n",
    "\n",
    "\n",
    "Si no tiene acceso a una GPU o no está seguro de cuál es, no se preocupe, puede ejecutar todo el código de este tutorial sin una GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f799ac6d",
   "metadata": {},
   "source": [
    "## Preparando los datos\n",
    "\n",
    "En [el tutorial anterior] (https://jovian.ai/aakashns/03-logistic-regression), entrenamos un modelo de regresión logística para identificar dígitos escritos a mano del conjunto de datos MNIST con una precisión de alrededor del 86%. El conjunto de datos consta de imágenes en escala de grises de 28 px por 28 px de dígitos escritos a mano (0 a 9) y etiquetas para cada imagen que indican qué dígito representa. Aquí hay algunas imágenes de muestra del conjunto de datos:\n",
    "\n",
    "![mnist-sample](https://i.imgur.com/CAYnuo1.jpg)\n",
    "\n",
    "Notamos que es bastante difícil mejorar la precisión de un modelo de regresión logística más allá del 87%, ya que el modelo supone una relación lineal entre las intensidades de los píxeles y las etiquetas de las imágenes. En esta publicación, intentaremos mejorarlo utilizando una *red neuronal de retroalimentación* que puede capturar relaciones no lineales entre entradas y objetivos.\n",
    "\n",
    "Comencemos instalando e importando los módulos y clases necesarios de `torch`, `torchvision`, `numpy` y `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b55c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomente y ejecute el comando apropiado para su sistema operativo, si es necesario\n",
    "\n",
    "# Linux / Carpeta\n",
    "# !pip install numpy matplotlib torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# ventanas\n",
    "# !pip install numpy matplotlib torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# Mac OS\n",
    "# !pip instalar numpy matplotlib antorcha torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5038bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "%matplotlib inline\n",
    "\n",
    "# Utilice un fondo blanco para las figuras matplotlib.\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141641c1",
   "metadata": {},
   "source": [
    "Podemos descargar los datos y crear un conjunto de datos de PyTorch usando la clase `MNIST` de `torchvision.datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c48b264",
   "metadata": {},
   "source": [
    "Veamos un par de imágenes del conjunto de datos. Las imágenes se convierten a tensores de PyTorch con la forma \"1x28x28\" (las dimensiones representan canales de color, ancho y alto). Podemos usar `plt.imshow` para mostrar las imágenes. Sin embargo, `plt.imshow` espera que los canales sean la última dimensión en un tensor de imagen, por lo que usamos el método `permute` para reordenar las dimensiones de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03344cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[0]\n",
    "print('image.shape:', image.shape)\n",
    "plt.imshow(image.permute(1, 2, 0), cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[0]\n",
    "print('image.shape:', image.shape)\n",
    "plt.imshow(image.permute(1, 2, 0), cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d547d",
   "metadata": {},
   "source": [
    "A continuación, usemos la función auxiliar `random_split` para reservar 10000 imágenes para nuestro conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adf271",
   "metadata": {},
   "source": [
    "Ahora podemos crear cargadores de datos PyTorch para entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b15719",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f8ca2",
   "metadata": {},
   "source": [
    "¿Puedes descubrir el propósito de los argumentos `num_workers` y `pin_memory`? Intente consultar la documentación: https://pytorch.org/docs/stable/data.html.\n",
    "\n",
    "Visualicemos un lote de datos en una cuadrícula usando la función `make_grid` de `torchvision`. También usaremos el método `.permute` en el tensor para mover los canales a la última dimensión, como lo esperaba `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc57b1",
   "metadata": {},
   "source": [
    "## Capas ocultas, funciones de activación y no linealidad\n",
    "\n",
    "Crearemos una red neuronal con dos capas: una _capa oculta_ y una _capa de salida_. Además, usaremos una _función de activación_ entre las dos capas. Veamos un ejemplo paso a paso para aprender cómo las capas ocultas y las funciones de activación pueden ayudar a capturar relaciones no lineales entre entradas y salidas.\n",
    "\n",
    "Primero, creemos un lote de tensores de entrada. Aplanaremos las imágenes `1x28x28` en vectores de tamaño `784`, para que puedan pasarse a un objeto `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images.shape:', images.shape)\n",
    "    inputs = images.reshape(-1, 784)\n",
    "    print('inputs.shape:', inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc119ad1",
   "metadata": {},
   "source": [
    "A continuación, creemos un objeto `nn.Linear`, que servirá como nuestra capa _oculta_. Estableceremos el tamaño de la salida de la capa oculta en 32. Este número se puede aumentar o disminuir para cambiar la _capacidad de aprendizaje_ del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = inputs.shape[-1]\n",
    "hidden_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8112c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571009b",
   "metadata": {},
   "source": [
    "Ahora podemos calcular salidas intermedias para el lote de imágenes pasando \"entradas\" a través de \"capa1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8723150",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a6c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_outputs = layer1(inputs)\n",
    "print('layer1_outputs.shape:', layer1_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86482728",
   "metadata": {},
   "source": [
    "Los vectores de imagen de tamaño `784` se transforman en vectores de salida intermedios de longitud `32` realizando una multiplicación matricial de la matriz de `inputs` con la matriz de pesos transpuesta de `layer1` y agregando el sesgo. Podemos verificar esto usando `torch.allclose`. Para obtener una explicación más detallada, revise el tutorial sobre [regresión lineal] (https://jovian.ai/aakshns/02-linear-regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_outputs_direct = inputs @ layer1.weight.t() + layer1.bias\n",
    "layer1_outputs_direct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(layer1_outputs, layer1_outputs_direct, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a57e8",
   "metadata": {},
   "source": [
    "Por lo tanto, \"layer1_outputs\" y \"inputs\" tienen una relación lineal, es decir, cada elemento de \"layer_outputs\" es una suma ponderada de elementos de \"inputs\". Por lo tanto, incluso cuando entrenamos el modelo y modificamos los pesos, la \"capa1\" solo puede capturar relaciones lineales entre las \"entradas\" y las \"salidas\".\n",
    "\n",
    "<img src=\"https://i.imgur.com/inXsLuq.png\" ancho=\"360\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f1ab8",
   "metadata": {},
   "source": [
    "A continuación, usaremos la función Unidad lineal rectificada (ReLU) como función de activación para las salidas. Tiene la fórmula `relu(x) = max(0,x)`, es decir, simplemente reemplaza los valores negativos en un tensor dado con el valor 0. ReLU es una función no lineal, como se ve aquí visualmente:\n",
    "\n",
    "<img src=\"https://i.imgur.com/yijV4xF.png\" ancho=\"420\">\n",
    "\n",
    "Podemos usar el método `F.relu` para aplicar ReLU a los elementos de un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf784d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.relu(torch.tensor([[1, -1, 0], \n",
    "                     [-0.1, .2, 3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87482e8b",
   "metadata": {},
   "source": [
    "Apliquemos la función de activación a `layer1_outputs` y verifiquemos que los valores negativos fueron reemplazados por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a16bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_outputs = F.relu(layer1_outputs)\n",
    "print('min(layer1_outputs):', torch.min(layer1_outputs).item())\n",
    "print('min(relu_outputs):', torch.min(relu_outputs).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3634c5",
   "metadata": {},
   "source": [
    "Ahora que hemos aplicado una función de activación no lineal, `relu_outputs` y `inputs` no tienen una relación lineal. Nos referimos a `ReLU` como la _función de activación_, porque para cada entrada se activan ciertas salidas (aquellas con valores distintos de cero) mientras que otras se apagan (aquellas con valores distintos de cero)\n",
    "\n",
    "A continuación, creemos una capa de salida para convertir vectores de longitud `hidden_size` en `relu_outputs` en vectores de longitud 10, que es la salida deseada de nuestro modelo (ya que hay 10 etiquetas de destino)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e005341",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 10\n",
    "layer2 = nn.Linear(hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2_outputs = layer2(relu_outputs)\n",
    "print(layer2_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5597296",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266b3ce",
   "metadata": {},
   "source": [
    "Como era de esperar, `layer2_outputs` contiene un lote de vectores de tamaño 10. Ahora podemos usar esta salida para calcular la pérdida usando `F.cross_entropy` y ajustar los pesos de `layer1` y `layer2` usando el descenso de gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df424f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(layer2_outputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4f0ec",
   "metadata": {},
   "source": [
    "Por lo tanto, nuestro modelo transforma `entradas` en `capa2_salidas` aplicando una transformación lineal (usando `capa1`), seguida de una activación no lineal (usando `F.relu`), seguida de otra transformación lineal (usando `capa2` ). Verifiquemos esto volviendo a calcular la salida usando operaciones matriciales básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3c3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versión ampliada de Layer2(F.relu(layer1(inputs)))\n",
    "outputs = (F.relu(inputs @ layer1.weight.t() + layer1.bias)) @ layer2.weight.t() + layer2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18015a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(outputs, layer2_outputs, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe55bb9",
   "metadata": {},
   "source": [
    "Tenga en cuenta que las \"salidas\" y las \"entradas\" no tienen una relación lineal debido a la función de activación no lineal \"F.relu\". A medida que entrenamos el modelo y ajustamos los pesos de \"capa1\" y \"capa2\", ahora podemos capturar relaciones no lineales entre las imágenes y sus etiquetas. En otras palabras, la introducción de la no linealidad hace que el modelo sea más potente y versátil. Además, dado que `hidden_size` no depende de las dimensiones de las entradas o salidas, lo variamos para aumentar la cantidad de parámetros dentro del modelo. También podemos introducir nuevas capas ocultas y aplicar la misma activación no lineal después de cada capa oculta.\n",
    "\n",
    "El modelo que acabamos de crear se llama red neuronal. Una _red neuronal profunda_ es simplemente una red neuronal con una o más capas ocultas. De hecho, el [Teorema de aproximación universal] (http://neuralnetworksanddeeplearning.com/chap4.html) establece que una red neuronal suficientemente grande y profunda puede calcular cualquier función arbitraria, es decir, puede aprender relaciones no lineales ricas y complejas entre entradas y objetivos. Aquí hay unos ejemplos:\n",
    "\n",
    "* Identificar si una imagen contiene un gato o un perro (o [algo más] (https://machinelearningmastery.com/introduction-to-the-imagenet-large-scale-visual-recognition-challenge-ilsvrc/))\n",
    "* Identificar el género de una canción usando una muestra de 10 segundos.\n",
    "* Clasificar las reseñas de películas como positivas o negativas según su contenido.\n",
    "* Navegar con vehículos autónomos utilizando una transmisión de video de la carretera.\n",
    "* Traducir oraciones del inglés al francés (y cientos de otros idiomas)\n",
    "* Convertir una grabación de voz a texto y viceversa\n",
    "* Y muchos más...\n",
    "\n",
    "Es difícil imaginar cómo el simple proceso de multiplicar entradas con matrices inicializadas aleatoriamente, aplicar activaciones no lineales y ajustar pesos repetidamente mediante el descenso de gradiente puede producir resultados tan sorprendentes. Los modelos de aprendizaje profundo a menudo contienen millones de parámetros, que en conjunto pueden capturar relaciones mucho más complejas de las que el cerebro humano puede comprender.\n",
    "\n",
    "Si no hubiéramos incluido una activación no lineal entre las dos capas lineales, la relación final entre entradas y salidas seguiría siendo lineal. Una simple refactorización de los cálculos ilustra esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Igual que capa2 (capa1 (entradas))\n",
    "outputs2 = (inputs @ layer1.weight.t() + layer1.bias) @ layer2.weight.t() + layer2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cree una sola capa para reemplazar las dos capas lineales\n",
    "combined_layer = nn.Linear(input_size, output_size)\n",
    "\n",
    "combined_layer.weight.data = layer2.weight @ layer1.weight\n",
    "combined_layer.bias.data = layer1.bias @ layer2.weight.t() + layer2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5beff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Igual que combine_layer(entradas)\n",
    "outputs3 = inputs @ combined_layer.weight.t() + combined_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(outputs2, outputs3, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67113492",
   "metadata": {},
   "source": [
    "### Guarda y sube tu libreta\n",
    "\n",
    "Ya sea que esté ejecutando este cuaderno Jupyter en línea o en su computadora, es esencial guardar su trabajo de vez en cuando. Puede continuar trabajando en un cuaderno guardado más tarde o compartirlo con amigos y colegas para permitirles ejecutar su código. [Jovian](https://jovian.ai/platform-features) ofrece una forma sencilla de guardar y compartir sus cuadernos de Jupyter en línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar la biblioteca\n",
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63190ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11c4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project='04-feedforward-nn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c9bd9",
   "metadata": {},
   "source": [
    "`jovian.commit` carga el cuaderno en su cuenta Jovian, captura el entorno Python y crea un enlace para compartir para su cuaderno, como se muestra arriba. Puede utilizar este enlace para compartir su trabajo y permitir que cualquiera (incluido usted) ejecute sus cuadernos y reproduzca su trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f35645",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Ahora estamos listos para definir nuestro modelo. Como se mencionó anteriormente, crearemos una red neuronal con una capa oculta. Esto es lo que eso significa:\n",
    "\n",
    "* En lugar de usar un solo objeto `nn.Linear` para transformar un lote de entradas (intensidades de píxeles) en salidas (probabilidades de clase), usaremos dos objetos `nn.Linear`. Cada uno de estos se denomina _capa_ en la red. \n",
    "\n",
    "* La primera capa (también conocida como capa oculta) transformará la matriz de entrada de la forma `batch_size x 784` en una matriz de salida intermedia de la forma `batch_size x hide_size`. El parámetro `hidden_size` se puede configurar manualmente (por ejemplo, 32 o 64).\n",
    "\n",
    "* Luego aplicaremos una *función de activación* no lineal a las salidas intermedias. La función de activación transforma elementos individuales de la matriz.\n",
    "\n",
    "* El resultado de la función de activación, que también es de tamaño `batch_size x hide_size`, se pasa a la segunda capa (también conocida como capa de salida).  La segunda capa lo transforma en una matriz de tamaño `batch_size x 10`. Podemos usar este resultado para calcular la pérdida y ajustar los pesos mediante el descenso de gradiente.\n",
    "\n",
    "\n",
    "Como se mencionó anteriormente, nuestro modelo contendrá una capa oculta. Así es como se ve visualmente:\n",
    "\n",
    "<img src=\"https://i.imgur.com/eN7FrpF.png\" ancho=\"480\">\n",
    "\n",
    "\n",
    "Definamos el modelo extendiendo la clase `nn.Module` de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b812f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        # Get intermediate outputs using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # Apply activation function\n",
    "        out = F.relu(out)\n",
    "        # Get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060171da",
   "metadata": {},
   "source": [
    "También necesitamos definir una función de \"precisión\" que calcule la precisión de la predicción del modelo en un lote de entradas. Se usa en `validation_step` arriba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee91420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5b811",
   "metadata": {},
   "source": [
    "Crearemos un modelo que contiene una capa oculta con 32 activaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a17cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 32 # you can change this\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387db04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel(input_size, hidden_size=32, out_size=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29292b",
   "metadata": {},
   "source": [
    "Echemos un vistazo a los parámetros del modelo. Esperamos ver una matriz de peso y sesgo para cada una de las capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47088924",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5314ec80",
   "metadata": {},
   "source": [
    "Intentemos generar algunos resultados usando nuestro modelo. Tomaremos el primer lote de 128 imágenes de nuestro conjunto de datos y las pasaremos a nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('Loss:', loss.item())\n",
    "    break\n",
    "\n",
    "print('outputs.shape : ', outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d102996d",
   "metadata": {},
   "source": [
    "## Usando una GPU\n",
    "\n",
    "A medida que aumentan los tamaños de nuestros modelos y conjuntos de datos, necesitamos usar GPU para entrenar nuestros modelos en un período de tiempo razonable. Las GPU contienen cientos de núcleos optimizados para realizar costosas operaciones matriciales en números de punto flotante rápidamente, lo que las hace ideales para entrenar redes neuronales profundas. Puede utilizar GPU de forma gratuita en [Google Colab](https://colab.research.google.com/) y [Kaggle](https://www.kaggle.com/kernels) o alquilar máquinas con GPU en servicios como [Google Cloud Platform](https://cloud.google.com/gpu/), [Amazon Web Services](https://docs.aws.amazon.com/dlami/latest/devguide/gpu.html), y [Paperspace](https://www.paperspace.com/).\n",
    "\n",
    "Podemos comprobar si hay una GPU disponible y si los controladores NVIDIA CUDA necesarios están instalados usando `torch.cuda.is_available`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d90a8",
   "metadata": {},
   "source": [
    "Definamos una función auxiliar para garantizar que nuestro código use la GPU si está disponible y use de manera predeterminada la CPU si no lo está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585400fb",
   "metadata": {},
   "source": [
    "A continuación, definamos una función que pueda mover datos y modelos a un dispositivo elegido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e52d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ba48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ff006",
   "metadata": {},
   "source": [
    "Finalmente, definimos una clase `DeviceDataLoader` para empaquetar nuestros cargadores de datos existentes y mover lotes de datos al dispositivo seleccionado. Curiosamente, no necesitamos ampliar una clase existente para crear un cargador de datos de PyTorch. Todo lo que necesitamos es un método `__iter__` para recuperar lotes de datos y un método `__len__` para obtener el número de lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6306572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d73b88",
   "metadata": {},
   "source": [
    "La palabra clave `yield` en Python se usa para crear una función generadora que se puede usar dentro de un bucle `for`, como se ilustra a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8377bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_numbers():\n",
    "    yield 10\n",
    "    yield 20\n",
    "    yield 30\n",
    "\n",
    "for value in some_numbers():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d115b",
   "metadata": {},
   "source": [
    "Ahora podemos empaquetar nuestros cargadores de datos usando `DeviceDataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51225c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c0c9a",
   "metadata": {},
   "source": [
    "Los tensores movidos a la GPU tienen una propiedad de \"dispositivo\" que incluye la palabra \"cuda\". Verifiquemos esto mirando un lote de datos de `valid_dl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, yb in val_loader:\n",
    "    print('xb.device:', xb.device)\n",
    "    print('yb:', yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b384237",
   "metadata": {},
   "source": [
    "## Entrenando el modelo\n",
    "\n",
    "Definiremos dos funciones: \"ajustar\" y \"evaluar\" para entrenar el modelo usando el descenso de gradiente y evaluar su desempeño en el conjunto de validación. Para obtener un tutorial detallado de estas funciones, consulte el [tutorial anterior](https://jovian.ai/aakashns/03-logistic-regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6ebe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498d743",
   "metadata": {},
   "source": [
    "Antes de entrenar el modelo, debemos asegurarnos de que los datos y los parámetros del modelo (pesos y sesgos) estén en el mismo dispositivo (CPU o GPU). Podemos reutilizar la función `to_device` para mover los parámetros del modelo al dispositivo correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafca4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo (en GPU)\n",
    "model = MnistModel(input_size, hidden_size=hidden_size, out_size=num_classes)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49a517",
   "metadata": {},
   "source": [
    "Veamos cómo se desempeña el modelo en el conjunto de validación con el conjunto inicial de ponderaciones y sesgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89dce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [evaluate(model, val_loader)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d529a20",
   "metadata": {},
   "source": [
    "La precisión inicial es de alrededor del 10%, como se podría esperar de un modelo inicializado aleatoriamente (ya que tiene una probabilidad de 1 entre 10 de obtener una etiqueta correcta al adivinar al azar).\n",
    "\n",
    "Entrenemos el modelo durante cinco épocas y observemos los resultados. Podemos utilizar una tasa de aprendizaje relativamente alta de 0,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319390f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history += fit(5, 0.5, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a86e8",
   "metadata": {},
   "source": [
    "¡96% es bastante bueno! Entrenemos el modelo para cinco épocas más a una tasa de aprendizaje más baja de 0,1 para mejorar aún más la precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history += fit(5, 0.1, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b04ef4",
   "metadata": {},
   "source": [
    "Ahora podemos trazar las pérdidas y las precisiones para estudiar cómo mejora el modelo con el tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2abdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [x['val_loss'] for x in history]\n",
    "plt.plot(losses, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Loss vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5362218",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [x['val_acc'] for x in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5653814",
   "metadata": {},
   "source": [
    "¡Nuestro modelo actual supera al modelo de regresión logística (que solo pudo lograr alrededor del 86% de precisión) por un margen considerable! Alcanza rápidamente una precisión del 97%, pero no mejora mucho más allá de esto. Para mejorar aún más la precisión, necesitamos hacer que el modelo sea más potente aumentando el tamaño de la capa oculta o agregando más capas ocultas con activaciones. Le animo a que pruebe ambos enfoques y vea cuál funciona mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b88a4",
   "metadata": {},
   "source": [
    "Como paso final, podemos guardar y confirmar nuestro trabajo usando la biblioteca \"joviana\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153da683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project='04-feedforward-nn', environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534ec04",
   "metadata": {},
   "source": [
    "## Pruebas con imágenes individuales\n",
    "\n",
    "Si bien hasta ahora hemos estado rastreando la precisión general de un modelo, también es una buena idea observar los resultados del modelo en algunas imágenes de muestra. Probemos nuestro modelo con algunas imágenes del conjunto de datos de prueba predefinido de 10000 imágenes. Comenzamos recreando el conjunto de datos de prueba con la transformación \"ToTensor\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir conjunto de datos de prueba\n",
    "test_dataset = MNIST(root='data/', \n",
    "                     train=False,\n",
    "                     transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ceb90",
   "metadata": {},
   "source": [
    "Definamos una función auxiliar `predict_image`, que devuelve la etiqueta predicha para un tensor de imagen único."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e9fa98",
   "metadata": {},
   "source": [
    "Probémoslo con algunas imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c2462",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbea9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_dataset[193]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e23b8c",
   "metadata": {},
   "source": [
    "Identificar dónde nuestro modelo funciona mal puede ayudarnos a mejorarlo, recopilando más datos de entrenamiento, aumentando/disminuyendo la complejidad del modelo y cambiando los hiperparámetros.\n",
    "\n",
    "Como paso final, veamos también la pérdida general y la precisión del modelo en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17120105",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size=256), device)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839d38c",
   "metadata": {},
   "source": [
    "Esperamos que esto sea similar a la precisión/pérdida en el conjunto de validación. De lo contrario, es posible que necesitemos un mejor conjunto de validación que tenga datos y distribución similares a los del conjunto de prueba (que a menudo proviene de datos del mundo real)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a3376f",
   "metadata": {},
   "source": [
    "Guardemos los pesos del modelo y adjuntémoslo al cuaderno usando `jovian.commit`. También registraremos el rendimiento del modelo en el conjunto de datos de prueba usando `jovian.log_metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.log_metrics(test_loss=result['val_loss'], test_acc=result['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c577678",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-feedforward.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8393e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(project='04-feedforward-nn', \n",
    "              environment=None, \n",
    "              outputs=['mnist-feedforward.pth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05edb9dd",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "Pruebe los siguientes ejercicios para aplicar los conceptos y técnicas que ha aprendido hasta ahora:\n",
    "\n",
    "* Ejercicios de codificación sobre entrenamiento de modelos de un extremo a otro: https://jovian.ai/aakashns/03-cifar10-feedforward\n",
    "* Cuaderno de inicio para modelos de aprendizaje profundo: https://jovian.ai/aakashns/fashion-feedforward-minimal\n",
    "\n",
    "Entrenar excelentes modelos de aprendizaje automático de manera confiable requiere práctica y experiencia. Intente experimentar con diferentes conjuntos de datos, modelos e hiperparámetros, es la mejor manera de adquirir esta habilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff5381",
   "metadata": {},
   "source": [
    "## Resumen y lecturas adicionales\n",
    "\n",
    "Aquí hay un resumen de los temas cubiertos en este tutorial:\n",
    "\n",
    "* Creamos una red neuronal con una capa oculta para mejorar el modelo de regresión logística del tutorial anterior. También utilizamos la función de activación ReLU para introducir no linealidad en el modelo, permitiéndole aprender relaciones más complejas entre las entradas (densidades de píxeles) y las salidas (probabilidades de clase).\n",
    "\n",
    "* Definimos algunas utilidades como `get_default_device`, `to_device` y `DeviceDataLoader` para aprovechar una GPU si está disponible, moviendo los datos de entrada y los parámetros del modelo al dispositivo apropiado.\n",
    "\n",
    "* Pudimos usar exactamente el mismo ciclo de entrenamiento: la función \"ajuste\" que habíamos definido anteriormente para entrenar el modelo y evaluarlo usando el conjunto de datos de validación.\n",
    "\n",
    "Hay muchas posibilidades para experimentar aquí y le recomiendo que utilice la naturaleza interactiva de Jupyter para jugar con los distintos parámetros. Aqui hay algunas ideas:\n",
    "\n",
    "* Intente cambiar el tamaño de la capa oculta o agregue más capas ocultas y vea si puede lograr una mayor precisión.\n",
    "\n",
    "* Intente cambiar el tamaño del lote y la tasa de aprendizaje para ver si puede lograr la misma precisión en menos épocas.\n",
    "\n",
    "* Compare los tiempos de entrenamiento en una CPU frente a una GPU. ¿Ves una diferencia significativa? ¿Cómo varía con el tamaño del conjunto de datos y el tamaño del modelo (número de pesos y parámetros)?\n",
    "\n",
    "* Intente crear un modelo para un conjunto de datos diferente, como los [conjuntos de datos CIFAR10 o CIFAR100](https://www.cs.toronto.edu/~kriz/cifar.html).\n",
    "\n",
    "Aquí hay algunas referencias para lectura adicional:\n",
    "\n",
    "* [Una prueba visual de que las redes neuronales pueden calcular cualquier función] (http://neuralnetworksanddeeplearning.com/chap4.html), también conocido como teorema de aproximación universal.\n",
    "\n",
    "* [Pero ¿qué *es* una red neuronal?](https://www.youtube.com/watch?v=aircAruvnKk) - Una introducción visual e intuitiva a qué son las redes neuronales y qué representan las capas intermedias\n",
    "\n",
    "* [Notas de la conferencia Stanford CS229 sobre retropropagación](https://github.com/BirajCoder/File-host-repo/blob/main/backprop.pdf) - para un tratamiento más matemático de cómo se calculan los gradientes y se actualizan los pesos para Redes neuronales con múltiples capas.\n",
    "\n",
    "\n",
    "Ahora está listo para pasar al siguiente tutorial: [Clasificación de imágenes mediante redes neuronales convolucionales] (https://jovian.ai/aakashns/05-cifar10-cnn)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
