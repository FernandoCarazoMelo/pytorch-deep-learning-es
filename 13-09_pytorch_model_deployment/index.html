
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Apuntes personales de Fernando Carazo">
      
      
      
        <link rel="canonical" href="https://fernandocarazomelo.github.io/pytorch-deep-learning-es/13-09_pytorch_model_deployment/">
      
      
        <link rel="prev" href="../12-08_pytorch_paper_replicating/">
      
      
        <link rel="next" href="../embeddings/">
      
      
      <link rel="icon" href="../assets/iconp.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.28">
    
    
      
        <title>09. Implementación del modelo PyTorch - Apuntes de PyTorch y Redes Neuronales</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.6543a935.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="13-09_pytorch_model_deployment.ipynb - Apuntes de PyTorch y Redes Neuronales" >
      
        <meta  property="og:description"  content="Apuntes personales de Fernando Carazo" >
      
        <meta  property="og:image"  content="https://fernandocarazomelo.github.io/pytorch-deep-learning-es/assets/images/social/13-09_pytorch_model_deployment.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://fernandocarazomelo.github.io/pytorch-deep-learning-es/13-09_pytorch_model_deployment/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="13-09_pytorch_model_deployment.ipynb - Apuntes de PyTorch y Redes Neuronales" >
      
        <meta  name="twitter:description"  content="Apuntes personales de Fernando Carazo" >
      
        <meta  name="twitter:image"  content="https://fernandocarazomelo.github.io/pytorch-deep-learning-es/assets/images/social/13-09_pytorch_model_deployment.png" >
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#09-implementacion-del-modelo-pytorch" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Apuntes de PyTorch y Redes Neuronales" class="md-header__button md-logo" aria-label="Apuntes de PyTorch y Redes Neuronales" data-md-component="logo">
      
  <img src="../assets/iconp.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Apuntes de PyTorch y Redes Neuronales
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              09. Implementación del modelo PyTorch
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Apuntes de PyTorch y Redes Neuronales" class="md-nav__button md-logo" aria-label="Apuntes de PyTorch y Redes Neuronales" data-md-component="logo">
      
  <img src="../assets/iconp.png" alt="logo">

    </a>
    Apuntes de PyTorch y Redes Neuronales
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PyTorch y Redes Neuronales
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_pytorch_fundamentals_es/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01. Fundamentos de PyTorch y Descenso de Gradiente
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_pytorch_linear_regression_es/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    02. Introducción a Redes Neuronales con PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_pytorch_logistic_regression_es/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    03. Procesamiento de Imágenes y Regresión Logística
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../04-00_pytorch_fundamentals/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    00. Fundamentos de PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../05-01_pytorch_workflow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    01. Fundamentos del flujo de trabajo de PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../06-04_pytorch_custom_datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    04. Conjuntos de datos personalizados de PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../07-04-feedforward-nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Entrenamiento de redes neuronales profundas en una GPU con PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../08-05-cifar10-cnn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Clasificación de imágenes utilizando redes neuronales convolucionales en PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../09-03_pytorch_computer_vision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    03. Visión por computadora PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../10-07_pytorch_experiment_tracking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    07. Seguimiento del experimento de PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../11-06_pytorch_transfer_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    06. Aprendizaje por transferencia de PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../12-08_pytorch_paper_replicating/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    08. Replicación de papel PyTorch
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    09. Implementación del modelo PyTorch
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    09. Implementación del modelo PyTorch
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#que-es-la-implementacion-del-modelo-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Qué es la implementación del modelo de aprendizaje automático?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#por-que-implementar-un-modelo-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Por qué implementar un modelo de aprendizaje automático?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diferentes-tipos-de-implementacion-de-modelos-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      Diferentes tipos de implementación de modelos de aprendizaje automático
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Diferentes tipos de implementación de modelos de aprendizaje automático">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-donde-ira" class="md-nav__link">
    <span class="md-ellipsis">
      ¿A dónde irá?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#como-va-a-funcionar" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Cómo va a funcionar?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formas-de-implementar-un-modelo-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      Formas de implementar un modelo de aprendizaje automático
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#que-vamos-a-cubrir" class="md-nav__link">
    <span class="md-ellipsis">
      Qué vamos a cubrir
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#donde-puedes-obtener-ayuda" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Dónde puedes obtener ayuda?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#0-configuracion" class="md-nav__link">
    <span class="md-ellipsis">
      0. Configuración
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-obtener-datos" class="md-nav__link">
    <span class="md-ellipsis">
      1. Obtener datos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-esquema-del-experimento-de-implementacion-del-modelo-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      2. Esquema del experimento de implementación del modelo FoodVision Mini
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-creando-un-extractor-de-funciones-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3. Creando un extractor de funciones EffNetB2
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Creando un extractor de funciones EffNetB2">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-creando-una-funcion-para-hacer-un-extractor-de-caracteristicas-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Creando una función para hacer un extractor de características EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-creando-cargadores-de-datos-para-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Creando cargadores de datos para EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-entrenamiento-del-extractor-de-funciones-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Entrenamiento del extractor de funciones de EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-inspeccionando-las-curvas-de-perdida-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 Inspeccionando las curvas de pérdida de EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-guardar-el-extractor-de-funciones-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 Guardar el extractor de funciones de EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-comprobar-el-tamano-del-extractor-de-funciones-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.6 Comprobar el tamaño del extractor de funciones EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#37-recopilacion-de-estadisticas-del-extractor-de-funciones-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.7 Recopilación de estadísticas del extractor de funciones de EffNetB2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-creacion-de-un-extractor-de-funciones-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4. Creación de un extractor de funciones ViT
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Creación de un extractor de funciones ViT">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-crear-cargadores-de-datos-para-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Crear cargadores de datos para ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-extractor-de-funciones-de-vit-de-entrenamiento" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Extractor de funciones de ViT de entrenamiento
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-inspeccionando-las-curvas-de-perdidas-de-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Inspeccionando las curvas de pérdidas de ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-guardar-el-extractor-de-funciones-de-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 Guardar el extractor de funciones de ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-comprobar-el-tamano-del-extractor-de-funciones-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 Comprobar el tamaño del extractor de funciones ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46-recopilacion-de-estadisticas-del-extractor-de-funciones-de-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 Recopilación de estadísticas del extractor de funciones de ViT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-hacer-predicciones-con-nuestros-modelos-entrenados-y-cronometrarlas" class="md-nav__link">
    <span class="md-ellipsis">
      5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-crear-una-funcion-para-hacer-predicciones-en-todo-el-conjunto-de-datos-de-prueba" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Crear una función para hacer predicciones en todo el conjunto de datos de prueba
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-realizacion-y-sincronizacion-de-predicciones-con-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Realización y sincronización de predicciones con EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-realizar-y-cronometrar-predicciones-con-vit" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 Realizar y cronometrar predicciones con ViT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-comparacion-de-resultados-de-modelos-tiempos-de-prediccion-y-tamano" class="md-nav__link">
    <span class="md-ellipsis">
      6. Comparación de resultados de modelos, tiempos de predicción y tamaño
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Comparación de resultados de modelos, tiempos de predicción y tamaño">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-visualizacion-del-equilibrio-entre-velocidad-y-rendimiento" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 Visualización del equilibrio entre velocidad y rendimiento
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-dar-vida-a-foodvision-mini-creando-una-demostracion-de-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      7. Dar vida a FoodVision Mini creando una demostración de Gradio
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Dar vida a FoodVision Mini creando una demostración de Gradio">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-descripcion-general-de-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 Descripción general de Gradio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-creando-una-funcion-para-mapear-nuestras-entradas-y-salidas" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Creando una función para mapear nuestras entradas y salidas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-crear-una-lista-de-imagenes-de-ejemplo" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 Crear una lista de imágenes de ejemplo
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-construyendo-una-interfaz-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 Construyendo una interfaz Gradio
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-convertir-nuestra-demostracion-foodvision-mini-gradio-en-una-aplicacion-implementable" class="md-nav__link">
    <span class="md-ellipsis">
      8. Convertir nuestra demostración FoodVision Mini Gradio en una aplicación implementable
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Convertir nuestra demostración FoodVision Mini Gradio en una aplicación implementable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-que-es-abrazar-los-espacios-faciales" class="md-nav__link">
    <span class="md-ellipsis">
      8.1 ¿Qué es abrazar los espacios faciales?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-estructura-de-la-aplicacion-gradio-implementada" class="md-nav__link">
    <span class="md-ellipsis">
      8.2 Estructura de la aplicación Gradio implementada
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-creando-una-carpeta-para-almacenar-los-archivos-de-nuestra-aplicacion-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.3 Creando una carpeta para almacenar los archivos de nuestra aplicación FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-crear-una-carpeta-de-imagenes-de-ejemplo-para-usar-con-nuestra-demostracion-de-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.4 Crear una carpeta de imágenes de ejemplo para usar con nuestra demostración de FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-mover-nuestro-modelo-effnetb2-entrenado-a-nuestro-directorio-de-demostracion-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.5 Mover nuestro modelo EffNetB2 entrenado a nuestro directorio de demostración FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86-convirtiendo-nuestro-modelo-effnetb2-en-un-script-python" class="md-nav__link">
    <span class="md-ellipsis">
      8.6 Convirtiendo nuestro modelo EffNetB2 en un script Python ()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#87-convirtiendo-nuestra-aplicacion-foodvision-mini-gradio-en-un-script-python" class="md-nav__link">
    <span class="md-ellipsis">
      8.7 Convirtiendo nuestra aplicación FoodVision Mini Gradio en un script Python ()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#88-creacion-de-un-archivo-de-requisitos-para-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.8 Creación de un archivo de requisitos para FoodVision Mini ()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-implementacion-de-nuestra-aplicacion-foodvision-mini-en-huggingface-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      9. Implementación de nuestra aplicación FoodVision Mini en HuggingFace Spaces
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Implementación de nuestra aplicación FoodVision Mini en HuggingFace Spaces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-descarga-de-los-archivos-de-nuestra-aplicacion-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 Descarga de los archivos de nuestra aplicación FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-ejecucion-de-nuestra-demostracion-foodvision-mini-localmente" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 Ejecución de nuestra demostración FoodVision Mini localmente
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-subir-a-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 Subir a Hugging Face
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-creando-foodvision-a-lo-grande" class="md-nav__link">
    <span class="md-ellipsis">
      10. Creando FoodVision a lo grande
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Creando FoodVision a lo grande">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-creando-un-modelo-y-transformaciones-para-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      10.1 Creando un modelo y transformaciones para FoodVision Big
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-obtencion-de-datos-para-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      10.2 Obtención de datos para FoodVision Big
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-creacion-de-un-subconjunto-del-conjunto-de-datos-food101-para-experimentar-mas-rapido" class="md-nav__link">
    <span class="md-ellipsis">
      10.3 Creación de un subconjunto del conjunto de datos Food101 para experimentar más rápido
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extracurricular" class="md-nav__link">
    <span class="md-ellipsis">
      Extracurricular
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../embeddings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Predicción de Características de Nodos Utilizando Node2Vec en Análisis de Grafos y Redes con Python
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../14-tutorial_spark_delta/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorial Delta Lake Spark
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#que-es-la-implementacion-del-modelo-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Qué es la implementación del modelo de aprendizaje automático?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#por-que-implementar-un-modelo-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Por qué implementar un modelo de aprendizaje automático?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#diferentes-tipos-de-implementacion-de-modelos-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      Diferentes tipos de implementación de modelos de aprendizaje automático
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Diferentes tipos de implementación de modelos de aprendizaje automático">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#a-donde-ira" class="md-nav__link">
    <span class="md-ellipsis">
      ¿A dónde irá?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#como-va-a-funcionar" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Cómo va a funcionar?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#formas-de-implementar-un-modelo-de-aprendizaje-automatico" class="md-nav__link">
    <span class="md-ellipsis">
      Formas de implementar un modelo de aprendizaje automático
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#que-vamos-a-cubrir" class="md-nav__link">
    <span class="md-ellipsis">
      Qué vamos a cubrir
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#donde-puedes-obtener-ayuda" class="md-nav__link">
    <span class="md-ellipsis">
      ¿Dónde puedes obtener ayuda?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#0-configuracion" class="md-nav__link">
    <span class="md-ellipsis">
      0. Configuración
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-obtener-datos" class="md-nav__link">
    <span class="md-ellipsis">
      1. Obtener datos
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-esquema-del-experimento-de-implementacion-del-modelo-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      2. Esquema del experimento de implementación del modelo FoodVision Mini
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-creando-un-extractor-de-funciones-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3. Creando un extractor de funciones EffNetB2
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Creando un extractor de funciones EffNetB2">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#31-creando-una-funcion-para-hacer-un-extractor-de-caracteristicas-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.1 Creando una función para hacer un extractor de características EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#32-creando-cargadores-de-datos-para-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.2 Creando cargadores de datos para EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#33-entrenamiento-del-extractor-de-funciones-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.3 Entrenamiento del extractor de funciones de EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#34-inspeccionando-las-curvas-de-perdida-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.4 Inspeccionando las curvas de pérdida de EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#35-guardar-el-extractor-de-funciones-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.5 Guardar el extractor de funciones de EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#36-comprobar-el-tamano-del-extractor-de-funciones-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.6 Comprobar el tamaño del extractor de funciones EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#37-recopilacion-de-estadisticas-del-extractor-de-funciones-de-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      3.7 Recopilación de estadísticas del extractor de funciones de EffNetB2
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-creacion-de-un-extractor-de-funciones-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4. Creación de un extractor de funciones ViT
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Creación de un extractor de funciones ViT">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#41-crear-cargadores-de-datos-para-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.1 Crear cargadores de datos para ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#42-extractor-de-funciones-de-vit-de-entrenamiento" class="md-nav__link">
    <span class="md-ellipsis">
      4.2 Extractor de funciones de ViT de entrenamiento
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#43-inspeccionando-las-curvas-de-perdidas-de-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.3 Inspeccionando las curvas de pérdidas de ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#44-guardar-el-extractor-de-funciones-de-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.4 Guardar el extractor de funciones de ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#45-comprobar-el-tamano-del-extractor-de-funciones-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.5 Comprobar el tamaño del extractor de funciones ViT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#46-recopilacion-de-estadisticas-del-extractor-de-funciones-de-vit" class="md-nav__link">
    <span class="md-ellipsis">
      4.6 Recopilación de estadísticas del extractor de funciones de ViT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-hacer-predicciones-con-nuestros-modelos-entrenados-y-cronometrarlas" class="md-nav__link">
    <span class="md-ellipsis">
      5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#51-crear-una-funcion-para-hacer-predicciones-en-todo-el-conjunto-de-datos-de-prueba" class="md-nav__link">
    <span class="md-ellipsis">
      5.1 Crear una función para hacer predicciones en todo el conjunto de datos de prueba
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#52-realizacion-y-sincronizacion-de-predicciones-con-effnetb2" class="md-nav__link">
    <span class="md-ellipsis">
      5.2 Realización y sincronización de predicciones con EffNetB2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#53-realizar-y-cronometrar-predicciones-con-vit" class="md-nav__link">
    <span class="md-ellipsis">
      5.3 Realizar y cronometrar predicciones con ViT
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-comparacion-de-resultados-de-modelos-tiempos-de-prediccion-y-tamano" class="md-nav__link">
    <span class="md-ellipsis">
      6. Comparación de resultados de modelos, tiempos de predicción y tamaño
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Comparación de resultados de modelos, tiempos de predicción y tamaño">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#61-visualizacion-del-equilibrio-entre-velocidad-y-rendimiento" class="md-nav__link">
    <span class="md-ellipsis">
      6.1 Visualización del equilibrio entre velocidad y rendimiento
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-dar-vida-a-foodvision-mini-creando-una-demostracion-de-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      7. Dar vida a FoodVision Mini creando una demostración de Gradio
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Dar vida a FoodVision Mini creando una demostración de Gradio">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#71-descripcion-general-de-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      7.1 Descripción general de Gradio
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#72-creando-una-funcion-para-mapear-nuestras-entradas-y-salidas" class="md-nav__link">
    <span class="md-ellipsis">
      7.2 Creando una función para mapear nuestras entradas y salidas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#73-crear-una-lista-de-imagenes-de-ejemplo" class="md-nav__link">
    <span class="md-ellipsis">
      7.3 Crear una lista de imágenes de ejemplo
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#74-construyendo-una-interfaz-gradio" class="md-nav__link">
    <span class="md-ellipsis">
      7.4 Construyendo una interfaz Gradio
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-convertir-nuestra-demostracion-foodvision-mini-gradio-en-una-aplicacion-implementable" class="md-nav__link">
    <span class="md-ellipsis">
      8. Convertir nuestra demostración FoodVision Mini Gradio en una aplicación implementable
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Convertir nuestra demostración FoodVision Mini Gradio en una aplicación implementable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#81-que-es-abrazar-los-espacios-faciales" class="md-nav__link">
    <span class="md-ellipsis">
      8.1 ¿Qué es abrazar los espacios faciales?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#82-estructura-de-la-aplicacion-gradio-implementada" class="md-nav__link">
    <span class="md-ellipsis">
      8.2 Estructura de la aplicación Gradio implementada
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#83-creando-una-carpeta-para-almacenar-los-archivos-de-nuestra-aplicacion-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.3 Creando una carpeta para almacenar los archivos de nuestra aplicación FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#84-crear-una-carpeta-de-imagenes-de-ejemplo-para-usar-con-nuestra-demostracion-de-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.4 Crear una carpeta de imágenes de ejemplo para usar con nuestra demostración de FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#85-mover-nuestro-modelo-effnetb2-entrenado-a-nuestro-directorio-de-demostracion-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.5 Mover nuestro modelo EffNetB2 entrenado a nuestro directorio de demostración FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#86-convirtiendo-nuestro-modelo-effnetb2-en-un-script-python" class="md-nav__link">
    <span class="md-ellipsis">
      8.6 Convirtiendo nuestro modelo EffNetB2 en un script Python ()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#87-convirtiendo-nuestra-aplicacion-foodvision-mini-gradio-en-un-script-python" class="md-nav__link">
    <span class="md-ellipsis">
      8.7 Convirtiendo nuestra aplicación FoodVision Mini Gradio en un script Python ()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#88-creacion-de-un-archivo-de-requisitos-para-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      8.8 Creación de un archivo de requisitos para FoodVision Mini ()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-implementacion-de-nuestra-aplicacion-foodvision-mini-en-huggingface-spaces" class="md-nav__link">
    <span class="md-ellipsis">
      9. Implementación de nuestra aplicación FoodVision Mini en HuggingFace Spaces
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Implementación de nuestra aplicación FoodVision Mini en HuggingFace Spaces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#91-descarga-de-los-archivos-de-nuestra-aplicacion-foodvision-mini" class="md-nav__link">
    <span class="md-ellipsis">
      9.1 Descarga de los archivos de nuestra aplicación FoodVision Mini
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#92-ejecucion-de-nuestra-demostracion-foodvision-mini-localmente" class="md-nav__link">
    <span class="md-ellipsis">
      9.2 Ejecución de nuestra demostración FoodVision Mini localmente
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#93-subir-a-hugging-face" class="md-nav__link">
    <span class="md-ellipsis">
      9.3 Subir a Hugging Face
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-creando-foodvision-a-lo-grande" class="md-nav__link">
    <span class="md-ellipsis">
      10. Creando FoodVision a lo grande
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Creando FoodVision a lo grande">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#101-creando-un-modelo-y-transformaciones-para-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      10.1 Creando un modelo y transformaciones para FoodVision Big
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#102-obtencion-de-datos-para-foodvision-big" class="md-nav__link">
    <span class="md-ellipsis">
      10.2 Obtención de datos para FoodVision Big
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#103-creacion-de-un-subconjunto-del-conjunto-de-datos-food101-para-experimentar-mas-rapido" class="md-nav__link">
    <span class="md-ellipsis">
      10.3 Creación de un subconjunto del conjunto de datos Food101 para experimentar más rápido
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#extracurricular" class="md-nav__link">
    <span class="md-ellipsis">
      Extracurricular
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<script>
(function (global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :
    typeof define === 'function' && define.amd ? define(factory) :
    (global = global || self, global.ClipboardCopyElement = factory());
  }(this, function () { 'use strict';

    function createNode(text) {
      const node = document.createElement('pre');
      node.style.width = '1px';
      node.style.height = '1px';
      node.style.position = 'fixed';
      node.style.top = '5px';
      node.textContent = text;
      return node;
    }

    function copyNode(node) {
      if ('clipboard' in navigator) {
        // eslint-disable-next-line flowtype/no-flow-fix-me-comments
        // $FlowFixMe Clipboard is not defined in Flow yet.
        return navigator.clipboard.writeText(node.textContent);
      }

      const selection = getSelection();

      if (selection == null) {
        return Promise.reject(new Error());
      }

      selection.removeAllRanges();
      const range = document.createRange();
      range.selectNodeContents(node);
      selection.addRange(range);
      document.execCommand('copy');
      selection.removeAllRanges();
      return Promise.resolve();
    }
    function copyText(text) {
      if ('clipboard' in navigator) {
        // eslint-disable-next-line flowtype/no-flow-fix-me-comments
        // $FlowFixMe Clipboard is not defined in Flow yet.
        return navigator.clipboard.writeText(text);
      }

      const body = document.body;

      if (!body) {
        return Promise.reject(new Error());
      }

      const node = createNode(text);
      body.appendChild(node);
      copyNode(node);
      body.removeChild(node);
      return Promise.resolve();
    }

    function copy(button) {
      const id = button.getAttribute('for');
      const text = button.getAttribute('value');

      function trigger() {
        button.dispatchEvent(new CustomEvent('clipboard-copy', {
          bubbles: true
        }));
      }

      if (text) {
        copyText(text).then(trigger);
      } else if (id) {
        const root = 'getRootNode' in Element.prototype ? button.getRootNode() : button.ownerDocument;
        if (!(root instanceof Document || 'ShadowRoot' in window && root instanceof ShadowRoot)) return;
        const node = root.getElementById(id);
        if (node) copyTarget(node).then(trigger);
      }
    }

    function copyTarget(content) {
      if (content instanceof HTMLInputElement || content instanceof HTMLTextAreaElement) {
        return copyText(content.value);
      } else if (content instanceof HTMLAnchorElement && content.hasAttribute('href')) {
        return copyText(content.href);
      } else {
        return copyNode(content);
      }
    }

    function clicked(event) {
      const button = event.currentTarget;

      if (button instanceof HTMLElement) {
        copy(button);
      }
    }

    function keydown(event) {
      if (event.key === ' ' || event.key === 'Enter') {
        const button = event.currentTarget;

        if (button instanceof HTMLElement) {
          event.preventDefault();
          copy(button);
        }
      }
    }

    function focused(event) {
      event.currentTarget.addEventListener('keydown', keydown);
    }

    function blurred(event) {
      event.currentTarget.removeEventListener('keydown', keydown);
    }

    class ClipboardCopyElement extends HTMLElement {
      constructor() {
        super();
        this.addEventListener('click', clicked);
        this.addEventListener('focus', focused);
        this.addEventListener('blur', blurred);
      }

      connectedCallback() {
        if (!this.hasAttribute('tabindex')) {
          this.setAttribute('tabindex', '0');
        }

        if (!this.hasAttribute('role')) {
          this.setAttribute('role', 'button');
        }
      }

      get value() {
        return this.getAttribute('value') || '';
      }

      set value(text) {
        this.setAttribute('value', text);
      }

    }

    if (!window.customElements.get('clipboard-copy')) {
      window.ClipboardCopyElement = ClipboardCopyElement;
      window.customElements.define('clipboard-copy', ClipboardCopyElement);
    }

    return ClipboardCopyElement;

  }));
</script>
<script>
      document.addEventListener('clipboard-copy', function(event) {
        const notice = event.target.querySelector('.notice')
        notice.hidden = false
        setTimeout(function() {
          notice.hidden = true
        }, 1000)
      })
</script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight-ipynb .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight-ipynb { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight-ipynb .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight-ipynb .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight-ipynb .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight-ipynb .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight-ipynb .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight-ipynb .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight-ipynb .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight-ipynb .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight-ipynb .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight-ipynb .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight-ipynb .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight-ipynb .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight-ipynb .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight-ipynb .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight-ipynb .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight-ipynb .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight-ipynb .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight-ipynb .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight-ipynb .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight-ipynb .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight-ipynb .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight-ipynb .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight-ipynb .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight-ipynb .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight-ipynb .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight-ipynb .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight-ipynb .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight-ipynb .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight-ipynb .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight-ipynb .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight-ipynb .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight-ipynb .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight-ipynb .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight-ipynb .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight-ipynb .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight-ipynb .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight-ipynb .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight-ipynb .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight-ipynb .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight-ipynb .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight-ipynb .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
@charset "UTF-8";.jupyter-wrapper{--md-red-50: #ffebee;--md-red-100: #ffcdd2;--md-red-200: #ef9a9a;--md-red-300: #e57373;--md-red-400: #ef5350;--md-red-500: #f44336;--md-red-600: #e53935;--md-red-700: #d32f2f;--md-red-800: #c62828;--md-red-900: #b71c1c;--md-red-A100: #ff8a80;--md-red-A200: #ff5252;--md-red-A400: #ff1744;--md-red-A700: #d50000;--md-pink-50: #fce4ec;--md-pink-100: #f8bbd0;--md-pink-200: #f48fb1;--md-pink-300: #f06292;--md-pink-400: #ec407a;--md-pink-500: #e91e63;--md-pink-600: #d81b60;--md-pink-700: #c2185b;--md-pink-800: #ad1457;--md-pink-900: #880e4f;--md-pink-A100: #ff80ab;--md-pink-A200: #ff4081;--md-pink-A400: #f50057;--md-pink-A700: #c51162;--md-purple-50: #f3e5f5;--md-purple-100: #e1bee7;--md-purple-200: #ce93d8;--md-purple-300: #ba68c8;--md-purple-400: #ab47bc;--md-purple-500: #9c27b0;--md-purple-600: #8e24aa;--md-purple-700: #7b1fa2;--md-purple-800: #6a1b9a;--md-purple-900: #4a148c;--md-purple-A100: #ea80fc;--md-purple-A200: #e040fb;--md-purple-A400: #d500f9;--md-purple-A700: #aa00ff;--md-deep-purple-50: #ede7f6;--md-deep-purple-100: #d1c4e9;--md-deep-purple-200: #b39ddb;--md-deep-purple-300: #9575cd;--md-deep-purple-400: #7e57c2;--md-deep-purple-500: #673ab7;--md-deep-purple-600: #5e35b1;--md-deep-purple-700: #512da8;--md-deep-purple-800: #4527a0;--md-deep-purple-900: #311b92;--md-deep-purple-A100: #b388ff;--md-deep-purple-A200: #7c4dff;--md-deep-purple-A400: #651fff;--md-deep-purple-A700: #6200ea;--md-indigo-50: #e8eaf6;--md-indigo-100: #c5cae9;--md-indigo-200: #9fa8da;--md-indigo-300: #7986cb;--md-indigo-400: #5c6bc0;--md-indigo-500: #3f51b5;--md-indigo-600: #3949ab;--md-indigo-700: #303f9f;--md-indigo-800: #283593;--md-indigo-900: #1a237e;--md-indigo-A100: #8c9eff;--md-indigo-A200: #536dfe;--md-indigo-A400: #3d5afe;--md-indigo-A700: #304ffe;--md-blue-50: #e3f2fd;--md-blue-100: #bbdefb;--md-blue-200: #90caf9;--md-blue-300: #64b5f6;--md-blue-400: #42a5f5;--md-blue-500: #2196f3;--md-blue-600: #1e88e5;--md-blue-700: #1976d2;--md-blue-800: #1565c0;--md-blue-900: #0d47a1;--md-blue-A100: #82b1ff;--md-blue-A200: #448aff;--md-blue-A400: #2979ff;--md-blue-A700: #2962ff;--md-light-blue-50: #e1f5fe;--md-light-blue-100: #b3e5fc;--md-light-blue-200: #81d4fa;--md-light-blue-300: #4fc3f7;--md-light-blue-400: #29b6f6;--md-light-blue-500: #03a9f4;--md-light-blue-600: #039be5;--md-light-blue-700: #0288d1;--md-light-blue-800: #0277bd;--md-light-blue-900: #01579b;--md-light-blue-A100: #80d8ff;--md-light-blue-A200: #40c4ff;--md-light-blue-A400: #00b0ff;--md-light-blue-A700: #0091ea;--md-cyan-50: #e0f7fa;--md-cyan-100: #b2ebf2;--md-cyan-200: #80deea;--md-cyan-300: #4dd0e1;--md-cyan-400: #26c6da;--md-cyan-500: #00bcd4;--md-cyan-600: #00acc1;--md-cyan-700: #0097a7;--md-cyan-800: #00838f;--md-cyan-900: #006064;--md-cyan-A100: #84ffff;--md-cyan-A200: #18ffff;--md-cyan-A400: #00e5ff;--md-cyan-A700: #00b8d4;--md-teal-50: #e0f2f1;--md-teal-100: #b2dfdb;--md-teal-200: #80cbc4;--md-teal-300: #4db6ac;--md-teal-400: #26a69a;--md-teal-500: #009688;--md-teal-600: #00897b;--md-teal-700: #00796b;--md-teal-800: #00695c;--md-teal-900: #004d40;--md-teal-A100: #a7ffeb;--md-teal-A200: #64ffda;--md-teal-A400: #1de9b6;--md-teal-A700: #00bfa5;--md-green-50: #e8f5e9;--md-green-100: #c8e6c9;--md-green-200: #a5d6a7;--md-green-300: #81c784;--md-green-400: #66bb6a;--md-green-500: #4caf50;--md-green-600: #43a047;--md-green-700: #388e3c;--md-green-800: #2e7d32;--md-green-900: #1b5e20;--md-green-A100: #b9f6ca;--md-green-A200: #69f0ae;--md-green-A400: #00e676;--md-green-A700: #00c853;--md-light-green-50: #f1f8e9;--md-light-green-100: #dcedc8;--md-light-green-200: #c5e1a5;--md-light-green-300: #aed581;--md-light-green-400: #9ccc65;--md-light-green-500: #8bc34a;--md-light-green-600: #7cb342;--md-light-green-700: #689f38;--md-light-green-800: #558b2f;--md-light-green-900: #33691e;--md-light-green-A100: #ccff90;--md-light-green-A200: #b2ff59;--md-light-green-A400: #76ff03;--md-light-green-A700: #64dd17;--md-lime-50: #f9fbe7;--md-lime-100: #f0f4c3;--md-lime-200: #e6ee9c;--md-lime-300: #dce775;--md-lime-400: #d4e157;--md-lime-500: #cddc39;--md-lime-600: #c0ca33;--md-lime-700: #afb42b;--md-lime-800: #9e9d24;--md-lime-900: #827717;--md-lime-A100: #f4ff81;--md-lime-A200: #eeff41;--md-lime-A400: #c6ff00;--md-lime-A700: #aeea00;--md-yellow-50: #fffde7;--md-yellow-100: #fff9c4;--md-yellow-200: #fff59d;--md-yellow-300: #fff176;--md-yellow-400: #ffee58;--md-yellow-500: #ffeb3b;--md-yellow-600: #fdd835;--md-yellow-700: #fbc02d;--md-yellow-800: #f9a825;--md-yellow-900: #f57f17;--md-yellow-A100: #ffff8d;--md-yellow-A200: #ffff00;--md-yellow-A400: #ffea00;--md-yellow-A700: #ffd600;--md-amber-50: #fff8e1;--md-amber-100: #ffecb3;--md-amber-200: #ffe082;--md-amber-300: #ffd54f;--md-amber-400: #ffca28;--md-amber-500: #ffc107;--md-amber-600: #ffb300;--md-amber-700: #ffa000;--md-amber-800: #ff8f00;--md-amber-900: #ff6f00;--md-amber-A100: #ffe57f;--md-amber-A200: #ffd740;--md-amber-A400: #ffc400;--md-amber-A700: #ffab00;--md-orange-50: #fff3e0;--md-orange-100: #ffe0b2;--md-orange-200: #ffcc80;--md-orange-300: #ffb74d;--md-orange-400: #ffa726;--md-orange-500: #ff9800;--md-orange-600: #fb8c00;--md-orange-700: #f57c00;--md-orange-800: #ef6c00;--md-orange-900: #e65100;--md-orange-A100: #ffd180;--md-orange-A200: #ffab40;--md-orange-A400: #ff9100;--md-orange-A700: #ff6d00;--md-deep-orange-50: #fbe9e7;--md-deep-orange-100: #ffccbc;--md-deep-orange-200: #ffab91;--md-deep-orange-300: #ff8a65;--md-deep-orange-400: #ff7043;--md-deep-orange-500: #ff5722;--md-deep-orange-600: #f4511e;--md-deep-orange-700: #e64a19;--md-deep-orange-800: #d84315;--md-deep-orange-900: #bf360c;--md-deep-orange-A100: #ff9e80;--md-deep-orange-A200: #ff6e40;--md-deep-orange-A400: #ff3d00;--md-deep-orange-A700: #dd2c00;--md-brown-50: #efebe9;--md-brown-100: #d7ccc8;--md-brown-200: #bcaaa4;--md-brown-300: #a1887f;--md-brown-400: #8d6e63;--md-brown-500: #795548;--md-brown-600: #6d4c41;--md-brown-700: #5d4037;--md-brown-800: #4e342e;--md-brown-900: #3e2723;--md-grey-50: #fafafa;--md-grey-100: #f5f5f5;--md-grey-200: #eeeeee;--md-grey-300: #e0e0e0;--md-grey-400: #bdbdbd;--md-grey-500: #9e9e9e;--md-grey-600: #757575;--md-grey-700: #616161;--md-grey-800: #424242;--md-grey-900: #212121;--md-blue-grey-50: #eceff1;--md-blue-grey-100: #cfd8dc;--md-blue-grey-200: #b0bec5;--md-blue-grey-300: #90a4ae;--md-blue-grey-400: #78909c;--md-blue-grey-500: #607d8b;--md-blue-grey-600: #546e7a;--md-blue-grey-700: #455a64;--md-blue-grey-800: #37474f;--md-blue-grey-900: #263238}.jupyter-wrapper{--jp-shadow-base-lightness: 0;--jp-shadow-umbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .2 );--jp-shadow-penumbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .14 );--jp-shadow-ambient-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .12 );--jp-elevation-z0: none;--jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color), 0px 1px 1px 0px var(--jp-shadow-penumbra-color), 0px 1px 3px 0px var(--jp-shadow-ambient-color);--jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color), 0px 2px 2px 0px var(--jp-shadow-penumbra-color), 0px 1px 5px 0px var(--jp-shadow-ambient-color);--jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color), 0px 4px 5px 0px var(--jp-shadow-penumbra-color), 0px 1px 10px 0px var(--jp-shadow-ambient-color);--jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color), 0px 6px 10px 0px var(--jp-shadow-penumbra-color), 0px 1px 18px 0px var(--jp-shadow-ambient-color);--jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color), 0px 8px 10px 1px var(--jp-shadow-penumbra-color), 0px 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color), 0px 12px 17px 2px var(--jp-shadow-penumbra-color), 0px 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color), 0px 16px 24px 2px var(--jp-shadow-penumbra-color), 0px 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color), 0px 20px 31px 3px var(--jp-shadow-penumbra-color), 0px 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color), 0px 24px 38px 3px var(--jp-shadow-penumbra-color), 0px 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width: 1px;--jp-border-color0: var(--md-grey-400);--jp-border-color1: var(--md-grey-400);--jp-border-color2: var(--md-grey-300);--jp-border-color3: var(--md-grey-200);--jp-inverse-border-color: var(--md-grey-600);--jp-border-radius: 2px;--jp-ui-font-scale-factor: 1.2;--jp-ui-font-size0: .83333em;--jp-ui-font-size1: 13px;--jp-ui-font-size2: 1.2em;--jp-ui-font-size3: 1.44em;--jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-ui-font-color0: rgba(0, 0, 0, 1);--jp-ui-font-color1: rgba(0, 0, 0, .87);--jp-ui-font-color2: rgba(0, 0, 0, .54);--jp-ui-font-color3: rgba(0, 0, 0, .38);--jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color2: rgba(255, 255, 255, .7);--jp-ui-inverse-font-color3: rgba(255, 255, 255, .5);--jp-content-line-height: 1.6;--jp-content-font-scale-factor: 1.2;--jp-content-font-size0: .83333em;--jp-content-font-size1: 14px;--jp-content-font-size2: 1.2em;--jp-content-font-size3: 1.44em;--jp-content-font-size4: 1.728em;--jp-content-font-size5: 2.0736em;--jp-content-presentation-font-size1: 17px;--jp-content-heading-line-height: 1;--jp-content-heading-margin-top: 1.2em;--jp-content-heading-margin-bottom: .8em;--jp-content-heading-font-weight: 500;--jp-content-font-color0: rgba(0, 0, 0, 1);--jp-content-font-color1: rgba(0, 0, 0, .87);--jp-content-font-color2: rgba(0, 0, 0, .54);--jp-content-font-color3: rgba(0, 0, 0, .38);--jp-content-link-color: var(--md-blue-700);--jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-code-font-size: 13px;--jp-code-line-height: 1.3077;--jp-code-padding: 5px;--jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono", monospace;--jp-code-font-family: var(--jp-code-font-family-default);--jp-code-presentation-font-size: 16px;--jp-code-cursor-width0: 1.4px;--jp-code-cursor-width1: 2px;--jp-code-cursor-width2: 4px;--jp-layout-color0: white;--jp-layout-color1: white;--jp-layout-color2: var(--md-grey-200);--jp-layout-color3: var(--md-grey-400);--jp-layout-color4: var(--md-grey-600);--jp-inverse-layout-color0: #111111;--jp-inverse-layout-color1: var(--md-grey-900);--jp-inverse-layout-color2: var(--md-grey-800);--jp-inverse-layout-color3: var(--md-grey-700);--jp-inverse-layout-color4: var(--md-grey-600);--jp-brand-color0: var(--md-blue-900);--jp-brand-color1: var(--md-blue-700);--jp-brand-color2: var(--md-blue-300);--jp-brand-color3: var(--md-blue-100);--jp-brand-color4: var(--md-blue-50);--jp-accent-color0: var(--md-green-900);--jp-accent-color1: var(--md-green-700);--jp-accent-color2: var(--md-green-300);--jp-accent-color3: var(--md-green-100);--jp-warn-color0: var(--md-orange-900);--jp-warn-color1: var(--md-orange-700);--jp-warn-color2: var(--md-orange-300);--jp-warn-color3: var(--md-orange-100);--jp-error-color0: var(--md-red-900);--jp-error-color1: var(--md-red-700);--jp-error-color2: var(--md-red-300);--jp-error-color3: var(--md-red-100);--jp-success-color0: var(--md-green-900);--jp-success-color1: var(--md-green-700);--jp-success-color2: var(--md-green-300);--jp-success-color3: var(--md-green-100);--jp-info-color0: var(--md-cyan-900);--jp-info-color1: var(--md-cyan-700);--jp-info-color2: var(--md-cyan-300);--jp-info-color3: var(--md-cyan-100);--jp-cell-padding: 5px;--jp-cell-collapser-width: 8px;--jp-cell-collapser-min-height: 20px;--jp-cell-collapser-not-active-hover-opacity: .6;--jp-cell-editor-background: var(--md-grey-100);--jp-cell-editor-border-color: var(--md-grey-300);--jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background: var(--jp-layout-color0);--jp-cell-editor-active-border-color: var(--jp-brand-color1);--jp-cell-prompt-width: 64px;--jp-cell-prompt-font-family: var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing: 0px;--jp-cell-prompt-opacity: 1;--jp-cell-prompt-not-active-opacity: .5;--jp-cell-prompt-not-active-font-color: var(--md-grey-700);--jp-cell-inprompt-font-color: #307fc1;--jp-cell-outprompt-font-color: #bf5b3d;--jp-notebook-padding: 10px;--jp-notebook-select-background: var(--jp-layout-color1);--jp-notebook-multiselected-color: var(--md-blue-50);--jp-notebook-scroll-padding: calc( 100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px );--jp-rendermime-error-background: #fdd;--jp-rendermime-table-row-background: var(--md-grey-100);--jp-rendermime-table-row-hover-background: var(--md-light-blue-50);--jp-dialog-background: rgba(0, 0, 0, .25);--jp-console-padding: 10px;--jp-toolbar-border-color: var(--jp-border-color1);--jp-toolbar-micro-height: 8px;--jp-toolbar-background: var(--jp-layout-color1);--jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, .24);--jp-toolbar-header-margin: 4px 4px 0px 4px;--jp-toolbar-active-background: var(--md-grey-300);--jp-statusbar-height: 24px;--jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-input-active-background: var(--jp-layout-color1);--jp-input-hover-background: var(--jp-layout-color1);--jp-input-background: var(--md-grey-100);--jp-input-border-color: var(--jp-inverse-border-color);--jp-input-active-border-color: var(--jp-brand-color1);--jp-input-active-box-shadow-color: rgba(19, 124, 189, .3);--jp-editor-selected-background: #d9d9d9;--jp-editor-selected-focused-background: #d7d4f0;--jp-editor-cursor-color: var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color: #008000;--jp-mirror-editor-atom-color: #88f;--jp-mirror-editor-number-color: #080;--jp-mirror-editor-def-color: #00f;--jp-mirror-editor-variable-color: var(--md-grey-900);--jp-mirror-editor-variable-2-color: #05a;--jp-mirror-editor-variable-3-color: #085;--jp-mirror-editor-punctuation-color: #05a;--jp-mirror-editor-property-color: #05a;--jp-mirror-editor-operator-color: #aa22ff;--jp-mirror-editor-comment-color: #408080;--jp-mirror-editor-string-color: #ba2121;--jp-mirror-editor-string-2-color: #708;--jp-mirror-editor-meta-color: #aa22ff;--jp-mirror-editor-qualifier-color: #555;--jp-mirror-editor-builtin-color: #008000;--jp-mirror-editor-bracket-color: #997;--jp-mirror-editor-tag-color: #170;--jp-mirror-editor-attribute-color: #00c;--jp-mirror-editor-header-color: blue;--jp-mirror-editor-quote-color: #090;--jp-mirror-editor-link-color: #00c;--jp-mirror-editor-error-color: #f00;--jp-mirror-editor-hr-color: #999;--jp-collaborator-color1: #ffad8e;--jp-collaborator-color2: #dac83d;--jp-collaborator-color3: #72dd76;--jp-collaborator-color4: #00e4d0;--jp-collaborator-color5: #45d4ff;--jp-collaborator-color6: #e2b1ff;--jp-collaborator-color7: #ff9de6;--jp-vega-background: white;--jp-sidebar-min-width: 250px;--jp-search-toggle-off-opacity: .5;--jp-search-toggle-hover-opacity: .8;--jp-search-toggle-on-opacity: 1;--jp-search-selected-match-background-color: rgb(245, 200, 0);--jp-search-selected-match-color: black;--jp-search-unselected-match-background-color: var( --jp-inverse-layout-color0 );--jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);--jp-icon-contrast-color0: var(--md-purple-600);--jp-icon-contrast-color1: var(--md-green-600);--jp-icon-contrast-color2: var(--md-pink-600);--jp-icon-contrast-color3: var(--md-blue-600);--jp-jupyter-icon-color: #f37626;--jp-notebook-icon-color: #f37626;--jp-json-icon-color: var(--md-orange-700);--jp-console-icon-background-color: var(--md-blue-700);--jp-console-icon-color: white;--jp-terminal-icon-background-color: var(--md-grey-800);--jp-terminal-icon-color: var(--md-grey-200);--jp-text-editor-icon-color: var(--md-grey-700);--jp-inspector-icon-color: var(--md-grey-700);--jp-switch-color: var(--md-grey-400);--jp-switch-true-position-color: var(--md-orange-900)}[data-md-color-scheme=slate] .jupyter-wrapper{--jp-shadow-base-lightness: 32;--jp-shadow-umbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .2 );--jp-shadow-penumbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .14 );--jp-shadow-ambient-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .12 );--jp-elevation-z0: none;--jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color), 0px 1px 1px 0px var(--jp-shadow-penumbra-color), 0px 1px 3px 0px var(--jp-shadow-ambient-color);--jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color), 0px 2px 2px 0px var(--jp-shadow-penumbra-color), 0px 1px 5px 0px var(--jp-shadow-ambient-color);--jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color), 0px 4px 5px 0px var(--jp-shadow-penumbra-color), 0px 1px 10px 0px var(--jp-shadow-ambient-color);--jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color), 0px 6px 10px 0px var(--jp-shadow-penumbra-color), 0px 1px 18px 0px var(--jp-shadow-ambient-color);--jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color), 0px 8px 10px 1px var(--jp-shadow-penumbra-color), 0px 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color), 0px 12px 17px 2px var(--jp-shadow-penumbra-color), 0px 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color), 0px 16px 24px 2px var(--jp-shadow-penumbra-color), 0px 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color), 0px 20px 31px 3px var(--jp-shadow-penumbra-color), 0px 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color), 0px 24px 38px 3px var(--jp-shadow-penumbra-color), 0px 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width: 1px;--jp-border-color0: var(--md-grey-700);--jp-border-color1: var(--md-grey-700);--jp-border-color2: var(--md-grey-800);--jp-border-color3: var(--md-grey-900);--jp-inverse-border-color: var(--md-grey-600);--jp-border-radius: 2px;--jp-ui-font-scale-factor: 1.2;--jp-ui-font-size0: .83333em;--jp-ui-font-size1: 13px;--jp-ui-font-size2: 1.2em;--jp-ui-font-size3: 1.44em;--jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-ui-font-color0: rgba(255, 255, 255, 1);--jp-ui-font-color1: rgba(255, 255, 255, .87);--jp-ui-font-color2: rgba(255, 255, 255, .54);--jp-ui-font-color3: rgba(255, 255, 255, .38);--jp-ui-inverse-font-color0: rgba(0, 0, 0, 1);--jp-ui-inverse-font-color1: rgba(0, 0, 0, .8);--jp-ui-inverse-font-color2: rgba(0, 0, 0, .5);--jp-ui-inverse-font-color3: rgba(0, 0, 0, .3);--jp-content-line-height: 1.6;--jp-content-font-scale-factor: 1.2;--jp-content-font-size0: .83333em;--jp-content-font-size1: 14px;--jp-content-font-size2: 1.2em;--jp-content-font-size3: 1.44em;--jp-content-font-size4: 1.728em;--jp-content-font-size5: 2.0736em;--jp-content-presentation-font-size1: 17px;--jp-content-heading-line-height: 1;--jp-content-heading-margin-top: 1.2em;--jp-content-heading-margin-bottom: .8em;--jp-content-heading-font-weight: 500;--jp-content-font-color0: rgba(255, 255, 255, 1);--jp-content-font-color1: rgba(255, 255, 255, 1);--jp-content-font-color2: rgba(255, 255, 255, .7);--jp-content-font-color3: rgba(255, 255, 255, .5);--jp-content-link-color: var(--md-blue-300);--jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-code-font-size: 13px;--jp-code-line-height: 1.3077;--jp-code-padding: 5px;--jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono", monospace;--jp-code-font-family: var(--jp-code-font-family-default);--jp-code-presentation-font-size: 16px;--jp-code-cursor-width0: 1.4px;--jp-code-cursor-width1: 2px;--jp-code-cursor-width2: 4px;--jp-layout-color0: #111111;--jp-layout-color1: var(--md-grey-900);--jp-layout-color2: var(--md-grey-800);--jp-layout-color3: var(--md-grey-700);--jp-layout-color4: var(--md-grey-600);--jp-inverse-layout-color0: white;--jp-inverse-layout-color1: white;--jp-inverse-layout-color2: var(--md-grey-200);--jp-inverse-layout-color3: var(--md-grey-400);--jp-inverse-layout-color4: var(--md-grey-600);--jp-brand-color0: var(--md-blue-700);--jp-brand-color1: var(--md-blue-500);--jp-brand-color2: var(--md-blue-300);--jp-brand-color3: var(--md-blue-100);--jp-brand-color4: var(--md-blue-50);--jp-accent-color0: var(--md-green-700);--jp-accent-color1: var(--md-green-500);--jp-accent-color2: var(--md-green-300);--jp-accent-color3: var(--md-green-100);--jp-warn-color0: var(--md-orange-700);--jp-warn-color1: var(--md-orange-500);--jp-warn-color2: var(--md-orange-300);--jp-warn-color3: var(--md-orange-100);--jp-error-color0: var(--md-red-700);--jp-error-color1: var(--md-red-500);--jp-error-color2: var(--md-red-300);--jp-error-color3: var(--md-red-100);--jp-success-color0: var(--md-green-700);--jp-success-color1: var(--md-green-500);--jp-success-color2: var(--md-green-300);--jp-success-color3: var(--md-green-100);--jp-info-color0: var(--md-cyan-700);--jp-info-color1: var(--md-cyan-500);--jp-info-color2: var(--md-cyan-300);--jp-info-color3: var(--md-cyan-100);--jp-cell-padding: 5px;--jp-cell-collapser-width: 8px;--jp-cell-collapser-min-height: 20px;--jp-cell-collapser-not-active-hover-opacity: .6;--jp-cell-editor-background: var(--jp-layout-color1);--jp-cell-editor-border-color: var(--md-grey-700);--jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background: var(--jp-layout-color0);--jp-cell-editor-active-border-color: var(--jp-brand-color1);--jp-cell-prompt-width: 64px;--jp-cell-prompt-font-family: var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing: 0px;--jp-cell-prompt-opacity: 1;--jp-cell-prompt-not-active-opacity: 1;--jp-cell-prompt-not-active-font-color: var(--md-grey-300);--jp-cell-inprompt-font-color: #307fc1;--jp-cell-outprompt-font-color: #bf5b3d;--jp-notebook-padding: 10px;--jp-notebook-select-background: var(--jp-layout-color1);--jp-notebook-multiselected-color: rgba(33, 150, 243, .24);--jp-notebook-scroll-padding: calc( 100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px );--jp-rendermime-error-background: rgba(244, 67, 54, .28);--jp-rendermime-table-row-background: var(--md-grey-900);--jp-rendermime-table-row-hover-background: rgba(3, 169, 244, .2);--jp-dialog-background: rgba(0, 0, 0, .6);--jp-console-padding: 10px;--jp-toolbar-border-color: var(--jp-border-color2);--jp-toolbar-micro-height: 8px;--jp-toolbar-background: var(--jp-layout-color1);--jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, .8);--jp-toolbar-header-margin: 4px 4px 0px 4px;--jp-toolbar-active-background: var(--jp-layout-color0);--jp-statusbar-height: 24px;--jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-input-active-background: var(--jp-layout-color0);--jp-input-hover-background: var(--jp-layout-color2);--jp-input-background: var(--md-grey-800);--jp-input-border-color: var(--jp-inverse-border-color);--jp-input-active-border-color: var(--jp-brand-color1);--jp-input-active-box-shadow-color: rgba(19, 124, 189, .3);--jp-editor-selected-background: var(--jp-layout-color2);--jp-editor-selected-focused-background: rgba(33, 150, 243, .24);--jp-editor-cursor-color: var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color: var(--md-green-500);--jp-mirror-editor-atom-color: var(--md-blue-300);--jp-mirror-editor-number-color: var(--md-green-400);--jp-mirror-editor-def-color: var(--md-blue-600);--jp-mirror-editor-variable-color: var(--md-grey-300);--jp-mirror-editor-variable-2-color: var(--md-blue-400);--jp-mirror-editor-variable-3-color: var(--md-green-600);--jp-mirror-editor-punctuation-color: var(--md-blue-400);--jp-mirror-editor-property-color: var(--md-blue-400);--jp-mirror-editor-operator-color: #aa22ff;--jp-mirror-editor-comment-color: #408080;--jp-mirror-editor-string-color: #ff7070;--jp-mirror-editor-string-2-color: var(--md-purple-300);--jp-mirror-editor-meta-color: #aa22ff;--jp-mirror-editor-qualifier-color: #555;--jp-mirror-editor-builtin-color: var(--md-green-600);--jp-mirror-editor-bracket-color: #997;--jp-mirror-editor-tag-color: var(--md-green-700);--jp-mirror-editor-attribute-color: var(--md-blue-700);--jp-mirror-editor-header-color: var(--md-blue-500);--jp-mirror-editor-quote-color: var(--md-green-300);--jp-mirror-editor-link-color: var(--md-blue-700);--jp-mirror-editor-error-color: #f00;--jp-mirror-editor-hr-color: #999;--jp-collaborator-color1: #ad4a00;--jp-collaborator-color2: #7b6a00;--jp-collaborator-color3: #007e00;--jp-collaborator-color4: #008772;--jp-collaborator-color5: #0079b9;--jp-collaborator-color6: #8b45c6;--jp-collaborator-color7: #be208b;--jp-vega-background: var(--md-grey-400);--jp-sidebar-min-width: 250px;--jp-search-toggle-off-opacity: .6;--jp-search-toggle-hover-opacity: .8;--jp-search-toggle-on-opacity: 1;--jp-search-selected-match-background-color: rgb(255, 225, 0);--jp-search-selected-match-color: black;--jp-search-unselected-match-background-color: var( --jp-inverse-layout-color0 );--jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);--jp-scrollbar-background-color: #3f4244;--jp-scrollbar-thumb-color: 88, 96, 97;--jp-scrollbar-endpad: 3px;--jp-scrollbar-thumb-margin: 3.5px;--jp-scrollbar-thumb-radius: 9px;--jp-icon-contrast-color0: var(--md-purple-600);--jp-icon-contrast-color1: var(--md-green-600);--jp-icon-contrast-color2: var(--md-pink-600);--jp-icon-contrast-color3: var(--md-blue-600);--jp-jupyter-icon-color: #f37626;--jp-notebook-icon-color: #f37626;--jp-json-icon-color: var(--md-orange-500);--jp-console-icon-background-color: var(--md-blue-500);--jp-console-icon-color: white;--jp-terminal-icon-background-color: var(--md-grey-200);--jp-terminal-icon-color: var(--md-grey-800);--jp-text-editor-icon-color: var(--md-grey-200);--jp-inspector-icon-color: var(--md-grey-200);--jp-switch-color: var(--md-grey-400);--jp-switch-true-position-color: var(--md-orange-700)}.jupyter-wrapper [data-jp-theme-scrollbars=true]{scrollbar-color:rgb(var(--jp-scrollbar-thumb-color)) var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color),.5) transparent}.jupyter-wrapper .jp-scrollbar-tiny{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color),.5) transparent;scrollbar-width:thin}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-corner{background:var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-thumb{background:rgb(var(--jp-scrollbar-thumb-color));border:var(--jp-scrollbar-thumb-margin) solid transparent;background-clip:content-box;border-radius:var(--jp-scrollbar-thumb-radius)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-track:horizontal{border-left:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color);border-right:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] ::-webkit-scrollbar-track:vertical{border-top:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color);border-bottom:var(--jp-scrollbar-endpad) solid var(--jp-scrollbar-background-color)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-corner,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-corner{background-color:transparent}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-thumb{background:rgba(var(--jp-scrollbar-thumb-color),.5);border:var(--jp-scrollbar-thumb-margin) solid transparent;background-clip:content-box;border-radius:var(--jp-scrollbar-thumb-radius)}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal{border-left:var(--jp-scrollbar-endpad) solid transparent;border-right:var(--jp-scrollbar-endpad) solid transparent}.jupyter-wrapper [data-jp-theme-scrollbars=true] .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical{border-top:var(--jp-scrollbar-endpad) solid transparent;border-bottom:var(--jp-scrollbar-endpad) solid transparent}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar,.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-corner{background-color:transparent;height:4px;width:4px}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-thumb{background:rgba(var(--jp-scrollbar-thumb-color),.5)}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal{border-left:0px solid transparent;border-right:0px solid transparent}.jupyter-wrapper .jp-scrollbar-tiny::-webkit-scrollbar-track:vertical{border-top:0px solid transparent;border-bottom:0px solid transparent}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal]{min-height:16px;max-height:16px;min-width:45px;border-top:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical]{min-width:16px;max-width:16px;min-height:45px;border-left:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar-button{background-color:#f0f0f0;background-position:center center;min-height:15px;max-height:15px;min-width:15px;max-width:15px}.jupyter-wrapper .lm-ScrollBar-button:hover{background-color:#dadada}.jupyter-wrapper .lm-ScrollBar-button.lm-mod-active{background-color:#cdcdcd}.jupyter-wrapper .lm-ScrollBar-track{background:#f0f0f0}.jupyter-wrapper .lm-ScrollBar-thumb{background:#cdcdcd}.jupyter-wrapper .lm-ScrollBar-thumb:hover{background:#bababa}.jupyter-wrapper .lm-ScrollBar-thumb.lm-mod-active{background:#a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-thumb{height:100%;min-width:15px;border-left:1px solid #a0a0a0;border-right:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-thumb{width:100%;min-height:15px;border-top:1px solid #a0a0a0;border-bottom:1px solid #a0a0a0}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-button[data-action=decrement]{background-image:var(--jp-icon-caret-left);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal] .lm-ScrollBar-button[data-action=increment]{background-image:var(--jp-icon-caret-right);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-button[data-action=decrement]{background-image:var(--jp-icon-caret-up);background-size:17px}.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical] .lm-ScrollBar-button[data-action=increment]{background-image:var(--jp-icon-caret-down);background-size:17px}.jupyter-wrapper .p-Widget,.jupyter-wrapper .lm-Widget{box-sizing:border-box;position:relative;overflow:hidden;cursor:default}.jupyter-wrapper .p-Widget.p-mod-hidden,.jupyter-wrapper .lm-Widget.lm-mod-hidden{display:none!important}.jupyter-wrapper .lm-AccordionPanel[data-orientation=horizontal]>.lm-AccordionPanel-title{display:block;transform-origin:top left;transform:rotate(-90deg) translate(-100%)}.jupyter-wrapper .p-CommandPalette,.jupyter-wrapper .lm-CommandPalette{display:flex;flex-direction:column;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-CommandPalette-search,.jupyter-wrapper .lm-CommandPalette-search{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-content,.jupyter-wrapper .lm-CommandPalette-content{flex:1 1 auto;margin:0;padding:0;min-height:0;overflow:auto;list-style-type:none}.jupyter-wrapper .p-CommandPalette-header,.jupyter-wrapper .lm-CommandPalette-header{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .p-CommandPalette-item,.jupyter-wrapper .lm-CommandPalette-item{display:flex;flex-direction:row}.jupyter-wrapper .p-CommandPalette-itemIcon,.jupyter-wrapper .lm-CommandPalette-itemIcon{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-itemContent,.jupyter-wrapper .lm-CommandPalette-itemContent{flex:1 1 auto;overflow:hidden}.jupyter-wrapper .p-CommandPalette-itemShortcut,.jupyter-wrapper .lm-CommandPalette-itemShortcut{flex:0 0 auto}.jupyter-wrapper .p-CommandPalette-itemLabel,.jupyter-wrapper .lm-CommandPalette-itemLabel{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .lm-close-icon{border:1px solid transparent;background-color:transparent;position:absolute;z-index:1;right:3%;top:0;bottom:0;margin:auto;padding:7px 0;display:none;vertical-align:middle;outline:0;cursor:pointer}.jupyter-wrapper .lm-close-icon:after{content:"X";display:block;width:15px;height:15px;text-align:center;color:#000;font-weight:400;font-size:12px;cursor:pointer}.jupyter-wrapper .p-DockPanel,.jupyter-wrapper .lm-DockPanel,.jupyter-wrapper .p-DockPanel-widget,.jupyter-wrapper .lm-DockPanel-widget{z-index:0}.jupyter-wrapper .p-DockPanel-tabBar,.jupyter-wrapper .lm-DockPanel-tabBar{z-index:1}.jupyter-wrapper .p-DockPanel-handle,.jupyter-wrapper .lm-DockPanel-handle{z-index:2}.jupyter-wrapper .p-DockPanel-handle.p-mod-hidden,.jupyter-wrapper .lm-DockPanel-handle.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-DockPanel-handle:after,.jupyter-wrapper .lm-DockPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:""}.jupyter-wrapper .p-DockPanel-handle[data-orientation=horizontal],.jupyter-wrapper .lm-DockPanel-handle[data-orientation=horizontal]{cursor:ew-resize}.jupyter-wrapper .p-DockPanel-handle[data-orientation=vertical],.jupyter-wrapper .lm-DockPanel-handle[data-orientation=vertical]{cursor:ns-resize}.jupyter-wrapper .p-DockPanel-handle[data-orientation=horizontal]:after,.jupyter-wrapper .lm-DockPanel-handle[data-orientation=horizontal]:after{left:50%;min-width:8px;transform:translate(-50%)}.jupyter-wrapper .p-DockPanel-handle[data-orientation=vertical]:after,.jupyter-wrapper .lm-DockPanel-handle[data-orientation=vertical]:after{top:50%;min-height:8px;transform:translateY(-50%)}.jupyter-wrapper .p-DockPanel-overlay,.jupyter-wrapper .lm-DockPanel-overlay{z-index:3;box-sizing:border-box;pointer-events:none}.jupyter-wrapper .p-DockPanel-overlay.p-mod-hidden,.jupyter-wrapper .lm-DockPanel-overlay.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-Menu,.jupyter-wrapper .lm-Menu{z-index:10000;position:absolute;white-space:nowrap;overflow-x:hidden;overflow-y:auto;outline:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-Menu-content,.jupyter-wrapper .lm-Menu-content{margin:0;padding:0;display:table;list-style-type:none}.jupyter-wrapper .p-Menu-item,.jupyter-wrapper .lm-Menu-item{display:table-row}.jupyter-wrapper .p-Menu-item.p-mod-hidden,.jupyter-wrapper .p-Menu-item.p-mod-collapsed,.jupyter-wrapper .lm-Menu-item.lm-mod-hidden,.jupyter-wrapper .lm-Menu-item.lm-mod-collapsed{display:none!important}.jupyter-wrapper .p-Menu-itemIcon,.jupyter-wrapper .p-Menu-itemSubmenuIcon,.jupyter-wrapper .lm-Menu-itemIcon,.jupyter-wrapper .lm-Menu-itemSubmenuIcon{display:table-cell;text-align:center}.jupyter-wrapper .p-Menu-itemLabel,.jupyter-wrapper .lm-Menu-itemLabel{display:table-cell;text-align:left}.jupyter-wrapper .p-Menu-itemShortcut,.jupyter-wrapper .lm-Menu-itemShortcut{display:table-cell;text-align:right}.jupyter-wrapper .p-MenuBar,.jupyter-wrapper .lm-MenuBar{outline:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-MenuBar-content,.jupyter-wrapper .lm-MenuBar-content{margin:0;padding:0;display:flex;flex-direction:row;list-style-type:none}.jupyter-wrapper .p--MenuBar-item,.jupyter-wrapper .lm-MenuBar-item{box-sizing:border-box}.jupyter-wrapper .p-MenuBar-itemIcon,.jupyter-wrapper .p-MenuBar-itemLabel,.jupyter-wrapper .lm-MenuBar-itemIcon,.jupyter-wrapper .lm-MenuBar-itemLabel{display:inline-block}.jupyter-wrapper .p-ScrollBar,.jupyter-wrapper .lm-ScrollBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-ScrollBar[data-orientation=horizontal],.jupyter-wrapper .lm-ScrollBar[data-orientation=horizontal]{flex-direction:row}.jupyter-wrapper .p-ScrollBar[data-orientation=vertical],.jupyter-wrapper .lm-ScrollBar[data-orientation=vertical]{flex-direction:column}.jupyter-wrapper .p-ScrollBar-button,.jupyter-wrapper .lm-ScrollBar-button{box-sizing:border-box;flex:0 0 auto}.jupyter-wrapper .p-ScrollBar-track,.jupyter-wrapper .lm-ScrollBar-track{box-sizing:border-box;position:relative;overflow:hidden;flex:1 1 auto}.jupyter-wrapper .p-ScrollBar-thumb,.jupyter-wrapper .lm-ScrollBar-thumb{box-sizing:border-box;position:absolute}.jupyter-wrapper .p-SplitPanel-child,.jupyter-wrapper .lm-SplitPanel-child{z-index:0}.jupyter-wrapper .p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel-handle{z-index:1}.jupyter-wrapper .p-SplitPanel-handle.p-mod-hidden,.jupyter-wrapper .lm-SplitPanel-handle.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:""}.jupyter-wrapper .p-SplitPanel[data-orientation=horizontal]>.p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel[data-orientation=horizontal]>.lm-SplitPanel-handle{cursor:ew-resize}.jupyter-wrapper .p-SplitPanel[data-orientation=vertical]>.p-SplitPanel-handle,.jupyter-wrapper .lm-SplitPanel[data-orientation=vertical]>.lm-SplitPanel-handle{cursor:ns-resize}.jupyter-wrapper .p-SplitPanel[data-orientation=horizontal]>.p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel[data-orientation=horizontal]>.lm-SplitPanel-handle:after{left:50%;min-width:8px;transform:translate(-50%)}.jupyter-wrapper .p-SplitPanel[data-orientation=vertical]>.p-SplitPanel-handle:after,.jupyter-wrapper .lm-SplitPanel[data-orientation=vertical]>.lm-SplitPanel-handle:after{top:50%;min-height:8px;transform:translateY(-50%)}.jupyter-wrapper .p-TabBar,.jupyter-wrapper .lm-TabBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .p-TabBar[data-orientation=horizontal],.jupyter-wrapper .lm-TabBar[data-orientation=horizontal]{flex-direction:row;align-items:flex-end}.jupyter-wrapper .p-TabBar[data-orientation=vertical],.jupyter-wrapper .lm-TabBar[data-orientation=vertical]{flex-direction:column;align-items:flex-end}.jupyter-wrapper .p-TabBar-content,.jupyter-wrapper .lm-TabBar-content{margin:0;padding:0;display:flex;flex:1 1 auto;list-style-type:none}.jupyter-wrapper .p-TabBar[data-orientation=horizontal]>.p-TabBar-content,.jupyter-wrapper .lm-TabBar[data-orientation=horizontal]>.lm-TabBar-content{flex-direction:row}.jupyter-wrapper .p-TabBar[data-orientation=vertical]>.p-TabBar-content,.jupyter-wrapper .lm-TabBar[data-orientation=vertical]>.lm-TabBar-content{flex-direction:column}.jupyter-wrapper .p-TabBar-tab,.jupyter-wrapper .lm-TabBar-tab{display:flex;flex-direction:row;box-sizing:border-box;overflow:hidden;touch-action:none}.jupyter-wrapper .p-TabBar-tabIcon,.jupyter-wrapper .p-TabBar-tabCloseIcon,.jupyter-wrapper .lm-TabBar-tabIcon,.jupyter-wrapper .lm-TabBar-tabCloseIcon{flex:0 0 auto}.jupyter-wrapper .p-TabBar-tabLabel,.jupyter-wrapper .lm-TabBar-tabLabel{flex:1 1 auto;overflow:hidden;white-space:nowrap}.jupyter-wrapper .lm-TabBar-tabInput{-webkit-user-select:all;user-select:all;width:100%;box-sizing:border-box}.jupyter-wrapper .p-TabBar-tab.p-mod-hidden,.jupyter-wrapper .lm-TabBar-tab.lm-mod-hidden,.jupyter-wrapper .lm-TabBar-addButton.lm-mod-hidden{display:none!important}.jupyter-wrapper .p-TabBar.p-mod-dragging .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging .lm-TabBar-tab{position:relative}.jupyter-wrapper .p-TabBar.p-mod-dragging[data-orientation=horizontal] .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging[data-orientation=horizontal] .lm-TabBar-tab{left:0;transition:left .15s ease}.jupyter-wrapper .p-TabBar.p-mod-dragging[data-orientation=vertical] .p-TabBar-tab,.jupyter-wrapper .lm-TabBar.lm-mod-dragging[data-orientation=vertical] .lm-TabBar-tab{top:0;transition:top .15s ease}.jupyter-wrapper .p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging,.jupyter-wrapper .lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging{transition:none}.jupyter-wrapper .lm-TabBar-tabLabel .lm-TabBar-tabInput{-webkit-user-select:all;user-select:all;width:100%;box-sizing:border-box;background:inherit}.jupyter-wrapper .p-TabPanel-tabBar,.jupyter-wrapper .lm-TabPanel-tabBar{z-index:1}.jupyter-wrapper .p-TabPanel-stackedPanel,.jupyter-wrapper .lm-TabPanel-stackedPanel{z-index:0}.jupyter-wrapper html{-webkit-box-sizing:border-box;box-sizing:border-box}.jupyter-wrapper *,.jupyter-wrapper *:before,.jupyter-wrapper *:after{-webkit-box-sizing:inherit;box-sizing:inherit}.jupyter-wrapper body{font-size:14px;font-weight:400;letter-spacing:0;line-height:1.28581;text-transform:none;color:#182026;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,Icons16,sans-serif}.jupyter-wrapper p{margin-bottom:10px;margin-top:0}.jupyter-wrapper small{font-size:12px}.jupyter-wrapper strong{font-weight:600}.jupyter-wrapper ::-moz-selection{background:rgba(125,188,255,.6)}.jupyter-wrapper ::selection{background:rgba(125,188,255,.6)}.jupyter-wrapper .bp3-heading{color:#182026;font-weight:600;margin:0 0 10px;padding:0}.jupyter-wrapper .bp3-dark .bp3-heading{color:#f5f8fa}.jupyter-wrapper h1.bp3-heading,.jupyter-wrapper .bp3-running-text h1{font-size:36px;line-height:40px}.jupyter-wrapper h2.bp3-heading,.jupyter-wrapper .bp3-running-text h2{font-size:28px;line-height:32px}.jupyter-wrapper h3.bp3-heading,.jupyter-wrapper .bp3-running-text h3{font-size:22px;line-height:25px}.jupyter-wrapper h4.bp3-heading,.jupyter-wrapper .bp3-running-text h4{font-size:18px;line-height:21px}.jupyter-wrapper h5.bp3-heading,.jupyter-wrapper .bp3-running-text h5{font-size:16px;line-height:19px}.jupyter-wrapper h6.bp3-heading,.jupyter-wrapper .bp3-running-text h6{font-size:14px;line-height:16px}.jupyter-wrapper .bp3-ui-text{font-size:14px;font-weight:400;letter-spacing:0;line-height:1.28581;text-transform:none}.jupyter-wrapper .bp3-monospace-text{font-family:monospace;text-transform:none}.jupyter-wrapper .bp3-text-muted{color:#5c7080}.jupyter-wrapper .bp3-dark .bp3-text-muted{color:#a7b6c2}.jupyter-wrapper .bp3-text-disabled{color:#5c708099}.jupyter-wrapper .bp3-dark .bp3-text-disabled{color:#a7b6c299}.jupyter-wrapper .bp3-text-overflow-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal}.jupyter-wrapper .bp3-running-text{font-size:14px;line-height:1.5}.jupyter-wrapper .bp3-running-text h1{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h1{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h2{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h2{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h3{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h3{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h4{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h4{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h5{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h5{color:#f5f8fa}.jupyter-wrapper .bp3-running-text h6{color:#182026;font-weight:600;margin-bottom:20px;margin-top:40px}.jupyter-wrapper .bp3-dark .bp3-running-text h6{color:#f5f8fa}.jupyter-wrapper .bp3-running-text hr{border:none;border-bottom:1px solid rgba(16,22,26,.15);margin:20px 0}.jupyter-wrapper .bp3-dark .bp3-running-text hr{border-color:#ffffff26}.jupyter-wrapper .bp3-running-text p{margin:0 0 10px;padding:0}.jupyter-wrapper .bp3-text-large{font-size:16px}.jupyter-wrapper .bp3-text-small{font-size:12px}.jupyter-wrapper a .bp3-icon,.jupyter-wrapper a .bp3-icon-standard,.jupyter-wrapper a .bp3-icon-large,.jupyter-wrapper a code,.jupyter-wrapper .bp3-dark a code{color:inherit}.jupyter-wrapper .bp3-dark a,.jupyter-wrapper .bp3-dark a:hover{color:#48aff0}.jupyter-wrapper .bp3-dark a .bp3-icon,.jupyter-wrapper .bp3-dark a .bp3-icon-standard,.jupyter-wrapper .bp3-dark a .bp3-icon-large,.jupyter-wrapper .bp3-dark a:hover .bp3-icon,.jupyter-wrapper .bp3-dark a:hover .bp3-icon-standard,.jupyter-wrapper .bp3-dark a:hover .bp3-icon-large{color:inherit}.jupyter-wrapper .bp3-running-text code,.jupyter-wrapper .bp3-code{font-family:monospace;text-transform:none;background:rgba(255,255,255,.7);border-radius:3px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33;color:#5c7080;font-size:smaller;padding:2px 5px}.jupyter-wrapper .bp3-dark .bp3-running-text code,.jupyter-wrapper .bp3-running-text .bp3-dark code,.jupyter-wrapper .bp3-dark .bp3-code{background:rgba(16,22,26,.3);-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66;color:#a7b6c2}.jupyter-wrapper .bp3-running-text a>code,.jupyter-wrapper a>.bp3-code{color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-running-text a>code,.jupyter-wrapper .bp3-running-text .bp3-dark a>code,.jupyter-wrapper .bp3-dark a>.bp3-code{color:inherit}.jupyter-wrapper .bp3-running-text pre,.jupyter-wrapper .bp3-code-block{font-family:monospace;text-transform:none;background:rgba(255,255,255,.7);border-radius:3px;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px #10161a26;color:#182026;display:block;font-size:13px;line-height:1.4;margin:10px 0;padding:13px 15px 12px;word-break:break-all;word-wrap:break-word}.jupyter-wrapper .bp3-dark .bp3-running-text pre,.jupyter-wrapper .bp3-running-text .bp3-dark pre,.jupyter-wrapper .bp3-dark .bp3-code-block{background:rgba(16,22,26,.3);-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-running-text pre>code,.jupyter-wrapper .bp3-code-block>code{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit;font-size:inherit;padding:0}.jupyter-wrapper .bp3-running-text kbd,.jupyter-wrapper .bp3-key{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background:#ffffff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33;color:#5c7080;display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;font-family:inherit;font-size:12px;height:24px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;line-height:24px;min-width:24px;padding:3px 6px;vertical-align:middle}.jupyter-wrapper .bp3-running-text kbd .bp3-icon,.jupyter-wrapper .bp3-key .bp3-icon,.jupyter-wrapper .bp3-running-text kbd .bp3-icon-standard,.jupyter-wrapper .bp3-key .bp3-icon-standard,.jupyter-wrapper .bp3-running-text kbd .bp3-icon-large,.jupyter-wrapper .bp3-key .bp3-icon-large{margin-right:5px}.jupyter-wrapper .bp3-dark .bp3-running-text kbd,.jupyter-wrapper .bp3-running-text .bp3-dark kbd,.jupyter-wrapper .bp3-dark .bp3-key{background:#394b59;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66;color:#a7b6c2}.jupyter-wrapper .bp3-running-text blockquote,.jupyter-wrapper .bp3-blockquote{border-left:solid 4px rgba(167,182,194,.5);margin:0 0 10px;padding:0 20px}.jupyter-wrapper .bp3-dark .bp3-running-text blockquote,.jupyter-wrapper .bp3-running-text .bp3-dark blockquote,.jupyter-wrapper .bp3-dark .bp3-blockquote{border-color:#73869480}.jupyter-wrapper .bp3-running-text ul,.jupyter-wrapper .bp3-running-text ol,.jupyter-wrapper .bp3-list{margin:10px 0;padding-left:30px}.jupyter-wrapper .bp3-running-text ul li:not(:last-child),.jupyter-wrapper .bp3-running-text ol li:not(:last-child),.jupyter-wrapper .bp3-list li:not(:last-child){margin-bottom:5px}.jupyter-wrapper .bp3-running-text ul ol,.jupyter-wrapper .bp3-running-text ol ol,.jupyter-wrapper .bp3-list ol,.jupyter-wrapper .bp3-running-text ul ul,.jupyter-wrapper .bp3-running-text ol ul,.jupyter-wrapper .bp3-list ul{margin-top:5px}.jupyter-wrapper .bp3-list-unstyled{list-style:none;margin:0;padding:0}.jupyter-wrapper .bp3-list-unstyled li{padding:0}.jupyter-wrapper .bp3-rtl{text-align:right}.jupyter-wrapper .bp3-dark{color:#f5f8fa}.jupyter-wrapper :focus{outline:rgba(19,124,189,.6) auto 2px;outline-offset:2px;-moz-outline-radius:6px}.jupyter-wrapper .bp3-focus-disabled :focus{outline:none!important}.jupyter-wrapper .bp3-focus-disabled :focus~.bp3-control-indicator{outline:none!important}.jupyter-wrapper .bp3-alert{max-width:400px;padding:20px}.jupyter-wrapper .bp3-alert-body{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-alert-body .bp3-icon{font-size:40px;margin-right:20px;margin-top:0}.jupyter-wrapper .bp3-alert-contents{word-break:break-word}.jupyter-wrapper .bp3-alert-footer{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;margin-top:10px}.jupyter-wrapper .bp3-alert-footer .bp3-button{margin-left:10px}.jupyter-wrapper .bp3-breadcrumbs{-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:default;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:wrap;flex-wrap:wrap;height:30px;list-style:none;margin:0;padding:0}.jupyter-wrapper .bp3-breadcrumbs>li{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-breadcrumbs>li:after{background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 00-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 001.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");content:"";display:block;height:16px;margin:0 5px;width:16px}.jupyter-wrapper .bp3-breadcrumbs>li:last-of-type:after{display:none}.jupyter-wrapper .bp3-breadcrumb,.jupyter-wrapper .bp3-breadcrumb-current,.jupyter-wrapper .bp3-breadcrumbs-collapsed{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;font-size:16px}.jupyter-wrapper .bp3-breadcrumb,.jupyter-wrapper .bp3-breadcrumbs-collapsed{color:#5c7080}.jupyter-wrapper .bp3-breadcrumb:hover{text-decoration:none}.jupyter-wrapper .bp3-breadcrumb.bp3-disabled{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-breadcrumb .bp3-icon{margin-right:5px}.jupyter-wrapper .bp3-breadcrumb-current{color:inherit;font-weight:600}.jupyter-wrapper .bp3-breadcrumb-current .bp3-input{font-size:inherit;font-weight:inherit;vertical-align:baseline}.jupyter-wrapper .bp3-breadcrumbs-collapsed{background:#ced9e0;border:none;border-radius:3px;cursor:pointer;margin-right:2px;padding:1px 5px;vertical-align:text-bottom}.jupyter-wrapper .bp3-breadcrumbs-collapsed:before{background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;content:"";display:block;height:16px;width:16px}.jupyter-wrapper .bp3-breadcrumbs-collapsed:hover{background:#bfccd6;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-dark .bp3-breadcrumb,.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs>li:after{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-breadcrumb.bp3-disabled{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-breadcrumb-current{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-breadcrumbs-collapsed:hover{background:rgba(16,22,26,.6);color:#f5f8fa}.jupyter-wrapper .bp3-button{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:none;border-radius:3px;cursor:pointer;font-size:14px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;padding:5px 10px;text-align:left;vertical-align:middle;min-height:30px;min-width:30px}.jupyter-wrapper .bp3-button>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-button>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-button:before,.jupyter-wrapper .bp3-button>*{margin-right:7px}.jupyter-wrapper .bp3-button:empty:before,.jupyter-wrapper .bp3-button>:last-child{margin-right:0}.jupyter-wrapper .bp3-button:empty{padding:0!important}.jupyter-wrapper .bp3-button:disabled,.jupyter-wrapper .bp3-button.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-button.bp3-align-right,.jupyter-wrapper .bp3-align-right .bp3-button{text-align:right}.jupyter-wrapper .bp3-button.bp3-align-left,.jupyter-wrapper .bp3-align-left .bp3-button{text-align:left}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]){background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active:hover,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-button.bp3-intent-primary{background-color:#137cbd;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-primary:hover{background-color:#106ba3;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-active{background-color:#0e5a8a;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-intent-primary.bp3-disabled{background-color:#137cbd80;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button.bp3-intent-success{background-color:#0f9960;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-success:hover{background-color:#0d8050;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-active{background-color:#0a6640;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-intent-success.bp3-disabled{background-color:#0f996080;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button.bp3-intent-warning{background-color:#d9822b;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-warning:hover{background-color:#bf7326;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-active{background-color:#a66321;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-intent-warning.bp3-disabled{background-color:#d9822b80;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button.bp3-intent-danger{background-color:#db3737;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-active{color:#fff}.jupyter-wrapper .bp3-button.bp3-intent-danger:hover{background-color:#c23030;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-active{background-color:#a82a2a;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-intent-danger.bp3-disabled{background-color:#db373780;background-image:none;border-color:transparent;-webkit-box-shadow:none;box-shadow:none;color:#fff9}.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-button-spinner .bp3-spinner-head{stroke:#fff}.jupyter-wrapper .bp3-button.bp3-large,.jupyter-wrapper .bp3-large .bp3-button{min-height:40px;min-width:40px;font-size:16px;padding:5px 15px}.jupyter-wrapper .bp3-button.bp3-large:before,.jupyter-wrapper .bp3-button.bp3-large>*,.jupyter-wrapper .bp3-large .bp3-button:before,.jupyter-wrapper .bp3-large .bp3-button>*{margin-right:10px}.jupyter-wrapper .bp3-button.bp3-large:empty:before,.jupyter-wrapper .bp3-button.bp3-large>:last-child,.jupyter-wrapper .bp3-large .bp3-button:empty:before,.jupyter-wrapper .bp3-large .bp3-button>:last-child{margin-right:0}.jupyter-wrapper .bp3-button.bp3-small,.jupyter-wrapper .bp3-small .bp3-button{min-height:24px;min-width:24px;padding:0 7px}.jupyter-wrapper .bp3-button.bp3-loading{position:relative}.jupyter-wrapper .bp3-button.bp3-loading[class*=bp3-icon-]:before{visibility:hidden}.jupyter-wrapper .bp3-button.bp3-loading .bp3-button-spinner{margin:0;position:absolute}.jupyter-wrapper .bp3-button.bp3-loading>:not(.bp3-button-spinner){visibility:hidden}.jupyter-wrapper .bp3-button[class*=bp3-icon-]:before{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;color:#5c7080}.jupyter-wrapper .bp3-button .bp3-icon,.jupyter-wrapper .bp3-button .bp3-icon-standard,.jupyter-wrapper .bp3-button .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-button .bp3-icon.bp3-align-right,.jupyter-wrapper .bp3-button .bp3-icon-standard.bp3-align-right,.jupyter-wrapper .bp3-button .bp3-icon-large.bp3-align-right{margin-left:7px}.jupyter-wrapper .bp3-button .bp3-icon:first-child:last-child,.jupyter-wrapper .bp3-button .bp3-spinner+.bp3-icon:last-child{margin:0 -7px}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]){background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):hover,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):disabled,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]):disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]).bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-])[class*=bp3-icon-]:before{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-button:not([class*=bp3-intent-]) .bp3-icon-large{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-],.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:active,.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-].bp3-active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-]:disabled,.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-].bp3-disabled{background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#ffffff4d}.jupyter-wrapper .bp3-dark .bp3-button[class*=bp3-intent-] .bp3-button-spinner .bp3-spinner-head{stroke:#8a9ba8}.jupyter-wrapper .bp3-button:disabled:before,.jupyter-wrapper .bp3-button:disabled .bp3-icon,.jupyter-wrapper .bp3-button:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-button:disabled .bp3-icon-large,.jupyter-wrapper .bp3-button.bp3-disabled:before,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon-standard,.jupyter-wrapper .bp3-button.bp3-disabled .bp3-icon-large,.jupyter-wrapper .bp3-button[class*=bp3-intent-]:before,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon-standard,.jupyter-wrapper .bp3-button[class*=bp3-intent-] .bp3-icon-large{color:inherit!important}.jupyter-wrapper .bp3-button.bp3-minimal{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-button.bp3-minimal:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-button.bp3-minimal:disabled:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-minimal:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-outlined{background:none;-webkit-box-shadow:none;box-shadow:none;border:1px solid rgba(24,32,38,.2);-webkit-box-sizing:border-box;box-sizing:border-box}.jupyter-wrapper .bp3-button.bp3-outlined:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-button.bp3-outlined:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-button.bp3-outlined:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-disabled:hover{border-color:#5c70801a}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined{border-color:#fff6}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-disabled:hover{border-color:#fff3}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary{border-color:#106ba399}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{border-color:#106ba333}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary{border-color:#48aff099}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-primary.bp3-disabled{border-color:#48aff033}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success{border-color:#0d805099}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{border-color:#0d805033}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success{border-color:#3dcc9199}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-success.bp3-disabled{border-color:#3dcc9133}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning{border-color:#bf732699}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{border-color:#bf732633}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning{border-color:#ffb36699}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-warning.bp3-disabled{border-color:#ffb36633}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger{border-color:#c2303099}.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{border-color:#c2303033}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger{border-color:#ff737399}.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button.bp3-outlined.bp3-intent-danger.bp3-disabled{border-color:#ff737333}.jupyter-wrapper a.bp3-button{text-align:center;text-decoration:none;-webkit-transition:none;transition:none}.jupyter-wrapper a.bp3-button,.jupyter-wrapper a.bp3-button:hover,.jupyter-wrapper a.bp3-button:active{color:#182026}.jupyter-wrapper a.bp3-button.bp3-disabled{color:#5c708099}.jupyter-wrapper .bp3-button-text{-webkit-box-flex:0;-ms-flex:0 1 auto;flex:0 1 auto}.jupyter-wrapper .bp3-button.bp3-align-left .bp3-button-text,.jupyter-wrapper .bp3-button.bp3-align-right .bp3-button-text,.jupyter-wrapper .bp3-button-group.bp3-align-left .bp3-button-text,.jupyter-wrapper .bp3-button-group.bp3-align-right .bp3-button-text{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex}.jupyter-wrapper .bp3-button-group .bp3-button{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;position:relative;z-index:4}.jupyter-wrapper .bp3-button-group .bp3-button:focus{z-index:5}.jupyter-wrapper .bp3-button-group .bp3-button:hover{z-index:6}.jupyter-wrapper .bp3-button-group .bp3-button:active,.jupyter-wrapper .bp3-button-group .bp3-button.bp3-active{z-index:7}.jupyter-wrapper .bp3-button-group .bp3-button:disabled,.jupyter-wrapper .bp3-button-group .bp3-button.bp3-disabled{z-index:3}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]{z-index:9}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:focus{z-index:10}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:hover{z-index:11}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:active,.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-].bp3-active{z-index:12}.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-]:disabled,.jupyter-wrapper .bp3-button-group .bp3-button[class*=bp3-intent-].bp3-disabled{z-index:8}.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:first-child) .bp3-button,.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:first-child){border-bottom-left-radius:0;border-top-left-radius:0}.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:last-child){border-bottom-right-radius:0;border-top-right-radius:0;margin-right:-1px}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-button-group .bp3-popover-wrapper,.jupyter-wrapper .bp3-button-group .bp3-popover-target{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-button-group .bp3-button.bp3-fill,.jupyter-wrapper .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-button-group.bp3-vertical{-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;vertical-align:top}.jupyter-wrapper .bp3-button-group.bp3-vertical.bp3-fill{height:100%;width:unset}.jupyter-wrapper .bp3-button-group.bp3-vertical .bp3-button{margin-right:0!important;width:100%}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:first-child .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:first-child{border-radius:3px 3px 0 0}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:last-child .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:last-child{border-radius:0 0 3px 3px}.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-button-group.bp3-vertical:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-bottom:-1px}.jupyter-wrapper .bp3-button-group.bp3-align-left .bp3-button{text-align:left}.jupyter-wrapper .bp3-dark .bp3-button-group:not(.bp3-minimal)>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-dark .bp3-button-group:not(.bp3-minimal)>.bp3-button:not(:last-child){margin-right:1px}.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-vertical>.bp3-popover-wrapper:not(:last-child) .bp3-button,.jupyter-wrapper .bp3-dark .bp3-button-group.bp3-vertical>.bp3-button:not(:last-child){margin-bottom:1px}.jupyter-wrapper .bp3-callout{font-size:14px;line-height:1.5;background-color:#8a9ba826;border-radius:3px;padding:10px 12px 9px;position:relative;width:100%}.jupyter-wrapper .bp3-callout[class*=bp3-icon-]{padding-left:40px}.jupyter-wrapper .bp3-callout[class*=bp3-icon-]:before{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;color:#5c7080;left:10px;position:absolute;top:10px}.jupyter-wrapper .bp3-callout.bp3-callout-icon{padding-left:40px}.jupyter-wrapper .bp3-callout.bp3-callout-icon>.bp3-icon:first-child{color:#5c7080;left:10px;position:absolute;top:10px}.jupyter-wrapper .bp3-callout .bp3-heading{line-height:20px;margin-bottom:5px;margin-top:0}.jupyter-wrapper .bp3-callout .bp3-heading:last-child{margin-bottom:0}.jupyter-wrapper .bp3-dark .bp3-callout{background-color:#8a9ba833}.jupyter-wrapper .bp3-dark .bp3-callout[class*=bp3-icon-]:before{color:#a7b6c2}.jupyter-wrapper .bp3-callout.bp3-intent-primary{background-color:#137cbd26}.jupyter-wrapper .bp3-callout.bp3-intent-primary[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-primary>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-primary .bp3-heading{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary{background-color:#137cbd40}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{color:#48aff0}.jupyter-wrapper .bp3-callout.bp3-intent-success{background-color:#0f996026}.jupyter-wrapper .bp3-callout.bp3-intent-success[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-success>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-success .bp3-heading{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success{background-color:#0f996040}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{color:#3dcc91}.jupyter-wrapper .bp3-callout.bp3-intent-warning{background-color:#d9822b26}.jupyter-wrapper .bp3-callout.bp3-intent-warning[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-warning>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-warning .bp3-heading{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning{background-color:#d9822b40}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{color:#ffb366}.jupyter-wrapper .bp3-callout.bp3-intent-danger{background-color:#db373726}.jupyter-wrapper .bp3-callout.bp3-intent-danger[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-callout.bp3-intent-danger>.bp3-icon:first-child,.jupyter-wrapper .bp3-callout.bp3-intent-danger .bp3-heading{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger{background-color:#db373740}.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger[class*=bp3-icon-]:before,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger>.bp3-icon:first-child,.jupyter-wrapper .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{color:#ff7373}.jupyter-wrapper .bp3-running-text .bp3-callout{margin:20px 0}.jupyter-wrapper .bp3-card{background-color:#fff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a26,0 0 #10161a00,0 0 #10161a00;padding:20px;-webkit-transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .2s cubic-bezier(.4,1,.75,.9);transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),box-shadow .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),box-shadow .2s cubic-bezier(.4,1,.75,.9),-webkit-transform .2s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-card.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a66,0 0 #10161a00,0 0 #10161a00}.jupyter-wrapper .bp3-elevation-0{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.15),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a26,0 0 #10161a00,0 0 #10161a00}.jupyter-wrapper .bp3-elevation-0.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-0{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),0 0 0 rgba(16,22,26,0),0 0 0 rgba(16,22,26,0);box-shadow:0 0 0 1px #10161a66,0 0 #10161a00,0 0 #10161a00}.jupyter-wrapper .bp3-elevation-1{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33}.jupyter-wrapper .bp3-elevation-1.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-1{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-elevation-2{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 1px 1px rgba(16,22,26,.2),0 2px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 1px 1px #10161a33,0 2px 6px #10161a33}.jupyter-wrapper .bp3-elevation-2.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-2{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.4),0 2px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a66,0 2px 6px #10161a66}.jupyter-wrapper .bp3-elevation-3{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33}.jupyter-wrapper .bp3-elevation-3.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-3{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-elevation-4{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33}.jupyter-wrapper .bp3-elevation-4.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-elevation-4{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66}.jupyter-wrapper .bp3-card.bp3-interactive:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;cursor:pointer}.jupyter-wrapper .bp3-card.bp3-interactive:hover.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card.bp3-interactive:hover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-card.bp3-interactive:active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33;opacity:.9;-webkit-transition-duration:0;transition-duration:0}.jupyter-wrapper .bp3-card.bp3-interactive:active.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-card.bp3-interactive:active{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-collapse{height:0;overflow-y:hidden;-webkit-transition:height .2s cubic-bezier(.4,1,.75,.9);transition:height .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-collapse .bp3-collapse-body{-webkit-transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),-webkit-transform .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-collapse .bp3-collapse-body[aria-hidden=true]{display:none}.jupyter-wrapper .bp3-context-menu .bp3-popover-target{display:block}.jupyter-wrapper .bp3-context-menu-popover-target{position:fixed}.jupyter-wrapper .bp3-dialog-container{opacity:1;-webkit-transform:scale(1);transform:scale(1);-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;min-height:100%;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:100%}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-enter>.bp3-dialog,.jupyter-wrapper .bp3-dialog-container.bp3-overlay-appear>.bp3-dialog{opacity:0;-webkit-transform:scale(.5);transform:scale(.5)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-enter-active>.bp3-dialog,.jupyter-wrapper .bp3-dialog-container.bp3-overlay-appear-active>.bp3-dialog{opacity:1;-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:opacity,transform;transition-property:opacity,transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-exit>.bp3-dialog{opacity:1;-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-dialog-container.bp3-overlay-exit-active>.bp3-dialog{opacity:0;-webkit-transform:scale(.5);transform:scale(.5);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:opacity,transform;transition-property:opacity,transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-dialog{background:#ebf1f5;border-radius:6px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:30px 0;padding-bottom:20px;pointer-events:all;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;width:500px}.jupyter-wrapper .bp3-dialog:focus{outline:0}.jupyter-wrapper .bp3-dialog.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-dialog{background:#293742;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dialog-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background:#ffffff;border-radius:6px 6px 0 0;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;min-height:40px;padding-left:20px;padding-right:5px;z-index:30}.jupyter-wrapper .bp3-dialog-header .bp3-icon-large,.jupyter-wrapper .bp3-dialog-header .bp3-icon{color:#5c7080;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-right:10px}.jupyter-wrapper .bp3-dialog-header .bp3-heading{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:inherit;margin:0}.jupyter-wrapper .bp3-dialog-header .bp3-heading:last-child{margin-right:20px}.jupyter-wrapper .bp3-dark .bp3-dialog-header{background:#30404d;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.4);box-shadow:0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-dialog-header .bp3-icon-large,.jupyter-wrapper .bp3-dark .bp3-dialog-header .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dialog-body{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:18px;margin:20px}.jupyter-wrapper .bp3-dialog-footer{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin:0 20px}.jupyter-wrapper .bp3-dialog-footer-actions{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end}.jupyter-wrapper .bp3-dialog-footer-actions .bp3-button{margin-left:10px}.jupyter-wrapper .bp3-multistep-dialog-panels{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-multistep-dialog-left-panel{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-dark .bp3-multistep-dialog-left-panel{background:#202b33}.jupyter-wrapper .bp3-multistep-dialog-right-panel{background-color:#f5f8fa;border-left:1px solid rgba(16,22,26,.15);border-radius:0 0 6px;-webkit-box-flex:3;-ms-flex:3;flex:3;min-width:0}.jupyter-wrapper .bp3-dark .bp3-multistep-dialog-right-panel{background-color:#293742;border-left:1px solid rgba(16,22,26,.4)}.jupyter-wrapper .bp3-multistep-dialog-footer{background-color:#fff;border-radius:0 0 6px;border-top:1px solid rgba(16,22,26,.15);padding:10px}.jupyter-wrapper .bp3-dark .bp3-multistep-dialog-footer{background:#30404d;border-top:1px solid rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dialog-step-container{background-color:#f5f8fa;border-bottom:1px solid rgba(16,22,26,.15)}.jupyter-wrapper .bp3-dark .bp3-dialog-step-container{background:#293742;border-bottom:1px solid rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dialog-step-container.bp3-dialog-step-viewed{background-color:#fff}.jupyter-wrapper .bp3-dark .bp3-dialog-step-container.bp3-dialog-step-viewed{background:#30404d}.jupyter-wrapper .bp3-dialog-step{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#f5f8fa;border-radius:6px;cursor:not-allowed;display:-webkit-box;display:-ms-flexbox;display:flex;margin:4px;padding:6px 14px}.jupyter-wrapper .bp3-dark .bp3-dialog-step{background:#293742}.jupyter-wrapper .bp3-dialog-step-viewed .bp3-dialog-step{background-color:#fff;cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-dialog-step-viewed .bp3-dialog-step{background:#30404d}.jupyter-wrapper .bp3-dialog-step:hover{background-color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-dialog-step:hover{background:#293742}.jupyter-wrapper .bp3-dialog-step-icon{-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#5c708099;border-radius:50%;color:#fff;display:-webkit-box;display:-ms-flexbox;display:flex;height:25px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;width:25px}.jupyter-wrapper .bp3-dark .bp3-dialog-step-icon{background-color:#a7b6c299}.jupyter-wrapper .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-icon{background-color:#2b95d6}.jupyter-wrapper .bp3-dialog-step-viewed .bp3-dialog-step-icon{background-color:#8a9ba8}.jupyter-wrapper .bp3-dialog-step-title{color:#5c708099;-webkit-box-flex:1;-ms-flex:1;flex:1;padding-left:10px}.jupyter-wrapper .bp3-dark .bp3-dialog-step-title{color:#a7b6c299}.jupyter-wrapper .bp3-active.bp3-dialog-step-viewed .bp3-dialog-step-title{color:#2b95d6}.jupyter-wrapper .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{color:#182026}.jupyter-wrapper .bp3-dark .bp3-dialog-step-viewed:not(.bp3-active) .bp3-dialog-step-title{color:#f5f8fa}.jupyter-wrapper .bp3-drawer{background:#ffffff;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:0;padding:0}.jupyter-wrapper .bp3-drawer:focus{outline:0}.jupyter-wrapper .bp3-drawer.bp3-position-top{height:50%;left:0;right:0;top:0}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-appear{-webkit-transform:translateY(-100%);transform:translateY(-100%)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{-webkit-transform:translateY(-100%);transform:translateY(-100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom{bottom:0;height:50%;left:0;right:0}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{-webkit-transform:translateY(100%);transform:translateY(100%)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{-webkit-transform:translateY(100%);transform:translateY(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-left{bottom:0;left:0;top:0;width:50%}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-appear{-webkit-transform:translateX(-100%);transform:translate(-100%)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translate(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-exit{-webkit-transform:translateX(0);transform:translate(0)}.jupyter-wrapper .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{-webkit-transform:translateX(-100%);transform:translate(-100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-right{bottom:0;right:0;top:0;width:50%}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-appear{-webkit-transform:translateX(100%);transform:translate(100%)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translate(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-exit{-webkit-transform:translateX(0);transform:translate(0)}.jupyter-wrapper .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical){bottom:0;right:0;top:0;width:50%}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-enter,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{-webkit-transform:translateX(100%);transform:translate(100%)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{-webkit-transform:translateX(0);transform:translate(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{-webkit-transform:translateX(0);transform:translate(0)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical{bottom:0;height:50%;left:0;right:0}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-enter,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-appear{-webkit-transform:translateY(100%);transform:translateY(100%)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-enter-active,.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-exit{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(.bp3-position-right).bp3-vertical.bp3-overlay-exit-active{-webkit-transform:translateY(100%);transform:translateY(100%);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-drawer.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-drawer{background:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-drawer-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:0;-webkit-box-shadow:0 1px 0 rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;min-height:40px;padding:5px 5px 5px 20px;position:relative}.jupyter-wrapper .bp3-drawer-header .bp3-icon-large,.jupyter-wrapper .bp3-drawer-header .bp3-icon{color:#5c7080;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;margin-right:10px}.jupyter-wrapper .bp3-drawer-header .bp3-heading{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:inherit;margin:0}.jupyter-wrapper .bp3-drawer-header .bp3-heading:last-child{margin-right:20px}.jupyter-wrapper .bp3-dark .bp3-drawer-header{-webkit-box-shadow:0 1px 0 rgba(16,22,26,.4);box-shadow:0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-drawer-header .bp3-icon-large,.jupyter-wrapper .bp3-dark .bp3-drawer-header .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-drawer-body{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:18px;overflow:auto}.jupyter-wrapper .bp3-drawer-footer{-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding:10px 20px;position:relative}.jupyter-wrapper .bp3-dark .bp3-drawer-footer{-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.4);box-shadow:inset 0 1px #10161a66}.jupyter-wrapper .bp3-editable-text{cursor:text;display:inline-block;max-width:100%;position:relative;vertical-align:top;white-space:nowrap}.jupyter-wrapper .bp3-editable-text:before{bottom:-3px;left:-3px;position:absolute;right:-3px;top:-3px;border-radius:3px;content:"";-webkit-transition:background-color .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9),box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9),box-shadow .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-editable-text:hover:before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a26}.jupyter-wrapper .bp3-editable-text.bp3-editable-text-editing:before{background-color:#fff;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-disabled:before{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{color:#137cbd}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary:hover:before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(19,124,189,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd66}.jupyter-wrapper .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{color:#0f9960}.jupyter-wrapper .bp3-editable-text.bp3-intent-success:hover:before{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px rgba(15,153,96,.4);box-shadow:0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f996066}.jupyter-wrapper .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{color:#d9822b}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning:hover:before{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px rgba(217,130,43,.4);box-shadow:0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b66}.jupyter-wrapper .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{color:#db3737}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger:hover:before{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px rgba(219,55,55,.4);box-shadow:0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db373766}.jupyter-wrapper .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-dark .bp3-editable-text:hover:before{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(255,255,255,.15);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #ffffff26}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-editable-text-editing:before{background-color:#10161a4d;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-disabled:before{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary:hover:before{-webkit-box-shadow:0 0 0 0 rgba(72,175,240,0),0 0 0 0 rgba(72,175,240,0),inset 0 0 0 1px rgba(72,175,240,.4);box-shadow:0 0 #48aff000,0 0 #48aff000,inset 0 0 0 1px #48aff066}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #48aff0,0 0 0 3px rgba(72,175,240,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #48aff0,0 0 0 3px #48aff04d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success:hover:before{-webkit-box-shadow:0 0 0 0 rgba(61,204,145,0),0 0 0 0 rgba(61,204,145,0),inset 0 0 0 1px rgba(61,204,145,.4);box-shadow:0 0 #3dcc9100,0 0 #3dcc9100,inset 0 0 0 1px #3dcc9166}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #3dcc91,0 0 0 3px rgba(61,204,145,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #3dcc91,0 0 0 3px #3dcc914d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning:hover:before{-webkit-box-shadow:0 0 0 0 rgba(255,179,102,0),0 0 0 0 rgba(255,179,102,0),inset 0 0 0 1px rgba(255,179,102,.4);box-shadow:0 0 #ffb36600,0 0 #ffb36600,inset 0 0 0 1px #ffb36666}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #ffb366,0 0 0 3px rgba(255,179,102,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #ffb366,0 0 0 3px #ffb3664d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger:hover:before{-webkit-box-shadow:0 0 0 0 rgba(255,115,115,0),0 0 0 0 rgba(255,115,115,0),inset 0 0 0 1px rgba(255,115,115,.4);box-shadow:0 0 #ff737300,0 0 #ff737300,inset 0 0 0 1px #ff737366}.jupyter-wrapper .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing:before{-webkit-box-shadow:0 0 0 1px #ff7373,0 0 0 3px rgba(255,115,115,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #ff7373,0 0 0 3px #ff73734d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-editable-text-input,.jupyter-wrapper .bp3-editable-text-content{color:inherit;display:inherit;font:inherit;letter-spacing:inherit;max-width:inherit;min-width:inherit;position:relative;resize:none;text-transform:inherit;vertical-align:top}.jupyter-wrapper .bp3-editable-text-input{background:none;border:none;-webkit-box-shadow:none;box-shadow:none;padding:0;white-space:pre-wrap;width:100%}.jupyter-wrapper .bp3-editable-text-input::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-editable-text-input:focus{outline:none}.jupyter-wrapper .bp3-editable-text-input::-ms-clear{display:none}.jupyter-wrapper .bp3-editable-text-content{overflow:hidden;padding-right:2px;text-overflow:ellipsis;white-space:pre}.jupyter-wrapper .bp3-editable-text-editing>.bp3-editable-text-content{left:0;position:absolute;visibility:hidden}.jupyter-wrapper .bp3-editable-text-placeholder>.bp3-editable-text-content{color:#5c708099}.jupyter-wrapper .bp3-dark .bp3-editable-text-placeholder>.bp3-editable-text-content{color:#a7b6c299}.jupyter-wrapper .bp3-editable-text.bp3-multiline{display:block}.jupyter-wrapper .bp3-editable-text.bp3-multiline .bp3-editable-text-content{overflow:auto;white-space:pre-wrap;word-wrap:break-word}.jupyter-wrapper .bp3-divider{border-bottom:1px solid rgba(16,22,26,.15);border-right:1px solid rgba(16,22,26,.15);margin:5px}.jupyter-wrapper .bp3-dark .bp3-divider{border-color:#10161a66}.jupyter-wrapper .bp3-control-group{-webkit-transform:translateZ(0);transform:translateZ(0);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch}.jupyter-wrapper .bp3-control-group>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-control-group>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-control-group .bp3-button,.jupyter-wrapper .bp3-control-group .bp3-html-select,.jupyter-wrapper .bp3-control-group .bp3-input,.jupyter-wrapper .bp3-control-group .bp3-select{position:relative}.jupyter-wrapper .bp3-control-group .bp3-input{border-radius:inherit;z-index:2}.jupyter-wrapper .bp3-control-group .bp3-input:focus{border-radius:3px;z-index:14}.jupyter-wrapper .bp3-control-group .bp3-input[class*=bp3-intent]{z-index:13}.jupyter-wrapper .bp3-control-group .bp3-input[class*=bp3-intent]:focus{z-index:15}.jupyter-wrapper .bp3-control-group .bp3-input[readonly],.jupyter-wrapper .bp3-control-group .bp3-input:disabled,.jupyter-wrapper .bp3-control-group .bp3-input.bp3-disabled{z-index:1}.jupyter-wrapper .bp3-control-group .bp3-input-group[class*=bp3-intent] .bp3-input{z-index:13}.jupyter-wrapper .bp3-control-group .bp3-input-group[class*=bp3-intent] .bp3-input:focus{z-index:15}.jupyter-wrapper .bp3-control-group .bp3-button,.jupyter-wrapper .bp3-control-group .bp3-html-select select,.jupyter-wrapper .bp3-control-group .bp3-select select{-webkit-transform:translateZ(0);transform:translateZ(0);border-radius:inherit;z-index:4}.jupyter-wrapper .bp3-control-group .bp3-button:focus,.jupyter-wrapper .bp3-control-group .bp3-html-select select:focus,.jupyter-wrapper .bp3-control-group .bp3-select select:focus{z-index:5}.jupyter-wrapper .bp3-control-group .bp3-button:hover,.jupyter-wrapper .bp3-control-group .bp3-html-select select:hover,.jupyter-wrapper .bp3-control-group .bp3-select select:hover{z-index:6}.jupyter-wrapper .bp3-control-group .bp3-button:active,.jupyter-wrapper .bp3-control-group .bp3-html-select select:active,.jupyter-wrapper .bp3-control-group .bp3-select select:active{z-index:7}.jupyter-wrapper .bp3-control-group .bp3-button[readonly],.jupyter-wrapper .bp3-control-group .bp3-button:disabled,.jupyter-wrapper .bp3-control-group .bp3-button.bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[readonly],.jupyter-wrapper .bp3-control-group .bp3-html-select select:disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[readonly],.jupyter-wrapper .bp3-control-group .bp3-select select:disabled,.jupyter-wrapper .bp3-control-group .bp3-select select.bp3-disabled{z-index:3}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent],.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent],.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]{z-index:9}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:focus,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:focus,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:focus{z-index:10}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:hover,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:hover,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:hover{z-index:11}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:active,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:active,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:active{z-index:12}.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-button[class*=bp3-intent].bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-html-select select[class*=bp3-intent].bp3-disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent][readonly],.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent]:disabled,.jupyter-wrapper .bp3-control-group .bp3-select select[class*=bp3-intent].bp3-disabled{z-index:8}.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-icon,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-button,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-input-left-container,.jupyter-wrapper .bp3-control-group .bp3-input-group>.bp3-input-action{z-index:16}.jupyter-wrapper .bp3-control-group .bp3-select:after,.jupyter-wrapper .bp3-control-group .bp3-html-select:after,.jupyter-wrapper .bp3-control-group .bp3-select>.bp3-icon,.jupyter-wrapper .bp3-control-group .bp3-html-select>.bp3-icon{z-index:17}.jupyter-wrapper .bp3-control-group .bp3-select:focus-within{z-index:5}.jupyter-wrapper .bp3-control-group:not(.bp3-vertical)>*:not(.bp3-divider){margin-right:-1px}.jupyter-wrapper .bp3-control-group:not(.bp3-vertical)>.bp3-divider:not(:first-child){margin-left:6px}.jupyter-wrapper .bp3-dark .bp3-control-group:not(.bp3-vertical)>*:not(.bp3-divider){margin-right:0}.jupyter-wrapper .bp3-dark .bp3-control-group:not(.bp3-vertical)>.bp3-button+.bp3-button{margin-left:1px}.jupyter-wrapper .bp3-control-group .bp3-popover-wrapper,.jupyter-wrapper .bp3-control-group .bp3-popover-target{border-radius:inherit}.jupyter-wrapper .bp3-control-group>:first-child{border-radius:3px 0 0 3px}.jupyter-wrapper .bp3-control-group>:last-child{border-radius:0 3px 3px 0;margin-right:0}.jupyter-wrapper .bp3-control-group>:only-child{border-radius:3px;margin-right:0}.jupyter-wrapper .bp3-control-group .bp3-input-group .bp3-button{border-radius:3px}.jupyter-wrapper .bp3-control-group .bp3-numeric-input:not(:first-child) .bp3-input-group{border-bottom-left-radius:0;border-top-left-radius:0}.jupyter-wrapper .bp3-control-group.bp3-fill{width:100%}.jupyter-wrapper .bp3-control-group>.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-control-group.bp3-fill>*:not(.bp3-fixed){-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto}.jupyter-wrapper .bp3-control-group.bp3-vertical{-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-control-group.bp3-vertical>*{margin-top:-1px}.jupyter-wrapper .bp3-control-group.bp3-vertical>:first-child{border-radius:3px 3px 0 0;margin-top:0}.jupyter-wrapper .bp3-control-group.bp3-vertical>:last-child{border-radius:0 0 3px 3px}.jupyter-wrapper .bp3-control{cursor:pointer;display:block;margin-bottom:10px;position:relative;text-transform:none}.jupyter-wrapper .bp3-control input:checked~.bp3-control-indicator{background-color:#137cbd;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-control:hover input:checked~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-control input:not(:disabled):active:checked~.bp3-control-indicator{background:#0e5a8a;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-control input:disabled:checked~.bp3-control-indicator{background:rgba(19,124,189,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-control input:checked~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control:hover input:checked~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control input:not(:disabled):active:checked~.bp3-control-indicator{background-color:#0e5a8a;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-control input:disabled:checked~.bp3-control-indicator{background:rgba(14,90,138,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-control:not(.bp3-align-right){padding-left:26px}.jupyter-wrapper .bp3-control:not(.bp3-align-right) .bp3-control-indicator{margin-left:-26px}.jupyter-wrapper .bp3-control.bp3-align-right{padding-right:26px}.jupyter-wrapper .bp3-control.bp3-align-right .bp3-control-indicator{margin-right:-26px}.jupyter-wrapper .bp3-control.bp3-disabled{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-control.bp3-inline{display:inline-block;margin-right:20px}.jupyter-wrapper .bp3-control input{left:0;opacity:0;position:absolute;top:0;z-index:-1}.jupyter-wrapper .bp3-control .bp3-control-indicator{background-clip:padding-box;background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));border:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;cursor:pointer;display:inline-block;font-size:16px;height:1em;margin-right:10px;margin-top:-3px;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;width:1em}.jupyter-wrapper .bp3-control .bp3-control-indicator:before{content:"";display:block;height:1em;width:1em}.jupyter-wrapper .bp3-control:hover .bp3-control-indicator{background-color:#ebf1f5}.jupyter-wrapper .bp3-control input:not(:disabled):active~.bp3-control-indicator{background:#d8e1e8;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-control input:disabled~.bp3-control-indicator{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;cursor:not-allowed}.jupyter-wrapper .bp3-control input:focus~.bp3-control-indicator{outline:rgba(19,124,189,.6) auto 2px;outline-offset:2px;-moz-outline-radius:6px}.jupyter-wrapper .bp3-control.bp3-align-right .bp3-control-indicator{float:right;margin-left:10px;margin-top:1px}.jupyter-wrapper .bp3-control.bp3-large{font-size:16px}.jupyter-wrapper .bp3-control.bp3-large:not(.bp3-align-right){padding-left:30px}.jupyter-wrapper .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{margin-left:-30px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right{padding-right:30px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{margin-right:-30px}.jupyter-wrapper .bp3-control.bp3-large .bp3-control-indicator{font-size:20px}.jupyter-wrapper .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{margin-top:0}.jupyter-wrapper .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator{background-color:#137cbd;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.1)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.1),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33;color:#fff}.jupyter-wrapper .bp3-control.bp3-checkbox:hover input:indeterminate~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 -1px 0 rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 -1px #10161a33}.jupyter-wrapper .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate~.bp3-control-indicator{background:#0e5a8a;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{background:rgba(19,124,189,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate~.bp3-control-indicator{background-color:#106ba3;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate~.bp3-control-indicator{background-color:#0e5a8a;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a66,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{background:rgba(14,90,138,.5);-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-control.bp3-checkbox .bp3-control-indicator{border-radius:3px}.jupyter-wrapper .bp3-control.bp3-checkbox input:checked~.bp3-control-indicator:before{background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 00-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0012 5z' fill='white'/%3e%3c/svg%3e")}.jupyter-wrapper .bp3-control.bp3-checkbox input:indeterminate~.bp3-control-indicator:before{background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e")}.jupyter-wrapper .bp3-control.bp3-radio .bp3-control-indicator{border-radius:50%}.jupyter-wrapper .bp3-control.bp3-radio input:checked~.bp3-control-indicator:before{background-image:radial-gradient(#ffffff,#ffffff 28%,transparent 32%)}.jupyter-wrapper .bp3-control.bp3-radio input:checked:disabled~.bp3-control-indicator:before{opacity:.5}.jupyter-wrapper .bp3-control.bp3-radio input:focus~.bp3-control-indicator{-moz-outline-radius:16px}.jupyter-wrapper .bp3-control.bp3-switch input~.bp3-control-indicator{background:rgba(167,182,194,.5)}.jupyter-wrapper .bp3-control.bp3-switch:hover input~.bp3-control-indicator{background:rgba(115,134,148,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:not(:disabled):active~.bp3-control-indicator{background:rgba(92,112,128,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:disabled~.bp3-control-indicator{background:rgba(206,217,224,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:disabled~.bp3-control-indicator:before{background:rgba(255,255,255,.8)}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator{background:#137cbd}.jupyter-wrapper .bp3-control.bp3-switch:hover input:checked~.bp3-control-indicator{background:#106ba3}.jupyter-wrapper .bp3-control.bp3-switch input:checked:not(:disabled):active~.bp3-control-indicator{background:#0e5a8a}.jupyter-wrapper .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator{background:rgba(19,124,189,.5)}.jupyter-wrapper .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator:before{background:rgba(255,255,255,.8)}.jupyter-wrapper .bp3-control.bp3-switch:not(.bp3-align-right){padding-left:38px}.jupyter-wrapper .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{margin-left:-38px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-align-right{padding-right:38px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{margin-right:-38px}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator{border:none;border-radius:1.75em;-webkit-box-shadow:none!important;box-shadow:none!important;min-width:1.75em;-webkit-transition:background-color .1s cubic-bezier(.4,1,.75,.9);transition:background-color .1s cubic-bezier(.4,1,.75,.9);width:auto}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator:before{background:#ffffff;border-radius:50%;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a33;height:calc(1em - 4px);left:0;margin:2px;position:absolute;-webkit-transition:left .1s cubic-bezier(.4,1,.75,.9);transition:left .1s cubic-bezier(.4,1,.75,.9);width:calc(1em - 4px)}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator:before{left:calc(100% - 1em)}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){padding-left:45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{margin-left:-45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large.bp3-align-right{padding-right:45px}.jupyter-wrapper .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{margin-right:-45px}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input~.bp3-control-indicator{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch:hover input~.bp3-control-indicator{background:rgba(16,22,26,.7)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active~.bp3-control-indicator{background:rgba(16,22,26,.9)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:disabled~.bp3-control-indicator{background:rgba(57,75,89,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:disabled~.bp3-control-indicator:before{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked~.bp3-control-indicator{background:#137cbd}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch:hover input:checked~.bp3-control-indicator{background:#106ba3}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active~.bp3-control-indicator{background:#0e5a8a}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator{background:rgba(14,90,138,.5)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked:disabled~.bp3-control-indicator:before{background:rgba(16,22,26,.4)}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator:before{background:#394b59;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control.bp3-switch input:checked~.bp3-control-indicator:before{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-control.bp3-switch .bp3-switch-inner-text{font-size:.7em;text-align:center}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{line-height:0;margin-left:.5em;margin-right:1.2em;visibility:hidden}.jupyter-wrapper .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{line-height:1em;margin-left:1.2em;margin-right:.5em;visibility:visible}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator .bp3-control-indicator-child:first-child{line-height:1em;visibility:visible}.jupyter-wrapper .bp3-control.bp3-switch input:checked~.bp3-control-indicator .bp3-control-indicator-child:last-child{line-height:0;visibility:hidden}.jupyter-wrapper .bp3-dark .bp3-control{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-control.bp3-disabled{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-control .bp3-control-indicator{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-control:hover .bp3-control-indicator{background-color:#30404d}.jupyter-wrapper .bp3-dark .bp3-control input:not(:disabled):active~.bp3-control-indicator{background:#202b33;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-control input:disabled~.bp3-control-indicator{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked~.bp3-control-indicator,.jupyter-wrapper .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate~.bp3-control-indicator{color:#a7b6c299}.jupyter-wrapper .bp3-file-input{cursor:pointer;display:inline-block;height:30px;position:relative}.jupyter-wrapper .bp3-file-input input{margin:0;min-width:200px;opacity:0}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;resize:none}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input:after,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input:after .bp3-active,.jupyter-wrapper .bp3-file-input input:disabled+.bp3-file-upload-input:after .bp3-active:hover,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after .bp3-active,.jupyter-wrapper .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after .bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input:after,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-input input:disabled+.bp3-file-upload-input:after .bp3-active,.jupyter-wrapper .bp3-dark .bp3-file-input input.bp3-disabled+.bp3-file-upload-input:after .bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{color:#182026}.jupyter-wrapper .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{color:#f5f8fa}.jupyter-wrapper .bp3-file-input.bp3-fill{width:100%}.jupyter-wrapper .bp3-file-input.bp3-large,.jupyter-wrapper .bp3-large .bp3-file-input{height:40px}.jupyter-wrapper .bp3-file-input .bp3-file-upload-input-custom-text:after{content:attr(bp3-button-text)}.jupyter-wrapper .bp3-file-upload-input{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#ffffff;border:none;border-radius:3px;-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33;color:#182026;font-size:14px;font-weight:400;height:30px;line-height:30px;outline:none;padding:0 80px 0 10px;-webkit-transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);vertical-align:middle;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;color:#5c708099;left:0;position:absolute;right:0;top:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-file-upload-input::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-file-upload-input:focus,.jupyter-wrapper .bp3-file-upload-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-file-upload-input[type=search],.jupyter-wrapper .bp3-file-upload-input.bp3-round{border-radius:30px;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:10px}.jupyter-wrapper .bp3-file-upload-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px #10161a26}.jupyter-wrapper .bp3-file-upload-input:disabled,.jupyter-wrapper .bp3-file-upload-input.bp3-disabled{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;resize:none}.jupyter-wrapper .bp3-file-upload-input:after{background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026;min-height:24px;min-width:24px;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;border-radius:3px;content:"Browse";line-height:24px;margin:3px;position:absolute;right:0;text-align:center;top:0;width:70px}.jupyter-wrapper .bp3-file-upload-input:after:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-file-upload-input:after:active,.jupyter-wrapper .bp3-file-upload-input:after .bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-file-upload-input:after:disabled,.jupyter-wrapper .bp3-file-upload-input:after .bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-file-upload-input:after:disabled .bp3-active,.jupyter-wrapper .bp3-file-upload-input:after:disabled .bp3-active:hover,.jupyter-wrapper .bp3-file-upload-input:after .bp3-disabled.bp3-active,.jupyter-wrapper .bp3-file-upload-input:after .bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-file-upload-input:hover:after{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-file-upload-input:active:after{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-large .bp3-file-upload-input{font-size:16px;height:40px;line-height:40px;padding-right:95px}.jupyter-wrapper .bp3-large .bp3-file-upload-input[type=search],.jupyter-wrapper .bp3-large .bp3-file-upload-input.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-large .bp3-file-upload-input:after{min-height:30px;min-width:30px;line-height:30px;margin:5px;width:85px}.jupyter-wrapper .bp3-dark .bp3-file-upload-input{background:rgba(16,22,26,.3);-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66;color:#f5f8fa;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:disabled,.jupyter-wrapper .bp3-dark .bp3-file-upload-input.bp3-disabled{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:hover,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:disabled,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after:disabled .bp3-active,.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:after .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:hover:after{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-file-upload-input:active:after{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-file-upload-input:after{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-form-group{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin:0 0 15px}.jupyter-wrapper .bp3-form-group label.bp3-label{margin-bottom:5px}.jupyter-wrapper .bp3-form-group .bp3-control{margin-top:7px}.jupyter-wrapper .bp3-form-group .bp3-form-helper-text{color:#5c7080;font-size:12px;margin-top:5px}.jupyter-wrapper .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{color:#106ba3}.jupyter-wrapper .bp3-form-group.bp3-intent-success .bp3-form-helper-text{color:#0d8050}.jupyter-wrapper .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{color:#bf7326}.jupyter-wrapper .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{color:#c23030}.jupyter-wrapper .bp3-form-group.bp3-inline{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row}.jupyter-wrapper .bp3-form-group.bp3-inline.bp3-large label.bp3-label{line-height:40px;margin:0 10px 0 0}.jupyter-wrapper .bp3-form-group.bp3-inline label.bp3-label{line-height:30px;margin:0 10px 0 0}.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-label,.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-text-muted,.jupyter-wrapper .bp3-form-group.bp3-disabled .bp3-form-helper-text{color:#5c708099!important}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-form-group .bp3-form-helper-text{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,.jupyter-wrapper .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{color:#a7b6c299!important}.jupyter-wrapper .bp3-input-group{display:block;position:relative}.jupyter-wrapper .bp3-input-group .bp3-input{position:relative;width:100%}.jupyter-wrapper .bp3-input-group .bp3-input:not(:first-child){padding-left:30px}.jupyter-wrapper .bp3-input-group .bp3-input:not(:last-child){padding-right:30px}.jupyter-wrapper .bp3-input-group .bp3-input-action,.jupyter-wrapper .bp3-input-group>.bp3-input-left-container,.jupyter-wrapper .bp3-input-group>.bp3-button,.jupyter-wrapper .bp3-input-group>.bp3-icon{position:absolute;top:0}.jupyter-wrapper .bp3-input-group .bp3-input-action:first-child,.jupyter-wrapper .bp3-input-group>.bp3-input-left-container:first-child,.jupyter-wrapper .bp3-input-group>.bp3-button:first-child,.jupyter-wrapper .bp3-input-group>.bp3-icon:first-child{left:0}.jupyter-wrapper .bp3-input-group .bp3-input-action:last-child,.jupyter-wrapper .bp3-input-group>.bp3-input-left-container:last-child,.jupyter-wrapper .bp3-input-group>.bp3-button:last-child,.jupyter-wrapper .bp3-input-group>.bp3-icon:last-child{right:0}.jupyter-wrapper .bp3-input-group .bp3-button{min-height:24px;min-width:24px;margin:3px;padding:0 7px}.jupyter-wrapper .bp3-input-group .bp3-button:empty{padding:0}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container,.jupyter-wrapper .bp3-input-group>.bp3-icon{z-index:1}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group>.bp3-icon{color:#5c7080}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container>.bp3-icon:empty,.jupyter-wrapper .bp3-input-group>.bp3-icon:empty{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}.jupyter-wrapper .bp3-input-group>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group>.bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input-action>.bp3-spinner{margin:7px}.jupyter-wrapper .bp3-input-group .bp3-tag{margin:5px}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus),.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){color:#5c7080}.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus),.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){color:#a7b6c2}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled{color:#5c708099!important}.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-button.bp3-minimal:disabled .bp3-icon-large,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,.jupyter-wrapper .bp3-input-group .bp3-input:not(:focus)+.bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{color:#5c708099!important}.jupyter-wrapper .bp3-input-group.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-input-group.bp3-disabled .bp3-icon{color:#5c708099}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-button{min-height:30px;min-width:30px;margin:5px}.jupyter-wrapper .bp3-input-group.bp3-large>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-large>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input-action>.bp3-spinner{margin:12px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input{font-size:16px;height:40px;line-height:40px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input[type=search],.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input:not(:first-child){padding-left:40px}.jupyter-wrapper .bp3-input-group.bp3-large .bp3-input:not(:last-child){padding-right:40px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-button,.jupyter-wrapper .bp3-input-group.bp3-small .bp3-tag{min-height:20px;min-width:20px;margin:2px}.jupyter-wrapper .bp3-input-group.bp3-small>.bp3-input-left-container>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-small>.bp3-icon,.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input-action>.bp3-spinner{margin:4px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input{font-size:12px;height:24px;line-height:24px;padding-left:8px;padding-right:8px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input[type=search],.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input.bp3-round{padding:0 12px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input:not(:first-child){padding-left:24px}.jupyter-wrapper .bp3-input-group.bp3-small .bp3-input:not(:last-child){padding-right:24px}.jupyter-wrapper .bp3-input-group.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:100%}.jupyter-wrapper .bp3-input-group.bp3-round .bp3-button,.jupyter-wrapper .bp3-input-group.bp3-round .bp3-input,.jupyter-wrapper .bp3-input-group.bp3-round .bp3-tag{border-radius:30px}.jupyter-wrapper .bp3-dark .bp3-input-group .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{color:#a7b6c299}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-primary>.bp3-icon{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-primary>.bp3-icon{color:#48aff0}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f9960,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-success>.bp3-icon{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-success>.bp3-icon{color:#3dcc91}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-warning>.bp3-icon{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-warning>.bp3-icon{color:#ffb366}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db3737,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input:disabled,.jupyter-wrapper .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input-group.bp3-intent-danger>.bp3-icon{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-input-group.bp3-intent-danger>.bp3-icon{color:#ff7373}.jupyter-wrapper .bp3-input{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#ffffff;border:none;border-radius:3px;-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33;color:#182026;font-size:14px;font-weight:400;height:30px;line-height:30px;outline:none;padding:0 10px;-webkit-transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9);transition:box-shadow .1s cubic-bezier(.4,1,.75,.9),-webkit-box-shadow .1s cubic-bezier(.4,1,.75,.9);vertical-align:middle}.jupyter-wrapper .bp3-input::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input:focus,.jupyter-wrapper .bp3-input.bp3-active{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input[type=search],.jupyter-wrapper .bp3-input.bp3-round{border-radius:30px;-webkit-box-sizing:border-box;box-sizing:border-box;padding-left:10px}.jupyter-wrapper .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.15);box-shadow:inset 0 0 0 1px #10161a26}.jupyter-wrapper .bp3-input:disabled,.jupyter-wrapper .bp3-input.bp3-disabled{background:rgba(206,217,224,.5);-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;resize:none}.jupyter-wrapper .bp3-input.bp3-large{font-size:16px;height:40px;line-height:40px}.jupyter-wrapper .bp3-input.bp3-large[type=search],.jupyter-wrapper .bp3-input.bp3-large.bp3-round{padding:0 15px}.jupyter-wrapper .bp3-input.bp3-small{font-size:12px;height:24px;line-height:24px;padding-left:8px;padding-right:8px}.jupyter-wrapper .bp3-input.bp3-small[type=search],.jupyter-wrapper .bp3-input.bp3-small.bp3-round{padding:0 12px}.jupyter-wrapper .bp3-input.bp3-fill{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;width:100%}.jupyter-wrapper .bp3-dark .bp3-input{background:rgba(16,22,26,.3);-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-input::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-disabled{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-input.bp3-intent-primary{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-primary:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-primary[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-input.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-input.bp3-intent-primary.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary{-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px #137cbd,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #137cbd,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary[readonly]{-webkit-box-shadow:inset 0 0 0 1px #137cbd;box-shadow:inset 0 0 0 1px #137cbd}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-success{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f9960,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-success:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-success[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-input.bp3-intent-success:disabled,.jupyter-wrapper .bp3-input.bp3-intent-success.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success{-webkit-box-shadow:0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),0 0 0 0 rgba(15,153,96,0),inset 0 0 0 1px #0f9960,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #0f996000,0 0 #0f996000,0 0 #0f996000,inset 0 0 0 1px #0f9960,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success:focus{-webkit-box-shadow:0 0 0 1px #0f9960,0 0 0 1px #0f9960,0 0 0 3px rgba(15,153,96,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #0f9960,0 0 0 1px #0f9960,0 0 0 3px #0f99604d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success[readonly]{-webkit-box-shadow:inset 0 0 0 1px #0f9960;box-shadow:inset 0 0 0 1px #0f9960}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-warning{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-warning:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-warning[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-input.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-input.bp3-intent-warning.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning{-webkit-box-shadow:0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),0 0 0 0 rgba(217,130,43,0),inset 0 0 0 1px #d9822b,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #d9822b00,0 0 #d9822b00,0 0 #d9822b00,inset 0 0 0 1px #d9822b,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning:focus{-webkit-box-shadow:0 0 0 1px #d9822b,0 0 0 1px #d9822b,0 0 0 3px rgba(217,130,43,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #d9822b,0 0 0 1px #d9822b,0 0 0 3px #d9822b4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning[readonly]{-webkit-box-shadow:inset 0 0 0 1px #d9822b;box-shadow:inset 0 0 0 1px #d9822b}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input.bp3-intent-danger{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.15),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db3737,inset 0 0 0 1px #10161a26,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-danger:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-input.bp3-intent-danger[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-input.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-input.bp3-intent-danger.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger{-webkit-box-shadow:0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),0 0 0 0 rgba(219,55,55,0),inset 0 0 0 1px #db3737,inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #db373700,0 0 #db373700,0 0 #db373700,inset 0 0 0 1px #db3737,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger:focus{-webkit-box-shadow:0 0 0 1px #db3737,0 0 0 1px #db3737,0 0 0 3px rgba(219,55,55,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #db3737,0 0 0 1px #db3737,0 0 0 3px #db37374d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger[readonly]{-webkit-box-shadow:inset 0 0 0 1px #db3737;box-shadow:inset 0 0 0 1px #db3737}.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-input::-ms-clear{display:none}.jupyter-wrapper textarea.bp3-input{max-width:100%;padding:10px}.jupyter-wrapper textarea.bp3-input,.jupyter-wrapper textarea.bp3-input.bp3-large,.jupyter-wrapper textarea.bp3-input.bp3-small{height:auto;line-height:inherit}.jupyter-wrapper textarea.bp3-input.bp3-small{padding:8px}.jupyter-wrapper .bp3-dark textarea.bp3-input{background:rgba(16,22,26,.3);-webkit-box-shadow:0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),0 0 0 0 rgba(19,124,189,0),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 #137cbd00,0 0 #137cbd00,0 0 #137cbd00,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark textarea.bp3-input::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark textarea.bp3-input:focus{-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark textarea.bp3-input[readonly]{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark textarea.bp3-input:disabled,.jupyter-wrapper .bp3-dark textarea.bp3-input.bp3-disabled{background:rgba(57,75,89,.5);-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper label.bp3-label{display:block;margin-bottom:15px;margin-top:0}.jupyter-wrapper label.bp3-label .bp3-html-select,.jupyter-wrapper label.bp3-label .bp3-input,.jupyter-wrapper label.bp3-label .bp3-select,.jupyter-wrapper label.bp3-label .bp3-slider,.jupyter-wrapper label.bp3-label .bp3-popover-wrapper{display:block;margin-top:5px;text-transform:none}.jupyter-wrapper label.bp3-label .bp3-button-group{margin-top:5px}.jupyter-wrapper label.bp3-label .bp3-select select,.jupyter-wrapper label.bp3-label .bp3-html-select select{font-weight:400;vertical-align:top;width:100%}.jupyter-wrapper label.bp3-label.bp3-disabled,.jupyter-wrapper label.bp3-label.bp3-disabled .bp3-text-muted{color:#5c708099}.jupyter-wrapper label.bp3-label.bp3-inline{line-height:30px}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-html-select,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input-group,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-select,.jupyter-wrapper label.bp3-label.bp3-inline .bp3-popover-wrapper{display:inline-block;margin:0 0 0 5px;vertical-align:top}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-button-group{margin:0 0 0 5px}.jupyter-wrapper label.bp3-label.bp3-inline .bp3-input-group .bp3-input{margin-left:0}.jupyter-wrapper label.bp3-label.bp3-inline.bp3-large{line-height:40px}.jupyter-wrapper label.bp3-label:not(.bp3-inline) .bp3-popover-target{display:block}.jupyter-wrapper .bp3-dark label.bp3-label{color:#f5f8fa}.jupyter-wrapper .bp3-dark label.bp3-label.bp3-disabled,.jupyter-wrapper .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{color:#a7b6c299}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button{-webkit-box-flex:1;-ms-flex:1 1 14px;flex:1 1 14px;min-height:0;padding:0;width:30px}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button:first-child{border-radius:0 3px 0 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical>.bp3-button:last-child{border-radius:0 0 3px}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical:first-child>.bp3-button:first-child{border-radius:3px 0 0}.jupyter-wrapper .bp3-numeric-input .bp3-button-group.bp3-vertical:first-child>.bp3-button:last-child{border-radius:0 0 0 3px}.jupyter-wrapper .bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical>.bp3-button{width:40px}.jupyter-wrapper form{display:block}.jupyter-wrapper .bp3-html-select select,.jupyter-wrapper .bp3-select select{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:none;cursor:pointer;font-size:14px;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:left;vertical-align:middle;background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026;-moz-appearance:none;-webkit-appearance:none;border-radius:3px;height:30px;padding:0 25px 0 10px;width:100%}.jupyter-wrapper .bp3-html-select select>*,.jupyter-wrapper .bp3-select select>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-html-select select>.bp3-fill,.jupyter-wrapper .bp3-select select>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-html-select select:before,.jupyter-wrapper .bp3-select select:before,.jupyter-wrapper .bp3-html-select select>*,.jupyter-wrapper .bp3-select select>*{margin-right:7px}.jupyter-wrapper .bp3-html-select select:empty:before,.jupyter-wrapper .bp3-select select:empty:before,.jupyter-wrapper .bp3-html-select select>:last-child,.jupyter-wrapper .bp3-select select>:last-child{margin-right:0}.jupyter-wrapper .bp3-html-select select:hover,.jupyter-wrapper .bp3-select select:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-html-select select:active,.jupyter-wrapper .bp3-select select:active,.jupyter-wrapper .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-select select.bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-html-select select:disabled,.jupyter-wrapper .bp3-select select:disabled,.jupyter-wrapper .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-select select.bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-html-select select:disabled.bp3-active,.jupyter-wrapper .bp3-select select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select select:disabled.bp3-active:hover,.jupyter-wrapper .bp3-select select:disabled.bp3-active:hover,.jupyter-wrapper .bp3-html-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select select.bp3-disabled.bp3-active:hover,.jupyter-wrapper .bp3-select select.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-html-select.bp3-minimal select,.jupyter-wrapper .bp3-select.bp3-minimal select{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal select:hover{background:rgba(167,182,194,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026;text-decoration:none}.jupyter-wrapper .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-active{background:rgba(115,134,148,.3);-webkit-box-shadow:none;box-shadow:none;color:#182026}.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled:hover{background:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{background:rgba(115,134,148,.3)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select{background:none;-webkit-box-shadow:none;box-shadow:none;color:inherit}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:hover{background:rgba(138,155,168,.15)}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-active{background:rgba(138,155,168,.3);color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled:hover,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{background:none;color:#a7b6c299;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{background:rgba(138,155,168,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:hover{background:rgba(19,124,189,.15);color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#106ba3}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{background:none;color:#106ba380}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{stroke:#106ba3}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{background:rgba(19,124,189,.2);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{background:rgba(19,124,189,.3);color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{background:none;color:#48aff080}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{background:rgba(19,124,189,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:hover{background:rgba(15,153,96,.15);color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#0d8050}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{background:none;color:#0d805080}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{stroke:#0d8050}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{background:rgba(15,153,96,.2);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{background:rgba(15,153,96,.3);color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{background:none;color:#3dcc9180}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{background:rgba(15,153,96,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:hover{background:rgba(217,130,43,.15);color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#bf7326}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{background:none;color:#bf732680}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{stroke:#bf7326}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{background:rgba(217,130,43,.2);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{background:rgba(217,130,43,.3);color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{background:none;color:#ffb36680}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{background:rgba(217,130,43,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{background:none;-webkit-box-shadow:none;box-shadow:none;color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:hover{background:rgba(219,55,55,.15);color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#c23030}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{background:none;color:#c2303080}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{stroke:#c23030}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{background:rgba(219,55,55,.2);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{background:rgba(219,55,55,.3);color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{background:none;color:#ff737380}.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{background:rgba(219,55,55,.3)}.jupyter-wrapper .bp3-html-select.bp3-large select,.jupyter-wrapper .bp3-select.bp3-large select{font-size:16px;height:40px;padding-right:35px}.jupyter-wrapper .bp3-dark .bp3-html-select select,.jupyter-wrapper .bp3-dark .bp3-select select{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select select:hover,.jupyter-wrapper .bp3-dark .bp3-select select:hover,.jupyter-wrapper .bp3-dark .bp3-html-select select:active,.jupyter-wrapper .bp3-dark .bp3-select select:active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select select:hover,.jupyter-wrapper .bp3-dark .bp3-select select:hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-html-select select:active,.jupyter-wrapper .bp3-dark .bp3-select select:active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-html-select select:disabled,.jupyter-wrapper .bp3-dark .bp3-select select:disabled,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-disabled,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-html-select select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-select select.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head,.jupyter-wrapper .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-html-select select:disabled,.jupyter-wrapper .bp3-select select:disabled{background-color:#ced9e080;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-select .bp3-icon,.jupyter-wrapper .bp3-select:after{color:#5c7080;pointer-events:none;position:absolute;right:7px;top:7px}.jupyter-wrapper .bp3-html-select .bp3-disabled.bp3-icon,.jupyter-wrapper .bp3-select .bp3-disabled.bp3-icon,.jupyter-wrapper .bp3-disabled.bp3-select:after{color:#5c708099}.jupyter-wrapper .bp3-html-select,.jupyter-wrapper .bp3-select{display:inline-block;letter-spacing:normal;position:relative;vertical-align:middle}.jupyter-wrapper .bp3-html-select select::-ms-expand,.jupyter-wrapper .bp3-select select::-ms-expand{display:none}.jupyter-wrapper .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-select .bp3-icon{color:#5c7080}.jupyter-wrapper .bp3-html-select .bp3-icon:hover,.jupyter-wrapper .bp3-select .bp3-icon:hover{color:#182026}.jupyter-wrapper .bp3-dark .bp3-html-select .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-select .bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-html-select .bp3-icon:hover,.jupyter-wrapper .bp3-dark .bp3-select .bp3-icon:hover{color:#f5f8fa}.jupyter-wrapper .bp3-html-select.bp3-large:after,.jupyter-wrapper .bp3-html-select.bp3-large .bp3-icon,.jupyter-wrapper .bp3-select.bp3-large:after,.jupyter-wrapper .bp3-select.bp3-large .bp3-icon{right:12px;top:12px}.jupyter-wrapper .bp3-html-select.bp3-fill,.jupyter-wrapper .bp3-html-select.bp3-fill select,.jupyter-wrapper .bp3-select.bp3-fill,.jupyter-wrapper .bp3-select.bp3-fill select{width:100%}.jupyter-wrapper .bp3-dark .bp3-html-select option,.jupyter-wrapper .bp3-dark .bp3-select option{background-color:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-html-select option:disabled,.jupyter-wrapper .bp3-dark .bp3-select option:disabled{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-html-select:after,.jupyter-wrapper .bp3-dark .bp3-select:after{color:#a7b6c2}.jupyter-wrapper .bp3-select:after{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;content:""}.jupyter-wrapper .bp3-running-text table,.jupyter-wrapper table.bp3-html-table{border-spacing:0;font-size:14px}.jupyter-wrapper .bp3-running-text table th,.jupyter-wrapper table.bp3-html-table th,.jupyter-wrapper .bp3-running-text table td,.jupyter-wrapper table.bp3-html-table td{padding:11px;text-align:left;vertical-align:top}.jupyter-wrapper .bp3-running-text table th,.jupyter-wrapper table.bp3-html-table th{color:#182026;font-weight:600}.jupyter-wrapper .bp3-running-text table td,.jupyter-wrapper table.bp3-html-table td{color:#182026}.jupyter-wrapper .bp3-running-text table tbody tr:first-child th,.jupyter-wrapper table.bp3-html-table tbody tr:first-child th,.jupyter-wrapper .bp3-running-text table tbody tr:first-child td,.jupyter-wrapper table.bp3-html-table tbody tr:first-child td,.jupyter-wrapper .bp3-running-text table tfoot tr:first-child th,.jupyter-wrapper table.bp3-html-table tfoot tr:first-child th,.jupyter-wrapper .bp3-running-text table tfoot tr:first-child td,.jupyter-wrapper table.bp3-html-table tfoot tr:first-child td{-webkit-box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26}.jupyter-wrapper .bp3-dark .bp3-running-text table th,.jupyter-wrapper .bp3-running-text .bp3-dark table th,.jupyter-wrapper .bp3-dark table.bp3-html-table th,.jupyter-wrapper .bp3-dark .bp3-running-text table td,.jupyter-wrapper .bp3-running-text .bp3-dark table td,.jupyter-wrapper .bp3-dark table.bp3-html-table td{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-running-text table tbody tr:first-child th,.jupyter-wrapper .bp3-running-text .bp3-dark table tbody tr:first-child th,.jupyter-wrapper .bp3-dark table.bp3-html-table tbody tr:first-child th,.jupyter-wrapper .bp3-dark .bp3-running-text table tbody tr:first-child td,.jupyter-wrapper .bp3-running-text .bp3-dark table tbody tr:first-child td,.jupyter-wrapper .bp3-dark table.bp3-html-table tbody tr:first-child td,.jupyter-wrapper .bp3-dark .bp3-running-text table tfoot tr:first-child th,.jupyter-wrapper .bp3-running-text .bp3-dark table tfoot tr:first-child th,.jupyter-wrapper .bp3-dark table.bp3-html-table tfoot tr:first-child th,.jupyter-wrapper .bp3-dark .bp3-running-text table tfoot tr:first-child td,.jupyter-wrapper .bp3-running-text .bp3-dark table tfoot tr:first-child td,.jupyter-wrapper .bp3-dark table.bp3-html-table tfoot tr:first-child td{-webkit-box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 0 1px #ffffff26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-condensed th,.jupyter-wrapper table.bp3-html-table.bp3-html-table-condensed td,.jupyter-wrapper table.bp3-html-table.bp3-small th,.jupyter-wrapper table.bp3-html-table.bp3-small td{padding-bottom:6px;padding-top:6px}.jupyter-wrapper table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{background:rgba(191,204,214,.15)}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 0 #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tbody tr td,.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tfoot tr td{-webkit-box-shadow:inset 0 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){-webkit-box-shadow:inset 1px 1px 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 1px #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(16,22,26,.15);box-shadow:inset 1px 0 #10161a26}.jupyter-wrapper table.bp3-html-table.bp3-interactive tbody tr:hover td{background-color:#bfccd64d;cursor:pointer}.jupyter-wrapper table.bp3-html-table.bp3-interactive tbody tr:active td{background-color:#bfccd666}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{background:rgba(92,112,128,.15)}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){-webkit-box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 0 #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td,.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td{-webkit-box-shadow:inset 0 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 0 1px #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child),.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered tfoot tr td:not(:first-child){-webkit-box-shadow:inset 1px 1px 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 1px #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{-webkit-box-shadow:inset 1px 0 0 0 rgba(255,255,255,.15);box-shadow:inset 1px 0 #ffffff26}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{background-color:#5c70804d;cursor:pointer}.jupyter-wrapper .bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{background-color:#5c708066}.jupyter-wrapper .bp3-key-combo{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center}.jupyter-wrapper .bp3-key-combo>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-key-combo>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-key-combo:before,.jupyter-wrapper .bp3-key-combo>*{margin-right:5px}.jupyter-wrapper .bp3-key-combo:empty:before,.jupyter-wrapper .bp3-key-combo>:last-child{margin-right:0}.jupyter-wrapper .bp3-hotkey-dialog{padding-bottom:0;top:40px}.jupyter-wrapper .bp3-hotkey-dialog .bp3-dialog-body{margin:0;padding:0}.jupyter-wrapper .bp3-hotkey-dialog .bp3-hotkey-label{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1}.jupyter-wrapper .bp3-hotkey-column{margin:auto;max-height:80vh;overflow-y:auto;padding:30px}.jupyter-wrapper .bp3-hotkey-column .bp3-heading{margin-bottom:20px}.jupyter-wrapper .bp3-hotkey-column .bp3-heading:not(:first-child){margin-top:40px}.jupyter-wrapper .bp3-hotkey{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;margin-left:0;margin-right:0}.jupyter-wrapper .bp3-hotkey:not(:last-child){margin-bottom:10px}.jupyter-wrapper .bp3-icon{display:inline-block;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;vertical-align:text-bottom}.jupyter-wrapper .bp3-icon:not(:empty):before{content:""!important;content:unset!important}.jupyter-wrapper .bp3-icon>svg{display:block}.jupyter-wrapper .bp3-icon>svg:not([fill]){fill:currentColor}.jupyter-wrapper .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-icon-large.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-icon-large.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-icon-large.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-icon-large.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-dark .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-icon-large.bp3-intent-danger{color:#ff7373}.jupyter-wrapper span.bp3-icon-standard{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block}.jupyter-wrapper span.bp3-icon-large{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;display:inline-block}.jupyter-wrapper span.bp3-icon:empty{font-family:Icons20;font-size:inherit;font-style:normal;font-weight:400;line-height:1}.jupyter-wrapper span.bp3-icon:empty:before{-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}.jupyter-wrapper .bp3-icon-add:before{content:""}.jupyter-wrapper .bp3-icon-add-column-left:before{content:""}.jupyter-wrapper .bp3-icon-add-column-right:before{content:""}.jupyter-wrapper .bp3-icon-add-row-bottom:before{content:""}.jupyter-wrapper .bp3-icon-add-row-top:before{content:""}.jupyter-wrapper .bp3-icon-add-to-artifact:before{content:""}.jupyter-wrapper .bp3-icon-add-to-folder:before{content:""}.jupyter-wrapper .bp3-icon-airplane:before{content:""}.jupyter-wrapper .bp3-icon-align-center:before{content:""}.jupyter-wrapper .bp3-icon-align-justify:before{content:""}.jupyter-wrapper .bp3-icon-align-left:before{content:""}.jupyter-wrapper .bp3-icon-align-right:before{content:""}.jupyter-wrapper .bp3-icon-alignment-bottom:before{content:""}.jupyter-wrapper .bp3-icon-alignment-horizontal-center:before{content:""}.jupyter-wrapper .bp3-icon-alignment-left:before{content:""}.jupyter-wrapper .bp3-icon-alignment-right:before{content:""}.jupyter-wrapper .bp3-icon-alignment-top:before{content:""}.jupyter-wrapper .bp3-icon-alignment-vertical-center:before{content:""}.jupyter-wrapper .bp3-icon-annotation:before{content:""}.jupyter-wrapper .bp3-icon-application:before{content:""}.jupyter-wrapper .bp3-icon-applications:before{content:""}.jupyter-wrapper .bp3-icon-archive:before{content:""}.jupyter-wrapper .bp3-icon-arrow-bottom-left:before{content:"↙"}.jupyter-wrapper .bp3-icon-arrow-bottom-right:before{content:"↘"}.jupyter-wrapper .bp3-icon-arrow-down:before{content:"↓"}.jupyter-wrapper .bp3-icon-arrow-left:before{content:"←"}.jupyter-wrapper .bp3-icon-arrow-right:before{content:"→"}.jupyter-wrapper .bp3-icon-arrow-top-left:before{content:"↖"}.jupyter-wrapper .bp3-icon-arrow-top-right:before{content:"↗"}.jupyter-wrapper .bp3-icon-arrow-up:before{content:"↑"}.jupyter-wrapper .bp3-icon-arrows-horizontal:before{content:"↔"}.jupyter-wrapper .bp3-icon-arrows-vertical:before{content:"↕"}.jupyter-wrapper .bp3-icon-asterisk:before{content:"*"}.jupyter-wrapper .bp3-icon-automatic-updates:before{content:""}.jupyter-wrapper .bp3-icon-badge:before{content:""}.jupyter-wrapper .bp3-icon-ban-circle:before{content:""}.jupyter-wrapper .bp3-icon-bank-account:before{content:""}.jupyter-wrapper .bp3-icon-barcode:before{content:""}.jupyter-wrapper .bp3-icon-blank:before{content:""}.jupyter-wrapper .bp3-icon-blocked-person:before{content:""}.jupyter-wrapper .bp3-icon-bold:before{content:""}.jupyter-wrapper .bp3-icon-book:before{content:""}.jupyter-wrapper .bp3-icon-bookmark:before{content:""}.jupyter-wrapper .bp3-icon-box:before{content:""}.jupyter-wrapper .bp3-icon-briefcase:before{content:""}.jupyter-wrapper .bp3-icon-bring-data:before{content:""}.jupyter-wrapper .bp3-icon-build:before{content:""}.jupyter-wrapper .bp3-icon-calculator:before{content:""}.jupyter-wrapper .bp3-icon-calendar:before{content:""}.jupyter-wrapper .bp3-icon-camera:before{content:""}.jupyter-wrapper .bp3-icon-caret-down:before{content:"⌄"}.jupyter-wrapper .bp3-icon-caret-left:before{content:"〈"}.jupyter-wrapper .bp3-icon-caret-right:before{content:"〉"}.jupyter-wrapper .bp3-icon-caret-up:before{content:"⌃"}.jupyter-wrapper .bp3-icon-cell-tower:before{content:""}.jupyter-wrapper .bp3-icon-MKDOCS_changes:before{content:""}.jupyter-wrapper .bp3-icon-chart:before{content:""}.jupyter-wrapper .bp3-icon-chat:before{content:""}.jupyter-wrapper .bp3-icon-chevron-backward:before{content:""}.jupyter-wrapper .bp3-icon-chevron-down:before{content:""}.jupyter-wrapper .bp3-icon-chevron-forward:before{content:""}.jupyter-wrapper .bp3-icon-chevron-left:before{content:""}.jupyter-wrapper .bp3-icon-chevron-right:before{content:""}.jupyter-wrapper .bp3-icon-chevron-up:before{content:""}.jupyter-wrapper .bp3-icon-circle:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-down:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-left:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-right:before{content:""}.jupyter-wrapper .bp3-icon-circle-arrow-up:before{content:""}.jupyter-wrapper .bp3-icon-citation:before{content:""}.jupyter-wrapper .bp3-icon-clean:before{content:""}.jupyter-wrapper .bp3-icon-clipboard:before{content:""}.jupyter-wrapper .bp3-icon-cloud:before{content:"☁"}.jupyter-wrapper .bp3-icon-cloud-download:before{content:""}.jupyter-wrapper .bp3-icon-cloud-upload:before{content:""}.jupyter-wrapper .bp3-icon-code:before{content:""}.jupyter-wrapper .bp3-icon-code-block:before{content:""}.jupyter-wrapper .bp3-icon-cog:before{content:""}.jupyter-wrapper .bp3-icon-collapse-all:before{content:""}.jupyter-wrapper .bp3-icon-column-layout:before{content:""}.jupyter-wrapper .bp3-icon-comment:before{content:""}.jupyter-wrapper .bp3-icon-comparison:before{content:""}.jupyter-wrapper .bp3-icon-compass:before{content:""}.jupyter-wrapper .bp3-icon-compressed:before{content:""}.jupyter-wrapper .bp3-icon-confirm:before{content:""}.jupyter-wrapper .bp3-icon-console:before{content:""}.jupyter-wrapper .bp3-icon-contrast:before{content:""}.jupyter-wrapper .bp3-icon-control:before{content:""}.jupyter-wrapper .bp3-icon-credit-card:before{content:""}.jupyter-wrapper .bp3-icon-cross:before{content:"✗"}.jupyter-wrapper .bp3-icon-crown:before{content:""}.jupyter-wrapper .bp3-icon-cube:before{content:""}.jupyter-wrapper .bp3-icon-cube-add:before{content:""}.jupyter-wrapper .bp3-icon-cube-remove:before{content:""}.jupyter-wrapper .bp3-icon-curved-range-chart:before{content:""}.jupyter-wrapper .bp3-icon-cut:before{content:""}.jupyter-wrapper .bp3-icon-dashboard:before{content:""}.jupyter-wrapper .bp3-icon-data-lineage:before{content:""}.jupyter-wrapper .bp3-icon-database:before{content:""}.jupyter-wrapper .bp3-icon-delete:before{content:""}.jupyter-wrapper .bp3-icon-delta:before{content:"Δ"}.jupyter-wrapper .bp3-icon-derive-column:before{content:""}.jupyter-wrapper .bp3-icon-desktop:before{content:""}.jupyter-wrapper .bp3-icon-diagnosis:before{content:""}.jupyter-wrapper .bp3-icon-diagram-tree:before{content:""}.jupyter-wrapper .bp3-icon-direction-left:before{content:""}.jupyter-wrapper .bp3-icon-direction-right:before{content:""}.jupyter-wrapper .bp3-icon-disable:before{content:""}.jupyter-wrapper .bp3-icon-document:before{content:""}.jupyter-wrapper .bp3-icon-document-open:before{content:""}.jupyter-wrapper .bp3-icon-document-share:before{content:""}.jupyter-wrapper .bp3-icon-dollar:before{content:"$"}.jupyter-wrapper .bp3-icon-dot:before{content:"•"}.jupyter-wrapper .bp3-icon-double-caret-horizontal:before{content:""}.jupyter-wrapper .bp3-icon-double-caret-vertical:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-down:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-left:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-right:before{content:""}.jupyter-wrapper .bp3-icon-double-chevron-up:before{content:""}.jupyter-wrapper .bp3-icon-doughnut-chart:before{content:""}.jupyter-wrapper .bp3-icon-download:before{content:""}.jupyter-wrapper .bp3-icon-drag-handle-horizontal:before{content:""}.jupyter-wrapper .bp3-icon-drag-handle-vertical:before{content:""}.jupyter-wrapper .bp3-icon-draw:before{content:""}.jupyter-wrapper .bp3-icon-drive-time:before{content:""}.jupyter-wrapper .bp3-icon-duplicate:before{content:""}.jupyter-wrapper .bp3-icon-edit:before{content:"✎"}.jupyter-wrapper .bp3-icon-eject:before{content:"⏏"}.jupyter-wrapper .bp3-icon-endorsed:before{content:""}.jupyter-wrapper .bp3-icon-envelope:before{content:"✉"}.jupyter-wrapper .bp3-icon-equals:before{content:""}.jupyter-wrapper .bp3-icon-eraser:before{content:""}.jupyter-wrapper .bp3-icon-error:before{content:""}.jupyter-wrapper .bp3-icon-euro:before{content:"€"}.jupyter-wrapper .bp3-icon-MKDOCS_exchange:before{content:""}.jupyter-wrapper .bp3-icon-exclude-row:before{content:""}.jupyter-wrapper .bp3-icon-expand-all:before{content:""}.jupyter-wrapper .bp3-icon-export:before{content:""}.jupyter-wrapper .bp3-icon-eye-off:before{content:""}.jupyter-wrapper .bp3-icon-eye-on:before{content:""}.jupyter-wrapper .bp3-icon-eye-open:before{content:""}.jupyter-wrapper .bp3-icon-fast-backward:before{content:""}.jupyter-wrapper .bp3-icon-fast-forward:before{content:""}.jupyter-wrapper .bp3-icon-feed:before{content:""}.jupyter-wrapper .bp3-icon-feed-subscribed:before{content:""}.jupyter-wrapper .bp3-icon-film:before{content:""}.jupyter-wrapper .bp3-icon-filter:before{content:""}.jupyter-wrapper .bp3-icon-filter-keep:before{content:""}.jupyter-wrapper .bp3-icon-filter-list:before{content:""}.jupyter-wrapper .bp3-icon-filter-open:before{content:""}.jupyter-wrapper .bp3-icon-filter-remove:before{content:""}.jupyter-wrapper .bp3-icon-flag:before{content:"⚑"}.jupyter-wrapper .bp3-icon-flame:before{content:""}.jupyter-wrapper .bp3-icon-flash:before{content:""}.jupyter-wrapper .bp3-icon-floppy-disk:before{content:""}.jupyter-wrapper .bp3-icon-flow-branch:before{content:""}.jupyter-wrapper .bp3-icon-flow-end:before{content:""}.jupyter-wrapper .bp3-icon-flow-linear:before{content:""}.jupyter-wrapper .bp3-icon-flow-review:before{content:""}.jupyter-wrapper .bp3-icon-flow-review-branch:before{content:""}.jupyter-wrapper .bp3-icon-flows:before{content:""}.jupyter-wrapper .bp3-icon-folder-close:before{content:""}.jupyter-wrapper .bp3-icon-folder-new:before{content:""}.jupyter-wrapper .bp3-icon-folder-open:before{content:""}.jupyter-wrapper .bp3-icon-folder-shared:before{content:""}.jupyter-wrapper .bp3-icon-folder-shared-open:before{content:""}.jupyter-wrapper .bp3-icon-follower:before{content:""}.jupyter-wrapper .bp3-icon-following:before{content:""}.jupyter-wrapper .bp3-icon-font:before{content:""}.jupyter-wrapper .bp3-icon-fork:before{content:""}.jupyter-wrapper .bp3-icon-form:before{content:""}.jupyter-wrapper .bp3-icon-full-circle:before{content:""}.jupyter-wrapper .bp3-icon-full-stacked-chart:before{content:""}.jupyter-wrapper .bp3-icon-fullscreen:before{content:""}.jupyter-wrapper .bp3-icon-function:before{content:""}.jupyter-wrapper .bp3-icon-gantt-chart:before{content:""}.jupyter-wrapper .bp3-icon-geolocation:before{content:""}.jupyter-wrapper .bp3-icon-geosearch:before{content:""}.jupyter-wrapper .bp3-icon-git-branch:before{content:""}.jupyter-wrapper .bp3-icon-git-commit:before{content:""}.jupyter-wrapper .bp3-icon-git-merge:before{content:""}.jupyter-wrapper .bp3-icon-git-new-branch:before{content:""}.jupyter-wrapper .bp3-icon-git-pull:before{content:""}.jupyter-wrapper .bp3-icon-git-push:before{content:""}.jupyter-wrapper .bp3-icon-git-repo:before{content:""}.jupyter-wrapper .bp3-icon-glass:before{content:""}.jupyter-wrapper .bp3-icon-globe:before{content:""}.jupyter-wrapper .bp3-icon-globe-network:before{content:""}.jupyter-wrapper .bp3-icon-graph:before{content:""}.jupyter-wrapper .bp3-icon-graph-remove:before{content:""}.jupyter-wrapper .bp3-icon-greater-than:before{content:""}.jupyter-wrapper .bp3-icon-greater-than-or-equal-to:before{content:""}.jupyter-wrapper .bp3-icon-grid:before{content:""}.jupyter-wrapper .bp3-icon-grid-view:before{content:""}.jupyter-wrapper .bp3-icon-group-objects:before{content:""}.jupyter-wrapper .bp3-icon-grouped-bar-chart:before{content:""}.jupyter-wrapper .bp3-icon-hand:before{content:""}.jupyter-wrapper .bp3-icon-hand-down:before{content:""}.jupyter-wrapper .bp3-icon-hand-left:before{content:""}.jupyter-wrapper .bp3-icon-hand-right:before{content:""}.jupyter-wrapper .bp3-icon-hand-up:before{content:""}.jupyter-wrapper .bp3-icon-header:before{content:""}.jupyter-wrapper .bp3-icon-header-one:before{content:""}.jupyter-wrapper .bp3-icon-header-two:before{content:""}.jupyter-wrapper .bp3-icon-headset:before{content:""}.jupyter-wrapper .bp3-icon-heart:before{content:"♥"}.jupyter-wrapper .bp3-icon-heart-broken:before{content:""}.jupyter-wrapper .bp3-icon-heat-grid:before{content:""}.jupyter-wrapper .bp3-icon-heatmap:before{content:""}.jupyter-wrapper .bp3-icon-help:before{content:"?"}.jupyter-wrapper .bp3-icon-helper-management:before{content:""}.jupyter-wrapper .bp3-icon-highlight:before{content:""}.jupyter-wrapper .bp3-icon-history:before{content:""}.jupyter-wrapper .bp3-icon-home:before{content:"⌂"}.jupyter-wrapper .bp3-icon-horizontal-bar-chart:before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart-asc:before{content:""}.jupyter-wrapper .bp3-icon-horizontal-bar-chart-desc:before{content:""}.jupyter-wrapper .bp3-icon-horizontal-distribution:before{content:""}.jupyter-wrapper .bp3-icon-id-number:before{content:""}.jupyter-wrapper .bp3-icon-image-rotate-left:before{content:""}.jupyter-wrapper .bp3-icon-image-rotate-right:before{content:""}.jupyter-wrapper .bp3-icon-import:before{content:""}.jupyter-wrapper .bp3-icon-inbox:before{content:""}.jupyter-wrapper .bp3-icon-inbox-filtered:before{content:""}.jupyter-wrapper .bp3-icon-inbox-geo:before{content:""}.jupyter-wrapper .bp3-icon-inbox-search:before{content:""}.jupyter-wrapper .bp3-icon-inbox-update:before{content:""}.jupyter-wrapper .bp3-icon-info-sign:before{content:"ℹ"}.jupyter-wrapper .bp3-icon-inheritance:before{content:""}.jupyter-wrapper .bp3-icon-inner-join:before{content:""}.jupyter-wrapper .bp3-icon-insert:before{content:""}.jupyter-wrapper .bp3-icon-intersection:before{content:""}.jupyter-wrapper .bp3-icon-ip-address:before{content:""}.jupyter-wrapper .bp3-icon-issue:before{content:""}.jupyter-wrapper .bp3-icon-issue-closed:before{content:""}.jupyter-wrapper .bp3-icon-issue-new:before{content:""}.jupyter-wrapper .bp3-icon-italic:before{content:""}.jupyter-wrapper .bp3-icon-join-table:before{content:""}.jupyter-wrapper .bp3-icon-key:before{content:""}.jupyter-wrapper .bp3-icon-key-backspace:before{content:""}.jupyter-wrapper .bp3-icon-key-command:before{content:""}.jupyter-wrapper .bp3-icon-key-control:before{content:""}.jupyter-wrapper .bp3-icon-key-delete:before{content:""}.jupyter-wrapper .bp3-icon-key-enter:before{content:""}.jupyter-wrapper .bp3-icon-key-escape:before{content:""}.jupyter-wrapper .bp3-icon-key-option:before{content:""}.jupyter-wrapper .bp3-icon-key-shift:before{content:""}.jupyter-wrapper .bp3-icon-key-tab:before{content:""}.jupyter-wrapper .bp3-icon-known-vehicle:before{content:""}.jupyter-wrapper .bp3-icon-lab-test:before{content:""}.jupyter-wrapper .bp3-icon-label:before{content:""}.jupyter-wrapper .bp3-icon-layer:before{content:""}.jupyter-wrapper .bp3-icon-layers:before{content:""}.jupyter-wrapper .bp3-icon-layout:before{content:""}.jupyter-wrapper .bp3-icon-layout-auto:before{content:""}.jupyter-wrapper .bp3-icon-layout-balloon:before{content:""}.jupyter-wrapper .bp3-icon-layout-circle:before{content:""}.jupyter-wrapper .bp3-icon-layout-grid:before{content:""}.jupyter-wrapper .bp3-icon-layout-group-by:before{content:""}.jupyter-wrapper .bp3-icon-layout-hierarchy:before{content:""}.jupyter-wrapper .bp3-icon-layout-linear:before{content:""}.jupyter-wrapper .bp3-icon-layout-skew-grid:before{content:""}.jupyter-wrapper .bp3-icon-layout-sorted-clusters:before{content:""}.jupyter-wrapper .bp3-icon-learning:before{content:""}.jupyter-wrapper .bp3-icon-left-join:before{content:""}.jupyter-wrapper .bp3-icon-less-than:before{content:""}.jupyter-wrapper .bp3-icon-less-than-or-equal-to:before{content:""}.jupyter-wrapper .bp3-icon-lifesaver:before{content:""}.jupyter-wrapper .bp3-icon-lightbulb:before{content:""}.jupyter-wrapper .bp3-icon-link:before{content:""}.jupyter-wrapper .bp3-icon-list:before{content:"☰"}.jupyter-wrapper .bp3-icon-list-columns:before{content:""}.jupyter-wrapper .bp3-icon-list-detail-view:before{content:""}.jupyter-wrapper .bp3-icon-locate:before{content:""}.jupyter-wrapper .bp3-icon-lock:before{content:""}.jupyter-wrapper .bp3-icon-log-in:before{content:""}.jupyter-wrapper .bp3-icon-log-out:before{content:""}.jupyter-wrapper .bp3-icon-manual:before{content:""}.jupyter-wrapper .bp3-icon-manually-entered-data:before{content:""}.jupyter-wrapper .bp3-icon-map:before{content:""}.jupyter-wrapper .bp3-icon-map-create:before{content:""}.jupyter-wrapper .bp3-icon-map-marker:before{content:""}.jupyter-wrapper .bp3-icon-maximize:before{content:""}.jupyter-wrapper .bp3-icon-media:before{content:""}.jupyter-wrapper .bp3-icon-menu:before{content:""}.jupyter-wrapper .bp3-icon-menu-closed:before{content:""}.jupyter-wrapper .bp3-icon-menu-open:before{content:""}.jupyter-wrapper .bp3-icon-merge-columns:before{content:""}.jupyter-wrapper .bp3-icon-merge-links:before{content:""}.jupyter-wrapper .bp3-icon-minimize:before{content:""}.jupyter-wrapper .bp3-icon-minus:before{content:"−"}.jupyter-wrapper .bp3-icon-mobile-phone:before{content:""}.jupyter-wrapper .bp3-icon-mobile-video:before{content:""}.jupyter-wrapper .bp3-icon-moon:before{content:""}.jupyter-wrapper .bp3-icon-more:before{content:""}.jupyter-wrapper .bp3-icon-mountain:before{content:""}.jupyter-wrapper .bp3-icon-move:before{content:""}.jupyter-wrapper .bp3-icon-mugshot:before{content:""}.jupyter-wrapper .bp3-icon-multi-select:before{content:""}.jupyter-wrapper .bp3-icon-music:before{content:""}.jupyter-wrapper .bp3-icon-new-drawing:before{content:""}.jupyter-wrapper .bp3-icon-new-grid-item:before{content:""}.jupyter-wrapper .bp3-icon-new-layer:before{content:""}.jupyter-wrapper .bp3-icon-new-layers:before{content:""}.jupyter-wrapper .bp3-icon-new-link:before{content:""}.jupyter-wrapper .bp3-icon-new-object:before{content:""}.jupyter-wrapper .bp3-icon-new-person:before{content:""}.jupyter-wrapper .bp3-icon-new-prescription:before{content:""}.jupyter-wrapper .bp3-icon-new-text-box:before{content:""}.jupyter-wrapper .bp3-icon-ninja:before{content:""}.jupyter-wrapper .bp3-icon-not-equal-to:before{content:""}.jupyter-wrapper .bp3-icon-notifications:before{content:""}.jupyter-wrapper .bp3-icon-notifications-updated:before{content:""}.jupyter-wrapper .bp3-icon-numbered-list:before{content:""}.jupyter-wrapper .bp3-icon-numerical:before{content:""}.jupyter-wrapper .bp3-icon-office:before{content:""}.jupyter-wrapper .bp3-icon-offline:before{content:""}.jupyter-wrapper .bp3-icon-oil-field:before{content:""}.jupyter-wrapper .bp3-icon-one-column:before{content:""}.jupyter-wrapper .bp3-icon-outdated:before{content:""}.jupyter-wrapper .bp3-icon-page-layout:before{content:""}.jupyter-wrapper .bp3-icon-panel-stats:before{content:""}.jupyter-wrapper .bp3-icon-panel-table:before{content:""}.jupyter-wrapper .bp3-icon-paperclip:before{content:""}.jupyter-wrapper .bp3-icon-paragraph:before{content:""}.jupyter-wrapper .bp3-icon-path:before{content:""}.jupyter-wrapper .bp3-icon-path-search:before{content:""}.jupyter-wrapper .bp3-icon-pause:before{content:""}.jupyter-wrapper .bp3-icon-people:before{content:""}.jupyter-wrapper .bp3-icon-percentage:before{content:""}.jupyter-wrapper .bp3-icon-person:before{content:""}.jupyter-wrapper .bp3-icon-phone:before{content:"☎"}.jupyter-wrapper .bp3-icon-pie-chart:before{content:""}.jupyter-wrapper .bp3-icon-pin:before{content:""}.jupyter-wrapper .bp3-icon-pivot:before{content:""}.jupyter-wrapper .bp3-icon-pivot-table:before{content:""}.jupyter-wrapper .bp3-icon-play:before{content:""}.jupyter-wrapper .bp3-icon-plus:before{content:"+"}.jupyter-wrapper .bp3-icon-polygon-filter:before{content:""}.jupyter-wrapper .bp3-icon-power:before{content:""}.jupyter-wrapper .bp3-icon-predictive-analysis:before{content:""}.jupyter-wrapper .bp3-icon-prescription:before{content:""}.jupyter-wrapper .bp3-icon-presentation:before{content:""}.jupyter-wrapper .bp3-icon-print:before{content:"⎙"}.jupyter-wrapper .bp3-icon-projects:before{content:""}.jupyter-wrapper .bp3-icon-properties:before{content:""}.jupyter-wrapper .bp3-icon-property:before{content:""}.jupyter-wrapper .bp3-icon-publish-function:before{content:""}.jupyter-wrapper .bp3-icon-pulse:before{content:""}.jupyter-wrapper .bp3-icon-random:before{content:""}.jupyter-wrapper .bp3-icon-record:before{content:""}.jupyter-wrapper .bp3-icon-redo:before{content:""}.jupyter-wrapper .bp3-icon-refresh:before{content:""}.jupyter-wrapper .bp3-icon-regression-chart:before{content:""}.jupyter-wrapper .bp3-icon-remove:before{content:""}.jupyter-wrapper .bp3-icon-remove-column:before{content:""}.jupyter-wrapper .bp3-icon-remove-column-left:before{content:""}.jupyter-wrapper .bp3-icon-remove-column-right:before{content:""}.jupyter-wrapper .bp3-icon-remove-row-bottom:before{content:""}.jupyter-wrapper .bp3-icon-remove-row-top:before{content:""}.jupyter-wrapper .bp3-icon-repeat:before{content:""}.jupyter-wrapper .bp3-icon-reset:before{content:""}.jupyter-wrapper .bp3-icon-resolve:before{content:""}.jupyter-wrapper .bp3-icon-rig:before{content:""}.jupyter-wrapper .bp3-icon-right-join:before{content:""}.jupyter-wrapper .bp3-icon-ring:before{content:""}.jupyter-wrapper .bp3-icon-rotate-document:before{content:""}.jupyter-wrapper .bp3-icon-rotate-page:before{content:""}.jupyter-wrapper .bp3-icon-satellite:before{content:""}.jupyter-wrapper .bp3-icon-saved:before{content:""}.jupyter-wrapper .bp3-icon-scatter-plot:before{content:""}.jupyter-wrapper .bp3-icon-search:before{content:""}.jupyter-wrapper .bp3-icon-search-around:before{content:""}.jupyter-wrapper .bp3-icon-search-template:before{content:""}.jupyter-wrapper .bp3-icon-search-text:before{content:""}.jupyter-wrapper .bp3-icon-segmented-control:before{content:""}.jupyter-wrapper .bp3-icon-select:before{content:""}.jupyter-wrapper .bp3-icon-selection:before{content:"⦿"}.jupyter-wrapper .bp3-icon-send-to:before{content:""}.jupyter-wrapper .bp3-icon-send-to-graph:before{content:""}.jupyter-wrapper .bp3-icon-send-to-map:before{content:""}.jupyter-wrapper .bp3-icon-series-add:before{content:""}.jupyter-wrapper .bp3-icon-series-configuration:before{content:""}.jupyter-wrapper .bp3-icon-series-derived:before{content:""}.jupyter-wrapper .bp3-icon-series-filtered:before{content:""}.jupyter-wrapper .bp3-icon-series-search:before{content:""}.jupyter-wrapper .bp3-icon-settings:before{content:""}.jupyter-wrapper .bp3-icon-share:before{content:""}.jupyter-wrapper .bp3-icon-shield:before{content:""}.jupyter-wrapper .bp3-icon-shop:before{content:""}.jupyter-wrapper .bp3-icon-shopping-cart:before{content:""}.jupyter-wrapper .bp3-icon-signal-search:before{content:""}.jupyter-wrapper .bp3-icon-sim-card:before{content:""}.jupyter-wrapper .bp3-icon-slash:before{content:""}.jupyter-wrapper .bp3-icon-small-cross:before{content:""}.jupyter-wrapper .bp3-icon-small-minus:before{content:""}.jupyter-wrapper .bp3-icon-small-plus:before{content:""}.jupyter-wrapper .bp3-icon-small-tick:before{content:""}.jupyter-wrapper .bp3-icon-snowflake:before{content:""}.jupyter-wrapper .bp3-icon-social-media:before{content:""}.jupyter-wrapper .bp3-icon-sort:before{content:""}.jupyter-wrapper .bp3-icon-sort-alphabetical:before{content:""}.jupyter-wrapper .bp3-icon-sort-alphabetical-desc:before{content:""}.jupyter-wrapper .bp3-icon-sort-asc:before{content:""}.jupyter-wrapper .bp3-icon-sort-desc:before{content:""}.jupyter-wrapper .bp3-icon-sort-numerical:before{content:""}.jupyter-wrapper .bp3-icon-sort-numerical-desc:before{content:""}.jupyter-wrapper .bp3-icon-split-columns:before{content:""}.jupyter-wrapper .bp3-icon-square:before{content:""}.jupyter-wrapper .bp3-icon-stacked-chart:before{content:""}.jupyter-wrapper .bp3-icon-star:before{content:"★"}.jupyter-wrapper .bp3-icon-star-empty:before{content:"☆"}.jupyter-wrapper .bp3-icon-step-backward:before{content:""}.jupyter-wrapper .bp3-icon-step-chart:before{content:""}.jupyter-wrapper .bp3-icon-step-forward:before{content:""}.jupyter-wrapper .bp3-icon-stop:before{content:""}.jupyter-wrapper .bp3-icon-stopwatch:before{content:""}.jupyter-wrapper .bp3-icon-strikethrough:before{content:""}.jupyter-wrapper .bp3-icon-style:before{content:""}.jupyter-wrapper .bp3-icon-swap-horizontal:before{content:""}.jupyter-wrapper .bp3-icon-swap-vertical:before{content:""}.jupyter-wrapper .bp3-icon-symbol-circle:before{content:""}.jupyter-wrapper .bp3-icon-symbol-cross:before{content:""}.jupyter-wrapper .bp3-icon-symbol-diamond:before{content:""}.jupyter-wrapper .bp3-icon-symbol-square:before{content:""}.jupyter-wrapper .bp3-icon-symbol-triangle-down:before{content:""}.jupyter-wrapper .bp3-icon-symbol-triangle-up:before{content:""}.jupyter-wrapper .bp3-icon-tag:before{content:""}.jupyter-wrapper .bp3-icon-take-action:before{content:""}.jupyter-wrapper .bp3-icon-taxi:before{content:""}.jupyter-wrapper .bp3-icon-text-highlight:before{content:""}.jupyter-wrapper .bp3-icon-th:before{content:""}.jupyter-wrapper .bp3-icon-th-derived:before{content:""}.jupyter-wrapper .bp3-icon-th-disconnect:before{content:""}.jupyter-wrapper .bp3-icon-th-filtered:before{content:""}.jupyter-wrapper .bp3-icon-th-list:before{content:""}.jupyter-wrapper .bp3-icon-thumbs-down:before{content:""}.jupyter-wrapper .bp3-icon-thumbs-up:before{content:""}.jupyter-wrapper .bp3-icon-tick:before{content:"✓"}.jupyter-wrapper .bp3-icon-tick-circle:before{content:""}.jupyter-wrapper .bp3-icon-time:before{content:"⏲"}.jupyter-wrapper .bp3-icon-timeline-area-chart:before{content:""}.jupyter-wrapper .bp3-icon-timeline-bar-chart:before{content:""}.jupyter-wrapper .bp3-icon-timeline-events:before{content:""}.jupyter-wrapper .bp3-icon-timeline-line-chart:before{content:""}.jupyter-wrapper .bp3-icon-tint:before{content:""}.jupyter-wrapper .bp3-icon-torch:before{content:""}.jupyter-wrapper .bp3-icon-tractor:before{content:""}.jupyter-wrapper .bp3-icon-train:before{content:""}.jupyter-wrapper .bp3-icon-translate:before{content:""}.jupyter-wrapper .bp3-icon-trash:before{content:""}.jupyter-wrapper .bp3-icon-tree:before{content:""}.jupyter-wrapper .bp3-icon-trending-down:before{content:""}.jupyter-wrapper .bp3-icon-trending-up:before{content:""}.jupyter-wrapper .bp3-icon-truck:before{content:""}.jupyter-wrapper .bp3-icon-two-columns:before{content:""}.jupyter-wrapper .bp3-icon-unarchive:before{content:""}.jupyter-wrapper .bp3-icon-underline:before{content:"⎁"}.jupyter-wrapper .bp3-icon-undo:before{content:"⎌"}.jupyter-wrapper .bp3-icon-ungroup-objects:before{content:""}.jupyter-wrapper .bp3-icon-unknown-vehicle:before{content:""}.jupyter-wrapper .bp3-icon-unlock:before{content:""}.jupyter-wrapper .bp3-icon-unpin:before{content:""}.jupyter-wrapper .bp3-icon-unresolve:before{content:""}.jupyter-wrapper .bp3-icon-updated:before{content:""}.jupyter-wrapper .bp3-icon-upload:before{content:""}.jupyter-wrapper .bp3-icon-user:before{content:""}.jupyter-wrapper .bp3-icon-variable:before{content:""}.jupyter-wrapper .bp3-icon-vertical-bar-chart-asc:before{content:""}.jupyter-wrapper .bp3-icon-vertical-bar-chart-desc:before{content:""}.jupyter-wrapper .bp3-icon-vertical-distribution:before{content:""}.jupyter-wrapper .bp3-icon-video:before{content:""}.jupyter-wrapper .bp3-icon-volume-down:before{content:""}.jupyter-wrapper .bp3-icon-volume-off:before{content:""}.jupyter-wrapper .bp3-icon-volume-up:before{content:""}.jupyter-wrapper .bp3-icon-walk:before{content:""}.jupyter-wrapper .bp3-icon-warning-sign:before{content:""}.jupyter-wrapper .bp3-icon-waterfall-chart:before{content:""}.jupyter-wrapper .bp3-icon-widget:before{content:""}.jupyter-wrapper .bp3-icon-widget-button:before{content:""}.jupyter-wrapper .bp3-icon-widget-footer:before{content:""}.jupyter-wrapper .bp3-icon-widget-header:before{content:""}.jupyter-wrapper .bp3-icon-wrench:before{content:""}.jupyter-wrapper .bp3-icon-zoom-in:before{content:""}.jupyter-wrapper .bp3-icon-zoom-out:before{content:""}.jupyter-wrapper .bp3-icon-zoom-to-fit:before{content:""}.jupyter-wrapper .bp3-submenu>.bp3-popover-wrapper{display:block}.jupyter-wrapper .bp3-submenu .bp3-popover-target{display:block}.jupyter-wrapper .bp3-submenu.bp3-popover{-webkit-box-shadow:none;box-shadow:none;padding:0 5px}.jupyter-wrapper .bp3-submenu.bp3-popover>.bp3-popover-content{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33}.jupyter-wrapper .bp3-dark .bp3-submenu.bp3-popover,.jupyter-wrapper .bp3-submenu.bp3-popover.bp3-dark{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-dark .bp3-submenu.bp3-popover>.bp3-popover-content,.jupyter-wrapper .bp3-submenu.bp3-popover.bp3-dark>.bp3-popover-content{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-menu{background:#ffffff;border-radius:3px;color:#182026;list-style:none;margin:0;min-width:180px;padding:5px;text-align:left}.jupyter-wrapper .bp3-menu-divider{border-top:1px solid rgba(16,22,26,.15);display:block;margin:5px}.jupyter-wrapper .bp3-dark .bp3-menu-divider{border-top-color:#ffffff26}.jupyter-wrapper .bp3-menu-item{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;border-radius:2px;color:inherit;line-height:20px;padding:5px 7px;text-decoration:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-menu-item>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-menu-item>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item>*{margin-right:7px}.jupyter-wrapper .bp3-menu-item:empty:before,.jupyter-wrapper .bp3-menu-item>:last-child{margin-right:0}.jupyter-wrapper .bp3-menu-item>.bp3-fill{word-break:break-word}.jupyter-wrapper .bp3-menu-item:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item{background-color:#a7b6c24d;cursor:pointer;text-decoration:none}.jupyter-wrapper .bp3-menu-item.bp3-disabled{background-color:inherit;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-dark .bp3-menu-item{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-menu-item{background-color:#8a9ba826;color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled{background-color:inherit;color:#a7b6c299}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary{color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active{background-color:#137cbd}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active{background-color:#106ba3}.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-success{color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active{background-color:#0f9960}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active{background-color:#0d8050}.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning{color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active{background-color:#d9822b}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active{background-color:#bf7326}.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger{color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger .bp3-icon{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active{background-color:#db3737}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active{background-color:#c23030}.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover:before,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover:after,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active:before,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active:after,.jupyter-wrapper .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-menu-item:before{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;margin-right:7px}.jupyter-wrapper .bp3-menu-item:before,.jupyter-wrapper .bp3-menu-item>.bp3-icon{color:#5c7080;margin-top:2px}.jupyter-wrapper .bp3-menu-item .bp3-menu-item-label{color:#5c7080}.jupyter-wrapper .bp3-menu-item:hover,.jupyter-wrapper .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-menu-item{color:inherit}.jupyter-wrapper .bp3-menu-item.bp3-active,.jupyter-wrapper .bp3-menu-item:active{background-color:#7386944d}.jupyter-wrapper .bp3-menu-item.bp3-disabled{background-color:inherit!important;color:#5c708099!important;cursor:not-allowed!important;outline:none!important}.jupyter-wrapper .bp3-menu-item.bp3-disabled:before,.jupyter-wrapper .bp3-menu-item.bp3-disabled>.bp3-icon,.jupyter-wrapper .bp3-menu-item.bp3-disabled .bp3-menu-item-label{color:#5c708099!important}.jupyter-wrapper .bp3-large .bp3-menu-item{font-size:16px;line-height:22px;padding:9px 7px}.jupyter-wrapper .bp3-large .bp3-menu-item .bp3-icon{margin-top:3px}.jupyter-wrapper .bp3-large .bp3-menu-item:before{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;margin-right:10px;margin-top:1px}.jupyter-wrapper button.bp3-menu-item{background:none;border:none;text-align:left;width:100%}.jupyter-wrapper .bp3-menu-header{border-top:1px solid rgba(16,22,26,.15);display:block;margin:5px;cursor:default;padding-left:2px}.jupyter-wrapper .bp3-dark .bp3-menu-header{border-top-color:#ffffff26}.jupyter-wrapper .bp3-menu-header:first-of-type{border-top:none}.jupyter-wrapper .bp3-menu-header>h6{color:#182026;font-weight:600;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;line-height:17px;margin:0;padding:10px 7px 0 1px}.jupyter-wrapper .bp3-menu-header:first-of-type>h6{padding-top:0}.jupyter-wrapper .bp3-large .bp3-menu-header>h6{font-size:18px;padding-bottom:5px;padding-top:15px}.jupyter-wrapper .bp3-large .bp3-menu-header:first-of-type>h6{padding-top:0}.jupyter-wrapper .bp3-dark .bp3-menu{background:#30404d;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{background-color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active{background-color:#106ba3}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{background-color:#0f9960}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active{background-color:#0d8050}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-success.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{background-color:#d9822b}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active{background-color:#bf7326}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{color:inherit}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{background-color:#db3737}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active{background-color:#c23030}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover:before,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:before,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover:after,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:after,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open>.bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active:after,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{color:#fff}.jupyter-wrapper .bp3-dark .bp3-menu-item:before,.jupyter-wrapper .bp3-dark .bp3-menu-item>.bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-menu-item .bp3-menu-item-label{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-active,.jupyter-wrapper .bp3-dark .bp3-menu-item:active{background-color:#8a9ba84d}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled{color:#a7b6c299!important}.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled:before,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{color:#a7b6c299!important}.jupyter-wrapper .bp3-dark .bp3-menu-divider,.jupyter-wrapper .bp3-dark .bp3-menu-header{border-color:#ffffff26}.jupyter-wrapper .bp3-dark .bp3-menu-header>h6{color:#f5f8fa}.jupyter-wrapper .bp3-label .bp3-menu{margin-top:5px}.jupyter-wrapper .bp3-navbar{background-color:#fff;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 0 #10161a00,0 1px 1px #10161a33;height:50px;padding:0 15px;position:relative;width:100%;z-index:10}.jupyter-wrapper .bp3-navbar.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-navbar{background-color:#394b59}.jupyter-wrapper .bp3-navbar.bp3-dark{-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:inset 0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-navbar{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 0 0 rgba(16,22,26,0),0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 0 #10161a00,0 1px 1px #10161a66}.jupyter-wrapper .bp3-navbar.bp3-fixed-top{left:0;position:fixed;right:0;top:0}.jupyter-wrapper .bp3-navbar-heading{font-size:16px;margin-right:15px}.jupyter-wrapper .bp3-navbar-group{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;height:50px}.jupyter-wrapper .bp3-navbar-group.bp3-align-left{float:left}.jupyter-wrapper .bp3-navbar-group.bp3-align-right{float:right}.jupyter-wrapper .bp3-navbar-divider{border-left:1px solid rgba(16,22,26,.15);height:20px;margin:0 10px}.jupyter-wrapper .bp3-dark .bp3-navbar-divider{border-left-color:#ffffff26}.jupyter-wrapper .bp3-non-ideal-state{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center;width:100%}.jupyter-wrapper .bp3-non-ideal-state>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-non-ideal-state>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-non-ideal-state:before,.jupyter-wrapper .bp3-non-ideal-state>*{margin-bottom:20px}.jupyter-wrapper .bp3-non-ideal-state:empty:before,.jupyter-wrapper .bp3-non-ideal-state>:last-child{margin-bottom:0}.jupyter-wrapper .bp3-non-ideal-state>*{max-width:400px}.jupyter-wrapper .bp3-non-ideal-state-visual{color:#5c708099;font-size:60px}.jupyter-wrapper .bp3-dark .bp3-non-ideal-state-visual{color:#a7b6c299}.jupyter-wrapper .bp3-overflow-list{display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-wrap:nowrap;flex-wrap:nowrap;min-width:0}.jupyter-wrapper .bp3-overflow-list-spacer{-ms-flex-negative:1;flex-shrink:1;width:1px}.jupyter-wrapper body.bp3-overlay-open{overflow:hidden}.jupyter-wrapper .bp3-overlay{bottom:0;left:0;position:static;right:0;top:0;z-index:20}.jupyter-wrapper .bp3-overlay:not(.bp3-overlay-open){pointer-events:none}.jupyter-wrapper .bp3-overlay.bp3-overlay-container{overflow:hidden;position:fixed}.jupyter-wrapper .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{position:absolute}.jupyter-wrapper .bp3-overlay.bp3-overlay-scroll-container{overflow:auto;position:fixed}.jupyter-wrapper .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{position:absolute}.jupyter-wrapper .bp3-overlay.bp3-overlay-inline{display:inline;overflow:visible}.jupyter-wrapper .bp3-overlay-content{position:fixed;z-index:20}.jupyter-wrapper .bp3-overlay-inline .bp3-overlay-content,.jupyter-wrapper .bp3-overlay-scroll-container .bp3-overlay-content{position:absolute}.jupyter-wrapper .bp3-overlay-backdrop{bottom:0;left:0;position:fixed;right:0;top:0;opacity:1;background-color:#10161ab3;overflow:auto;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;z-index:20}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-enter,.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-appear{opacity:0}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-enter-active,.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-appear-active{opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-exit{opacity:1}.jupyter-wrapper .bp3-overlay-backdrop.bp3-overlay-exit-active{opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-overlay-backdrop:focus{outline:none}.jupyter-wrapper .bp3-overlay-inline .bp3-overlay-backdrop{position:absolute}.jupyter-wrapper .bp3-panel-stack{overflow:hidden;position:relative}.jupyter-wrapper .bp3-panel-stack-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-shadow:0 1px rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-negative:0;flex-shrink:0;height:30px;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack-header{-webkit-box-shadow:0 1px rgba(255,255,255,.15);box-shadow:0 1px #ffffff26}.jupyter-wrapper .bp3-panel-stack-header>span{-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1}.jupyter-wrapper .bp3-panel-stack-header .bp3-heading{margin:0 5px}.jupyter-wrapper .bp3-button.bp3-panel-stack-header-back{margin-left:5px;padding-left:0;white-space:nowrap}.jupyter-wrapper .bp3-button.bp3-panel-stack-header-back .bp3-icon{margin:0 2px}.jupyter-wrapper .bp3-panel-stack-view{bottom:0;left:0;position:absolute;right:0;top:0;background-color:#fff;border-right:1px solid rgba(16,22,26,.15);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin-right:-1px;overflow-y:auto;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack-view{background-color:#30404d}.jupyter-wrapper .bp3-panel-stack-view:nth-last-child(n+4){display:none}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-enter,.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-appear{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-enter-active,.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack-push .bp3-panel-stack-exit-active{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-enter,.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-appear{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-enter-active,.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack-pop .bp3-panel-stack-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2{overflow:hidden;position:relative}.jupyter-wrapper .bp3-panel-stack2-header{-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-shadow:0 1px rgba(16,22,26,.15);box-shadow:0 1px #10161a26;display:-webkit-box;display:-ms-flexbox;display:flex;-ms-flex-negative:0;flex-shrink:0;height:30px;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack2-header{-webkit-box-shadow:0 1px rgba(255,255,255,.15);box-shadow:0 1px #ffffff26}.jupyter-wrapper .bp3-panel-stack2-header>span{-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:1;-ms-flex:1;flex:1}.jupyter-wrapper .bp3-panel-stack2-header .bp3-heading{margin:0 5px}.jupyter-wrapper .bp3-button.bp3-panel-stack2-header-back{margin-left:5px;padding-left:0;white-space:nowrap}.jupyter-wrapper .bp3-button.bp3-panel-stack2-header-back .bp3-icon{margin:0 2px}.jupyter-wrapper .bp3-panel-stack2-view{bottom:0;left:0;position:absolute;right:0;top:0;background-color:#fff;border-right:1px solid rgba(16,22,26,.15);display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;margin-right:-1px;overflow-y:auto;z-index:1}.jupyter-wrapper .bp3-dark .bp3-panel-stack2-view{background-color:#30404d}.jupyter-wrapper .bp3-panel-stack2-view:nth-last-child(n+4){display:none}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-enter,.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-appear{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-enter-active,.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack2-push .bp3-panel-stack2-exit-active{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-enter,.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-appear{-webkit-transform:translateX(-50%);transform:translate(-50%);opacity:0}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-enter-active,.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-appear-active{-webkit-transform:translate(0%);transform:translate(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-exit{-webkit-transform:translate(0%);transform:translate(0);opacity:1}.jupyter-wrapper .bp3-panel-stack2-pop .bp3-panel-stack2-exit-active{-webkit-transform:translateX(100%);transform:translate(100%);opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.4s;transition-duration:.4s;-webkit-transition-property:opacity,-webkit-transform;transition-property:opacity,-webkit-transform;transition-property:transform,opacity;transition-property:transform,opacity,-webkit-transform;-webkit-transition-timing-function:ease;transition-timing-function:ease}.jupyter-wrapper .bp3-popover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;-webkit-transform:scale(1);transform:scale(1);border-radius:3px;display:inline-block;z-index:20}.jupyter-wrapper .bp3-popover .bp3-popover-arrow{height:30px;position:absolute;width:30px}.jupyter-wrapper .bp3-popover .bp3-popover-arrow:before{height:20px;margin:5px;width:20px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover{margin-bottom:17px;margin-top:-17px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow{bottom:-11px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover{margin-left:17px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow{left:-11px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(0);transform:rotate(0)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover{margin-top:17px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow{top:-11px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover{margin-left:-17px;margin-right:17px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow{right:-11px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow svg{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.jupyter-wrapper .bp3-tether-element-attached-middle>.bp3-popover>.bp3-popover-arrow{top:50%;-webkit-transform:translateY(-50%);transform:translateY(-50%)}.jupyter-wrapper .bp3-tether-element-attached-center>.bp3-popover>.bp3-popover-arrow{right:50%;-webkit-transform:translateX(50%);transform:translate(50%)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-top>.bp3-popover>.bp3-popover-arrow{top:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-right>.bp3-popover>.bp3-popover-arrow{right:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-left>.bp3-popover>.bp3-popover-arrow{left:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom>.bp3-popover>.bp3-popover-arrow{bottom:-.3934px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:top left;transform-origin:top left}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:top center;transform-origin:top center}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:top right;transform-origin:top right}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:center left;transform-origin:center left}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:center center;transform-origin:center center}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:center right;transform-origin:center right}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left>.bp3-popover{-webkit-transform-origin:bottom left;transform-origin:bottom left}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center>.bp3-popover{-webkit-transform-origin:bottom center;transform-origin:bottom center}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right>.bp3-popover{-webkit-transform-origin:bottom right;transform-origin:bottom right}.jupyter-wrapper .bp3-popover .bp3-popover-content{background:#ffffff;color:inherit}.jupyter-wrapper .bp3-popover .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.2);box-shadow:1px 1px 6px #10161a33}.jupyter-wrapper .bp3-popover .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.1}.jupyter-wrapper .bp3-popover .bp3-popover-arrow-fill{fill:#fff}.jupyter-wrapper .bp3-popover-enter>.bp3-popover,.jupyter-wrapper .bp3-popover-appear>.bp3-popover{-webkit-transform:scale(.3);transform:scale(.3)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-popover,.jupyter-wrapper .bp3-popover-appear-active>.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-popover-exit>.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-popover{-webkit-transform:scale(.3);transform:scale(.3);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-popover .bp3-popover-content{border-radius:3px;position:relative}.jupyter-wrapper .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{max-width:350px;padding:20px}.jupyter-wrapper .bp3-popover-target+.bp3-overlay .bp3-popover.bp3-popover-content-sizing{width:350px}.jupyter-wrapper .bp3-popover.bp3-minimal{margin:0!important}.jupyter-wrapper .bp3-popover.bp3-minimal .bp3-popover-arrow{display:none}.jupyter-wrapper .bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-enter>.bp3-popover.bp3-minimal.bp3-popover,.jupyter-wrapper .bp3-popover-appear>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-popover.bp3-minimal.bp3-popover,.jupyter-wrapper .bp3-popover-appear-active>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-popover-exit>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-popover.bp3-minimal.bp3-popover{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-popover.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-popover{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-content,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-content{background:#30404d;color:inherit}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow:before,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.4);box-shadow:1px 1px 6px #10161a66}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow-border,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.2}.jupyter-wrapper .bp3-popover.bp3-dark .bp3-popover-arrow-fill,.jupyter-wrapper .bp3-dark .bp3-popover .bp3-popover-arrow-fill{fill:#30404d}.jupyter-wrapper .bp3-popover-arrow:before{border-radius:2px;content:"";display:block;position:absolute;-webkit-transform:rotate(45deg);transform:rotate(45deg)}.jupyter-wrapper .bp3-tether-pinned .bp3-popover-arrow{display:none}.jupyter-wrapper .bp3-popover-backdrop{background:rgba(255,255,255,0)}.jupyter-wrapper .bp3-transition-container{opacity:1;display:-webkit-box;display:-ms-flexbox;display:flex;z-index:20}.jupyter-wrapper .bp3-transition-container.bp3-popover-enter,.jupyter-wrapper .bp3-transition-container.bp3-popover-appear{opacity:0}.jupyter-wrapper .bp3-transition-container.bp3-popover-enter-active,.jupyter-wrapper .bp3-transition-container.bp3-popover-appear-active{opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-transition-container.bp3-popover-exit{opacity:1}.jupyter-wrapper .bp3-transition-container.bp3-popover-exit-active{opacity:0;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:opacity;transition-property:opacity;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-transition-container:focus{outline:none}.jupyter-wrapper .bp3-transition-container.bp3-popover-leave .bp3-popover-content{pointer-events:none}.jupyter-wrapper .bp3-transition-container[data-x-out-of-boundaries]{display:none}.jupyter-wrapper span.bp3-popover-target{display:inline-block}.jupyter-wrapper .bp3-popover-wrapper.bp3-fill{width:100%}.jupyter-wrapper .bp3-portal{left:0;position:absolute;right:0;top:0}@-webkit-keyframes linear-progress-bar-stripes{0%{background-position:0 0}to{background-position:30px 0}}@keyframes linear-progress-bar-stripes{0%{background-position:0 0}to{background-position:30px 0}}.jupyter-wrapper .bp3-progress-bar{background:rgba(92,112,128,.2);border-radius:40px;display:block;height:8px;overflow:hidden;position:relative;width:100%}.jupyter-wrapper .bp3-progress-bar .bp3-progress-meter{background:linear-gradient(-45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%);background-color:#5c7080cc;background-size:30px 30px;border-radius:40px;height:100%;position:absolute;-webkit-transition:width .2s cubic-bezier(.4,1,.75,.9);transition:width .2s cubic-bezier(.4,1,.75,.9);width:100%}.jupyter-wrapper .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{animation:linear-progress-bar-stripes .3s linear infinite reverse}.jupyter-wrapper .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{background-image:none}.jupyter-wrapper .bp3-dark .bp3-progress-bar{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-dark .bp3-progress-bar .bp3-progress-meter{background-color:#8a9ba8}.jupyter-wrapper .bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{background-color:#137cbd}.jupyter-wrapper .bp3-progress-bar.bp3-intent-success .bp3-progress-meter{background-color:#0f9960}.jupyter-wrapper .bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{background-color:#d9822b}.jupyter-wrapper .bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{background-color:#db3737}@-webkit-keyframes skeleton-glow{0%{background:rgba(206,217,224,.2);border-color:#ced9e033}to{background:rgba(92,112,128,.2);border-color:#5c708033}}@keyframes skeleton-glow{0%{background:rgba(206,217,224,.2);border-color:#ced9e033}to{background:rgba(92,112,128,.2);border-color:#5c708033}}.jupyter-wrapper .bp3-skeleton{-webkit-animation:1s linear infinite alternate skeleton-glow;animation:1s linear infinite alternate skeleton-glow;background:rgba(206,217,224,.2);background-clip:padding-box!important;border-color:#ced9e033!important;border-radius:2px;-webkit-box-shadow:none!important;box-shadow:none!important;color:transparent!important;cursor:default;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-skeleton:before,.jupyter-wrapper .bp3-skeleton:after,.jupyter-wrapper .bp3-skeleton *{visibility:hidden!important}.jupyter-wrapper .bp3-slider{height:40px;min-width:150px;width:100%;cursor:default;outline:none;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-slider:hover{cursor:pointer}.jupyter-wrapper .bp3-slider:active{cursor:-webkit-grabbing;cursor:grabbing}.jupyter-wrapper .bp3-slider.bp3-disabled{cursor:not-allowed;opacity:.5}.jupyter-wrapper .bp3-slider.bp3-slider-unlabeled{height:16px}.jupyter-wrapper .bp3-slider-track,.jupyter-wrapper .bp3-slider-progress{height:6px;left:0;right:0;top:5px;position:absolute}.jupyter-wrapper .bp3-slider-track{border-radius:3px;overflow:hidden}.jupyter-wrapper .bp3-slider-progress{background:rgba(92,112,128,.2)}.jupyter-wrapper .bp3-dark .bp3-slider-progress{background:rgba(16,22,26,.5)}.jupyter-wrapper .bp3-slider-progress.bp3-intent-primary{background-color:#137cbd}.jupyter-wrapper .bp3-slider-progress.bp3-intent-success{background-color:#0f9960}.jupyter-wrapper .bp3-slider-progress.bp3-intent-warning{background-color:#d9822b}.jupyter-wrapper .bp3-slider-progress.bp3-intent-danger{background-color:#db3737}.jupyter-wrapper .bp3-slider-handle{background-color:#f5f8fa;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.8)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.8),rgba(255,255,255,0));-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;color:#182026;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a33;cursor:pointer;height:16px;left:0;position:absolute;top:0;width:16px}.jupyter-wrapper .bp3-slider-handle:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a}.jupyter-wrapper .bp3-slider-handle:active,.jupyter-wrapper .bp3-slider-handle.bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-slider-handle:disabled,.jupyter-wrapper .bp3-slider-handle.bp3-disabled{background-color:#ced9e080;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#5c708099;cursor:not-allowed;outline:none}.jupyter-wrapper .bp3-slider-handle:disabled.bp3-active,.jupyter-wrapper .bp3-slider-handle:disabled.bp3-active:hover,.jupyter-wrapper .bp3-slider-handle.bp3-disabled.bp3-active,.jupyter-wrapper .bp3-slider-handle.bp3-disabled.bp3-active:hover{background:rgba(206,217,224,.7)}.jupyter-wrapper .bp3-slider-handle:focus{z-index:1}.jupyter-wrapper .bp3-slider-handle:hover{background-clip:padding-box;background-color:#ebf1f5;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 -1px 0 rgba(16,22,26,.1);box-shadow:inset 0 0 0 1px #10161a33,inset 0 -1px #10161a1a;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a33,0 1px 1px #10161a33;cursor:-webkit-grab;cursor:grab;z-index:2}.jupyter-wrapper .bp3-slider-handle.bp3-active{background-color:#d8e1e8;background-image:none;-webkit-box-shadow:inset 0 0 0 1px rgba(16,22,26,.2),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:inset 0 0 0 1px #10161a33,inset 0 1px 2px #10161a33;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),inset 0 1px 1px rgba(16,22,26,.1);box-shadow:0 0 0 1px #10161a33,inset 0 1px 1px #10161a1a;cursor:-webkit-grabbing;cursor:grabbing}.jupyter-wrapper .bp3-disabled .bp3-slider-handle{background:#bfccd6;-webkit-box-shadow:none;box-shadow:none;pointer-events:none}.jupyter-wrapper .bp3-dark .bp3-slider-handle{background-color:#394b59;background-image:-webkit-gradient(linear,left top,left bottom,from(rgba(255,255,255,.05)),to(rgba(255,255,255,0)));background-image:linear-gradient(to bottom,rgba(255,255,255,.05),rgba(255,255,255,0));-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66;color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover,.jupyter-wrapper .bp3-dark .bp3-slider-handle:active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-slider-handle:active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{background-color:#202b33;background-image:none;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.6),inset 0 1px 2px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a99,inset 0 1px 2px #10161a33}.jupyter-wrapper .bp3-dark .bp3-slider-handle:disabled,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-disabled{background-color:#394b5980;background-image:none;-webkit-box-shadow:none;box-shadow:none;color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-slider-handle:disabled.bp3-active,.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{background:rgba(57,75,89,.7)}.jupyter-wrapper .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{background:rgba(16,22,26,.5);stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-slider-handle,.jupyter-wrapper .bp3-dark .bp3-slider-handle:hover{background-color:#394b59}.jupyter-wrapper .bp3-dark .bp3-slider-handle.bp3-active{background-color:#293742}.jupyter-wrapper .bp3-dark .bp3-disabled .bp3-slider-handle{background:#5c7080;border-color:#5c7080;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-slider-handle .bp3-slider-label{background:#394b59;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;color:#f5f8fa;margin-left:8px}.jupyter-wrapper .bp3-dark .bp3-slider-handle .bp3-slider-label{background:#e1e8ed;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66;color:#394b59}.jupyter-wrapper .bp3-disabled .bp3-slider-handle .bp3-slider-label{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-slider-handle.bp3-start,.jupyter-wrapper .bp3-slider-handle.bp3-end{width:8px}.jupyter-wrapper .bp3-slider-handle.bp3-start{border-bottom-right-radius:0;border-top-right-radius:0}.jupyter-wrapper .bp3-slider-handle.bp3-end{border-bottom-left-radius:0;border-top-left-radius:0;margin-left:8px}.jupyter-wrapper .bp3-slider-handle.bp3-end .bp3-slider-label{margin-left:0}.jupyter-wrapper .bp3-slider-label{-webkit-transform:translate(-50%,20px);transform:translate(-50%,20px);display:inline-block;font-size:12px;line-height:1;padding:2px 5px;position:absolute;vertical-align:top}.jupyter-wrapper .bp3-slider.bp3-vertical{height:150px;min-width:40px;width:40px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-track,.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-progress{bottom:0;height:auto;left:5px;top:0;width:6px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-progress{top:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-label{-webkit-transform:translate(20px,50%);transform:translate(20px,50%)}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle{top:auto}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{margin-left:0;margin-top:-8px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end,.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{height:8px;margin-left:0;width:16px}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{border-bottom-right-radius:3px;border-top-left-radius:0}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{-webkit-transform:translate(20px);transform:translate(20px)}.jupyter-wrapper .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{border-bottom-left-radius:0;border-bottom-right-radius:0;border-top-left-radius:3px;margin-bottom:8px}@-webkit-keyframes pt-spinner-animation{0%{-webkit-transform:rotate(0deg);transform:rotate(0)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes pt-spinner-animation{0%{-webkit-transform:rotate(0deg);transform:rotate(0)}to{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.jupyter-wrapper .bp3-spinner{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;overflow:visible;vertical-align:middle}.jupyter-wrapper .bp3-spinner svg{display:block}.jupyter-wrapper .bp3-spinner path{fill-opacity:0}.jupyter-wrapper .bp3-spinner .bp3-spinner-head{stroke:#5c7080cc;stroke-linecap:round;-webkit-transform-origin:center;transform-origin:center;-webkit-transition:stroke-dashoffset .2s cubic-bezier(.4,1,.75,.9);transition:stroke-dashoffset .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-spinner .bp3-spinner-track{stroke:#5c708033}.jupyter-wrapper .bp3-spinner-animation{-webkit-animation:pt-spinner-animation .5s linear infinite;animation:pt-spinner-animation .5s linear infinite}.jupyter-wrapper .bp3-no-spin>.bp3-spinner-animation{-webkit-animation:none;animation:none}.jupyter-wrapper .bp3-dark .bp3-spinner .bp3-spinner-head{stroke:#8a9ba8}.jupyter-wrapper .bp3-dark .bp3-spinner .bp3-spinner-track{stroke:#10161a80}.jupyter-wrapper .bp3-spinner.bp3-intent-primary .bp3-spinner-head{stroke:#137cbd}.jupyter-wrapper .bp3-spinner.bp3-intent-success .bp3-spinner-head{stroke:#0f9960}.jupyter-wrapper .bp3-spinner.bp3-intent-warning .bp3-spinner-head{stroke:#d9822b}.jupyter-wrapper .bp3-spinner.bp3-intent-danger .bp3-spinner-head{stroke:#db3737}.jupyter-wrapper .bp3-tabs.bp3-vertical{display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab{border-radius:3px;padding:0 10px;width:100%}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab[aria-selected=true]{background-color:#137cbd33;-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{background-color:#137cbd33;border-radius:3px;bottom:0;height:auto;left:0;right:0;top:0}.jupyter-wrapper .bp3-tabs.bp3-vertical>.bp3-tab-panel{margin-top:0;padding-left:20px}.jupyter-wrapper .bp3-tab-list{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end;border:none;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;list-style:none;margin:0;padding:0;position:relative}.jupyter-wrapper .bp3-tab-list>*:not(:last-child){margin-right:20px}.jupyter-wrapper .bp3-tab{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;color:#182026;cursor:pointer;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;font-size:14px;line-height:30px;max-width:100%;position:relative;vertical-align:top}.jupyter-wrapper .bp3-tab a{color:inherit;display:block;text-decoration:none}.jupyter-wrapper .bp3-tab-indicator-wrapper~.bp3-tab{background-color:transparent!important;-webkit-box-shadow:none!important;box-shadow:none!important}.jupyter-wrapper .bp3-tab[aria-disabled=true]{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-tab[aria-selected=true]{border-radius:0;-webkit-box-shadow:inset 0 -3px 0 #106ba3;box-shadow:inset 0 -3px #106ba3}.jupyter-wrapper .bp3-tab[aria-selected=true],.jupyter-wrapper .bp3-tab:not([aria-disabled=true]):hover{color:#106ba3}.jupyter-wrapper .bp3-tab:focus{-moz-outline-radius:0}.jupyter-wrapper .bp3-large>.bp3-tab{font-size:16px;line-height:40px}.jupyter-wrapper .bp3-tab-panel{margin-top:20px}.jupyter-wrapper .bp3-tab-panel[aria-hidden=true]{display:none}.jupyter-wrapper .bp3-tab-indicator-wrapper{left:0;pointer-events:none;position:absolute;top:0;-webkit-transform:translateX(0),translateY(0);transform:translate(0),translateY(0);-webkit-transition:height,width,-webkit-transform;transition:height,width,-webkit-transform;transition:height,transform,width;transition:height,transform,width,-webkit-transform;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-tab-indicator-wrapper .bp3-tab-indicator{background-color:#106ba3;bottom:0;height:3px;left:0;position:absolute;right:0}.jupyter-wrapper .bp3-tab-indicator-wrapper.bp3-no-animation{-webkit-transition:none;transition:none}.jupyter-wrapper .bp3-dark .bp3-tab{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tab[aria-disabled=true]{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tab[aria-selected=true]{-webkit-box-shadow:inset 0 -3px 0 #48aff0;box-shadow:inset 0 -3px #48aff0}.jupyter-wrapper .bp3-dark .bp3-tab[aria-selected=true],.jupyter-wrapper .bp3-dark .bp3-tab:not([aria-disabled=true]):hover{color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-tab-indicator{background-color:#48aff0}.jupyter-wrapper .bp3-flex-expander{-webkit-box-flex:1;-ms-flex:1 1;flex:1 1}.jupyter-wrapper .bp3-tag{display:-webkit-inline-box;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#5c7080;border:none;border-radius:3px;-webkit-box-shadow:none;box-shadow:none;color:#f5f8fa;font-size:12px;line-height:16px;max-width:100%;min-height:20px;min-width:20px;padding:2px 6px;position:relative}.jupyter-wrapper .bp3-tag.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-interactive:hover{background-color:#5c7080d9}.jupyter-wrapper .bp3-tag.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-interactive:active{background-color:#5c7080b3}.jupyter-wrapper .bp3-tag>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag:before,.jupyter-wrapper .bp3-tag>*{margin-right:4px}.jupyter-wrapper .bp3-tag:empty:before,.jupyter-wrapper .bp3-tag>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag:focus{outline:rgba(19,124,189,.6) auto 2px;outline-offset:0;-moz-outline-radius:6px}.jupyter-wrapper .bp3-tag.bp3-round{border-radius:30px;padding-left:8px;padding-right:8px}.jupyter-wrapper .bp3-dark .bp3-tag{background-color:#bfccd6;color:#182026}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive:hover{background-color:#bfccd6d9}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-interactive:active{background-color:#bfccd6b3}.jupyter-wrapper .bp3-dark .bp3-tag>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tag .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tag .bp3-icon-large{fill:currentColor}.jupyter-wrapper .bp3-tag>.bp3-icon,.jupyter-wrapper .bp3-tag .bp3-icon-standard,.jupyter-wrapper .bp3-tag .bp3-icon-large{fill:#fff}.jupyter-wrapper .bp3-tag.bp3-large,.jupyter-wrapper .bp3-large .bp3-tag{font-size:14px;line-height:20px;min-height:30px;min-width:30px;padding:5px 10px}.jupyter-wrapper .bp3-tag.bp3-large:before,.jupyter-wrapper .bp3-tag.bp3-large>*,.jupyter-wrapper .bp3-large .bp3-tag:before,.jupyter-wrapper .bp3-large .bp3-tag>*{margin-right:7px}.jupyter-wrapper .bp3-tag.bp3-large:empty:before,.jupyter-wrapper .bp3-tag.bp3-large>:last-child,.jupyter-wrapper .bp3-large .bp3-tag:empty:before,.jupyter-wrapper .bp3-large .bp3-tag>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag.bp3-large.bp3-round,.jupyter-wrapper .bp3-large .bp3-tag.bp3-round{padding-left:12px;padding-right:12px}.jupyter-wrapper .bp3-tag.bp3-intent-primary{background:#137cbd;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive:hover{background-color:#137cbdd9}.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-primary.bp3-interactive:active{background-color:#137cbdb3}.jupyter-wrapper .bp3-tag.bp3-intent-success{background:#0f9960;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive:hover{background-color:#0f9960d9}.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-success.bp3-interactive:active{background-color:#0f9960b3}.jupyter-wrapper .bp3-tag.bp3-intent-warning{background:#d9822b;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive:hover{background-color:#d9822bd9}.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-warning.bp3-interactive:active{background-color:#d9822bb3}.jupyter-wrapper .bp3-tag.bp3-intent-danger{background:#db3737;color:#fff}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive:hover{background-color:#db3737d9}.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-intent-danger.bp3-interactive:active{background-color:#db3737b3}.jupyter-wrapper .bp3-tag.bp3-fill{display:-webkit-box;display:-ms-flexbox;display:flex;width:100%}.jupyter-wrapper .bp3-tag.bp3-minimal>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal .bp3-icon-large{fill:#5c7080}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]){background-color:#8a9ba833;color:#182026}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:hover{background-color:#5c70804d}.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:active{background-color:#5c708066}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]){color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:hover{background-color:#bfccd64d}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]).bp3-interactive:active{background-color:#bfccd666}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-])>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]) .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal:not([class*=bp3-intent-]) .bp3-icon-large{fill:#a7b6c2}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary{background-color:#137cbd26;color:#106ba3}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{background-color:#137cbd40}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{background-color:#137cbd59}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{fill:#137cbd}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{background-color:#137cbd40;color:#48aff0}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{background-color:#137cbd59}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{background-color:#137cbd73}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success{background-color:#0f996026;color:#0d8050}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{background-color:#0f996040}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{background-color:#0f996059}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{fill:#0f9960}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{background-color:#0f996040;color:#3dcc91}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{background-color:#0f996059}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{background-color:#0f996073}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning{background-color:#d9822b26;color:#bf7326}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{background-color:#d9822b40}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{background-color:#d9822b59}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{fill:#d9822b}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{background-color:#d9822b40;color:#ffb366}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{background-color:#d9822b59}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{background-color:#d9822b73}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger{background-color:#db373726;color:#c23030}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{background-color:#db373740}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{background-color:#db373759}.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger>.bp3-icon,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard,.jupyter-wrapper .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{fill:#db3737}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{background-color:#db373740;color:#ff7373}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{cursor:pointer}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{background-color:#db373759}.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active,.jupyter-wrapper .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{background-color:#db373773}.jupyter-wrapper .bp3-tag-remove{background:none;border:none;color:inherit;cursor:pointer;display:-webkit-box;display:-ms-flexbox;display:flex;margin-bottom:-2px;margin-right:-6px!important;margin-top:-2px;opacity:.5;padding:2px 2px 2px 0}.jupyter-wrapper .bp3-tag-remove:hover{background:none;opacity:.8;text-decoration:none}.jupyter-wrapper .bp3-tag-remove:active{opacity:1}.jupyter-wrapper .bp3-tag-remove:empty:before{font-family:Icons16,sans-serif;font-size:16px;font-style:normal;font-weight:400;line-height:1;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;content:""}.jupyter-wrapper .bp3-large .bp3-tag-remove{margin-right:-10px!important;padding:0 5px 0 0}.jupyter-wrapper .bp3-large .bp3-tag-remove:empty:before{font-family:Icons20,sans-serif;font-size:20px;font-style:normal;font-weight:400;line-height:1}.jupyter-wrapper .bp3-tag-input{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;cursor:text;height:auto;line-height:inherit;min-height:30px;padding-left:5px;padding-right:0}.jupyter-wrapper .bp3-tag-input>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag-input>.bp3-tag-input-values{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-icon{color:#5c7080;margin-left:2px;margin-right:7px;margin-top:7px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-ms-flex-item-align:stretch;align-self:stretch;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:7px;margin-top:5px;min-width:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{-webkit-box-flex:0;-ms-flex-positive:0;flex-grow:0;-ms-flex-negative:0;flex-shrink:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>.bp3-fill{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-negative:1;flex-shrink:1}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:before,.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{margin-right:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:empty:before,.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{padding-left:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag-input-values>*{margin-bottom:5px}.jupyter-wrapper .bp3-tag-input .bp3-tag{overflow-wrap:break-word}.jupyter-wrapper .bp3-tag-input .bp3-tag.bp3-active{outline:rgba(19,124,189,.6) auto 2px;outline-offset:0;-moz-outline-radius:6px}.jupyter-wrapper .bp3-tag-input .bp3-input-ghost{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;line-height:20px;width:80px}.jupyter-wrapper .bp3-tag-input .bp3-input-ghost:disabled,.jupyter-wrapper .bp3-tag-input .bp3-input-ghost.bp3-disabled{cursor:not-allowed}.jupyter-wrapper .bp3-tag-input .bp3-button,.jupyter-wrapper .bp3-tag-input .bp3-spinner{margin:3px 3px 3px 0}.jupyter-wrapper .bp3-tag-input .bp3-button{min-height:24px;min-width:24px;padding:0 7px}.jupyter-wrapper .bp3-tag-input.bp3-large{height:auto;min-height:40px}.jupyter-wrapper .bp3-tag-input.bp3-large:before,.jupyter-wrapper .bp3-tag-input.bp3-large>*{margin-right:10px}.jupyter-wrapper .bp3-tag-input.bp3-large:empty:before,.jupyter-wrapper .bp3-tag-input.bp3-large>:last-child{margin-right:0}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-tag-input-icon{margin-left:5px;margin-top:10px}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-input-ghost{line-height:30px}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-button{min-height:30px;min-width:30px;padding:5px 10px;margin:5px 5px 5px 0}.jupyter-wrapper .bp3-tag-input.bp3-large .bp3-spinner{margin:8px 8px 8px 0}.jupyter-wrapper .bp3-tag-input.bp3-active{background-color:#fff;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-primary{-webkit-box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #106ba3,0 0 0 3px #106ba34d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-success{-webkit-box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #0d8050,0 0 0 3px #0d80504d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-warning{-webkit-box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #bf7326,0 0 0 3px #bf73264d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-tag-input.bp3-active.bp3-intent-danger{-webkit-box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 1px 1px rgba(16,22,26,.2);box-shadow:0 0 0 1px #c23030,0 0 0 3px #c230304d,inset 0 1px 1px #10161a33}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-tag-input-icon,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-tag-input-icon{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost{color:#f5f8fa}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder,.jupyter-wrapper .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{color:#a7b6c299}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active{background-color:#10161a4d;-webkit-box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px rgba(19,124,189,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #137cbd,0 0 0 1px #137cbd,0 0 0 3px #137cbd4d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{-webkit-box-shadow:0 0 0 1px #106ba3,0 0 0 3px rgba(16,107,163,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #106ba3,0 0 0 3px #106ba34d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{-webkit-box-shadow:0 0 0 1px #0d8050,0 0 0 3px rgba(13,128,80,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #0d8050,0 0 0 3px #0d80504d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{-webkit-box-shadow:0 0 0 1px #bf7326,0 0 0 3px rgba(191,115,38,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #bf7326,0 0 0 3px #bf73264d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger,.jupyter-wrapper .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{-webkit-box-shadow:0 0 0 1px #c23030,0 0 0 3px rgba(194,48,48,.3),inset 0 0 0 1px rgba(16,22,26,.3),inset 0 1px 1px rgba(16,22,26,.4);box-shadow:0 0 0 1px #c23030,0 0 0 3px #c230304d,inset 0 0 0 1px #10161a4d,inset 0 1px 1px #10161a66}.jupyter-wrapper .bp3-input-ghost{background:none;border:none;-webkit-box-shadow:none;box-shadow:none;padding:0}.jupyter-wrapper .bp3-input-ghost::-webkit-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost::-moz-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost:-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost::-ms-input-placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost::placeholder{color:#5c708099;opacity:1}.jupyter-wrapper .bp3-input-ghost:focus{outline:none!important}.jupyter-wrapper .bp3-toast{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start;background-color:#fff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;display:-webkit-box;display:-ms-flexbox;display:flex;margin:20px 0 0;max-width:500px;min-width:300px;pointer-events:all;position:relative!important}.jupyter-wrapper .bp3-toast.bp3-toast-enter,.jupyter-wrapper .bp3-toast.bp3-toast-appear{-webkit-transform:translateY(-40px);transform:translateY(-40px)}.jupyter-wrapper .bp3-toast.bp3-toast-enter-active,.jupyter-wrapper .bp3-toast.bp3-toast-appear-active{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-toast.bp3-toast-enter~.bp3-toast,.jupyter-wrapper .bp3-toast.bp3-toast-appear~.bp3-toast{-webkit-transform:translateY(-40px);transform:translateY(-40px)}.jupyter-wrapper .bp3-toast.bp3-toast-enter-active~.bp3-toast,.jupyter-wrapper .bp3-toast.bp3-toast-appear-active~.bp3-toast{-webkit-transform:translateY(0);transform:translateY(0);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.54,1.12,.38,1.11);transition-timing-function:cubic-bezier(.54,1.12,.38,1.11)}.jupyter-wrapper .bp3-toast.bp3-toast-exit{opacity:1;-webkit-filter:blur(0);filter:blur(0)}.jupyter-wrapper .bp3-toast.bp3-toast-exit-active{opacity:0;-webkit-filter:blur(10px);filter:blur(10px);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.3s;transition-duration:.3s;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:opacity,filter;transition-property:opacity,filter,-webkit-filter;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-toast.bp3-toast-exit~.bp3-toast{-webkit-transform:translateY(0);transform:translateY(0)}.jupyter-wrapper .bp3-toast.bp3-toast-exit-active~.bp3-toast{-webkit-transform:translateY(-40px);transform:translateY(-40px);-webkit-transition-delay:50ms;transition-delay:50ms;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-toast .bp3-button-group{-webkit-box-flex:0;-ms-flex:0 0 auto;flex:0 0 auto;padding:5px 5px 5px 0}.jupyter-wrapper .bp3-toast>.bp3-icon{color:#5c7080;margin:12px 0 12px 12px}.jupyter-wrapper .bp3-toast.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-toast{background-color:#394b59;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-toast.bp3-dark>.bp3-icon,.jupyter-wrapper .bp3-dark .bp3-toast>.bp3-icon{color:#a7b6c2}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] a{color:#ffffffb3}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] a:hover{color:#fff}.jupyter-wrapper .bp3-toast[class*=bp3-intent-]>.bp3-icon{color:#fff}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:before,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button .bp3-icon,.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:active{color:#ffffffb3!important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:focus{outline-color:#ffffff80}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:hover{background-color:#ffffff26!important;color:#fff!important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:active{background-color:#ffffff4d!important;color:#fff!important}.jupyter-wrapper .bp3-toast[class*=bp3-intent-] .bp3-button:after{background:rgba(255,255,255,.3)!important}.jupyter-wrapper .bp3-toast.bp3-intent-primary{background-color:#137cbd;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-success{background-color:#0f9960;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-warning{background-color:#d9822b;color:#fff}.jupyter-wrapper .bp3-toast.bp3-intent-danger{background-color:#db3737;color:#fff}.jupyter-wrapper .bp3-toast-message{-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;padding:11px;word-break:break-word}.jupyter-wrapper .bp3-toast-container{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box!important;display:-ms-flexbox!important;display:flex!important;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;left:0;overflow:hidden;padding:0 20px 20px;pointer-events:none;right:0;z-index:40}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-in-portal{position:fixed}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-inline{position:absolute}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-top{top:0}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-bottom{bottom:0;-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;top:auto}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-left{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.jupyter-wrapper .bp3-toast-container.bp3-toast-container-right{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active)~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active)~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-exit-active~.bp3-toast,.jupyter-wrapper .bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active~.bp3-toast{-webkit-transform:translateY(60px);transform:translateY(60px)}.jupyter-wrapper .bp3-tooltip{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 2px 4px rgba(16,22,26,.2),0 8px 24px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 2px 4px #10161a33,0 8px 24px #10161a33;-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow{height:22px;position:absolute;width:22px}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow:before{height:14px;margin:4px;width:14px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip{margin-bottom:11px;margin-top:-11px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow{bottom:-8px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip{margin-left:11px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow{left:-8px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(0);transform:rotate(0)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip{margin-top:11px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow{top:-8px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip{margin-left:-11px;margin-right:11px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow{right:-8px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow svg{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.jupyter-wrapper .bp3-tether-element-attached-middle>.bp3-tooltip>.bp3-popover-arrow{top:50%;-webkit-transform:translateY(-50%);transform:translateY(-50%)}.jupyter-wrapper .bp3-tether-element-attached-center>.bp3-tooltip>.bp3-popover-arrow{right:50%;-webkit-transform:translateX(50%);transform:translate(50%)}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-target-attached-top>.bp3-tooltip>.bp3-popover-arrow{top:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-right.bp3-tether-target-attached-right>.bp3-tooltip>.bp3-popover-arrow{right:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-left.bp3-tether-target-attached-left>.bp3-tooltip>.bp3-popover-arrow{left:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom>.bp3-tooltip>.bp3-popover-arrow{bottom:-.22183px}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:top left;transform-origin:top left}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:top center;transform-origin:top center}.jupyter-wrapper .bp3-tether-element-attached-top.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:top right;transform-origin:top right}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:center left;transform-origin:center left}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:center center;transform-origin:center center}.jupyter-wrapper .bp3-tether-element-attached-middle.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:center right;transform-origin:center right}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left>.bp3-tooltip{-webkit-transform-origin:bottom left;transform-origin:bottom left}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center>.bp3-tooltip{-webkit-transform-origin:bottom center;transform-origin:bottom center}.jupyter-wrapper .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right>.bp3-tooltip{-webkit-transform-origin:bottom right;transform-origin:bottom right}.jupyter-wrapper .bp3-tooltip .bp3-popover-content{background:#394b59;color:#f5f8fa}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.2);box-shadow:1px 1px 6px #10161a33}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.1}.jupyter-wrapper .bp3-tooltip .bp3-popover-arrow-fill{fill:#394b59}.jupyter-wrapper .bp3-popover-enter>.bp3-tooltip,.jupyter-wrapper .bp3-popover-appear>.bp3-tooltip{-webkit-transform:scale(.8);transform:scale(.8)}.jupyter-wrapper .bp3-popover-enter-active>.bp3-tooltip,.jupyter-wrapper .bp3-popover-appear-active>.bp3-tooltip{-webkit-transform:scale(1);transform:scale(1);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-popover-exit>.bp3-tooltip{-webkit-transform:scale(1);transform:scale(1)}.jupyter-wrapper .bp3-popover-exit-active>.bp3-tooltip{-webkit-transform:scale(.8);transform:scale(.8);-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.1s;transition-duration:.1s;-webkit-transition-property:-webkit-transform;transition-property:-webkit-transform;transition-property:transform;transition-property:transform,-webkit-transform;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-tooltip .bp3-popover-content{padding:10px 12px}.jupyter-wrapper .bp3-tooltip.bp3-dark,.jupyter-wrapper .bp3-dark .bp3-tooltip{-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 2px 4px rgba(16,22,26,.4),0 8px 24px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 2px 4px #10161a66,0 8px 24px #10161a66}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-content,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-content{background:#e1e8ed;color:#394b59}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow:before,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow:before{-webkit-box-shadow:1px 1px 6px rgba(16,22,26,.4);box-shadow:1px 1px 6px #10161a66}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{fill:#10161a;fill-opacity:.2}.jupyter-wrapper .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,.jupyter-wrapper .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{fill:#e1e8ed}.jupyter-wrapper .bp3-tooltip.bp3-intent-primary .bp3-popover-content{background:#137cbd;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{fill:#137cbd}.jupyter-wrapper .bp3-tooltip.bp3-intent-success .bp3-popover-content{background:#0f9960;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{fill:#0f9960}.jupyter-wrapper .bp3-tooltip.bp3-intent-warning .bp3-popover-content{background:#d9822b;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{fill:#d9822b}.jupyter-wrapper .bp3-tooltip.bp3-intent-danger .bp3-popover-content{background:#db3737;color:#fff}.jupyter-wrapper .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{fill:#db3737}.jupyter-wrapper .bp3-tooltip-indicator{border-bottom:dotted 1px;cursor:help}.jupyter-wrapper .bp3-tree .bp3-icon,.jupyter-wrapper .bp3-tree .bp3-icon-standard,.jupyter-wrapper .bp3-tree .bp3-icon-large{color:#5c7080}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-primary{color:#137cbd}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-success{color:#0f9960}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-warning{color:#d9822b}.jupyter-wrapper .bp3-tree .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-tree .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-tree .bp3-icon-large.bp3-intent-danger{color:#db3737}.jupyter-wrapper .bp3-tree-node-list{list-style:none;margin:0;padding-left:0}.jupyter-wrapper .bp3-tree-root{background-color:transparent;cursor:default;padding-left:0;position:relative}.jupyter-wrapper .bp3-tree-node-content-0{padding-left:0}.jupyter-wrapper .bp3-tree-node-content-1{padding-left:23px}.jupyter-wrapper .bp3-tree-node-content-2{padding-left:46px}.jupyter-wrapper .bp3-tree-node-content-3{padding-left:69px}.jupyter-wrapper .bp3-tree-node-content-4{padding-left:92px}.jupyter-wrapper .bp3-tree-node-content-5{padding-left:115px}.jupyter-wrapper .bp3-tree-node-content-6{padding-left:138px}.jupyter-wrapper .bp3-tree-node-content-7{padding-left:161px}.jupyter-wrapper .bp3-tree-node-content-8{padding-left:184px}.jupyter-wrapper .bp3-tree-node-content-9{padding-left:207px}.jupyter-wrapper .bp3-tree-node-content-10{padding-left:230px}.jupyter-wrapper .bp3-tree-node-content-11{padding-left:253px}.jupyter-wrapper .bp3-tree-node-content-12{padding-left:276px}.jupyter-wrapper .bp3-tree-node-content-13{padding-left:299px}.jupyter-wrapper .bp3-tree-node-content-14{padding-left:322px}.jupyter-wrapper .bp3-tree-node-content-15{padding-left:345px}.jupyter-wrapper .bp3-tree-node-content-16{padding-left:368px}.jupyter-wrapper .bp3-tree-node-content-17{padding-left:391px}.jupyter-wrapper .bp3-tree-node-content-18{padding-left:414px}.jupyter-wrapper .bp3-tree-node-content-19{padding-left:437px}.jupyter-wrapper .bp3-tree-node-content-20{padding-left:460px}.jupyter-wrapper .bp3-tree-node-content{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex;height:30px;padding-right:5px;width:100%}.jupyter-wrapper .bp3-tree-node-content:hover{background-color:#bfccd666}.jupyter-wrapper .bp3-tree-node-caret,.jupyter-wrapper .bp3-tree-node-caret-none{min-width:30px}.jupyter-wrapper .bp3-tree-node-caret{color:#5c7080;cursor:pointer;padding:7px;-webkit-transform:rotate(0deg);transform:rotate(0);-webkit-transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:-webkit-transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9);transition:transform .2s cubic-bezier(.4,1,.75,.9),-webkit-transform .2s cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-tree-node-caret:hover{color:#182026}.jupyter-wrapper .bp3-dark .bp3-tree-node-caret{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tree-node-caret:hover{color:#f5f8fa}.jupyter-wrapper .bp3-tree-node-caret.bp3-tree-node-caret-open{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.jupyter-wrapper .bp3-tree-node-caret.bp3-icon-standard:before{content:""}.jupyter-wrapper .bp3-tree-node-icon{margin-right:7px;position:relative}.jupyter-wrapper .bp3-tree-node-label{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-wrap:normal;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-tree-node-label span{display:inline}.jupyter-wrapper .bp3-tree-node-secondary-label{padding:0 5px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .bp3-tree-node-secondary-label .bp3-popover-wrapper,.jupyter-wrapper .bp3-tree-node-secondary-label .bp3-popover-target{-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-ms-flexbox;display:flex}.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-content{background-color:inherit;color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-caret,.jupyter-wrapper .bp3-tree-node.bp3-disabled .bp3-tree-node-icon{color:#5c708099;cursor:not-allowed}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content{background-color:#137cbd}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon-standard,.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-icon-large{color:#fff}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-tree-node-caret:before{color:#ffffffb3}.jupyter-wrapper .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content .bp3-tree-node-caret:hover:before{color:#fff}.jupyter-wrapper .bp3-dark .bp3-tree-node-content:hover{background-color:#5c70804d}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large{color:#a7b6c2}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{color:#137cbd}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{color:#0f9960}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{color:#d9822b}.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger,.jupyter-wrapper .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{color:#db3737}.jupyter-wrapper .bp3-dark .bp3-tree-node.bp3-tree-node-selected>.bp3-tree-node-content{background-color:#137cbd}.jupyter-wrapper .bp3-omnibar{-webkit-filter:blur(0);filter:blur(0);opacity:1;background-color:#fff;border-radius:3px;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.1),0 4px 8px rgba(16,22,26,.2),0 18px 46px 6px rgba(16,22,26,.2);box-shadow:0 0 0 1px #10161a1a,0 4px 8px #10161a33,0 18px 46px 6px #10161a33;left:calc(50% - 250px);top:20vh;width:500px;z-index:21}.jupyter-wrapper .bp3-omnibar.bp3-overlay-enter,.jupyter-wrapper .bp3-omnibar.bp3-overlay-appear{-webkit-filter:blur(20px);filter:blur(20px);opacity:.2}.jupyter-wrapper .bp3-omnibar.bp3-overlay-enter-active,.jupyter-wrapper .bp3-omnibar.bp3-overlay-appear-active{-webkit-filter:blur(0);filter:blur(0);opacity:1;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:filter,opacity;transition-property:filter,opacity,-webkit-filter;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-omnibar.bp3-overlay-exit{-webkit-filter:blur(0);filter:blur(0);opacity:1}.jupyter-wrapper .bp3-omnibar.bp3-overlay-exit-active{-webkit-filter:blur(20px);filter:blur(20px);opacity:.2;-webkit-transition-delay:0;transition-delay:0;-webkit-transition-duration:.2s;transition-duration:.2s;-webkit-transition-property:opacity,-webkit-filter;transition-property:opacity,-webkit-filter;transition-property:filter,opacity;transition-property:filter,opacity,-webkit-filter;-webkit-transition-timing-function:cubic-bezier(.4,1,.75,.9);transition-timing-function:cubic-bezier(.4,1,.75,.9)}.jupyter-wrapper .bp3-omnibar .bp3-input{background-color:transparent;border-radius:0}.jupyter-wrapper .bp3-omnibar .bp3-input,.jupyter-wrapper .bp3-omnibar .bp3-input:focus{-webkit-box-shadow:none;box-shadow:none}.jupyter-wrapper .bp3-omnibar .bp3-menu{background-color:transparent;border-radius:0;-webkit-box-shadow:inset 0 1px 0 rgba(16,22,26,.15);box-shadow:inset 0 1px #10161a26;max-height:calc(60vh - 40px);overflow:auto}.jupyter-wrapper .bp3-omnibar .bp3-menu:empty{display:none}.jupyter-wrapper .bp3-dark .bp3-omnibar,.jupyter-wrapper .bp3-omnibar.bp3-dark{background-color:#30404d;-webkit-box-shadow:0 0 0 1px rgba(16,22,26,.2),0 4px 8px rgba(16,22,26,.4),0 18px 46px 6px rgba(16,22,26,.4);box-shadow:0 0 0 1px #10161a33,0 4px 8px #10161a66,0 18px 46px 6px #10161a66}.jupyter-wrapper .bp3-omnibar-overlay .bp3-overlay-backdrop{background-color:#10161a33}.jupyter-wrapper .bp3-multi-select{min-width:150px}.jupyter-wrapper .bp3-multi-select-popover .bp3-menu{max-height:300px;max-width:400px;overflow:auto}.jupyter-wrapper .bp3-select-popover .bp3-popover-content{padding:5px}.jupyter-wrapper .bp3-select-popover .bp3-input-group{margin-bottom:0}.jupyter-wrapper .bp3-select-popover .bp3-menu{max-height:300px;max-width:400px;overflow:auto;padding:0}.jupyter-wrapper .bp3-select-popover .bp3-menu:not(:first-child){padding-top:5px}.jupyter-wrapper :root{--jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);--jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);--jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);--jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-build: url(data:image/svg+xml;base64,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);--jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);--jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);--jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);--jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);--jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);--jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);--jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);--jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);--jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);--jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-jupyter: url(data:image/svg+xml;base64,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);--jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);--jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);--jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);--jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);--jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);--jp-icon-listings-info: url(data:image/svg+xml;base64,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);--jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);--jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);--jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);--jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);--jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);--jp-icon-python: url(data:image/svg+xml;base64,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);--jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);--jp-icon-react: url(data:image/svg+xml;base64,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);--jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);--jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);--jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4=);--jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-terminal: url(data:image/svg+xml;base64,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);--jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);--jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4=);--jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);--jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+);--jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);--jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K)}.jupyter-wrapper .jp-AddAboveIcon{background-image:var(--jp-icon-add-above)}.jupyter-wrapper .jp-AddBelowIcon{background-image:var(--jp-icon-add-below)}.jupyter-wrapper .jp-AddIcon{background-image:var(--jp-icon-add)}.jupyter-wrapper .jp-BellIcon{background-image:var(--jp-icon-bell)}.jupyter-wrapper .jp-BugDotIcon{background-image:var(--jp-icon-bug-dot)}.jupyter-wrapper .jp-BugIcon{background-image:var(--jp-icon-bug)}.jupyter-wrapper .jp-BuildIcon{background-image:var(--jp-icon-build)}.jupyter-wrapper .jp-CaretDownEmptyIcon{background-image:var(--jp-icon-caret-down-empty)}.jupyter-wrapper .jp-CaretDownEmptyThinIcon{background-image:var(--jp-icon-caret-down-empty-thin)}.jupyter-wrapper .jp-CaretDownIcon{background-image:var(--jp-icon-caret-down)}.jupyter-wrapper .jp-CaretLeftIcon{background-image:var(--jp-icon-caret-left)}.jupyter-wrapper .jp-CaretRightIcon{background-image:var(--jp-icon-caret-right)}.jupyter-wrapper .jp-CaretUpEmptyThinIcon{background-image:var(--jp-icon-caret-up-empty-thin)}.jupyter-wrapper .jp-CaretUpIcon{background-image:var(--jp-icon-caret-up)}.jupyter-wrapper .jp-CaseSensitiveIcon{background-image:var(--jp-icon-case-sensitive)}.jupyter-wrapper .jp-CheckIcon{background-image:var(--jp-icon-check)}.jupyter-wrapper .jp-CircleEmptyIcon{background-image:var(--jp-icon-circle-empty)}.jupyter-wrapper .jp-CircleIcon{background-image:var(--jp-icon-circle)}.jupyter-wrapper .jp-ClearIcon{background-image:var(--jp-icon-clear)}.jupyter-wrapper .jp-CloseIcon{background-image:var(--jp-icon-close)}.jupyter-wrapper .jp-CodeIcon{background-image:var(--jp-icon-code)}.jupyter-wrapper .jp-ConsoleIcon{background-image:var(--jp-icon-console)}.jupyter-wrapper .jp-CopyIcon{background-image:var(--jp-icon-copy)}.jupyter-wrapper .jp-CopyrightIcon{background-image:var(--jp-icon-copyright)}.jupyter-wrapper .jp-CutIcon{background-image:var(--jp-icon-cut)}.jupyter-wrapper .jp-DeleteIcon{background-image:var(--jp-icon-delete)}.jupyter-wrapper .jp-DownloadIcon{background-image:var(--jp-icon-download)}.jupyter-wrapper .jp-DuplicateIcon{background-image:var(--jp-icon-duplicate)}.jupyter-wrapper .jp-EditIcon{background-image:var(--jp-icon-edit)}.jupyter-wrapper .jp-EllipsesIcon{background-image:var(--jp-icon-ellipses)}.jupyter-wrapper .jp-ExtensionIcon{background-image:var(--jp-icon-extension)}.jupyter-wrapper .jp-FastForwardIcon{background-image:var(--jp-icon-fast-forward)}.jupyter-wrapper .jp-FileIcon{background-image:var(--jp-icon-file)}.jupyter-wrapper .jp-FileUploadIcon{background-image:var(--jp-icon-file-upload)}.jupyter-wrapper .jp-FilterListIcon{background-image:var(--jp-icon-filter-list)}.jupyter-wrapper .jp-FolderFavoriteIcon{background-image:var(--jp-icon-folder-favorite)}.jupyter-wrapper .jp-FolderIcon{background-image:var(--jp-icon-folder)}.jupyter-wrapper .jp-HomeIcon{background-image:var(--jp-icon-home)}.jupyter-wrapper .jp-Html5Icon{background-image:var(--jp-icon-html5)}.jupyter-wrapper .jp-ImageIcon{background-image:var(--jp-icon-image)}.jupyter-wrapper .jp-InspectorIcon{background-image:var(--jp-icon-inspector)}.jupyter-wrapper .jp-JsonIcon{background-image:var(--jp-icon-json)}.jupyter-wrapper .jp-JuliaIcon{background-image:var(--jp-icon-julia)}.jupyter-wrapper .jp-JupyterFaviconIcon{background-image:var(--jp-icon-jupyter-favicon)}.jupyter-wrapper .jp-JupyterIcon{background-image:var(--jp-icon-jupyter)}.jupyter-wrapper .jp-JupyterlabWordmarkIcon{background-image:var(--jp-icon-jupyterlab-wordmark)}.jupyter-wrapper .jp-KernelIcon{background-image:var(--jp-icon-kernel)}.jupyter-wrapper .jp-KeyboardIcon{background-image:var(--jp-icon-keyboard)}.jupyter-wrapper .jp-LaunchIcon{background-image:var(--jp-icon-launch)}.jupyter-wrapper .jp-LauncherIcon{background-image:var(--jp-icon-launcher)}.jupyter-wrapper .jp-LineFormIcon{background-image:var(--jp-icon-line-form)}.jupyter-wrapper .jp-LinkIcon{background-image:var(--jp-icon-link)}.jupyter-wrapper .jp-ListIcon{background-image:var(--jp-icon-list)}.jupyter-wrapper .jp-ListingsInfoIcon{background-image:var(--jp-icon-listings-info)}.jupyter-wrapper .jp-MarkdownIcon{background-image:var(--jp-icon-markdown)}.jupyter-wrapper .jp-MoveDownIcon{background-image:var(--jp-icon-move-down)}.jupyter-wrapper .jp-MoveUpIcon{background-image:var(--jp-icon-move-up)}.jupyter-wrapper .jp-NewFolderIcon{background-image:var(--jp-icon-new-folder)}.jupyter-wrapper .jp-NotTrustedIcon{background-image:var(--jp-icon-not-trusted)}.jupyter-wrapper .jp-NotebookIcon{background-image:var(--jp-icon-notebook)}.jupyter-wrapper .jp-NumberingIcon{background-image:var(--jp-icon-numbering)}.jupyter-wrapper .jp-OfflineBoltIcon{background-image:var(--jp-icon-offline-bolt)}.jupyter-wrapper .jp-PaletteIcon{background-image:var(--jp-icon-palette)}.jupyter-wrapper .jp-PasteIcon{background-image:var(--jp-icon-paste)}.jupyter-wrapper .jp-PdfIcon{background-image:var(--jp-icon-pdf)}.jupyter-wrapper .jp-PythonIcon{background-image:var(--jp-icon-python)}.jupyter-wrapper .jp-RKernelIcon{background-image:var(--jp-icon-r-kernel)}.jupyter-wrapper .jp-ReactIcon{background-image:var(--jp-icon-react)}.jupyter-wrapper .jp-RedoIcon{background-image:var(--jp-icon-redo)}.jupyter-wrapper .jp-RefreshIcon{background-image:var(--jp-icon-refresh)}.jupyter-wrapper .jp-RegexIcon{background-image:var(--jp-icon-regex)}.jupyter-wrapper .jp-RunIcon{background-image:var(--jp-icon-run)}.jupyter-wrapper .jp-RunningIcon{background-image:var(--jp-icon-running)}.jupyter-wrapper .jp-SaveIcon{background-image:var(--jp-icon-save)}.jupyter-wrapper .jp-SearchIcon{background-image:var(--jp-icon-search)}.jupyter-wrapper .jp-SettingsIcon{background-image:var(--jp-icon-settings)}.jupyter-wrapper .jp-ShareIcon{background-image:var(--jp-icon-share)}.jupyter-wrapper .jp-SpreadsheetIcon{background-image:var(--jp-icon-spreadsheet)}.jupyter-wrapper .jp-StopIcon{background-image:var(--jp-icon-stop)}.jupyter-wrapper .jp-TabIcon{background-image:var(--jp-icon-tab)}.jupyter-wrapper .jp-TableRowsIcon{background-image:var(--jp-icon-table-rows)}.jupyter-wrapper .jp-TagIcon{background-image:var(--jp-icon-tag)}.jupyter-wrapper .jp-TerminalIcon{background-image:var(--jp-icon-terminal)}.jupyter-wrapper .jp-TextEditorIcon{background-image:var(--jp-icon-text-editor)}.jupyter-wrapper .jp-TocIcon{background-image:var(--jp-icon-toc)}.jupyter-wrapper .jp-TreeViewIcon{background-image:var(--jp-icon-tree-view)}.jupyter-wrapper .jp-TrustedIcon{background-image:var(--jp-icon-trusted)}.jupyter-wrapper .jp-UndoIcon{background-image:var(--jp-icon-undo)}.jupyter-wrapper .jp-UserIcon{background-image:var(--jp-icon-user)}.jupyter-wrapper .jp-UsersIcon{background-image:var(--jp-icon-users)}.jupyter-wrapper .jp-VegaIcon{background-image:var(--jp-icon-vega)}.jupyter-wrapper .jp-YamlIcon{background-image:var(--jp-icon-yaml)}.jupyter-wrapper .jp-Icon,.jupyter-wrapper .jp-MaterialIcon{background-position:center;background-repeat:no-repeat;background-size:16px;min-width:16px;min-height:16px}.jupyter-wrapper .jp-Icon-cover{background-position:center;background-repeat:no-repeat;background-size:cover}.jupyter-wrapper .jp-Icon-16{background-size:16px;min-width:16px;min-height:16px}.jupyter-wrapper .jp-Icon-18{background-size:18px;min-width:18px;min-height:18px}.jupyter-wrapper .jp-Icon-20{background-size:20px;min-width:20px;min-height:20px}.jupyter-wrapper .lm-TabBar .lm-TabBar-addButton{align-items:center;display:flex;padding:4px 4px 5px;margin-right:1px;background-color:var(--jp-layout-color2)}.jupyter-wrapper .lm-TabBar .lm-TabBar-addButton:hover{background-color:var(--jp-layout-color1)}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab{width:var(--jp-private-horizontal-tab-width)}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-content{flex:unset}.jupyter-wrapper .lm-DockPanel-tabBar[data-orientation=horizontal]{flex:1 1 auto}.jupyter-wrapper .jp-icon0[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon1[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon2[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon3[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon4[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-accent0[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-accent1[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-accent2[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-accent3[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-accent4[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-accent0[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-accent1[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-accent2[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-accent3[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-accent4[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-none[fill]{fill:none}.jupyter-wrapper .jp-icon-none[stroke]{stroke:none}.jupyter-wrapper .jp-icon-brand0[fill]{fill:var(--jp-brand-color0)}.jupyter-wrapper .jp-icon-brand1[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper .jp-icon-brand2[fill]{fill:var(--jp-brand-color2)}.jupyter-wrapper .jp-icon-brand3[fill]{fill:var(--jp-brand-color3)}.jupyter-wrapper .jp-icon-brand4[fill]{fill:var(--jp-brand-color4)}.jupyter-wrapper .jp-icon-brand0[stroke]{stroke:var(--jp-brand-color0)}.jupyter-wrapper .jp-icon-brand1[stroke]{stroke:var(--jp-brand-color1)}.jupyter-wrapper .jp-icon-brand2[stroke]{stroke:var(--jp-brand-color2)}.jupyter-wrapper .jp-icon-brand3[stroke]{stroke:var(--jp-brand-color3)}.jupyter-wrapper .jp-icon-brand4[stroke]{stroke:var(--jp-brand-color4)}.jupyter-wrapper .jp-icon-warn0[fill]{fill:var(--jp-warn-color0)}.jupyter-wrapper .jp-icon-warn1[fill]{fill:var(--jp-warn-color1)}.jupyter-wrapper .jp-icon-warn2[fill]{fill:var(--jp-warn-color2)}.jupyter-wrapper .jp-icon-warn3[fill]{fill:var(--jp-warn-color3)}.jupyter-wrapper .jp-icon-warn0[stroke]{stroke:var(--jp-warn-color0)}.jupyter-wrapper .jp-icon-warn1[stroke]{stroke:var(--jp-warn-color1)}.jupyter-wrapper .jp-icon-warn2[stroke]{stroke:var(--jp-warn-color2)}.jupyter-wrapper .jp-icon-warn3[stroke]{stroke:var(--jp-warn-color3)}.jupyter-wrapper .jp-icon-contrast0[fill]{fill:var(--jp-icon-contrast-color0)}.jupyter-wrapper .jp-icon-contrast1[fill]{fill:var(--jp-icon-contrast-color1)}.jupyter-wrapper .jp-icon-contrast2[fill]{fill:var(--jp-icon-contrast-color2)}.jupyter-wrapper .jp-icon-contrast3[fill]{fill:var(--jp-icon-contrast-color3)}.jupyter-wrapper .jp-icon-contrast0[stroke]{stroke:var(--jp-icon-contrast-color0)}.jupyter-wrapper .jp-icon-contrast1[stroke]{stroke:var(--jp-icon-contrast-color1)}.jupyter-wrapper .jp-icon-contrast2[stroke]{stroke:var(--jp-icon-contrast-color2)}.jupyter-wrapper .jp-icon-contrast3[stroke]{stroke:var(--jp-icon-contrast-color3)}.jupyter-wrapper .jp-jupyter-icon-color[fill]{fill:var(--jp-jupyter-icon-color, var(--jp-warn-color0))}.jupyter-wrapper .jp-notebook-icon-color[fill]{fill:var(--jp-notebook-icon-color, var(--jp-warn-color0))}.jupyter-wrapper .jp-json-icon-color[fill]{fill:var(--jp-json-icon-color, var(--jp-warn-color1))}.jupyter-wrapper .jp-console-icon-color[fill]{fill:var(--jp-console-icon-color, white)}.jupyter-wrapper .jp-console-icon-background-color[fill]{fill:var(--jp-console-icon-background-color, var(--jp-brand-color1))}.jupyter-wrapper .jp-terminal-icon-color[fill]{fill:var(--jp-terminal-icon-color, var(--jp-layout-color2))}.jupyter-wrapper .jp-terminal-icon-background-color[fill]{fill:var(--jp-terminal-icon-background-color, var(--jp-inverse-layout2))}.jupyter-wrapper .jp-text-editor-icon-color[fill]{fill:var(--jp-text-editor-icon-color, var(--jp-inverse-layout3))}.jupyter-wrapper .jp-inspector-icon-color[fill]{fill:var(--jp-inspector-icon-color, var(--jp-inverse-layout3))}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill],.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-hover :hover .jp-icon-selectable[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-hover :hover .jp-icon-selectable-inverse[fill]{fill:#fff}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper #tab-manager .lm-TabBar-tab.jp-mod-dirty.jp-mod-active>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:#fff}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.jupyter-wrapper .lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper #jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jupyter-wrapper #jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}.jupyter-wrapper :root{--jp-warn-color0: var(--md-orange-700)}.jupyter-wrapper .jp-DragIcon{margin-right:4px}.jupyter-wrapper .jp-icon-alt .jp-icon0[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon1[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon2[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon3[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon4[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon0[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon1[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon2[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon3[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon4[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent0[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent1[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent2[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent3[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent4[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-alt .jp-icon-accent4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content{display:none!important}.jupyter-wrapper .jp-icon-hover :hover .jp-icon0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-none-hover[fill]{fill:none}.jupyter-wrapper .jp-icon-hover :hover .jp-icon-none-hover[stroke]{stroke:none}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill]{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill]{fill:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill]{fill:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill]{fill:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke]{stroke:var(--jp-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke]{stroke:var(--jp-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke]{stroke:var(--jp-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke]{stroke:var(--jp-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke]{stroke:var(--jp-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jupyter-wrapper .jp-switch{display:flex;align-items:center;padding-left:4px;padding-right:4px;font-size:var(--jp-ui-font-size1);background-color:transparent;color:var(--jp-ui-font-color1);border:none;height:20px}.jupyter-wrapper .jp-switch:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-switch-label{margin-right:5px}.jupyter-wrapper .jp-switch-track{cursor:pointer;background-color:var(--jp-switch-color, var(--jp-border-color1));-webkit-transition:.4s;transition:.4s;border-radius:34px;height:16px;width:35px;position:relative}.jupyter-wrapper .jp-switch-track:before{content:"";position:absolute;height:10px;width:10px;margin:3px;left:0;background-color:var(--jp-ui-inverse-font-color1);-webkit-transition:.4s;transition:.4s;border-radius:50%}.jupyter-wrapper .jp-switch[aria-checked=true] .jp-switch-track{background-color:var(--jp-switch-true-position-color, var(--jp-warn-color0))}.jupyter-wrapper .jp-switch[aria-checked=true] .jp-switch-track:before{left:19px}.jupyter-wrapper html{box-sizing:unset}.jupyter-wrapper *,.jupyter-wrapper *:before,.jupyter-wrapper *:after{box-sizing:unset}.jupyter-wrapper body{color:unset;font-family:var(--jp-ui-font-family)}.jupyter-wrapper :focus{outline:unset;outline-offset:unset;-moz-outline-radius:unset}.jupyter-wrapper .jp-Button{border-radius:var(--jp-border-radius);padding:0 12px;font-size:var(--jp-ui-font-size1)}.jupyter-wrapper button.jp-Button.bp3-button.bp3-minimal:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-Button.minimal{color:unset!important}.jupyter-wrapper .jp-Button.jp-ToolbarButtonComponent{text-transform:none}.jupyter-wrapper .jp-InputGroup input{box-sizing:border-box;border-radius:0;background-color:transparent;color:var(--jp-ui-font-color0);box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.jupyter-wrapper .jp-InputGroup input:focus{box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jupyter-wrapper .jp-InputGroup input::placeholder,.jupyter-wrapper input::placeholder{color:var(--jp-ui-font-color3)}.jupyter-wrapper .jp-BPIcon{display:inline-block;vertical-align:middle;margin:auto}.jupyter-wrapper .bp3-icon.jp-BPIcon>svg:not([fill]){fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-InputGroupAction{padding:6px}.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select{background-color:initial;border:none;border-radius:0;box-shadow:none;color:var(--jp-ui-font-color0);display:block;font-size:var(--jp-ui-font-size1);height:24px;line-height:14px;padding:0 25px 0 10px;text-align:left;-moz-appearance:none;-webkit-appearance:none}.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select:hover,.jupyter-wrapper .jp-HTMLSelect.jp-DefaultStyle select>option{background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color0)}.jupyter-wrapper select{box-sizing:border-box}.jupyter-wrapper .jp-Collapse{display:flex;flex-direction:column;align-items:stretch;border-top:1px solid var(--jp-border-color2);border-bottom:1px solid var(--jp-border-color2)}.jupyter-wrapper .jp-Collapse-header{padding:1px 12px;color:var(--jp-ui-font-color1);background-color:var(--jp-layout-color1);font-size:var(--jp-ui-font-size2)}.jupyter-wrapper .jp-Collapse-header:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-Collapse-contents{padding:0 12px;background-color:var(--jp-layout-color1);color:var(--jp-ui-font-color1);overflow:auto}.jupyter-wrapper :root{--jp-private-commandpalette-search-height: 28px}.jupyter-wrapper .lm-CommandPalette{padding-bottom:0;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .jp-ModalCommandPalette{position:absolute;z-index:10000;top:38px;left:30%;margin:0;padding:4px;width:40%;box-shadow:var(--jp-elevation-z4);border-radius:4px;background:var(--jp-layout-color0)}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette{max-height:40vh}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon:after{display:none}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header{display:none}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item{margin-left:4px;margin-right:4px}.jupyter-wrapper .jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item.lm-mod-disabled{display:none}.jupyter-wrapper .lm-CommandPalette-search{padding:4px;background-color:var(--jp-layout-color1);z-index:2}.jupyter-wrapper .lm-CommandPalette-wrapper{overflow:overlay;padding:0 9px;background-color:var(--jp-input-active-background);height:30px;box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.jupyter-wrapper .lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper{box-shadow:inset 0 0 0 1px var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jupyter-wrapper .jp-SearchIconGroup{color:#fff;background-color:var(--jp-brand-color1);position:absolute;top:4px;right:4px;padding:5px 5px 1px}.jupyter-wrapper .jp-SearchIconGroup svg{height:20px;width:20px}.jupyter-wrapper .jp-SearchIconGroup .jp-icon3[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .lm-CommandPalette-input{background:transparent;width:calc(100% - 18px);float:left;border:none;outline:none;font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);line-height:var(--jp-private-commandpalette-search-height)}.jupyter-wrapper .lm-CommandPalette-input::-webkit-input-placeholder,.jupyter-wrapper .lm-CommandPalette-input::-moz-placeholder,.jupyter-wrapper .lm-CommandPalette-input:-ms-input-placeholder{color:var(--jp-ui-font-color2);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .lm-CommandPalette-header:first-child{margin-top:0}.jupyter-wrapper .lm-CommandPalette-header{border-bottom:solid var(--jp-border-width) var(--jp-border-color2);color:var(--jp-ui-font-color1);cursor:pointer;display:flex;font-size:var(--jp-ui-font-size0);font-weight:600;letter-spacing:1px;margin-top:8px;padding:8px 0 8px 12px;text-transform:uppercase}.jupyter-wrapper .lm-CommandPalette-header.lm-mod-active{background:var(--jp-layout-color2)}.jupyter-wrapper .lm-CommandPalette-header>mark{background-color:transparent;font-weight:700;color:var(--jp-ui-font-color1)}.jupyter-wrapper .lm-CommandPalette-item{padding:4px 12px 4px 4px;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);font-weight:400;display:flex}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled{color:var(--jp-ui-font-color2)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active{color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill]{fill:var(--jp-layout-color0)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-inverse-font-color0)}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled){color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jupyter-wrapper .lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled){background:var(--jp-layout-color2)}.jupyter-wrapper .lm-CommandPalette-itemContent{overflow:hidden}.jupyter-wrapper .lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-font-color0);background-color:transparent;font-weight:700}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled mark{color:var(--jp-ui-font-color2)}.jupyter-wrapper .lm-CommandPalette-item .lm-CommandPalette-itemIcon{margin:0 4px 0 0;position:relative;width:16px;top:2px;flex:0 0 auto}.jupyter-wrapper .lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon{opacity:.6}.jupyter-wrapper .lm-CommandPalette-item .lm-CommandPalette-itemShortcut{flex:0 0 auto}.jupyter-wrapper .lm-CommandPalette-itemCaption{display:none}.jupyter-wrapper .lm-CommandPalette-content{background-color:var(--jp-layout-color1)}.jupyter-wrapper .lm-CommandPalette-content:empty:after{content:"No results";margin:20px auto auto;width:100px;display:block;font-size:var(--jp-ui-font-size2);font-family:var(--jp-ui-font-family);font-weight:lighter}.jupyter-wrapper .lm-CommandPalette-emptyMessage{text-align:center;margin-top:24px;line-height:1.32;padding:0 8px;color:var(--jp-content-font-color3)}.jupyter-wrapper .jp-Dialog{position:absolute;z-index:10000;display:flex;flex-direction:column;align-items:center;justify-content:center;top:0;left:0;margin:0;padding:0;width:100%;height:100%;background:var(--jp-dialog-background)}.jupyter-wrapper .jp-Dialog-content{display:flex;flex-direction:column;margin-left:auto;margin-right:auto;background:var(--jp-layout-color1);padding:24px 24px 12px;min-width:300px;min-height:150px;max-width:1000px;max-height:500px;box-sizing:border-box;box-shadow:var(--jp-elevation-z20);word-wrap:break-word;border-radius:var(--jp-border-radius);font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color1);resize:both}.jupyter-wrapper .jp-Dialog-content.jp-Dialog-content-small{max-width:500px}.jupyter-wrapper .jp-Dialog-button{overflow:visible}.jupyter-wrapper button.jp-Dialog-button:focus{outline:1px solid var(--jp-brand-color1);outline-offset:4px;-moz-outline-radius:0px}.jupyter-wrapper button.jp-Dialog-button:focus::-moz-focus-inner{border:0}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus{outline-offset:4px;-moz-outline-radius:0px}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus{outline:1px solid var(--md-blue-700)}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus{outline:1px solid var(--md-red-600)}.jupyter-wrapper button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus{outline:1px solid var(--md-grey-700)}.jupyter-wrapper button.jp-Dialog-close-button{padding:0;height:100%;min-width:unset;min-height:unset}.jupyter-wrapper .jp-Dialog-header{display:flex;justify-content:space-between;flex:0 0 auto;padding-bottom:12px;font-size:var(--jp-ui-font-size3);font-weight:400;color:var(--jp-ui-font-color0)}.jupyter-wrapper .jp-Dialog-body{display:flex;flex-direction:column;flex:1 1 auto;font-size:var(--jp-ui-font-size1);background:var(--jp-layout-color1);overflow:auto}.jupyter-wrapper .jp-Dialog-footer{display:flex;flex-direction:row;justify-content:flex-end;align-items:center;flex:0 0 auto;margin-left:-12px;margin-right:-12px;padding:12px}.jupyter-wrapper .jp-Dialog-checkbox{padding-right:5px}.jupyter-wrapper .jp-Dialog-checkbox>input:focus-visible{outline:1px solid var(--jp-input-active-border-color);outline-offset:1px}.jupyter-wrapper .jp-Dialog-spacer{flex:1 1 auto}.jupyter-wrapper .jp-Dialog-title{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jupyter-wrapper .jp-Dialog-body>.jp-select-wrapper{width:100%}.jupyter-wrapper .jp-Dialog-body>button{padding:0 16px}.jupyter-wrapper .jp-Dialog-body>label{line-height:1.4;color:var(--jp-ui-font-color0)}.jupyter-wrapper .jp-Dialog-button.jp-mod-styled:not(:last-child){margin-right:12px}.jupyter-wrapper .jp-HoverBox{position:fixed}.jupyter-wrapper .jp-HoverBox.jp-mod-outofview{display:none}.jupyter-wrapper .jp-IFrame{width:100%;height:100%}.jupyter-wrapper .jp-IFrame>iframe{border:none}.jupyter-wrapper body.lm-mod-override-cursor .jp-IFrame{position:relative}.jupyter-wrapper body.lm-mod-override-cursor .jp-IFrame:before{content:"";position:absolute;top:0;left:0;right:0;bottom:0;background:transparent}.jupyter-wrapper .jp-Input-Boolean-Dialog{flex-direction:row-reverse;align-items:end;width:100%}.jupyter-wrapper .jp-Input-Boolean-Dialog>label{flex:1 1 auto}.jupyter-wrapper .jp-MainAreaWidget>:focus{outline:none}.jupyter-wrapper .jp-MainAreaWidget .jp-MainAreaWidget-error{padding:6px}.jupyter-wrapper .jp-MainAreaWidget .jp-MainAreaWidget-error>pre{width:auto;padding:10px;background:var(--jp-error-color3);border:var(--jp-border-width) solid var(--jp-error-color1);border-radius:var(--jp-border-radius);color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);white-space:pre-wrap;word-wrap:break-word}.jupyter-wrapper .jp-MainAreaWidget{contain:strict}.jupyter-wrapper :root{--md-red-50: #ffebee;--md-red-100: #ffcdd2;--md-red-200: #ef9a9a;--md-red-300: #e57373;--md-red-400: #ef5350;--md-red-500: #f44336;--md-red-600: #e53935;--md-red-700: #d32f2f;--md-red-800: #c62828;--md-red-900: #b71c1c;--md-red-A100: #ff8a80;--md-red-A200: #ff5252;--md-red-A400: #ff1744;--md-red-A700: #d50000;--md-pink-50: #fce4ec;--md-pink-100: #f8bbd0;--md-pink-200: #f48fb1;--md-pink-300: #f06292;--md-pink-400: #ec407a;--md-pink-500: #e91e63;--md-pink-600: #d81b60;--md-pink-700: #c2185b;--md-pink-800: #ad1457;--md-pink-900: #880e4f;--md-pink-A100: #ff80ab;--md-pink-A200: #ff4081;--md-pink-A400: #f50057;--md-pink-A700: #c51162;--md-purple-50: #f3e5f5;--md-purple-100: #e1bee7;--md-purple-200: #ce93d8;--md-purple-300: #ba68c8;--md-purple-400: #ab47bc;--md-purple-500: #9c27b0;--md-purple-600: #8e24aa;--md-purple-700: #7b1fa2;--md-purple-800: #6a1b9a;--md-purple-900: #4a148c;--md-purple-A100: #ea80fc;--md-purple-A200: #e040fb;--md-purple-A400: #d500f9;--md-purple-A700: #aa00ff;--md-deep-purple-50: #ede7f6;--md-deep-purple-100: #d1c4e9;--md-deep-purple-200: #b39ddb;--md-deep-purple-300: #9575cd;--md-deep-purple-400: #7e57c2;--md-deep-purple-500: #673ab7;--md-deep-purple-600: #5e35b1;--md-deep-purple-700: #512da8;--md-deep-purple-800: #4527a0;--md-deep-purple-900: #311b92;--md-deep-purple-A100: #b388ff;--md-deep-purple-A200: #7c4dff;--md-deep-purple-A400: #651fff;--md-deep-purple-A700: #6200ea;--md-indigo-50: #e8eaf6;--md-indigo-100: #c5cae9;--md-indigo-200: #9fa8da;--md-indigo-300: #7986cb;--md-indigo-400: #5c6bc0;--md-indigo-500: #3f51b5;--md-indigo-600: #3949ab;--md-indigo-700: #303f9f;--md-indigo-800: #283593;--md-indigo-900: #1a237e;--md-indigo-A100: #8c9eff;--md-indigo-A200: #536dfe;--md-indigo-A400: #3d5afe;--md-indigo-A700: #304ffe;--md-blue-50: #e3f2fd;--md-blue-100: #bbdefb;--md-blue-200: #90caf9;--md-blue-300: #64b5f6;--md-blue-400: #42a5f5;--md-blue-500: #2196f3;--md-blue-600: #1e88e5;--md-blue-700: #1976d2;--md-blue-800: #1565c0;--md-blue-900: #0d47a1;--md-blue-A100: #82b1ff;--md-blue-A200: #448aff;--md-blue-A400: #2979ff;--md-blue-A700: #2962ff;--md-light-blue-50: #e1f5fe;--md-light-blue-100: #b3e5fc;--md-light-blue-200: #81d4fa;--md-light-blue-300: #4fc3f7;--md-light-blue-400: #29b6f6;--md-light-blue-500: #03a9f4;--md-light-blue-600: #039be5;--md-light-blue-700: #0288d1;--md-light-blue-800: #0277bd;--md-light-blue-900: #01579b;--md-light-blue-A100: #80d8ff;--md-light-blue-A200: #40c4ff;--md-light-blue-A400: #00b0ff;--md-light-blue-A700: #0091ea;--md-cyan-50: #e0f7fa;--md-cyan-100: #b2ebf2;--md-cyan-200: #80deea;--md-cyan-300: #4dd0e1;--md-cyan-400: #26c6da;--md-cyan-500: #00bcd4;--md-cyan-600: #00acc1;--md-cyan-700: #0097a7;--md-cyan-800: #00838f;--md-cyan-900: #006064;--md-cyan-A100: #84ffff;--md-cyan-A200: #18ffff;--md-cyan-A400: #00e5ff;--md-cyan-A700: #00b8d4;--md-teal-50: #e0f2f1;--md-teal-100: #b2dfdb;--md-teal-200: #80cbc4;--md-teal-300: #4db6ac;--md-teal-400: #26a69a;--md-teal-500: #009688;--md-teal-600: #00897b;--md-teal-700: #00796b;--md-teal-800: #00695c;--md-teal-900: #004d40;--md-teal-A100: #a7ffeb;--md-teal-A200: #64ffda;--md-teal-A400: #1de9b6;--md-teal-A700: #00bfa5;--md-green-50: #e8f5e9;--md-green-100: #c8e6c9;--md-green-200: #a5d6a7;--md-green-300: #81c784;--md-green-400: #66bb6a;--md-green-500: #4caf50;--md-green-600: #43a047;--md-green-700: #388e3c;--md-green-800: #2e7d32;--md-green-900: #1b5e20;--md-green-A100: #b9f6ca;--md-green-A200: #69f0ae;--md-green-A400: #00e676;--md-green-A700: #00c853;--md-light-green-50: #f1f8e9;--md-light-green-100: #dcedc8;--md-light-green-200: #c5e1a5;--md-light-green-300: #aed581;--md-light-green-400: #9ccc65;--md-light-green-500: #8bc34a;--md-light-green-600: #7cb342;--md-light-green-700: #689f38;--md-light-green-800: #558b2f;--md-light-green-900: #33691e;--md-light-green-A100: #ccff90;--md-light-green-A200: #b2ff59;--md-light-green-A400: #76ff03;--md-light-green-A700: #64dd17;--md-lime-50: #f9fbe7;--md-lime-100: #f0f4c3;--md-lime-200: #e6ee9c;--md-lime-300: #dce775;--md-lime-400: #d4e157;--md-lime-500: #cddc39;--md-lime-600: #c0ca33;--md-lime-700: #afb42b;--md-lime-800: #9e9d24;--md-lime-900: #827717;--md-lime-A100: #f4ff81;--md-lime-A200: #eeff41;--md-lime-A400: #c6ff00;--md-lime-A700: #aeea00;--md-yellow-50: #fffde7;--md-yellow-100: #fff9c4;--md-yellow-200: #fff59d;--md-yellow-300: #fff176;--md-yellow-400: #ffee58;--md-yellow-500: #ffeb3b;--md-yellow-600: #fdd835;--md-yellow-700: #fbc02d;--md-yellow-800: #f9a825;--md-yellow-900: #f57f17;--md-yellow-A100: #ffff8d;--md-yellow-A200: #ffff00;--md-yellow-A400: #ffea00;--md-yellow-A700: #ffd600;--md-amber-50: #fff8e1;--md-amber-100: #ffecb3;--md-amber-200: #ffe082;--md-amber-300: #ffd54f;--md-amber-400: #ffca28;--md-amber-500: #ffc107;--md-amber-600: #ffb300;--md-amber-700: #ffa000;--md-amber-800: #ff8f00;--md-amber-900: #ff6f00;--md-amber-A100: #ffe57f;--md-amber-A200: #ffd740;--md-amber-A400: #ffc400;--md-amber-A700: #ffab00;--md-orange-50: #fff3e0;--md-orange-100: #ffe0b2;--md-orange-200: #ffcc80;--md-orange-300: #ffb74d;--md-orange-400: #ffa726;--md-orange-500: #ff9800;--md-orange-600: #fb8c00;--md-orange-700: #f57c00;--md-orange-800: #ef6c00;--md-orange-900: #e65100;--md-orange-A100: #ffd180;--md-orange-A200: #ffab40;--md-orange-A400: #ff9100;--md-orange-A700: #ff6d00;--md-deep-orange-50: #fbe9e7;--md-deep-orange-100: #ffccbc;--md-deep-orange-200: #ffab91;--md-deep-orange-300: #ff8a65;--md-deep-orange-400: #ff7043;--md-deep-orange-500: #ff5722;--md-deep-orange-600: #f4511e;--md-deep-orange-700: #e64a19;--md-deep-orange-800: #d84315;--md-deep-orange-900: #bf360c;--md-deep-orange-A100: #ff9e80;--md-deep-orange-A200: #ff6e40;--md-deep-orange-A400: #ff3d00;--md-deep-orange-A700: #dd2c00;--md-brown-50: #efebe9;--md-brown-100: #d7ccc8;--md-brown-200: #bcaaa4;--md-brown-300: #a1887f;--md-brown-400: #8d6e63;--md-brown-500: #795548;--md-brown-600: #6d4c41;--md-brown-700: #5d4037;--md-brown-800: #4e342e;--md-brown-900: #3e2723;--md-grey-50: #fafafa;--md-grey-100: #f5f5f5;--md-grey-200: #eeeeee;--md-grey-300: #e0e0e0;--md-grey-400: #bdbdbd;--md-grey-500: #9e9e9e;--md-grey-600: #757575;--md-grey-700: #616161;--md-grey-800: #424242;--md-grey-900: #212121;--md-blue-grey-50: #eceff1;--md-blue-grey-100: #cfd8dc;--md-blue-grey-200: #b0bec5;--md-blue-grey-300: #90a4ae;--md-blue-grey-400: #78909c;--md-blue-grey-500: #607d8b;--md-blue-grey-600: #546e7a;--md-blue-grey-700: #455a64;--md-blue-grey-800: #37474f;--md-blue-grey-900: #263238}.jupyter-wrapper .jp-Spinner{position:absolute;display:flex;justify-content:center;align-items:center;z-index:10;left:0;top:0;width:100%;height:100%;background:var(--jp-layout-color0);outline:none}.jupyter-wrapper .jp-SpinnerContent{font-size:10px;margin:50px auto;text-indent:-9999em;width:3em;height:3em;border-radius:50%;background:var(--jp-brand-color3);background:linear-gradient(to right,#f37626 10%,rgba(255,255,255,0) 42%);position:relative;animation:load3 1s infinite linear,fadeIn 1s}.jupyter-wrapper .jp-SpinnerContent:before{width:50%;height:50%;background:#f37626;border-radius:100% 0 0;position:absolute;top:0;left:0;content:""}.jupyter-wrapper .jp-SpinnerContent:after{background:var(--jp-layout-color0);width:75%;height:75%;border-radius:50%;content:"";margin:auto;position:absolute;top:0;left:0;bottom:0;right:0}@keyframes fadeIn{0%{opacity:0}to{opacity:1}}@keyframes load3{0%{transform:rotate(0)}to{transform:rotate(360deg)}}.jupyter-wrapper button.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:none;box-sizing:border-box;text-align:center;line-height:32px;height:32px;padding:0 12px;letter-spacing:.8px;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper input.jp-mod-styled{background:var(--jp-input-background);height:28px;box-sizing:border-box;border:var(--jp-border-width) solid var(--jp-border-color1);padding-left:7px;padding-right:7px;font-size:var(--jp-ui-font-size2);color:var(--jp-ui-font-color0);outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper input[type=checkbox].jp-mod-styled{appearance:checkbox;-webkit-appearance:checkbox;-moz-appearance:checkbox;height:auto}.jupyter-wrapper input.jp-mod-styled:focus{border:var(--jp-border-width) solid var(--md-blue-500);box-shadow:inset 0 0 4px var(--md-blue-300)}.jupyter-wrapper .jp-FileDialog-Checkbox{margin-top:35px;display:flex;flex-direction:row;align-items:end;width:100%}.jupyter-wrapper .jp-FileDialog-Checkbox>label{flex:1 1 auto}.jupyter-wrapper .jp-select-wrapper{display:flex;position:relative;flex-direction:column;padding:1px;background-color:var(--jp-layout-color1);height:28px;box-sizing:border-box;margin-bottom:12px}.jupyter-wrapper .jp-select-wrapper.jp-mod-focused select.jp-mod-styled{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-input-active-background)}.jupyter-wrapper select.jp-mod-styled:hover{background-color:var(--jp-layout-color1);cursor:pointer;color:var(--jp-ui-font-color0);background-color:var(--jp-input-hover-background);box-shadow:inset 0 0 1px #00000080}.jupyter-wrapper select.jp-mod-styled{flex:1 1 auto;height:32px;width:100%;font-size:var(--jp-ui-font-size2);background:var(--jp-input-background);color:var(--jp-ui-font-color0);padding:0 25px 0 8px;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none}.jupyter-wrapper :root{--jp-private-toolbar-height: calc( 28px + var(--jp-border-width) )}.jupyter-wrapper .jp-Toolbar{color:var(--jp-ui-font-color1);flex:0 0 auto;display:flex;flex-direction:row;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:2px;z-index:8;overflow-x:hidden}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-item.jp-Toolbar-spacer{flex-grow:1;flex-shrink:1}.jupyter-wrapper .jp-Toolbar-item.jp-Toolbar-kernelStatus{display:inline-block;width:32px;background-repeat:no-repeat;background-position:center;background-size:16px}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-item{flex:0 0 auto;display:flex;padding-left:1px;padding-right:1px;font-size:var(--jp-ui-font-size1);line-height:var(--jp-private-toolbar-height);height:100%}.jupyter-wrapper div.jp-ToolbarButton{color:transparent;border:none;box-sizing:border-box;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0;margin:0}.jupyter-wrapper button.jp-ToolbarButtonComponent{background:var(--jp-layout-color1);border:none;box-sizing:border-box;outline:none;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0 6px;margin:0;height:24px;border-radius:var(--jp-border-radius);display:flex;align-items:center;text-align:center;font-size:14px;min-width:unset;min-height:unset}.jupyter-wrapper button.jp-ToolbarButtonComponent:disabled{opacity:.4}.jupyter-wrapper button.jp-ToolbarButtonComponent span{padding:0;flex:0 0 auto}.jupyter-wrapper button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label{font-size:var(--jp-ui-font-size1);line-height:100%;padding-left:2px;color:var(--jp-ui-font-color1)}.jupyter-wrapper #jp-main-dock-panel[data-mode=single-document] .jp-MainAreaWidget>.jp-Toolbar.jp-Toolbar-micro{padding:0;min-height:0}.jupyter-wrapper #jp-main-dock-panel[data-mode=single-document] .jp-MainAreaWidget>.jp-Toolbar{border:none;box-shadow:none}.jupyter-wrapper body.p-mod-override-cursor *,.jupyter-wrapper body.lm-mod-override-cursor *{cursor:inherit!important}.jupyter-wrapper .jp-JSONEditor{display:flex;flex-direction:column;width:100%}.jupyter-wrapper .jp-JSONEditor-host{flex:1 1 auto;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0;background:var(--jp-layout-color0);min-height:50px;padding:1px}.jupyter-wrapper .jp-JSONEditor.jp-mod-error .jp-JSONEditor-host{border-color:red;outline-color:red}.jupyter-wrapper .jp-JSONEditor-header{display:flex;flex:1 0 auto;padding:0 0 0 12px}.jupyter-wrapper .jp-JSONEditor-header label{flex:0 0 auto}.jupyter-wrapper .jp-JSONEditor-commitButton{height:16px;width:16px;background-size:18px;background-repeat:no-repeat;background-position:center}.jupyter-wrapper .jp-JSONEditor-host.jp-mod-focused{background-color:var(--jp-input-active-background);border:1px solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jupyter-wrapper .jp-Editor.jp-mod-dropTarget{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jupyter-wrapper .jp-Statusbar-ProgressCircle svg{display:block;margin:0 auto;width:16px;height:24px;align-self:normal}.jupyter-wrapper .jp-Statusbar-ProgressCircle path{fill:var(--jp-inverse-layout-color3)}.jupyter-wrapper .jp-Statusbar-ProgressBar-progress-bar{height:10px;width:100px;border:solid .25px var(--jp-brand-color2);border-radius:3px;overflow:hidden;align-self:center}.jupyter-wrapper .jp-Statusbar-ProgressBar-progress-bar>div{background-color:var(--jp-brand-color2);background-image:linear-gradient(-45deg,rgba(255,255,255,.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,.2) 50%,rgba(255,255,255,.2) 75%,transparent 75%,transparent);background-size:40px 40px;float:left;width:0%;height:100%;font-size:12px;line-height:14px;color:#fff;text-align:center;animation:jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite}.jupyter-wrapper .jp-Statusbar-ProgressBar-progress-bar p{color:var(--jp-ui-font-color1);font-family:var(--jp-ui-font-family);font-size:var(--jp-ui-font-size1);line-height:10px;width:100px}@keyframes jp-Statusbar-ExecutionTime-progress-bar{0%{background-position:0 0}to{background-position:40px 40px}}.jupyter-wrapper .CodeMirror{font-family:monospace;height:300px;color:#000;direction:ltr}.jupyter-wrapper .CodeMirror-lines{padding:4px 0}.jupyter-wrapper .CodeMirror pre.CodeMirror-line,.jupyter-wrapper .CodeMirror pre.CodeMirror-line-like{padding:0 4px}.jupyter-wrapper .CodeMirror-scrollbar-filler,.jupyter-wrapper .CodeMirror-gutter-filler{background-color:#fff}.jupyter-wrapper .CodeMirror-gutters{border-right:1px solid #ddd;background-color:#f7f7f7;white-space:nowrap}.jupyter-wrapper .CodeMirror-linenumber{padding:0 3px 0 5px;min-width:20px;text-align:right;color:#999;white-space:nowrap}.jupyter-wrapper .CodeMirror-guttermarker{color:#000}.jupyter-wrapper .CodeMirror-guttermarker-subtle{color:#999}.jupyter-wrapper .CodeMirror-cursor{border-left:1px solid black;border-right:none;width:0}.jupyter-wrapper .CodeMirror div.CodeMirror-secondarycursor{border-left:1px solid silver}.jupyter-wrapper .cm-fat-cursor .CodeMirror-cursor{width:auto;border:0!important;background:#7e7}.jupyter-wrapper .cm-fat-cursor div.CodeMirror-cursors{z-index:1}.jupyter-wrapper .cm-fat-cursor-mark{background-color:#14ff1480;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite}.jupyter-wrapper .cm-animate-fat-cursor{width:auto;border:0;-webkit-animation:blink 1.06s steps(1) infinite;-moz-animation:blink 1.06s steps(1) infinite;animation:blink 1.06s steps(1) infinite;background-color:#7e7}@-moz-keyframes blink{50%{background-color:transparent}}@-webkit-keyframes blink{50%{background-color:transparent}}@keyframes blink{50%{background-color:transparent}}.jupyter-wrapper .cm-tab{display:inline-block;text-decoration:inherit}.jupyter-wrapper .CodeMirror-rulers{position:absolute;left:0;right:0;top:-50px;bottom:0;overflow:hidden}.jupyter-wrapper .CodeMirror-ruler{border-left:1px solid #ccc;top:0;bottom:0;position:absolute}.jupyter-wrapper .cm-s-default .cm-header{color:#00f}.jupyter-wrapper .cm-s-default .cm-quote{color:#090}.jupyter-wrapper .cm-negative{color:#d44}.jupyter-wrapper .cm-positive{color:#292}.jupyter-wrapper .cm-header,.jupyter-wrapper .cm-strong{font-weight:700}.jupyter-wrapper .cm-em{font-style:italic}.jupyter-wrapper .cm-link{text-decoration:underline}.jupyter-wrapper .cm-strikethrough{text-decoration:line-through}.jupyter-wrapper .cm-s-default .cm-keyword{color:#708}.jupyter-wrapper .cm-s-default .cm-atom{color:#219}.jupyter-wrapper .cm-s-default .cm-number{color:#164}.jupyter-wrapper .cm-s-default .cm-def{color:#00f}.jupyter-wrapper .cm-s-default .cm-variable-2{color:#05a}.jupyter-wrapper .cm-s-default .cm-variable-3,.jupyter-wrapper .cm-s-default .cm-type{color:#085}.jupyter-wrapper .cm-s-default .cm-comment{color:#a50}.jupyter-wrapper .cm-s-default .cm-string{color:#a11}.jupyter-wrapper .cm-s-default .cm-string-2{color:#f50}.jupyter-wrapper .cm-s-default .cm-meta,.jupyter-wrapper .cm-s-default .cm-qualifier{color:#555}.jupyter-wrapper .cm-s-default .cm-builtin{color:#30a}.jupyter-wrapper .cm-s-default .cm-bracket{color:#997}.jupyter-wrapper .cm-s-default .cm-tag{color:#170}.jupyter-wrapper .cm-s-default .cm-attribute{color:#00c}.jupyter-wrapper .cm-s-default .cm-hr{color:#999}.jupyter-wrapper .cm-s-default .cm-link{color:#00c}.jupyter-wrapper .cm-s-default .cm-error,.jupyter-wrapper .cm-invalidchar{color:red}.jupyter-wrapper .CodeMirror-composing{border-bottom:2px solid}.jupyter-wrapper div.CodeMirror span.CodeMirror-matchingbracket{color:#0b0}.jupyter-wrapper div.CodeMirror span.CodeMirror-nonmatchingbracket{color:#a22}.jupyter-wrapper .CodeMirror-matchingtag{background:rgba(255,150,0,.3)}.jupyter-wrapper .CodeMirror-activeline-background{background:#e8f2ff}.jupyter-wrapper .CodeMirror{position:relative;overflow:hidden;background:white}.jupyter-wrapper .CodeMirror-scroll{overflow:scroll!important;margin-bottom:-50px;margin-right:-50px;padding-bottom:50px;height:100%;outline:none;position:relative}.jupyter-wrapper .CodeMirror-sizer{position:relative;border-right:50px solid transparent}.jupyter-wrapper .CodeMirror-vscrollbar,.jupyter-wrapper .CodeMirror-hscrollbar,.jupyter-wrapper .CodeMirror-scrollbar-filler,.jupyter-wrapper .CodeMirror-gutter-filler{position:absolute;z-index:6;display:none;outline:none}.jupyter-wrapper .CodeMirror-vscrollbar{right:0;top:0;overflow-x:hidden;overflow-y:scroll}.jupyter-wrapper .CodeMirror-hscrollbar{bottom:0;left:0;overflow-y:hidden;overflow-x:scroll}.jupyter-wrapper .CodeMirror-scrollbar-filler{right:0;bottom:0}.jupyter-wrapper .CodeMirror-gutter-filler{left:0;bottom:0}.jupyter-wrapper .CodeMirror-gutters{position:absolute;left:0;top:0;min-height:100%;z-index:3}.jupyter-wrapper .CodeMirror-gutter{white-space:normal;height:100%;display:inline-block;vertical-align:top;margin-bottom:-50px}.jupyter-wrapper .CodeMirror-gutter-wrapper{position:absolute;z-index:4;background:none!important;border:none!important}.jupyter-wrapper .CodeMirror-gutter-background{position:absolute;top:0;bottom:0;z-index:4}.jupyter-wrapper .CodeMirror-gutter-elt{position:absolute;cursor:default;z-index:4}.jupyter-wrapper .CodeMirror-gutter-wrapper ::selection{background-color:transparent}.jupyter-wrapper .CodeMirror-gutter-wrapper ::-moz-selection{background-color:transparent}.jupyter-wrapper .CodeMirror-lines{cursor:text;min-height:1px}.jupyter-wrapper .CodeMirror pre.CodeMirror-line,.jupyter-wrapper .CodeMirror pre.CodeMirror-line-like{-moz-border-radius:0;-webkit-border-radius:0;border-radius:0;border-width:0;background:transparent;font-family:inherit;font-size:inherit;margin:0;white-space:pre;word-wrap:normal;line-height:inherit;color:inherit;z-index:2;position:relative;overflow:visible;-webkit-tap-highlight-color:transparent;-webkit-font-variant-ligatures:contextual;font-variant-ligatures:contextual}.jupyter-wrapper .CodeMirror-wrap pre.CodeMirror-line,.jupyter-wrapper .CodeMirror-wrap pre.CodeMirror-line-like{word-wrap:break-word;white-space:pre-wrap;word-break:normal}.jupyter-wrapper .CodeMirror-linebackground{position:absolute;left:0;right:0;top:0;bottom:0;z-index:0}.jupyter-wrapper .CodeMirror-linewidget{position:relative;z-index:2;padding:.1px}.jupyter-wrapper .CodeMirror-rtl pre{direction:rtl}.jupyter-wrapper .CodeMirror-code{outline:none}.jupyter-wrapper .CodeMirror-scroll,.jupyter-wrapper .CodeMirror-sizer,.jupyter-wrapper .CodeMirror-gutter,.jupyter-wrapper .CodeMirror-gutters,.jupyter-wrapper .CodeMirror-linenumber{-moz-box-sizing:content-box;box-sizing:content-box}.jupyter-wrapper .CodeMirror-measure{position:absolute;width:100%;height:0;overflow:hidden;visibility:hidden}.jupyter-wrapper .CodeMirror-cursor{position:absolute;pointer-events:none}.jupyter-wrapper .CodeMirror-measure pre{position:static}.jupyter-wrapper div.CodeMirror-cursors{visibility:hidden;position:relative;z-index:3}.jupyter-wrapper div.CodeMirror-dragcursors,.jupyter-wrapper .CodeMirror-focused div.CodeMirror-cursors{visibility:visible}.jupyter-wrapper .CodeMirror-selected{background:#d9d9d9}.jupyter-wrapper .CodeMirror-focused .CodeMirror-selected{background:#d7d4f0}.jupyter-wrapper .CodeMirror-crosshair{cursor:crosshair}.jupyter-wrapper .CodeMirror-line::selection,.jupyter-wrapper .CodeMirror-line>span::selection,.jupyter-wrapper .CodeMirror-line>span>span::selection{background:#d7d4f0}.jupyter-wrapper .CodeMirror-line::-moz-selection,.jupyter-wrapper .CodeMirror-line>span::-moz-selection,.jupyter-wrapper .CodeMirror-line>span>span::-moz-selection{background:#d7d4f0}.jupyter-wrapper .cm-searching{background-color:#ffa;background-color:#ff06}.jupyter-wrapper .cm-force-border{padding-right:.1px}@media print{.jupyter-wrapper .CodeMirror div.CodeMirror-cursors{visibility:hidden}}.jupyter-wrapper .cm-tab-wrap-hack:after{content:""}.jupyter-wrapper span.CodeMirror-selectedtext{background:none}.jupyter-wrapper .CodeMirror-dialog{position:absolute;left:0;right:0;background:inherit;z-index:15;padding:.1em .8em;overflow:hidden;color:inherit}.jupyter-wrapper .CodeMirror-dialog-top{border-bottom:1px solid #eee;top:0}.jupyter-wrapper .CodeMirror-dialog-bottom{border-top:1px solid #eee;bottom:0}.jupyter-wrapper .CodeMirror-dialog input{border:none;outline:none;background:transparent;width:20em;color:inherit;font-family:monospace}.jupyter-wrapper .CodeMirror-dialog button{font-size:70%}.jupyter-wrapper .CodeMirror-foldmarker{color:#00f;text-shadow:#b9f 1px 1px 2px,#b9f -1px -1px 2px,#b9f 1px -1px 2px,#b9f -1px 1px 2px;font-family:arial;line-height:.3;cursor:pointer}.jupyter-wrapper .CodeMirror-foldgutter{width:.7em}.jupyter-wrapper .CodeMirror-foldgutter-open,.jupyter-wrapper .CodeMirror-foldgutter-folded{cursor:pointer}.jupyter-wrapper .CodeMirror-foldgutter-open:after{content:"▾"}.jupyter-wrapper .CodeMirror-foldgutter-folded:after{content:"▸"}.jupyter-wrapper .CodeMirror{line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);border:0;border-radius:0;height:auto}.jupyter-wrapper .CodeMirror pre{padding:0 var(--jp-code-padding)}.jupyter-wrapper .CodeMirror.cm-fat-cursor .cm-overlay.cm-searching{opacity:.5}.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-dialog{background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jupyter-wrapper .CodeMirror-lines{padding:var(--jp-code-padding) 0}.jupyter-wrapper .CodeMirror-linenumber{padding:0 8px}.jupyter-wrapper .jp-CodeMirrorEditor{cursor:text}.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color)}@media screen and (min-width: 2138px) and (max-width: 4319px){.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width1) solid var(--jp-editor-cursor-color)}}@media screen and (min-width: 4320px){.jupyter-wrapper .jp-CodeMirrorEditor[data-type=inline] .CodeMirror-cursor{border-left:var(--jp-code-cursor-width2) solid var(--jp-editor-cursor-color)}}.jupyter-wrapper .CodeMirror.jp-mod-readOnly .CodeMirror-cursor{display:none}.jupyter-wrapper .CodeMirror-gutters{border-right:1px solid var(--jp-border-color2);background-color:var(--jp-layout-color0)}.jupyter-wrapper .jp-CollaboratorCursor{border-left:5px solid transparent;border-right:5px solid transparent;border-top:none;border-bottom:3px solid;background-clip:content-box;margin-left:-5px;margin-right:-5px}.jupyter-wrapper .CodeMirror-selectedtext.cm-searching{background-color:var(--jp-search-selected-match-background-color)!important;color:var(--jp-search-selected-match-color)!important}.jupyter-wrapper .cm-searching{background-color:var(--jp-search-unselected-match-background-color)!important;color:var(--jp-search-unselected-match-color)!important}.jupyter-wrapper .cm-trailingspace{background-image:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);background-position:center left;background-repeat:repeat-x}.jupyter-wrapper .CodeMirror-focused .CodeMirror-selected{background-color:var(--jp-editor-selected-focused-background)}.jupyter-wrapper .CodeMirror-selected{background-color:var(--jp-editor-selected-background)}.jupyter-wrapper .jp-CollaboratorCursor-hover{position:absolute;z-index:1;transform:translate(-50%);color:#fff;border-radius:3px;padding:1px 4px;text-align:center;font-size:var(--jp-ui-font-size1);white-space:nowrap}.jupyter-wrapper .jp-CodeMirror-ruler{border-left:1px dashed var(--jp-border-color2)}.jupyter-wrapper .CodeMirror.cm-s-jupyter{background:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jupyter-wrapper .jp-CodeConsole .CodeMirror.cm-s-jupyter,.jupyter-wrapper .jp-Notebook .CodeMirror.cm-s-jupyter{background:transparent}.jupyter-wrapper .cm-s-jupyter .CodeMirror-cursor{border-left:var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color)}.jupyter-wrapper .cm-s-jupyter span.cm-keyword{color:var(--jp-mirror-editor-keyword-color);font-weight:700}.jupyter-wrapper .cm-s-jupyter span.cm-atom{color:var(--jp-mirror-editor-atom-color)}.jupyter-wrapper .cm-s-jupyter span.cm-number{color:var(--jp-mirror-editor-number-color)}.jupyter-wrapper .cm-s-jupyter span.cm-def{color:var(--jp-mirror-editor-def-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable{color:var(--jp-mirror-editor-variable-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable-2{color:var(--jp-mirror-editor-variable-2-color)}.jupyter-wrapper .cm-s-jupyter span.cm-variable-3{color:var(--jp-mirror-editor-variable-3-color)}.jupyter-wrapper .cm-s-jupyter span.cm-punctuation{color:var(--jp-mirror-editor-punctuation-color)}.jupyter-wrapper .cm-s-jupyter span.cm-property{color:var(--jp-mirror-editor-property-color)}.jupyter-wrapper .cm-s-jupyter span.cm-operator{color:var(--jp-mirror-editor-operator-color);font-weight:700}.jupyter-wrapper .cm-s-jupyter span.cm-comment{color:var(--jp-mirror-editor-comment-color);font-style:italic}.jupyter-wrapper .cm-s-jupyter span.cm-string{color:var(--jp-mirror-editor-string-color)}.jupyter-wrapper .cm-s-jupyter span.cm-string-2{color:var(--jp-mirror-editor-string-2-color)}.jupyter-wrapper .cm-s-jupyter span.cm-meta{color:var(--jp-mirror-editor-meta-color)}.jupyter-wrapper .cm-s-jupyter span.cm-qualifier{color:var(--jp-mirror-editor-qualifier-color)}.jupyter-wrapper .cm-s-jupyter span.cm-builtin{color:var(--jp-mirror-editor-builtin-color)}.jupyter-wrapper .cm-s-jupyter span.cm-bracket{color:var(--jp-mirror-editor-bracket-color)}.jupyter-wrapper .cm-s-jupyter span.cm-tag{color:var(--jp-mirror-editor-tag-color)}.jupyter-wrapper .cm-s-jupyter span.cm-attribute{color:var(--jp-mirror-editor-attribute-color)}.jupyter-wrapper .cm-s-jupyter span.cm-header{color:var(--jp-mirror-editor-header-color)}.jupyter-wrapper .cm-s-jupyter span.cm-quote{color:var(--jp-mirror-editor-quote-color)}.jupyter-wrapper .cm-s-jupyter span.cm-link{color:var(--jp-mirror-editor-link-color)}.jupyter-wrapper .cm-s-jupyter span.cm-error{color:var(--jp-mirror-editor-error-color)}.jupyter-wrapper .cm-s-jupyter span.cm-hr{color:#999}.jupyter-wrapper .cm-s-jupyter span.cm-tab{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);background-position:right;background-repeat:no-repeat}.jupyter-wrapper .cm-s-jupyter .CodeMirror-activeline-background,.jupyter-wrapper .cm-s-jupyter .CodeMirror-gutter{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret{position:relative;border-left:2px solid black;margin-left:-1px;margin-right:-1px;box-sizing:border-box}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret>div{white-space:nowrap;position:absolute;top:-1.15em;padding-bottom:.05em;left:-2px;font-size:.95em;background-color:#fa8100;font-family:var(--jp-ui-font-family);font-weight:700;line-height:normal;-webkit-user-select:none;user-select:none;color:#fff;padding-left:2px;padding-right:2px;z-index:3;transition:opacity .3s ease-in-out}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret.hide-name>div{transition-delay:.7s;opacity:0}.jupyter-wrapper .jp-CodeMirrorEditor .remote-caret:hover>div[style]{opacity:1;transition-delay:0s}.jupyter-wrapper :root{--jp-private-code-span-padding: calc( (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2 )}.jupyter-wrapper .jp-RenderedText{text-align:left;padding-left:var(--jp-code-padding);line-height:var(--jp-code-line-height);font-family:var(--jp-code-font-family)}.jupyter-wrapper .jp-RenderedText pre,.jupyter-wrapper .jp-RenderedJavaScript pre,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore pre{color:var(--jp-content-font-color1);font-size:var(--jp-code-font-size);border:none;margin:0;padding:0}.jupyter-wrapper .jp-RenderedText pre a:link{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedText pre a:hover{text-decoration:underline;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedText pre a:visited{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedText pre .ansi-black-fg{color:#3e424d}.jupyter-wrapper .jp-RenderedText pre .ansi-red-fg{color:#e75c58}.jupyter-wrapper .jp-RenderedText pre .ansi-green-fg{color:#00a250}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-fg{color:#ddb62b}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-fg{color:#208ffb}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-fg{color:#d160c4}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-fg{color:#60c6c8}.jupyter-wrapper .jp-RenderedText pre .ansi-white-fg{color:#c5c1b4}.jupyter-wrapper .jp-RenderedText pre .ansi-black-bg{background-color:#3e424d;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-red-bg{background-color:#e75c58;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-green-bg{background-color:#00a250;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-bg{background-color:#ddb62b;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-bg{background-color:#208ffb;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-bg{background-color:#d160c4;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-bg{background-color:#60c6c8;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-white-bg{background-color:#c5c1b4;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-black-intense-fg{color:#282c36}.jupyter-wrapper .jp-RenderedText pre .ansi-red-intense-fg{color:#b22b31}.jupyter-wrapper .jp-RenderedText pre .ansi-green-intense-fg{color:#007427}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-intense-fg{color:#b27d12}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-intense-fg{color:#0065ca}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-intense-fg{color:#a03196}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-intense-fg{color:#258f8f}.jupyter-wrapper .jp-RenderedText pre .ansi-white-intense-fg{color:#a1a6b2}.jupyter-wrapper .jp-RenderedText pre .ansi-black-intense-bg{background-color:#282c36;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-red-intense-bg{background-color:#b22b31;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-green-intense-bg{background-color:#007427;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-yellow-intense-bg{background-color:#b27d12;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-blue-intense-bg{background-color:#0065ca;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-magenta-intense-bg{background-color:#a03196;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-cyan-intense-bg{background-color:#258f8f;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-white-intense-bg{background-color:#a1a6b2;padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-default-inverse-fg{color:var(--jp-ui-inverse-font-color0)}.jupyter-wrapper .jp-RenderedText pre .ansi-default-inverse-bg{background-color:var(--jp-inverse-layout-color0);padding:var(--jp-private-code-span-padding) 0}.jupyter-wrapper .jp-RenderedText pre .ansi-bold{font-weight:700}.jupyter-wrapper .jp-RenderedText pre .ansi-underline{text-decoration:underline}.jupyter-wrapper .jp-RenderedText[data-mime-type="application/vnd.jupyter.stderr"]{background:var(--jp-rendermime-error-background);padding-top:var(--jp-code-padding)}.jupyter-wrapper .jp-RenderedLatex{color:var(--jp-content-font-color1);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height)}.jupyter-wrapper .jp-OutputArea-output.jp-RenderedLatex{padding:var(--jp-code-padding);text-align:left}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore{color:var(--jp-content-font-color1);font-family:var(--jp-content-font-family);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height);padding-right:20px}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore em{font-style:italic}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore strong{font-weight:700}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore u{text-decoration:underline}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore a:link{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore a:hover{text-decoration:underline;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore a:visited{text-decoration:none;color:var(--jp-content-link-color)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6{line-height:var(--jp-content-heading-line-height);font-weight:var(--jp-content-heading-font-weight);font-style:normal;margin:var(--jp-content-heading-margin-top) 0 var(--jp-content-heading-margin-bottom) 0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5:first-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6:first-child{margin-top:calc(.5 * var(--jp-content-heading-margin-top))}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6:last-child{margin-bottom:calc(.5 * var(--jp-content-heading-margin-bottom))}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h1{font-size:var(--jp-content-font-size5)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h2{font-size:var(--jp-content-font-size4)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h3{font-size:var(--jp-content-font-size3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h4{font-size:var(--jp-content-font-size2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h5{font-size:var(--jp-content-font-size1)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore h6{font-size:var(--jp-content-font-size0)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul:not(.list-inline),.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol:not(.list-inline){padding-left:2em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul{list-style:disc}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ul{list-style:square}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ul ul{list-style:circle}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol{list-style:decimal}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol{list-style:upper-alpha}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol ol{list-style:lower-alpha}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol ol ol{list-style:lower-roman}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol ol ol ol{list-style:decimal}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul{margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ul,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ul ol,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ul,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore ol ol{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore hr{color:var(--jp-border-color2);background-color:var(--jp-border-color1);margin-top:1em;margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore>pre{margin:1.5em 2em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore pre,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore code{border:0;background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1);font-family:var(--jp-code-font-family);font-size:inherit;line-height:var(--jp-code-line-height);padding:0;white-space:pre-wrap}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore :not(pre)>code{background-color:var(--jp-layout-color2);padding:1px 5px}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore table{border-collapse:collapse;border-spacing:0;border:none;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);table-layout:fixed;margin-left:auto;margin-right:auto}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore thead{border-bottom:var(--jp-border-width) solid var(--jp-border-color1);vertical-align:bottom}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore td,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore th,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tr{vertical-align:middle;padding:.5em;line-height:normal;white-space:normal;max-width:none;border:none}.jupyter-wrapper .jp-RenderedMarkdown.jp-RenderedHTMLCommon-ignore td,.jupyter-wrapper .jp-RenderedMarkdown.jp-RenderedHTMLCommon-ignore th{max-width:none}.jupyter-wrapper :not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon-ignore td,.jupyter-wrapper :not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon-ignore th,.jupyter-wrapper :not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon-ignore tr{text-align:right}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore th{font-weight:700}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tbody tr:nth-child(odd){background:var(--jp-layout-color0)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tbody tr:nth-child(2n){background:var(--jp-rendermime-table-row-background)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore tbody tr:hover{background:var(--jp-rendermime-table-row-hover-background)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore table{margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore p{text-align:left;margin:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore p{margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore img{-moz-force-broken-image-icon:1}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore>img{display:block;margin-left:0;margin-right:0;margin-bottom:1em}.jupyter-wrapper [data-jp-theme-light=false] .jp-RenderedImage img.jp-needs-light-background,.jupyter-wrapper [data-jp-theme-light=true] .jp-RenderedImage img.jp-needs-dark-background{background-color:var(--jp-inverse-layout-color1)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore img,.jupyter-wrapper .jp-RenderedImage img,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore svg,.jupyter-wrapper .jp-RenderedSVG svg{max-width:100%;height:auto}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore img.jp-mod-unconfined,.jupyter-wrapper .jp-RenderedImage img.jp-mod-unconfined,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore svg.jp-mod-unconfined,.jupyter-wrapper .jp-RenderedSVG svg.jp-mod-unconfined{max-width:none}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert{padding:var(--jp-notebook-padding);border:var(--jp-border-width) solid transparent;border-radius:var(--jp-border-radius);margin-bottom:1em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info{color:var(--jp-info-color0);background-color:var(--jp-info-color3);border-color:var(--jp-info-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info hr{border-color:var(--jp-info-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-info>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning{color:var(--jp-warn-color0);background-color:var(--jp-warn-color3);border-color:var(--jp-warn-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning hr{border-color:var(--jp-warn-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-warning>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success{color:var(--jp-success-color0);background-color:var(--jp-success-color3);border-color:var(--jp-success-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success hr{border-color:var(--jp-success-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-success>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger{color:var(--jp-error-color0);background-color:var(--jp-error-color3);border-color:var(--jp-error-color2)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger hr{border-color:var(--jp-error-color3)}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger>p:last-child,.jupyter-wrapper .jp-RenderedHTMLCommon-ignore .alert-danger>ul:last-child{margin-bottom:0}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore blockquote{margin:1em 2em;padding:0 1em;border-left:5px solid var(--jp-border-color2)}.jupyter-wrapper a.jp-InternalAnchorLink{visibility:hidden;margin-left:8px;color:var(--md-blue-800)}.jupyter-wrapper h1:hover .jp-InternalAnchorLink,.jupyter-wrapper h2:hover .jp-InternalAnchorLink,.jupyter-wrapper h3:hover .jp-InternalAnchorLink,.jupyter-wrapper h4:hover .jp-InternalAnchorLink,.jupyter-wrapper h5:hover .jp-InternalAnchorLink,.jupyter-wrapper h6:hover .jp-InternalAnchorLink{visibility:visible}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore kbd{background-color:var(--jp-rendermime-table-row-background);border:1px solid var(--jp-border-color0);border-bottom-color:var(--jp-border-color2);border-radius:3px;box-shadow:inset 0 -1px #00000040;display:inline-block;font-size:var(--jp-ui-font-size0);line-height:1em;padding:.2em .5em}.jupyter-wrapper .jp-RenderedHTMLCommon-ignore>*:last-child{margin-bottom:.5em}.jupyter-wrapper .jp-MimeDocument{outline:none}.jupyter-wrapper :root{--jp-private-filebrowser-button-height: 28px;--jp-private-filebrowser-button-width: 48px}.jupyter-wrapper .jp-FileBrowser{display:flex;flex-direction:column;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jupyter-wrapper .jp-FileBrowser-toolbar.jp-Toolbar{border-bottom:none;height:auto;margin:8px 12px 0;padding:0;box-shadow:none;justify-content:flex-start}.jupyter-wrapper .jp-BreadCrumbs{flex:0 0 auto;margin:8px 12px}.jupyter-wrapper .jp-BreadCrumbs-item{margin:0 2px;padding:0 2px;border-radius:var(--jp-border-radius);cursor:pointer}.jupyter-wrapper .jp-BreadCrumbs-item:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-BreadCrumbs-item:first-child{margin-left:0}.jupyter-wrapper .jp-BreadCrumbs-item.jp-mod-dropTarget{background-color:var(--jp-brand-color2);opacity:.7}.jupyter-wrapper .jp-FileBrowser-toolbar>.jp-Toolbar-item{flex:0 0 auto;padding-left:0;padding-right:2px}.jupyter-wrapper .jp-FileBrowser-toolbar>.jp-Toolbar-item .jp-ToolbarButtonComponent{width:40px}.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"]{width:72px;background:var(--jp-brand-color1)}.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"]:hover,.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"]:focus-visible{background-color:var(--jp-brand-color0)!important}.jupyter-wrapper .jp-FileBrowser-toolbar .jp-ToolbarButtonComponent[data-command="filebrowser:create-main-launcher"] .jp-icon3{fill:var(--jp-layout-color1)}.jupyter-wrapper .jp-FileDialog.jp-mod-conflict input{color:var(--jp-error-color1)}.jupyter-wrapper .jp-FileDialog .jp-new-name-title{margin-top:12px}.jupyter-wrapper .jp-LastModified-hidden{display:none}.jupyter-wrapper .jp-FileBrowser-filterBox{padding:0;flex:0 0 auto;margin:8px 12px 0}.jupyter-wrapper .jp-DirListing{flex:1 1 auto;display:flex;flex-direction:column;outline:0}.jupyter-wrapper .jp-DirListing:focus-visible{outline:1px solid var(--jp-brand-color1);outline-offset:-2px}.jupyter-wrapper .jp-DirListing-header{flex:0 0 auto;display:flex;flex-direction:row;overflow:hidden;border-top:var(--jp-border-width) solid var(--jp-border-color2);border-bottom:var(--jp-border-width) solid var(--jp-border-color1);box-shadow:var(--jp-toolbar-box-shadow);z-index:2}.jupyter-wrapper .jp-DirListing-headerItem{padding:4px 12px 2px;font-weight:500}.jupyter-wrapper .jp-DirListing-headerItem:hover{background:var(--jp-layout-color2)}.jupyter-wrapper .jp-DirListing-headerItem.jp-id-name{flex:1 0 84px}.jupyter-wrapper .jp-DirListing-headerItem.jp-id-modified{flex:0 0 112px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right}.jupyter-wrapper .jp-id-narrow{display:none;flex:0 0 5px;padding:4px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right;color:var(--jp-border-color2)}.jupyter-wrapper .jp-DirListing-narrow .jp-id-narrow{display:block}.jupyter-wrapper .jp-DirListing-narrow .jp-id-modified,.jupyter-wrapper .jp-DirListing-narrow .jp-DirListing-itemModified{display:none}.jupyter-wrapper .jp-DirListing-headerItem.jp-mod-selected{font-weight:600}.jupyter-wrapper .jp-DirListing-content{flex:1 1 auto;margin:0;padding:0;list-style-type:none;overflow:auto;background-color:var(--jp-layout-color1)}.jupyter-wrapper .jp-DirListing-content mark{color:var(--jp-ui-font-color0);background-color:transparent;font-weight:700}.jupyter-wrapper .jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark{color:var(--jp-ui-inverse-font-color0)}.jupyter-wrapper .jp-DirListing.jp-mod-native-drop .jp-DirListing-content{outline:5px dashed rgba(128,128,128,.5);outline-offset:-10px;cursor:copy}.jupyter-wrapper .jp-DirListing-item{display:flex;flex-direction:row;padding:4px 12px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper .jp-DirListing-item[data-is-dot]{opacity:75%}.jupyter-wrapper .jp-DirListing-item.jp-mod-selected{color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jupyter-wrapper .jp-DirListing-item.jp-mod-dropTarget{background:var(--jp-brand-color3)}.jupyter-wrapper .jp-DirListing-item:hover:not(.jp-mod-selected){background:var(--jp-layout-color2)}.jupyter-wrapper .jp-DirListing-itemIcon{flex:0 0 20px;margin-right:4px}.jupyter-wrapper .jp-DirListing-itemText{flex:1 0 64px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;user-select:none}.jupyter-wrapper .jp-DirListing-itemModified{flex:0 0 125px;text-align:right}.jupyter-wrapper .jp-DirListing-editor{flex:1 0 64px;outline:none;border:none;color:var(--jp-ui-font-color1);background-color:var(--jp-layout-color1)}.jupyter-wrapper .jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before{color:var(--jp-success-color1);content:"●";font-size:8px;position:absolute;left:-8px}.jupyter-wrapper .jp-DirListing-item.jp-mod-running.jp-mod-selected .jp-DirListing-itemIcon:before{color:var(--jp-ui-inverse-font-color1)}.jupyter-wrapper .jp-DirListing-item.lm-mod-drag-image,.jupyter-wrapper .jp-DirListing-item.jp-mod-selected.lm-mod-drag-image{font-size:var(--jp-ui-font-size1);padding-left:4px;margin-left:4px;width:160px;background-color:var(--jp-ui-inverse-font-color2);box-shadow:var(--jp-elevation-z2);border-radius:0;color:var(--jp-ui-font-color1);transform:translate(-40%) translateY(-58%)}.jupyter-wrapper .jp-Document{min-width:120px;min-height:120px;outline:none}.jupyter-wrapper .jp-OutputArea{overflow-y:auto}.jupyter-wrapper .jp-OutputArea-child{display:flex;flex-direction:row}.jupyter-wrapper body[data-format=mobile] .jp-OutputArea-child{flex-direction:column}.jupyter-wrapper .jp-OutputPrompt{flex:0 0 var(--jp-cell-prompt-width);color:var(--jp-cell-outprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent;opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper body[data-format=mobile] .jp-OutputPrompt{flex:0 0 auto;text-align:left}.jupyter-wrapper .jp-OutputArea-output{height:auto;overflow:auto;user-select:text;-moz-user-select:text;-webkit-user-select:text;-ms-user-select:text}.jupyter-wrapper .jp-OutputArea-child .jp-OutputArea-output{flex-grow:1;flex-shrink:1}.jupyter-wrapper body[data-format=mobile] .jp-OutputArea-child .jp-OutputArea-output{margin-left:var(--jp-notebook-padding)}.jupyter-wrapper .jp-OutputArea-output.jp-mod-isolated{width:100%;display:block}.jupyter-wrapper body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated{position:relative}.jupyter-wrapper body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before{content:"";position:absolute;top:0;left:0;right:0;bottom:0;background:transparent}.jupyter-wrapper .jp-OutputArea-output pre{border:none;margin:0;padding:0;overflow-x:auto;overflow-y:auto;word-break:break-all;word-wrap:break-word;white-space:pre-wrap}.jupyter-wrapper .jp-OutputArea-output.jp-RenderedHTMLCommon-ignore table{margin-left:0;margin-right:0}.jupyter-wrapper .jp-OutputArea-output dl,.jupyter-wrapper .jp-OutputArea-output dt,.jupyter-wrapper .jp-OutputArea-output dd{display:block}.jupyter-wrapper .jp-OutputArea-output dl{width:100%;overflow:hidden;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea-output dt{font-weight:700;float:left;width:20%;padding:0;margin:0}.jupyter-wrapper .jp-OutputArea-output dd{float:left;width:80%;padding:0;margin:0}.jupyter-wrapper .jp-TrimmedOutputs a{margin:10px;text-decoration:none;cursor:pointer}.jupyter-wrapper .jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt{display:none}.jupyter-wrapper .jp-OutputArea-prompt:empty{padding:0;border:0}.jupyter-wrapper .jp-OutputArea-output.jp-OutputArea-executeResult{margin-left:0;flex:1 1 auto}.jupyter-wrapper .jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output{padding-top:var(--jp-code-padding);border-top:var(--jp-border-width) solid transparent}.jupyter-wrapper .jp-Stdin-prompt{color:var(--jp-content-font-color0);padding-right:var(--jp-code-padding);vertical-align:baseline;flex:0 0 auto}.jupyter-wrapper .jp-Stdin-input{font-family:var(--jp-code-font-family);font-size:inherit;color:inherit;background-color:inherit;width:42%;min-width:200px;vertical-align:baseline;padding:0 .25em;margin:0 .25em;flex:0 0 70%}.jupyter-wrapper .jp-Stdin-input::placeholder{opacity:0}.jupyter-wrapper .jp-Stdin-input:focus{box-shadow:none}.jupyter-wrapper .jp-Stdin-input:focus::placeholder{opacity:1}.jupyter-wrapper .jp-LinkedOutputView .jp-OutputArea{height:100%;display:block}.jupyter-wrapper .jp-LinkedOutputView .jp-OutputArea-output:only-child{height:100%}.jupyter-wrapper .jp-Collapser{flex:0 0 var(--jp-cell-collapser-width);padding:0;margin:0;border:none;outline:none;background:transparent;border-radius:var(--jp-border-radius);opacity:1}.jupyter-wrapper .jp-Collapser-child{display:block;width:100%;box-sizing:border-box;position:absolute;top:0;bottom:0}.jupyter-wrapper .jp-CellHeader,.jupyter-wrapper .jp-CellFooter{height:0px;width:100%;padding:0;margin:0;border:none;outline:none;background:transparent}.jupyter-wrapper .jp-InputArea{display:flex;flex-direction:row;overflow:hidden}.jupyter-wrapper body[data-format=mobile] .jp-InputArea{flex-direction:column}.jupyter-wrapper .jp-InputArea-editor{flex:1 1 auto;overflow:hidden}.jupyter-wrapper .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);border-radius:0;background:var(--jp-cell-editor-background)}.jupyter-wrapper body[data-format=mobile] .jp-InputArea-editor{margin-left:var(--jp-notebook-padding)}.jupyter-wrapper .jp-InputPrompt{flex:0 0 var(--jp-cell-prompt-width);color:var(--jp-cell-inprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent;opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jupyter-wrapper body[data-format=mobile] .jp-InputPrompt{flex:0 0 auto;text-align:left}.jupyter-wrapper .jp-Placeholder{display:flex;flex-direction:row;flex:1 1 auto}.jupyter-wrapper .jp-Placeholder-prompt{box-sizing:border-box}.jupyter-wrapper .jp-Placeholder-content{flex:1 1 auto;border:none;background:transparent;height:20px;box-sizing:border-box}.jupyter-wrapper .jp-Placeholder-content .jp-MoreHorizIcon{width:32px;height:16px;border:1px solid transparent;border-radius:var(--jp-border-radius)}.jupyter-wrapper .jp-Placeholder-content .jp-MoreHorizIcon:hover{border:1px solid var(--jp-border-color1);box-shadow:0 0 2px #00000040;background-color:var(--jp-layout-color0)}.jupyter-wrapper :root{--jp-private-cell-scrolling-output-offset: 5px}.jupyter-wrapper .jp-Cell{padding:var(--jp-cell-padding);margin:0;border:none;outline:none;background:transparent}.jupyter-wrapper .jp-Cell-inputWrapper,.jupyter-wrapper .jp-Cell-outputWrapper{display:flex;flex-direction:row;padding:0;margin:0;overflow:visible}.jupyter-wrapper .jp-Cell-inputArea,.jupyter-wrapper .jp-Cell-outputArea{flex:1 1 auto}.jupyter-wrapper .jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser{border:none!important;background:transparent!important}.jupyter-wrapper .jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser{min-height:var(--jp-cell-collapser-min-height)}.jupyter-wrapper .jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper{margin-top:5px}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea{overflow-y:auto;max-height:24em;margin-left:var(--jp-private-cell-scrolling-output-offset)}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea:after{content:" ";box-shadow:inset 0 0 6px 2px #0000004d;width:100%;height:100%;position:sticky;bottom:0;top:0;margin-top:-50%;float:left;display:block;pointer-events:none}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child{padding-top:6px}.jupyter-wrapper .jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt{flex:0 0 calc(var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset))}.jupyter-wrapper .jp-MarkdownOutput{flex:1 1 auto;margin-top:0;margin-bottom:0;padding-left:var(--jp-code-padding)}.jupyter-wrapper .jp-MarkdownOutput.jp-RenderedHTMLCommon-ignore{overflow:auto}.jupyter-wrapper .jp-collapseHeadingButton{display:none;min-height:var(--jp-cell-collapser-min-height);font-size:var(--jp-code-font-size);position:absolute;right:0;top:0;bottom:0;background-color:transparent;background-size:25px;background-repeat:no-repeat;background-position-x:center;background-position-y:top;background-image:var(--jp-icon-caret-down);border:none;cursor:pointer}.jupyter-wrapper .jp-collapseHeadingButton:hover{background-color:var(--jp-layout-color2)}.jupyter-wrapper .jp-collapseHeadingButton.jp-mod-collapsed{background-image:var(--jp-icon-caret-right)}.jupyter-wrapper :is(.jp-MarkdownCell:hover,.jp-mod-active) .jp-collapseHeadingButton{display:flex}.jupyter-wrapper .jp-MarkdownCell .jp-InputPrompt{font-size:var(--jp-content-font-size1)}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="1"]{font-size:var(--jp-content-font-size5);background-position-y:calc(.3 * var(--jp-content-font-size5))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="2"]{font-size:var(--jp-content-font-size4);background-position-y:calc(.3 * var(--jp-content-font-size4))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="3"]{font-size:var(--jp-content-font-size3);background-position-y:calc(.3 * var(--jp-content-font-size3))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="4"]{font-size:var(--jp-content-font-size2);background-position-y:calc(.3 * var(--jp-content-font-size2))}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="5"]{font-size:var(--jp-content-font-size1);background-position-y:top}.jupyter-wrapper .jp-mod-rendered .jp-collapseHeadingButton[data-heading-level="6"]{font-size:var(--jp-content-font-size0);background-position-y:top}.jupyter-wrapper .jp-showHiddenCellsButton{margin-left:calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));margin-top:var(--jp-code-padding);border:1px solid var(--jp-border-color2);background-color:var(--jp-border-color3)!important;color:var(--jp-content-font-color0)!important}.jupyter-wrapper .jp-showHiddenCellsButton:hover{background-color:var(--jp-border-color2)!important}.jupyter-wrapper :root{--jp-notebook-toolbar-padding: 2px 5px 2px 2px}.jupyter-wrapper .jp-NotebookPanel-toolbar{padding:var(--jp-notebook-toolbar-padding)}.jupyter-wrapper .jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused{border:none;box-shadow:none}.jupyter-wrapper .jp-Notebook-toolbarCellTypeDropdown select{height:24px;font-size:var(--jp-ui-font-size1);line-height:14px;border-radius:0;display:block}.jupyter-wrapper .jp-Notebook-toolbarCellTypeDropdown span{top:5px!important}.jupyter-wrapper .jp-Toolbar-responsive-popup{position:absolute;height:fit-content;display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:var(--jp-notebook-toolbar-padding);z-index:1;right:0;top:0}.jupyter-wrapper .jp-Toolbar>.jp-Toolbar-responsive-opener{margin-left:auto}.jupyter-wrapper .jp-Notebook-ExecutionIndicator{position:relative;display:inline-block;height:100%;z-index:9997}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip{visibility:hidden;height:auto;width:max-content;width:-moz-max-content;background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color1);text-align:justify;border-radius:6px;padding:0 5px;position:fixed;display:table}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip.up{transform:translate(-50%) translateY(-100%) translateY(-32px)}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip.down{transform:translate(calc(-100% + 16px)) translateY(5px)}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-tooltip.hidden{display:none}.jupyter-wrapper .jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip{visibility:visible}.jupyter-wrapper .jp-Notebook-ExecutionIndicator span{font-size:var(--jp-ui-font-size1);font-family:var(--jp-ui-font-family);color:var(--jp-ui-font-color1);line-height:24px;display:block}.jupyter-wrapper .jp-Notebook-ExecutionIndicator-progress-bar{display:flex;justify-content:center;height:100%}.jupyter-wrapper :root{--jp-private-notebook-dragImage-width: 304px;--jp-private-notebook-dragImage-height: 36px;--jp-private-notebook-selected-color: var(--md-blue-400);--jp-private-notebook-active-color: var(--md-green-400)}.jupyter-wrapper .jp-NotebookPanel{display:block;height:100%}.jupyter-wrapper .jp-NotebookPanel.jp-Document{min-width:240px;min-height:120px}.jupyter-wrapper .jp-Notebook{padding:var(--jp-notebook-padding);outline:none;overflow:auto}.jupyter-wrapper .jp-Notebook.jp-mod-scrollPastEnd:after{display:block;content:"";min-height:var(--jp-notebook-scroll-padding)}.jupyter-wrapper .jp-MainAreaWidget-ContainStrict .jp-Notebook *{contain:strict}.jupyter-wrapper .jp-Notebook .jp-Cell{overflow:visible}.jupyter-wrapper .jp-Notebook .jp-Cell .jp-InputPrompt{cursor:move;float:left}.jupyter-wrapper .jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jupyter-wrapper .jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser{background:var(--jp-brand-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt{color:var(--jp-warn-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt:before{color:var(--jp-warn-color1);content:"•"}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser{background:var(--jp-warn-color1)}.jupyter-wrapper .jp-Notebook .jp-Cell .jp-Collapser:hover{box-shadow:var(--jp-elevation-z2);background:var(--jp-brand-color1);opacity:var(--jp-cell-collapser-not-active-hover-opacity)}.jupyter-wrapper .jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover{background:var(--jp-brand-color0);opacity:1}.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected{background:var(--jp-notebook-multiselected-color)}.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected){background:transparent}.jupyter-wrapper .jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-cell-editor-active-background)}.jupyter-wrapper .jp-Notebook-cell.jp-mod-dropSource{opacity:.5}.jupyter-wrapper .jp-Notebook-cell.jp-mod-dropTarget,.jupyter-wrapper .jp-Notebook.jp-mod-commandMode .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget{border-top-color:var(--jp-private-notebook-selected-color);border-top-style:solid;border-top-width:2px}.jupyter-wrapper .jp-dragImage{display:block;flex-direction:row;width:var(--jp-private-notebook-dragImage-width);height:var(--jp-private-notebook-dragImage-height);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background);overflow:visible}.jupyter-wrapper .jp-dragImage-singlePrompt{box-shadow:2px 2px 4px #0000001f}.jupyter-wrapper .jp-dragImage .jp-dragImage-content{flex:1 1 auto;z-index:2;font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);line-height:var(--jp-code-line-height);padding:var(--jp-code-padding);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background-color);color:var(--jp-content-font-color3);text-align:left;margin:4px 4px 4px 0}.jupyter-wrapper .jp-dragImage .jp-dragImage-prompt{flex:0 0 auto;min-width:36px;color:var(--jp-cell-inprompt-font-color);padding:var(--jp-code-padding);padding-left:12px;font-family:var(--jp-cell-prompt-font-family);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:1.9;font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent}.jupyter-wrapper .jp-dragImage-multipleBack{z-index:-1;position:absolute;height:32px;width:300px;top:8px;left:8px;background:var(--jp-layout-color2);border:var(--jp-border-width) solid var(--jp-input-border-color);box-shadow:2px 2px 4px #0000001f}.jupyter-wrapper .jp-NotebookTools{display:block;min-width:var(--jp-sidebar-min-width);color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1);overflow:auto}.jupyter-wrapper .jp-NotebookTools-tool{padding:0 12px}.jupyter-wrapper .jp-ActiveCellTool{padding:12px;background-color:var(--jp-layout-color1);border-top:none!important}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-prompt{flex:0 0 auto;padding-left:0}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-editor{flex:1 1 auto;background:var(--jp-cell-editor-background);border-color:var(--jp-cell-editor-border-color)}.jupyter-wrapper .jp-ActiveCellTool .jp-InputArea-editor .CodeMirror{background:transparent}.jupyter-wrapper .jp-MetadataEditorTool{flex-direction:column;padding:12px 0}.jupyter-wrapper .jp-RankedPanel>:not(:first-child){margin-top:12px}.jupyter-wrapper .jp-KeySelector select.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:var(--jp-border-width) solid var(--jp-border-color1)}.jupyter-wrapper .jp-KeySelector label,.jupyter-wrapper .jp-MetadataEditorTool label{line-height:1.4}.jupyter-wrapper .jp-NotebookTools .jp-select-wrapper{margin-top:4px;margin-bottom:0}.jupyter-wrapper .jp-NotebookTools .jp-Collapse{margin-top:16px}.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook{--jp-content-font-size1: var(--jp-content-presentation-font-size1);--jp-code-font-size: var(--jp-code-presentation-font-size)}.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,.jupyter-wrapper .jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt{flex:0 0 110px}.jupyter-wrapper :root{--jp-side-by-side-output-size: 1fr;--jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size)}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell{margin:3em 5%}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell{display:grid;grid-template-columns:minmax(0,1fr) min-content minmax(0,var(--jp-side-by-side-output-size));grid-template-rows:auto minmax(0,1fr) auto;grid-template-areas:"header header header" "input handle output" "footer footer footer"}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell{grid-template-columns:minmax(0,1fr) min-content minmax(0,var(--jp-side-by-side-resized-cell))}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader{grid-area:header}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper{grid-area:input}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper{margin-top:0;grid-area:output}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter{grid-area:footer}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle{grid-area:handle;-webkit-user-select:none;user-select:none;display:block;height:100%;cursor:ew-resize;padding:0 var(--jp-cell-padding)}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle:after{content:"";display:block;background:var(--jp-border-color2);height:100%;width:5px}.jupyter-wrapper .jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell .jp-CellResizeHandle:after{background:var(--jp-border-color0)}.jupyter-wrapper .jp-CellResizeHandle{display:none}.jupyter-wrapper .jp-Cell-Placeholder{padding-left:55px}.jupyter-wrapper .jp-Cell-Placeholder-wrapper{background:#fff;border:1px solid;border-color:#e5e6e9 #dfe0e4 #d0d1d5;border-radius:4px;-webkit-border-radius:4px;margin:10px 15px}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-inner{padding:15px;position:relative}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-body{background-repeat:repeat;background-size:50% auto}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-body div{background:#f6f7f8;background-image:-webkit-linear-gradient(left,#f6f7f8 0%,#edeef1 20%,#f6f7f8 40%,#f6f7f8 100%);background-repeat:no-repeat;background-size:800px 104px;height:104px;position:relative}.jupyter-wrapper .jp-Cell-Placeholder-wrapper-body div{position:absolute;right:15px;left:15px;top:15px}.jupyter-wrapper div.jp-Cell-Placeholder-h1{top:20px;height:20px;left:15px;width:150px}.jupyter-wrapper div.jp-Cell-Placeholder-h2{left:15px;top:50px;height:10px;width:100px}.jupyter-wrapper div.jp-Cell-Placeholder-content-1,.jupyter-wrapper div.jp-Cell-Placeholder-content-2,.jupyter-wrapper div.jp-Cell-Placeholder-content-3{left:15px;right:15px;height:10px}.jupyter-wrapper div.jp-Cell-Placeholder-content-1{top:100px}.jupyter-wrapper div.jp-Cell-Placeholder-content-2{top:120px}.jupyter-wrapper div.jp-Cell-Placeholder-content-3{top:140px}.jupyter-wrapper table.dataframe{table-layout:auto!important}.jupyter-wrapper .md-typeset__scrollwrap{margin:0}.jupyter-wrapper .jp-MarkdownOutput{padding:0}.jupyter-wrapper h1 .anchor-link,.jupyter-wrapper h2 .anchor-link,.jupyter-wrapper h3 .anchor-link,.jupyter-wrapper h4 .anchor-link,.jupyter-wrapper h5 .anchor-link,.jupyter-wrapper h6 .anchor-link{display:none;margin-left:.5rem;color:var(--md-default-fg-color--lighter)}.jupyter-wrapper h1 .anchor-link:hover,.jupyter-wrapper h2 .anchor-link:hover,.jupyter-wrapper h3 .anchor-link:hover,.jupyter-wrapper h4 .anchor-link:hover,.jupyter-wrapper h5 .anchor-link:hover,.jupyter-wrapper h6 .anchor-link:hover{text-decoration:none;color:var(--md-accent-fg-color)}.jupyter-wrapper h1:hover .anchor-link,.jupyter-wrapper h2:hover .anchor-link,.jupyter-wrapper h3:hover .anchor-link,.jupyter-wrapper h4:hover .anchor-link,.jupyter-wrapper h5:hover .anchor-link,.jupyter-wrapper h6:hover .anchor-link{display:inline-block}.jupyter-wrapper .jp-InputArea,.jupyter-wrapper .jp-Cell-inputArea,.jupyter-wrapper .jp-RenderedHTMLCommon{width:100%}.jupyter-wrapper .jp-Cell-inputWrapper .jp-InputPrompt{display:none}.jupyter-wrapper .jp-CodeCell .jp-Cell-inputWrapper .jp-InputPrompt{display:block}.jupyter-wrapper .jp-Cell .jp-InputPrompt{cursor:normal}.jupyter-wrapper .highlight pre{background-color:#f5f5f5;padding:10px;overflow:auto}.jupyter-wrapper .celltoolbar{border:none;background:#eee;border-radius:2px 2px 0 0;width:100%;height:29px;padding-right:4px;box-orient:horizontal;box-align:stretch;display:flex;flex-direction:row;align-items:stretch;box-pack:end;justify-content:flex-start;display:-webkit-flex}.jupyter-wrapper .celltoolbar .tags_button_container{display:flex}.jupyter-wrapper .celltoolbar .tags_button_container .tag-container{display:flex;flex-direction:row;flex-grow:1;overflow:hidden;position:relative}.jupyter-wrapper .celltoolbar .tags_button_container .tag-container .cell-tag{display:inline-flex;align-items:center;background-color:#fff;white-space:nowrap;margin:3px 4px;padding:0 4px;border-radius:1px;border:1px solid #ccc;box-shadow:none;width:inherit;font-size:11px;font-family:Roboto Mono,SFMono-Regular,Consolas,Menlo,monospace;height:17px}.jupyter-wrapper .jp-InputArea-editor{width:1px}.jupyter-wrapper .jp-InputPrompt,.jupyter-wrapper .jp-OutputPrompt{overflow:unset}.jupyter-wrapper .jp-RenderedText{font-size:var(--jp-code-font-size)}.jupyter-wrapper .highlight-ipynb{overflow:auto}.jupyter-wrapper .highlight-ipynb pre{margin:0;padding:5px 10px}.jupyter-wrapper table{width:max-content}.jupyter-wrapper table.dataframe{margin-left:auto;margin-right:auto;border:none;border-collapse:collapse;border-spacing:0;color:#000;font-size:12px;table-layout:fixed}.jupyter-wrapper table.dataframe thead{border-bottom:1px solid black;vertical-align:bottom}.jupyter-wrapper table.dataframe tr,.jupyter-wrapper table.dataframe th,.jupyter-wrapper table.dataframe td{text-align:right;vertical-align:middle;padding:.5em;line-height:normal;white-space:normal;max-width:none;border:none}.jupyter-wrapper table.dataframe th{font-weight:700}.jupyter-wrapper table.dataframe tbody tr:nth-child(odd){background:#f5f5f5}.jupyter-wrapper table.dataframe tbody tr:hover{background:rgba(66,165,245,.2)}.jupyter-wrapper *+table{margin-top:1em}.jupyter-wrapper .jp-InputArea-editor{position:relative}.jupyter-wrapper .zeroclipboard-container{position:absolute;top:-3px;right:0;z-index:1}.jupyter-wrapper .zeroclipboard-container clipboard-copy{-webkit-appearance:button;-moz-appearance:button;padding:7px 5px;font:11px system-ui,sans-serif;display:inline-block;cursor:default}.jupyter-wrapper .zeroclipboard-container clipboard-copy:hover{cursor:pointer}.jupyter-wrapper .zeroclipboard-container .clipboard-copy-icon{width:15px;padding:2px 0;color:#57606a;vertical-align:text-bottom}.jupyter-wrapper .clipboard-copy-txt{display:none}[data-md-color-scheme=slate] .highlight pre{background-color:#21222c;padding:10px;overflow:auto}[data-md-color-scheme=slate] .clipboard-copy-icon{color:#555!important}[data-md-color-scheme=slate] .celltoolbar{background:#333!important}[data-md-color-scheme=slate] .celltoolbar .tags_button_container .tag-container .cell-tag{background-color:transparent!important;border:1px solid #666!important}[data-md-color-scheme=slate] table.dataframe{color:#e9ebfc}[data-md-color-scheme=slate] table.dataframe thead{border-bottom:1px solid rgba(233,235,252,.12)}[data-md-color-scheme=slate] table.dataframe tbody tr:nth-child(odd){background:#222}[data-md-color-scheme=slate] table.dataframe tbody tr:hover{background:rgba(66,165,245,.2)}table{width:max-content}
</style>
<style type="text/css">
.jupyter-wrapper{--jp-shadow-base-lightness: 0;--jp-shadow-umbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .2 );--jp-shadow-penumbra-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .14 );--jp-shadow-ambient-color: rgba( var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), var(--jp-shadow-base-lightness), .12 );--jp-elevation-z0: none;--jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color), 0px 1px 1px 0px var(--jp-shadow-penumbra-color), 0px 1px 3px 0px var(--jp-shadow-ambient-color);--jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color), 0px 2px 2px 0px var(--jp-shadow-penumbra-color), 0px 1px 5px 0px var(--jp-shadow-ambient-color);--jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color), 0px 4px 5px 0px var(--jp-shadow-penumbra-color), 0px 1px 10px 0px var(--jp-shadow-ambient-color);--jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color), 0px 6px 10px 0px var(--jp-shadow-penumbra-color), 0px 1px 18px 0px var(--jp-shadow-ambient-color);--jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color), 0px 8px 10px 1px var(--jp-shadow-penumbra-color), 0px 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color), 0px 12px 17px 2px var(--jp-shadow-penumbra-color), 0px 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color), 0px 16px 24px 2px var(--jp-shadow-penumbra-color), 0px 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color), 0px 20px 31px 3px var(--jp-shadow-penumbra-color), 0px 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color), 0px 24px 38px 3px var(--jp-shadow-penumbra-color), 0px 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width: 1px;--jp-border-color0: var(--md-grey-400);--jp-border-color1: var(--md-grey-400);--jp-border-color2: var(--md-grey-300);--jp-border-color3: var(--md-grey-200);--jp-inverse-border-color: var(--md-grey-600);--jp-border-radius: 2px;--jp-ui-font-scale-factor: 1.2;--jp-ui-font-size0: .83333em;--jp-ui-font-size1: 13px;--jp-ui-font-size2: 1.2em;--jp-ui-font-size3: 1.44em;--jp-ui-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-ui-font-color0: rgba(0, 0, 0, 1);--jp-ui-font-color1: rgba(0, 0, 0, .87);--jp-ui-font-color2: rgba(0, 0, 0, .54);--jp-ui-font-color3: rgba(0, 0, 0, .38);--jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);--jp-ui-inverse-font-color2: rgba(255, 255, 255, .7);--jp-ui-inverse-font-color3: rgba(255, 255, 255, .5);--jp-content-line-height: 1.6;--jp-content-font-scale-factor: 1.2;--jp-content-font-size0: .83333em;--jp-content-font-size1: 14px;--jp-content-font-size2: 1.2em;--jp-content-font-size3: 1.44em;--jp-content-font-size4: 1.728em;--jp-content-font-size5: 2.0736em;--jp-content-presentation-font-size1: 17px;--jp-content-heading-line-height: 1;--jp-content-heading-margin-top: 1.2em;--jp-content-heading-margin-bottom: .8em;--jp-content-heading-font-weight: 500;--jp-content-font-color0: rgba(0, 0, 0, 1);--jp-content-font-color1: rgba(0, 0, 0, .87);--jp-content-font-color2: rgba(0, 0, 0, .54);--jp-content-font-color3: rgba(0, 0, 0, .38);--jp-content-link-color: var(--md-blue-700);--jp-content-font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";--jp-code-font-size: 13px;--jp-code-line-height: 1.3077;--jp-code-padding: 5px;--jp-code-font-family-default: Menlo, Consolas, "DejaVu Sans Mono", monospace;--jp-code-font-family: var(--jp-code-font-family-default);--jp-code-presentation-font-size: 16px;--jp-code-cursor-width0: 1.4px;--jp-code-cursor-width1: 2px;--jp-code-cursor-width2: 4px;--jp-layout-color0: white;--jp-layout-color1: white;--jp-layout-color2: var(--md-grey-200);--jp-layout-color3: var(--md-grey-400);--jp-layout-color4: var(--md-grey-600);--jp-inverse-layout-color0: #111111;--jp-inverse-layout-color1: var(--md-grey-900);--jp-inverse-layout-color2: var(--md-grey-800);--jp-inverse-layout-color3: var(--md-grey-700);--jp-inverse-layout-color4: var(--md-grey-600);--jp-brand-color0: var(--md-blue-900);--jp-brand-color1: var(--md-blue-700);--jp-brand-color2: var(--md-blue-300);--jp-brand-color3: var(--md-blue-100);--jp-brand-color4: var(--md-blue-50);--jp-accent-color0: var(--md-green-900);--jp-accent-color1: var(--md-green-700);--jp-accent-color2: var(--md-green-300);--jp-accent-color3: var(--md-green-100);--jp-warn-color0: var(--md-orange-900);--jp-warn-color1: var(--md-orange-700);--jp-warn-color2: var(--md-orange-300);--jp-warn-color3: var(--md-orange-100);--jp-error-color0: var(--md-red-900);--jp-error-color1: var(--md-red-700);--jp-error-color2: var(--md-red-300);--jp-error-color3: var(--md-red-100);--jp-success-color0: var(--md-green-900);--jp-success-color1: var(--md-green-700);--jp-success-color2: var(--md-green-300);--jp-success-color3: var(--md-green-100);--jp-info-color0: var(--md-cyan-900);--jp-info-color1: var(--md-cyan-700);--jp-info-color2: var(--md-cyan-300);--jp-info-color3: var(--md-cyan-100);--jp-cell-padding: 5px;--jp-cell-collapser-width: 8px;--jp-cell-collapser-min-height: 20px;--jp-cell-collapser-not-active-hover-opacity: .6;--jp-cell-editor-background: var(--md-grey-100);--jp-cell-editor-border-color: var(--md-grey-300);--jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background: var(--jp-layout-color0);--jp-cell-editor-active-border-color: var(--jp-brand-color1);--jp-cell-prompt-width: 64px;--jp-cell-prompt-font-family: var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing: 0px;--jp-cell-prompt-opacity: 1;--jp-cell-prompt-not-active-opacity: .5;--jp-cell-prompt-not-active-font-color: var(--md-grey-700);--jp-cell-inprompt-font-color: #307fc1;--jp-cell-outprompt-font-color: #bf5b3d;--jp-notebook-padding: 10px;--jp-notebook-select-background: var(--jp-layout-color1);--jp-notebook-multiselected-color: var(--md-blue-50);--jp-notebook-scroll-padding: calc( 100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px );--jp-rendermime-error-background: #fdd;--jp-rendermime-table-row-background: var(--md-grey-100);--jp-rendermime-table-row-hover-background: var(--md-light-blue-50);--jp-dialog-background: rgba(0, 0, 0, .25);--jp-console-padding: 10px;--jp-toolbar-border-color: var(--jp-border-color1);--jp-toolbar-micro-height: 8px;--jp-toolbar-background: var(--jp-layout-color1);--jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, .24);--jp-toolbar-header-margin: 4px 4px 0px 4px;--jp-toolbar-active-background: var(--md-grey-300);--jp-statusbar-height: 24px;--jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);--jp-input-active-background: var(--jp-layout-color1);--jp-input-hover-background: var(--jp-layout-color1);--jp-input-background: var(--md-grey-100);--jp-input-border-color: var(--jp-inverse-border-color);--jp-input-active-border-color: var(--jp-brand-color1);--jp-input-active-box-shadow-color: rgba(19, 124, 189, .3);--jp-editor-selected-background: #d9d9d9;--jp-editor-selected-focused-background: #d7d4f0;--jp-editor-cursor-color: var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color: #008000;--jp-mirror-editor-atom-color: #88f;--jp-mirror-editor-number-color: #080;--jp-mirror-editor-def-color: #00f;--jp-mirror-editor-variable-color: var(--md-grey-900);--jp-mirror-editor-variable-2-color: #05a;--jp-mirror-editor-variable-3-color: #085;--jp-mirror-editor-punctuation-color: #05a;--jp-mirror-editor-property-color: #05a;--jp-mirror-editor-operator-color: #aa22ff;--jp-mirror-editor-comment-color: #408080;--jp-mirror-editor-string-color: #ba2121;--jp-mirror-editor-string-2-color: #708;--jp-mirror-editor-meta-color: #aa22ff;--jp-mirror-editor-qualifier-color: #555;--jp-mirror-editor-builtin-color: #008000;--jp-mirror-editor-bracket-color: #997;--jp-mirror-editor-tag-color: #170;--jp-mirror-editor-attribute-color: #00c;--jp-mirror-editor-header-color: blue;--jp-mirror-editor-quote-color: #090;--jp-mirror-editor-link-color: #00c;--jp-mirror-editor-error-color: #f00;--jp-mirror-editor-hr-color: #999;--jp-collaborator-color1: #ffad8e;--jp-collaborator-color2: #dac83d;--jp-collaborator-color3: #72dd76;--jp-collaborator-color4: #00e4d0;--jp-collaborator-color5: #45d4ff;--jp-collaborator-color6: #e2b1ff;--jp-collaborator-color7: #ff9de6;--jp-vega-background: white;--jp-sidebar-min-width: 250px;--jp-search-toggle-off-opacity: .5;--jp-search-toggle-hover-opacity: .8;--jp-search-toggle-on-opacity: 1;--jp-search-selected-match-background-color: rgb(245, 200, 0);--jp-search-selected-match-color: black;--jp-search-unselected-match-background-color: var( --jp-inverse-layout-color0 );--jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);--jp-icon-contrast-color0: var(--md-purple-600);--jp-icon-contrast-color1: var(--md-green-600);--jp-icon-contrast-color2: var(--md-pink-600);--jp-icon-contrast-color3: var(--md-blue-600);--jp-jupyter-icon-color: #f37626;--jp-notebook-icon-color: #f37626;--jp-json-icon-color: var(--md-orange-700);--jp-console-icon-background-color: var(--md-blue-700);--jp-console-icon-color: white;--jp-terminal-icon-background-color: var(--md-grey-800);--jp-terminal-icon-color: var(--md-grey-200);--jp-text-editor-icon-color: var(--md-grey-700);--jp-inspector-icon-color: var(--md-grey-700);--jp-switch-color: var(--md-grey-400);--jp-switch-true-position-color: var(--md-orange-900)}
</style>
<!-- Load mathjax -->
<script src=""> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --><div class="jupyter-wrapper">
<div class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a45184ef">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><a href="https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/09_pytorch_model_deployment.ipynb" target="_parent"><img alt="Abrir en Colab" src="https:// colab.research.google.com/assets/colab-badge.svg"/></a></p>
<p><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/09_pytorch_model_deployment.ipynb">Ver código fuente</a> | [Ver diapositivas] (<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/09_pytorch_model_deployment.pdf">https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/09_pytorch_model_deployment.pdf</a>)</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=05699eda">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="09-implementacion-del-modelo-pytorch">09. Implementación del modelo PyTorch<a class="anchor-link" href="#09-implementacion-del-modelo-pytorch">¶</a></h1><p>Bienvenido al Proyecto Milestone 3: ¡Implementación del modelo PyTorch!</p>
<p>Hemos recorrido un largo camino con nuestro proyecto FoodVision Mini.</p>
<p>Pero hasta ahora solo nosotros hemos podido acceder a nuestros modelos PyTorch.</p>
<p>¿Qué tal si le damos vida a FoodVision Mini y lo hacemos públicamente accesible?</p>
<p>En otras palabras, <strong>¡vamos a implementar nuestro modelo FoodVision Mini en Internet como una aplicación utilizable!</strong></p>
<img alt="demostración del mini modelo de visión por computadora de Foodvision que se utiliza en un dispositivo móvil para predecir una imagen de sushi y hacerlo bien" src="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/09-model-deployment-what-were-doing-demo-trimmed-cropped-small.gif" width="900/"/>
<p><em>Probando la <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">versión implementada de FoodVision Mini</a> (lo que vamos a crear) en mi almuerzo. ¡La modelo también acertó 🍣!</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=21abd76d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="que-es-la-implementacion-del-modelo-de-aprendizaje-automatico">¿Qué es la implementación del modelo de aprendizaje automático?<a class="anchor-link" href="#que-es-la-implementacion-del-modelo-de-aprendizaje-automatico">¶</a></h2><p><strong>Implementación del modelo de aprendizaje automático</strong> es el proceso de hacer que su modelo de aprendizaje automático sea accesible para alguien o algo más.</p>
<p>Alguien más es una persona que puede interactuar con tu modelo de alguna manera.</p>
<p>Por ejemplo, alguien que toma una fotografía de una comida con su teléfono inteligente y luego hace que nuestro modelo FoodVision Mini la clasifique en pizza, filete o sushi.</p>
<p>Otra cosa podría ser otro programa, aplicación o incluso otro modelo que interactúe con sus modelos de aprendizaje automático.</p>
<p>Por ejemplo, una base de datos bancaria podría depender de un modelo de aprendizaje automático que haga predicciones sobre si una transacción es fraudulenta o no antes de transferir fondos.</p>
<p>O un sistema operativo puede reducir su consumo de recursos basándose en un modelo de aprendizaje automático que hace predicciones sobre cuánta energía usa generalmente alguien en momentos específicos del día.</p>
<p>Estos casos de uso también se pueden mezclar y combinar.</p>
<p>Por ejemplo, el sistema de visión por computadora de un automóvil Tesla interactuará con el programa de planificación de rutas del automóvil (algo más) y luego el programa de planificación de rutas recibirá información y comentarios del conductor (otra persona).</p>
<p><img alt="dos casos de uso para la implementación de modelos, hacer que su modelo esté disponible para otra persona, por ejemplo, alguien que lo use en una aplicación, o ponerlo a disposición de otra cosa, como otro programa o modelo" ancho="900" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-what-is-model-deployment-someone-or-something-else.png"/></p>
<p><em>La implementación del modelo de aprendizaje automático implica poner su modelo a disposición de alguien o de algo más. Por ejemplo, alguien podría usar su modelo como parte de una aplicación de reconocimiento de alimentos (como FoodVision Mini o <a href="https://nutrify.app">Nutrify</a>). Y algo más podría ser otro modelo o programa que utilice su modelo, como un sistema bancario que utilice un modelo de aprendizaje automático para detectar si una transacción es fraudulenta o no.</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4fca5fc3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="por-que-implementar-un-modelo-de-aprendizaje-automatico">¿Por qué implementar un modelo de aprendizaje automático?<a class="anchor-link" href="#por-que-implementar-un-modelo-de-aprendizaje-automatico">¶</a></h2><p>Una de las cuestiones filosóficas más importantes en el aprendizaje automático es:</p>
<div align="centro">
<img .="" alt="dinosaurio curioso al que a menudo se hace referencia como filósofo raptor que hace la pregunta Si un modelo de aprendizaje automático nunca sale de un cuaderno, ¿existe?" ancho="300/" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-does-it-exist.jpeg"/>
</div>
<p>Implementar un modelo es tan importante como entrenarlo.</p>
<p>Porque aunque puedes tener una idea bastante clara de cómo funcionará tu modelo evaluándolo en un conjunto de pruebas bien diseñado o visualizando sus resultados, nunca sabes realmente cómo funcionará hasta que lo liberas.</p>
<p>Hacer que personas que nunca han usado su modelo interactúen con él a menudo revelará casos extremos en los que nunca pensó durante el entrenamiento.</p>
<p>Por ejemplo, ¿qué pasaría si alguien subiera una foto que <em>no</em> fuera de comida a nuestro modelo FoodVision Mini?</p>
<p>Una solución sería crear otro modelo que primero clasifique las imágenes como "comida" o "no comida" y pase primero la imagen de destino a través de ese modelo (esto es lo que hace <a href="https://nutrify.app">Nutrify</a>).</p>
<p>Luego, si la imagen es de "comida", pasa a nuestro modelo FoodVision Mini y se clasifica en pizza, bistec o sushi.</p>
<p>Y si "no es comida", se muestra un mensaje.</p>
<p>Pero ¿y si estas predicciones estuvieran equivocadas?</p>
<p>¿Qué pasa entonces?</p>
<p>Puedes ver cómo estas preguntas podrían continuar.</p>
<p>Por lo tanto, esto resalta la importancia de la implementación del modelo: le ayuda a descubrir errores en su modelo que no son obvios durante el entrenamiento/prueba.</p>
<img alt="Un flujo de trabajo de PyTorch con implementación de modelo adicional y paso de monitoreo" ancho="900/" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-pytorch-workflow-with-deployment.png"/>
<p><em>Cubrimos un flujo de trabajo de PyTorch en <a href="https://www.learnpytorch.io/01_pytorch_workflow/">01. Flujo de trabajo de PyTorch</a>. Pero una vez que se tiene un buen modelo, la implementación es un buen siguiente paso. El monitoreo implica ver cómo funciona su modelo en la división de datos más importante: los datos del mundo real. Para obtener más recursos sobre implementación y monitoreo, consulte <a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and-deep-learning-engineering">Recursos adicionales de PyTorch</a>.</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0565ad5e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="diferentes-tipos-de-implementacion-de-modelos-de-aprendizaje-automatico">Diferentes tipos de implementación de modelos de aprendizaje automático<a class="anchor-link" href="#diferentes-tipos-de-implementacion-de-modelos-de-aprendizaje-automatico">¶</a></h2><p>Se podrían escribir libros completos sobre los diferentes tipos de implementación de modelos de aprendizaje automático (y muchos buenos se enumeran en [Recursos adicionales de PyTorch](<a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and">https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and</a> -ingeniería-de-aprendizaje-profundo)).</p>
<p>Y el campo aún se está desarrollando en términos de mejores prácticas.</p>
<p>Pero me gusta empezar con la pregunta:</p>
<blockquote>
<p>"¿Cuál es el escenario más ideal para utilizar mi modelo de aprendizaje automático?"</p>
</blockquote>
<p>Y luego trabaje hacia atrás desde allí.</p>
<p>Por supuesto, es posible que no lo sepas de antemano. Pero eres lo suficientemente inteligente como para imaginar esas cosas.</p>
<p>En el caso de FoodVision Mini, nuestro escenario ideal podría ser:</p>
<ul>
<li>Alguien toma una foto en un dispositivo móvil (a través de una aplicación o navegador web).</li>
<li>La predicción vuelve rápidamente.</li>
</ul>
<p>Fácil.</p>
<p>Entonces tenemos dos criterios principales:</p>
<ol>
<li>El modelo debería funcionar en un dispositivo móvil (esto significa que habrá algunas restricciones informáticas).</li>
<li>El modelo debe hacer predicciones <em>rápidas</em> (porque una aplicación lenta es una aplicación aburrida).</li>
</ol>
<p>Y, por supuesto, según su caso de uso, sus requisitos pueden variar.</p>
<p>Puede notar que los dos puntos anteriores se dividen en otras dos preguntas:</p>
<ol>
<li><strong>¿A dónde irá?</strong> - Es decir, ¿dónde se almacenará?</li>
<li><strong>¿Cómo va a funcionar?</strong> - Es decir, ¿devuelve predicciones inmediatamente? ¿O vienen más tarde?</li>
</ol>
<img alt="algunas preguntas para hacer al comenzar la implementación modelos de aprendizaje automático, cuál es el caso de uso ideal del modelo, luego trabaje hacia atrás y pregunte dónde irá mi modelo y cómo funcionará" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-deployment-questions-to-ask.png" width="900/"/>
<p><em>Al comenzar a implementar modelos de aprendizaje automático, es útil comenzar preguntando cuál es el caso de uso más ideal y luego trabajar hacia atrás desde allí, preguntando hacia dónde irá el modelo y luego cómo funcionará.</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=919e0e01">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="a-donde-ira">¿A dónde irá?<a class="anchor-link" href="#a-donde-ira">¶</a></h3><p>Cuando implementas tu modelo de aprendizaje automático, ¿dónde reside?</p>
<p>El debate principal aquí suele ser en el dispositivo (también llamado borde/en el navegador) o en la nube (una computadora/servidor que no es el dispositivo <em>real</em> desde donde alguien/algo llama al modelo).</p>
<p>Ambos tienen pros y contras.</p>
<table>
<thead>
<tr>
<th><strong>Ubicación de implementación</strong></th>
<th><strong>Ventajas</strong></th>
<th><strong>Desventajas</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>En el dispositivo (borde/en el navegador)</strong></td>
<td>Puede ser muy rápido (ya que no salen datos del dispositivo)</td>
<td>Potencia informática limitada (los modelos más grandes tardan más en ejecutarse)</td>
</tr>
<tr>
<td></td>
<td>Preservación de la privacidad (nuevamente, ningún dato tiene que salir del dispositivo)</td>
<td>Espacio de almacenamiento limitado (se requiere un tamaño de modelo más pequeño)</td>
</tr>
<tr>
<td></td>
<td>No se requiere conexión a Internet (a veces)</td>
<td>A menudo se requieren habilidades específicas del dispositivo</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>En la nube</strong></td>
<td>Potencia informática casi ilimitada (puede ampliarse cuando sea necesario)</td>
<td>Los costos pueden salirse de control (si no se aplican límites de escala adecuados)</td>
</tr>
<tr>
<td></td>
<td>Puede implementar un modelo y usarlo en todas partes (a través de API)</td>
<td>Las predicciones pueden ser más lentas debido a que los datos tienen que salir del dispositivo y las predicciones tienen que regresar (latencia de red)</td>
</tr>
<tr>
<td></td>
<td>Vínculos con el ecosistema de nube existente</td>
<td>Los datos deben salir del dispositivo (esto puede causar problemas de privacidad)</td>
</tr>
</tbody>
</table>
<p>Hay más detalles sobre estos, pero dejé recursos en el <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#extra-curriculum">extracurriculum</a> para obtener más información.</p>
<p>Pongamos un ejemplo.</p>
<p>Si implementamos FoodVision Mini como una aplicación, queremos que funcione bien y rápido.</p>
<p>Entonces, ¿qué modelo preferiríamos?</p>
<ol>
<li>Un modelo en el dispositivo que funciona con una precisión del 95 % con un tiempo de inferencia (latencia) de un segundo por predicción.</li>
<li>Un modelo en la nube que funciona con una precisión del 98 % con un tiempo de inferencia de 10 segundos por predicción (un modelo mejor y más grande, pero lleva más tiempo calcularlo).</li>
</ol>
<p>He inventado estos números, pero muestran una diferencia potencial entre el dispositivo y la nube.</p>
<p>La opción 1 podría ser potencialmente un modelo más pequeño, de menor rendimiento y que funcione más rápido porque puede caber en un dispositivo móvil.</p>
<p>La opción 2 podría potencialmente ser un modelo más grande y con mayor rendimiento que requiere más computación y almacenamiento, pero tarda un poco más en ejecutarse porque tenemos que enviar datos desde el dispositivo y recuperarlos (por lo que, aunque la predicción real pueda ser rápida, el tiempo de red y la transferencia de datos debe tenerse en cuenta).</p>
<p>Para FoodVision Mini, probablemente preferiríamos la opción 1, porque el pequeño impacto en el rendimiento se ve superado con creces por la velocidad de inferencia más rápida.</p>
<p><img alt="tesla sistema de visión por computadora en el dispositivo versus en la nube" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-on-device-vs-cloud.png" width="900"/></p>
<p><em>En el caso del sistema de visión por computadora de un automóvil Tesla, ¿cuál sería mejor? ¿Un modelo más pequeño que funciona bien en el dispositivo (el modelo está en el automóvil) o un modelo más grande que funciona mejor en la nube? En este caso, preferirías que el modelo estuviera en el auto. El tiempo de red adicional que tomaría para que los datos vayan del automóvil a la nube y luego de regreso al automóvil simplemente no valdría la pena (o incluso sería potencialmente imposible en áreas con mala señal).</em></p>
<blockquote>
<p><strong>Nota:</strong> Para ver un ejemplo completo de cómo es implementar un modelo de PyTorch en un dispositivo perimetral, consulte el [tutorial de PyTorch sobre cómo lograr inferencia en tiempo real (30 fps+)](<a href="https://pytorch.org/">https://pytorch.org/</a> tutorials/intermediate/realtime_rpi.html) con un modelo de visión por computadora en una Raspberry Pi.</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=abf30596">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="como-va-a-funcionar">¿Cómo va a funcionar?<a class="anchor-link" href="#como-va-a-funcionar">¶</a></h3><p>Volviendo al caso de uso ideal, cuando implementa su modelo de aprendizaje automático, ¿cómo debería funcionar?</p>
<p>Es decir, ¿le gustaría que se le devolvieran las predicciones de inmediato?</p>
<p>¿O está bien que sucedan más tarde?</p>
<p>Estos dos escenarios generalmente se denominan:</p>
<ul>
<li><strong>En línea (en tiempo real)</strong>: las predicciones/inferencias ocurren <strong>inmediatamente</strong>. Por ejemplo, alguien sube una imagen, la imagen se transforma y se devuelven predicciones o alguien realiza una compra y un modelo verifica que la transacción no es fraudulenta para que la compra pueda realizarse.</li>
<li><strong>Sin conexión (por lotes)</strong>: las predicciones/inferencias ocurren <strong>periódicamente</strong>. Por ejemplo, una aplicación de fotos clasifica sus imágenes en diferentes categorías (como playa, hora de comer, familia, amigos) mientras su dispositivo móvil está enchufado a la carga.</li>
</ul>
<blockquote>
<p><strong>Nota:</strong> "Lote" se refiere a la inferencia que se realiza en varias muestras a la vez. Sin embargo, para agregar un poco de confusión, el procesamiento por lotes puede realizarse inmediatamente/en línea (se clasifican varias imágenes a la vez) y/o fuera de línea (se predicen/entrenan varias imágenes a la vez).</p>
</blockquote>
<p>La principal diferencia entre cada ser: las predicciones se realizan de forma inmediata o periódica.</p>
<p>Periódicamente también puede tener una escala de tiempo variable, desde cada pocos segundos hasta cada pocas horas o días.</p>
<p>Y puedes mezclar y combinar los dos.</p>
<p>En el caso de FoodVision Mini, queremos que nuestro proceso de inferencia se realice en línea (en tiempo real), de modo que cuando alguien suba una imagen de pizza, bistec o sushi, los resultados de la predicción se devuelvan inmediatamente (cualquier cosa más lenta de lo que lo haría el tiempo real). hacer una experiencia aburrida).</p>
<p>Pero para nuestro proceso de capacitación, está bien que suceda por lotes (fuera de línea), que es lo que hemos estado haciendo a lo largo de los capítulos anteriores.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1df767b0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="formas-de-implementar-un-modelo-de-aprendizaje-automatico">Formas de implementar un modelo de aprendizaje automático<a class="anchor-link" href="#formas-de-implementar-un-modelo-de-aprendizaje-automatico">¶</a></h3><p>Hemos analizado un par de opciones para implementar modelos de aprendizaje automático (en el dispositivo y en la nube).</p>
<p>Y cada uno de estos tendrá sus requisitos específicos:</p>
<p>| <strong>Herramienta/recurso</strong> | <strong>Tipo de implementación</strong> |
| ----- | ----- |
| <a href="https://developers.google.com/ml-kit">Kit de aprendizaje automático de Google</a> | En el dispositivo (Android e iOS) |
| <a href="https://developer.apple.com/documentation/coreml">Core ML de Apple</a> y <a href="https://coremltools.readme.io/docs">paquete Python <code>coremltools</code></a> | En el dispositivo (todos los dispositivos Apple) |
| <a href="https://aws.amazon.com/sagemaker/">Sagemaker de Amazon Web Service (AWS)</a> | Nube |
| <a href="https://cloud.google.com/vertex-ai">Vertex AI de Google Cloud</a> | Nube |
| <a href="https://azure.microsoft.com/en-au/services/machine-learning/">Aprendizaje automático de Azure de Microsoft</a> | Nube |
| <a href="https://huggingface.co/spaces">Abrazando espacios faciales</a> | Nube |
| API con <a href="https://fastapi.tiangolo.com">FastAPI</a> | Servidor en la nube/autohospedado |
| API con <a href="https://pytorch.org/serve/">TorchServe</a> | Servidor en la nube/autohospedado |
| <a href="https://onnx.ai/index.html">ONNX (Intercambio de redes neuronales abiertas)</a> | Muchos/general |
| Muchos más... |</p>
<blockquote>
<p><strong>Nota:</strong> Una <a href="https://en.wikipedia.org/wiki/API">interfaz de programación de aplicaciones (API)</a> es una forma en que dos (o más) programas informáticos interactúan entre sí. Por ejemplo, si su modelo se implementó como API, podría escribir un programa que pudiera enviarle datos y luego recibir predicciones.</p>
</blockquote>
<p>La opción que elija dependerá en gran medida de lo que esté creando y con quién esté trabajando.</p>
<p>Pero con tantas opciones, puede resultar muy intimidante.</p>
<p>Así que lo mejor es empezar poco a poco y hacerlo sencillo.</p>
<p>Y una de las mejores formas de hacerlo es convertir su modelo de aprendizaje automático en una aplicación de demostración con <a href="https://gradio.app">Gradio</a> y luego implementarlo en Hugging Face Spaces.</p>
<p>Más adelante haremos precisamente eso con FoodVision Mini.</p>
<img alt="herramientas y Lugares para implementar modelos de aprendizaje automático" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-tools-and-places-to-deploy-ml-models.png" width="900/"/>
<p><em>Un puñado de lugares y herramientas para alojar e implementar modelos de aprendizaje automático. Hay muchas cosas que me he perdido, así que si desea agregar más, deje una <a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">discusión en GitHub</a>.</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=8369bc51">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="que-vamos-a-cubrir">Qué vamos a cubrir<a class="anchor-link" href="#que-vamos-a-cubrir">¶</a></h2><p>Ya basta de hablar de implementar un modelo de aprendizaje automático.</p>
<p>Convirtámonos en ingenieros de aprendizaje automático e implementemos uno.</p>
<p>Nuestro objetivo es implementar nuestro modelo FoodVision a través de una aplicación de demostración de Gradio con las siguientes métricas:</p>
<ol>
<li><strong>Rendimiento:</strong> 95%+ precisión.</li>
<li><strong>Velocidad:</strong> inferencia en tiempo real de 30 FPS+ (cada predicción tiene una latencia inferior a ~0,03 s).</li>
</ol>
<p>Comenzaremos ejecutando un experimento para comparar nuestros dos mejores modelos hasta el momento: extractores de funciones EffNetB2 y ViT.</p>
<p>Luego implementaremos el que se acerque más a nuestras métricas objetivo.</p>
<p>Finalmente, terminaremos con un (GRANDE) bono sorpresa.</p>
<table>
<thead>
<tr>
<th><strong>Tema</strong></th>
<th><strong>Contenido</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>0. Obteniendo configuración</strong></td>
<td>Hemos escrito bastante código útil en las últimas secciones, descarguémoslo y asegurémonos de poder usarlo nuevamente.</td>
</tr>
<tr>
<td><strong>1. Obtener datos</strong></td>
<td>Descarguemos el conjunto de datos <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip"><code>pizza_steak_sushi_20_percent.zip</code></a> para que podamos entrenar nuestros modelos que anteriormente tenían mejor rendimiento en el mismo conjunto de datos.</td>
</tr>
<tr>
<td><strong>2. Esquema del experimento de implementación del modelo FoodVision Mini</strong></td>
<td>Incluso en el proyecto del tercer hito, todavía realizaremos múltiples experimentos para ver qué modelo (EffNetB2 o ViT) se acerca más a nuestras métricas objetivo.</td>
</tr>
<tr>
<td><strong>3. Creando un extractor de funciones EffNetB2</strong></td>
<td>Un extractor de funciones EfficientNetB2 tuvo el mejor rendimiento en nuestro conjunto de datos de pizza, bistec y sushi en [07. Seguimiento de experimentos de PyTorch] (<a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/">https://www.learnpytorch.io/07_pytorch_experiment_tracking/</a>), vamos a recrearlo como candidato para su implementación.</td>
</tr>
<tr>
<td><strong>4. Creando un extractor de funciones ViT</strong></td>
<td>Un extractor de funciones ViT ha sido el modelo con mejor rendimiento hasta ahora en nuestro conjunto de datos de pizza, bistec y sushi en <a href="https://www.learnpytorch.io/08_pytorch_paper_replicating/">08. PyTorch Paper Replicating</a>, vamos a recrearlo como candidato para su implementación junto con EffNetB2.</td>
</tr>
<tr>
<td><strong>5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas</strong></td>
<td>Hemos creado dos de los modelos con mejor rendimiento hasta el momento. Hagamos predicciones con ellos y realicemos un seguimiento de sus resultados.</td>
</tr>
<tr>
<td><strong>6. Comparación de resultados de modelos, tiempos de predicción y tamaño</strong></td>
<td>Comparemos nuestros modelos para ver cuál funciona mejor con nuestros objetivos.</td>
</tr>
<tr>
<td><strong>7. Dar vida a FoodVision Mini creando una demostración de Gradio</strong></td>
<td>Uno de nuestros modelos funciona mejor que el otro (en términos de nuestros objetivos), así que ¡convirtámoslo en una demostración de aplicación funcional!</td>
</tr>
<tr>
<td><strong>8. Convirtiendo nuestra demostración de FoodVision Mini Gradio en una aplicación implementable</strong></td>
<td>Nuestra demostración de la aplicación Gradio funciona localmente, ¡preparémosla para su implementación!</td>
</tr>
<tr>
<td><strong>9. Implementando nuestra demostración de Gradio en HuggingFace Spaces</strong></td>
<td>¡Llevemos FoodVision Mini a la web y hagámoslo accesible públicamente para todos!</td>
</tr>
<tr>
<td><strong>10. Creando una GRAN sorpresa</strong></td>
<td>Hemos creado FoodVision Mini, es hora de dar un paso más.</td>
</tr>
<tr>
<td><strong>11. Desplegando nuestra GRAN sorpresa</strong></td>
<td>Implementar una aplicación fue divertido, ¿qué tal si hacemos dos?</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c2cec63e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="donde-puedes-obtener-ayuda">¿Dónde puedes obtener ayuda?<a class="anchor-link" href="#donde-puedes-obtener-ayuda">¶</a></h2><p>Todos los materiales de este curso <a href="https://github.com/mrdbourke/pytorch-deep-learning">están disponibles en GitHub</a>.</p>
<p>Si tiene problemas, puede hacer una pregunta en el curso [página de debates de GitHub] (<a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">https://github.com/mrdbourke/pytorch-deep-learning/discussions</a>).</p>
<p>Y, por supuesto, está la <a href="https://pytorch.org/docs/stable/index.html">documentación de PyTorch</a> y los <a href="https://discuss.pytorch.org/">foros de desarrolladores de PyTorch</a>, un lugar muy útil para todo lo relacionado con PyTorch.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2598c6e3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="0-configuracion">0. Configuración<a class="anchor-link" href="#0-configuracion">¶</a></h2><p>Como lo hicimos anteriormente, asegurémonos de tener todos los módulos que necesitaremos para esta sección.</p>
<p>Importaremos los scripts de Python (como <code>data_setup.py</code> y <code>engine.py</code>) que creamos en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/">05. PyTorch se vuelve modular</a>.</p>
<p>Para hacerlo, descargaremos el directorio <a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular"><code>going_modular</code></a> del repositorio <a href="https://github.com/mrdbourke/pytorch-deep-learning"><code>pytorch-deep-learning</code></a> (si aún no lo tenemos).</p>
<p>También obtendremos el paquete <a href="https://github.com/TylerYep/torchinfo"><code>torchinfo</code></a> si no está disponible.</p>
<p><code>torchinfo</code> nos ayudará más adelante a darnos una representación visual de nuestro modelo.</p>
<p>Y dado que más adelante usaremos el paquete <code>torchvision</code> v0.13 (disponible a partir de julio de 2022), nos aseguraremos de tener las últimas versiones.</p>
<blockquote>
<p><strong>Nota:</strong> Si estás usando Google Colab y aún no tienes una GPU activada, ahora es el momento de activar una a través de <code>Runtime -&gt; Cambiar tipo de tiempo de ejecución -&gt; Acelerador de hardware -&gt; GPU</code> .</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=505447aa">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-1">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Para que este portátil se ejecute con API actualizadas, necesitamos torch 1.12+ y torchvision 0.13+.</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torchvision</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"."</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">12</span><span class="p">,</span> <span class="s2">"torch version should be 1.12+"</span>
    <span class="k">assert</span> <span class="nb">int</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"."</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;=</span> <span class="mi">13</span><span class="p">,</span> <span class="s2">"torchvision version should be 0.13+"</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"torch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"torchvision version: </span><span class="si">{</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] torch/torchvision versions not as required, installing nightly versions."</span><span class="p">)</span>
    <span class="err">!</span><span class="n">pip3</span> <span class="n">install</span> <span class="o">-</span><span class="n">U</span> <span class="n">torch</span> <span class="n">torchvision</span> <span class="n">torchaudio</span> <span class="o">--</span><span class="n">extra</span><span class="o">-</span><span class="n">index</span><span class="o">-</span><span class="n">url</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">download</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="n">whl</span><span class="o">/</span><span class="n">cu113</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torchvision</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"torch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"torchvision version: </span><span class="si">{</span><span class="n">torchvision</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-1"># Para que este portátil se ejecute con API actualizadas, necesitamos torch 1.12+ y torchvision 0.13+.
try:
    import torch
    import torchvision
    assert int(torch.__version__.split(".")[1]) &gt;= 12, "torch version should be 1.12+"
    assert int(torchvision.__version__.split(".")[1]) &gt;= 13, "torchvision version should be 0.13+"
    print(f"torch version: {torch.__version__}")
    print(f"torchvision version: {torchvision.__version__}")
except:
    print(f"[INFO] torch/torchvision versions not as required, installing nightly versions.")
    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113
    import torch
    import torchvision
    print(f"torch version: {torch.__version__}")
    print(f"torchvision version: {torchvision.__version__}")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=42c43b1d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<blockquote>
<p><strong>Nota:</strong> Si está utilizando Google Colab y la celda de arriba comienza a instalar varios paquetes de software, es posible que deba reiniciar su tiempo de ejecución después de ejecutar la celda de arriba. Después de reiniciar, puede ejecutar la celda nuevamente y verificar que tenga las versiones correctas de <code>torch</code> y <code>torchvision</code>.</p>
</blockquote>
<p>Ahora continuaremos con las importaciones regulares, configurando el código independiente del dispositivo y esta vez también obtendremos [<code>helper_functions.py</code>](<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/">https://github.com/mrdbourke/pytorch-deep-learning/blob/</a> main/helper_functions.py) script de GitHub.</p>
<p>El script <code>helper_functions.py</code> contiene varias funciones que creamos en secciones anteriores:</p>
<ul>
<li><code>set_seeds()</code> para configurar las semillas aleatorias (creadas en <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#create-a-helper-function-to-set-seeds">07. Sección 0 de seguimiento de experimentos de PyTorch</a>).</li>
<li><code>download_data()</code> para descargar una fuente de datos mediante un enlace (creado en [07. Sección 1 de seguimiento de experimentos de PyTorch] (<a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#1-get-data">https://www.learnpytorch.io/07_pytorch_experiment_tracking/#1-get-data</a>)).</li>
<li><code>plot_loss_curves()</code> para inspeccionar los resultados del entrenamiento de nuestro modelo (creado en [04. PyTorch Custom Datasets sección 7.8](<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#78-plot-the-loss-curves-of-">https://www.learnpytorch.io/04_pytorch_custom_datasets/#78-plot-the-loss-curves-of-</a> modelo-0))</li>
</ul>
<blockquote>
<p><strong>Nota:</strong> Puede ser una mejor idea que muchas de las funciones en el script <code>helper_functions.py</code> se fusionen en <code>going_modular/going_modular/utils.py</code>, tal vez sea una extensión que le gustaría probar .</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=d840f165">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-2">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Continuar con las importaciones regulares</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="c1"># Intente obtener torchinfo, instálelo si no funciona</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"[INFO] Couldn't find torchinfo... installing it."</span><span class="p">)</span>
    <span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">torchinfo</span>
    <span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># Intente importar el directorio going_modular, descárguelo de GitHub si no funciona</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span><span class="p">,</span> <span class="n">engine</span>
    <span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">download_data</span><span class="p">,</span> <span class="n">set_seeds</span><span class="p">,</span> <span class="n">plot_loss_curves</span>
<span class="k">except</span><span class="p">:</span>
    <span class="c1"># Get the going_modular scripts</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub."</span><span class="p">)</span>
    <span class="err">!</span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mrdbourke</span><span class="o">/</span><span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span>
    <span class="err">!</span><span class="n">mv</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">going_modular</span> <span class="o">.</span>
    <span class="err">!</span><span class="n">mv</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">helper_functions</span><span class="o">.</span><span class="n">py</span> <span class="o">.</span> <span class="c1"># get the helper_functions.py script</span>
    <span class="err">!</span><span class="n">rm</span> <span class="o">-</span><span class="n">rf</span> <span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span>
    <span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span><span class="p">,</span> <span class="n">engine</span>
    <span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">download_data</span><span class="p">,</span> <span class="n">set_seeds</span><span class="p">,</span> <span class="n">plot_loss_curves</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-2"># Continuar con las importaciones regulares
import matplotlib.pyplot as plt
import torch
import torchvision

from torch import nn
from torchvision import transforms

# Intente obtener torchinfo, instálelo si no funciona
try:
    from torchinfo import summary
except:
    print("[INFO] Couldn't find torchinfo... installing it.")
    !pip install -q torchinfo
    from torchinfo import summary

# Intente importar el directorio going_modular, descárguelo de GitHub si no funciona
try:
    from going_modular.going_modular import data_setup, engine
    from helper_functions import download_data, set_seeds, plot_loss_curves
except:
    # Get the going_modular scripts
    print("[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.")
    !git clone https://github.com/mrdbourke/pytorch-deep-learning
    !mv pytorch-deep-learning/going_modular .
    !mv pytorch-deep-learning/helper_functions.py . # get the helper_functions.py script
    !rm -rf pytorch-deep-learning
    from going_modular.going_modular import data_setup, engine
    from helper_functions import download_data, set_seeds, plot_loss_curves</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6d3865a8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Finalmente, configuraremos un código independiente del dispositivo para asegurarnos de que nuestros modelos se ejecuten en la GPU.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9a9b02f5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-3">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
<span class="n">device</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-3">device = "cuda" if torch.cuda.is_available() else "cpu"
device</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=77eb0e12">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="1-obtener-datos">1. Obtener datos<a class="anchor-link" href="#1-obtener-datos">¶</a></h2><p>Lo dejamos en <a href="https://www.learnpytorch.io/08_pytorch_paper_replicating/#106-save-feature-extractor-vit-model-and-check-file-size">08. PyTorch Paper Replicating</a> comparando nuestro propio modelo de extractor de funciones Vision Transformer (ViT) con El modelo de extracción de características EfficientNetB2 (EffNetB2) que creamos en <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#9-load-in-the-best-model-and-make-predictions-with-it">07. Seguimiento de experimentos de PyTorch</a>.</p>
<p>Y descubrimos que había una ligera diferencia en la comparación.</p>
<p>El modelo EffNetB2 se entrenó en el 20 % de los datos de pizza, bistec y sushi de Food101, mientras que el modelo ViT se entrenó en el 10 %.</p>
<p>Dado que nuestro objetivo es implementar el mejor modelo para nuestro problema FoodVision Mini, comencemos descargando el [conjunto de datos del 20 % de pizza, bistec y sushi] (<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main">https://github.com/mrdbourke/pytorch-deep-learning/blob/main</a> /data/pizza_steak_sushi_20_percent.zip) y entrene un extractor de funciones EffNetB2 y un extractor de funciones ViT en él y luego compare los dos modelos.</p>
<p>De esta manera, compararemos manzanas con manzanas (un modelo entrenado en un conjunto de datos con otro modelo entrenado en el mismo conjunto de datos).</p>
<blockquote>
<p><strong>Nota:</strong> El conjunto de datos que estamos descargando es una muestra de todo el <a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html#food101">conjunto de datos de Food101</a> (101 clases de comida con 1.000 imágenes cada una). Más específicamente, 20% se refiere al 20% de imágenes de las clases de pizza, bistec y sushi seleccionadas al azar. Puede ver cómo se creó este conjunto de datos en <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb"><code>extras/04_custom_data_creation.ipynb</code></a> y más detalles en [ 04. Sección 1 de conjuntos de datos personalizados de PyTorch] (<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data">https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data</a>).</p>
</blockquote>
<p>Podemos descargar los datos usando la función <code>download_data()</code> que creamos en <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#1-get-data">07. Sección 1 de seguimiento de experimentos de PyTorch</a> de [<code>helper_functions.py</code>](<a href="https://github.com/mrdbourke/pytorch-deep-learning">https://github.com/mrdbourke/pytorch-deep-learning</a> /blob/main/helper_functions.py).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4ed6e71f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-4">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Descargue imágenes de pizza, bistec y sushi desde GitHub</span>
<span class="n">data_20_percent_path</span> <span class="o">=</span> <span class="n">download_data</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip"</span><span class="p">,</span>
                                     <span class="n">destination</span><span class="o">=</span><span class="s2">"pizza_steak_sushi_20_percent"</span><span class="p">)</span>

<span class="n">data_20_percent_path</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-4"># Descargue imágenes de pizza, bistec y sushi desde GitHub
data_20_percent_path = download_data(source="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip",
                                     destination="pizza_steak_sushi_20_percent")

data_20_percent_path</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ca45e09a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Maravilloso!</p>
<p>Ahora que tenemos un conjunto de datos, creemos rutas de entrenamiento y prueba.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6c86d2cd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-5">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Configurar rutas de directorio para entrenar y probar imágenes</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="n">data_20_percent_path</span> <span class="o">/</span> <span class="s2">"train"</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="n">data_20_percent_path</span> <span class="o">/</span> <span class="s2">"test"</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-5"># Configurar rutas de directorio para entrenar y probar imágenes
train_dir = data_20_percent_path / "train"
test_dir = data_20_percent_path / "test"</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=908f7d61">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="2-esquema-del-experimento-de-implementacion-del-modelo-foodvision-mini">2. Esquema del experimento de implementación del modelo FoodVision Mini<a class="anchor-link" href="#2-esquema-del-experimento-de-implementacion-del-modelo-foodvision-mini">¶</a></h2><p>El modelo implementado ideal, FoodVision Mini, funciona bien y rápido.</p>
<p>Nos gustaría que nuestro modelo funcione lo más cerca posible del tiempo real.</p>
<p>En este caso, el tiempo real es ~30 FPS (cuadros por segundo) porque eso es [aproximadamente qué tan rápido puede ver el ojo humano] (<a href="https://www.healthline.com/health/human-eye-fps">https://www.healthline.com/health/human-eye-fps</a>) (hay debate sobre esto, pero usemos ~30FPS como nuestro punto de referencia).</p>
<p>Y para clasificar tres clases diferentes (pizza, bistec y sushi), nos gustaría un modelo que funcione con una precisión superior al 95 %.</p>
<p>Por supuesto, una mayor precisión sería buena, pero esto podría sacrificar la velocidad.</p>
<p>Entonces nuestros objetivos son:</p>
<ol>
<li><strong>Rendimiento</strong>: un modelo que funciona con una precisión superior al 95 %.</li>
<li><strong>Velocidad</strong>: un modelo que puede clasificar una imagen a ~30 FPS (tiempo de inferencia de 0,03 segundos por imagen, también conocido como latencia).</li>
</ol>
<img alt="mini objetivos de foodvision en términos de tiempo de desempeño y de inferencia." ancho="750/" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployments-speed-vs-inference.png"/>
<p><em>Objetivos de implementación de FoodVision Mini. Nos gustaría un modelo de predicción rápida y con buen rendimiento (porque una aplicación lenta es aburrida).</em></p>
<p>Pondremos énfasis en la velocidad, es decir, preferiríamos un modelo con un rendimiento superior al 90 % a ~30 FPS que un modelo con un rendimiento superior al 95 % a 10 FPS.</p>
<p>Para intentar lograr estos resultados, incluyamos nuestros modelos con mejor rendimiento de las secciones anteriores:</p>
<ol>
<li><strong>Extractor de funciones EffNetB2</strong> (EffNetB2 para abreviar): creado originalmente en <a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#75-create-feature-extractor-models">07. Sección 7.5 de seguimiento de experimentos de PyTorch</a> usando [<code>torchvision.models.ficientnet_b2()</code>](<a href="https://pytorch.org">https://pytorch.org</a> /vision/stable/models/generated/torchvision.models.ficientnet_b2.html#ficientnet-b2) con capas de <code>clasificador</code> ajustadas.</li>
<li><strong>Extractor de funciones ViT-B/16</strong> (ViT para abreviar): creado originalmente en [08. Sección 10 de replicación de papel de PyTorch] (<a href="https://www.learnpytorch.io/08_pytorch_paper_replicating/#10-using-a-pretrained-vit-from-torchvisionmodels-on-the-same-dataset">https://www.learnpytorch.io/08_pytorch_paper_replicating/#10-using-a-pretrained-vit-from-torchvisionmodels-on-the-same-dataset</a>) usando <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.vit_b_16.html#vit-b-16"><code>torchvision.models.vit_b_16 ()</code></a> con capas de <code>cabeza</code> ajustadas.<ul>
<li><strong>Nota</strong> ViT-B/16 significa "Vision Transformer Base, tamaño de parche 16".</li>
</ul>
</li>
</ol>
<p><img alt="experimentos de modelado para mini implementaciones de foodvision, uno Modelo de extractor de características effnetb2 y modelo de extractor de características de transformador de visión" ancho="750" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-two-experiments.png"/></p>
<blockquote>
<p><strong>Nota:</strong> Un "modelo de extracción de características" a menudo comienza con un modelo que ha sido previamente entrenado en un conjunto de datos similar a su propio problema. Las capas base del modelo previamente entrenado a menudo se dejan congeladas (los patrones/pesos previamente entrenados permanecen iguales) mientras que algunas de las capas superiores (o clasificador/cabeza de clasificación) se personalizan según su propio problema entrenando con sus propios datos. Cubrimos el concepto de un modelo de extracción de características en [06. Sección 3.4 de aprendizaje por transferencia de PyTorch] (<a href="https://www.learnpytorch.io/06_pytorch_transfer_learning/#34-freezing-the-base-model-and-changing-the-output-layer-to-suit-our-needs">https://www.learnpytorch.io/06_pytorch_transfer_learning/#34-freezing-the-base-model-and-changing-the-output-layer-to-suit-our-needs</a>).</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=89626ee3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="3-creando-un-extractor-de-funciones-effnetb2">3. Creando un extractor de funciones EffNetB2<a class="anchor-link" href="#3-creando-un-extractor-de-funciones-effnetb2">¶</a></h2><p>Primero creamos un modelo de extracción de características EffNetB2 en [07. Sección 7.5 de seguimiento de experimentos de PyTorch] (<a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#75-create-feature-extractor-models">https://www.learnpytorch.io/07_pytorch_experiment_tracking/#75-create-feature-extractor-models</a>).</p>
<p>Y al final de esa sección vimos que funcionó muy bien.</p>
<p>Así que ahora vamos a recrearlo aquí para que podamos comparar sus resultados con un extractor de funciones de ViT entrenado con los mismos datos.</p>
<p>Para hacerlo podemos:</p>
<ol>
<li>Configure los pesos previamente entrenados como <a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.ficientnet_b2.html#torchvision.models.EfficientNet_B2_Weights"><code>weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT</code></a>, donde "<code>DEFAULT</code>" significa "mejor disponible actualmente" (o podría usar <code>weights="DEFAULT"</code>).</li>
<li>Obtenga las transformaciones de la imagen del modelo previamente entrenado a partir de los pesos con el método <code>transforms()</code> (los necesitamos para poder convertir nuestras imágenes al mismo formato en el que se entrenó el EffNetB2 previamente entrenado).</li>
<li>Cree una instancia de modelo previamente entrenada pasando los pesos a una instancia de [<code>torchvision.models.ficientnet_b2</code>](<a href="https://pytorch.org/vision/stable/models/generated/torchvision.models.ficientnet_b2.html#ficientnet">https://pytorch.org/vision/stable/models/generated/torchvision.models.ficientnet_b2.html#ficientnet</a> -b2).</li>
<li>Congele las capas base en el modelo.</li>
<li>Actualizar el cabezal del clasificador para adaptarlo a nuestros propios datos.</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=687129c2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-6">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># 1. Configurar pesas EffNetB2 previamente entrenadas</span>
<span class="n">effnetb2_weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>

<span class="c1"># 2. Obtenga transformaciones EffNetB2</span>
<span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">effnetb2_weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>

<span class="c1"># 3. Configurar el modelo previamente entrenado</span>
<span class="n">effnetb2</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">effnetb2_weights</span><span class="p">)</span> <span class="c1"># could also use weights="DEFAULT"</span>

<span class="c1"># 4. Congele las capas base en el modelo (esto congelará todas las capas para empezar)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-6"># 1. Configurar pesas EffNetB2 previamente entrenadas
effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT

# 2. Obtenga transformaciones EffNetB2
effnetb2_transforms = effnetb2_weights.transforms()

# 3. Configurar el modelo previamente entrenado
effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights) # could also use weights="DEFAULT"

# 4. Congele las capas base en el modelo (esto congelará todas las capas para empezar)
for param in effnetb2.parameters():
    param.requires_grad = False</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=55f8c763">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Ahora, para cambiar el encabezado del clasificador, primero inspeccionémoslo usando el atributo "clasificador" de nuestro modelo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=482f1cf6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-7">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Consulte el cabezal clasificador EffNetB2</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">classifier</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-7"># Consulte el cabezal clasificador EffNetB2
effnetb2.classifier</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=19619350">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Excelente! Para cambiar el encabezado del clasificador para adaptarlo a nuestro propio problema, reemplacemos la variable <code>out_features</code> con el mismo número de clases que tenemos (en nuestro caso, <code>out_features=3</code>, una para pizza, bistec, sushi).</p>
<blockquote>
<p><strong>Nota:</strong> Este proceso de cambiar las capas de salida/cabezal clasificador dependerá del problema en el que esté trabajando. Por ejemplo, si quisiera un <em>número</em> diferente de salidas o un <em>tipo</em> diferente de salida, tendría que cambiar las capas de salida en consecuencia.</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ce32b47b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-8">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># 5. Actualice el cabezal del clasificador.</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="c1"># keep dropout layer same</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="c1"># keep in_features same </span>
              <span class="n">out_features</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># change out_features to suit our number of classes</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-8"># 5. Actualice el cabezal del clasificador.
effnetb2.classifier = nn.Sequential(
    nn.Dropout(p=0.3, inplace=True), # keep dropout layer same
    nn.Linear(in_features=1408, # keep in_features same 
              out_features=3)) # change out_features to suit our number of classes</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b41d55f5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Hermoso!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c4e31bd4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="31-creando-una-funcion-para-hacer-un-extractor-de-caracteristicas-effnetb2">3.1 Creando una función para hacer un extractor de características EffNetB2<a class="anchor-link" href="#31-creando-una-funcion-para-hacer-un-extractor-de-caracteristicas-effnetb2">¶</a></h3><p>Parece que nuestro extractor de funciones EffNetB2 está listo para funcionar; sin embargo, dado que aquí hay bastantes pasos involucrados, ¿qué tal si convertimos el código anterior en una función que podamos reutilizar más adelante?</p>
<p>Lo llamaremos <code>create_effnetb2_model()</code> y necesitará un número personalizable de clases y un parámetro inicial aleatorio para su reproducibilidad.</p>
<p>Idealmente, devolverá un extractor de funciones EffNetB2 junto con sus transformaciones asociadas.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6541597c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-9">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="k">def</span> <span class="nf">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Creates an EfficientNetB2 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of classes in the classifier head. </span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): EffNetB2 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): EffNetB2 image transforms.</span>
<span class="sd">    """</span>
    <span class="c1"># 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># 4. Freeze all layers in base model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># 5. Change classifier head with random seed for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-9">def create_effnetb2_model(num_classes:int=3, 
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head. 
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model. 
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # 4. Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # 5. Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )
    
    return model, transforms</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a5b91a57">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Guau! Es una función muy bonita, probémosla.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=62808c55">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-10">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="n">effnetb2</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                                      <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-10">effnetb2, effnetb2_transforms = create_effnetb2_model(num_classes=3,
                                                      seed=42)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1271ac57">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Sin errores, genial, ahora para probarlo realmente, obtengamos un resumen con <code>torchinfo.summary()</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a5cbc7e6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-11">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># # Imprimir resumen del modelo EffNetB2 (descomentar para obtener un resultado completo)</span>
<span class="c1"># resumen(effnetb2,</span>
<span class="c1"># tamaño_entrada=(1, 3, 224, 224),</span>
<span class="c1"># col_names=["input_size", "output_size", "num_params", "entrenable"],</span>
<span class="c1"># ancho_columna=20,</span>
<span class="c1"># row_settings=["var_names"])</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-11">from torchinfo import summary

# # Imprimir resumen del modelo EffNetB2 (descomentar para obtener un resultado completo)
# resumen(effnetb2,
# tamaño_entrada=(1, 3, 224, 224),
# col_names=["input_size", "output_size", "num_params", "entrenable"],
# ancho_columna=20,
# row_settings=["var_names"])</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a40a5fdd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<img alt="resumen del modelo de extractor de funciones effnetb2" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-effnetb2-feature-extractor.png" width="900/"/>
<p>¡Capas base congeladas, capas superiores entrenables y personalizadas!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=37f9837a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="32-creando-cargadores-de-datos-para-effnetb2">3.2 Creando cargadores de datos para EffNetB2<a class="anchor-link" href="#32-creando-cargadores-de-datos-para-effnetb2">¶</a></h3><p>Nuestro extractor de funciones EffNetB2 está listo, es hora de crear algunos <code>DataLoader</code>.</p>
<p>Podemos hacer esto usando la función <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/data_setup.py"><code>data_setup.create_dataloaders()</code></a> que creamos en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#2-create-datasets-and-dataloaders-data_setuppy"> 05. PyTorch Going Modular sección 2</a>.</p>
<p>Usaremos un <code>batch_size</code> de 32 y transformaremos nuestras imágenes usando <code>effnetb2_transforms</code> para que estén en el mismo formato en el que se entrenó nuestro modelo <code>effnetb2</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=5658ad9c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-12">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Configurar cargadores de datos</span>
<span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span>
<span class="n">train_dataloader_effnetb2</span><span class="p">,</span> <span class="n">test_dataloader_effnetb2</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="n">data_setup</span><span class="o">.</span><span class="n">create_dataloaders</span><span class="p">(</span><span class="n">train_dir</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                                                 <span class="n">test_dir</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                                                 <span class="n">transform</span><span class="o">=</span><span class="n">effnetb2_transforms</span><span class="p">,</span>
                                                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-12"># Configurar cargadores de datos
from going_modular.going_modular import data_setup
train_dataloader_effnetb2, test_dataloader_effnetb2, class_names = data_setup.create_dataloaders(train_dir=train_dir,
                                                                                                 test_dir=test_dir,
                                                                                                 transform=effnetb2_transforms,
                                                                                                 batch_size=32)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0071f49b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="33-entrenamiento-del-extractor-de-funciones-de-effnetb2">3.3 Entrenamiento del extractor de funciones de EffNetB2<a class="anchor-link" href="#33-entrenamiento-del-extractor-de-funciones-de-effnetb2">¶</a></h3><p>Modelo listo, <code>DataLoader</code>s listo, ¡entrenemos!</p>
<p>Al igual que en [07. Sección 7.6 de seguimiento de experimentos de PyTorch] (<a href="https://www.learnpytorch.io/07_pytorch_experiment_tracking/#76-create-experiments-and-set-up-training-code">https://www.learnpytorch.io/07_pytorch_experiment_tracking/#76-create-experiments-and-set-up-training-code</a>), diez épocas deberían ser suficientes para obtener buenos resultados.</p>
<p>Podemos hacerlo creando un optimizador (usaremos [<code>torch.optim.Adam()</code>](<a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim">https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim</a> .Adam) con una tasa de aprendizaje de <code>1e-3</code>), una función de pérdida (usaremos [<code>torch.nn.CrossEntropyLoss()</code>](<a href="https://pytorch.org/docs/stable/generated/torch">https://pytorch.org/docs/stable/generated/torch</a> .nn.CrossEntropyLoss.html) para clasificación de clases múltiples) y luego pasarlos junto con nuestro <code>DataLoader</code>s al [<code>engine.train()</code>](<a href="https://github.com/mrdbourke/pytorch-deep">https://github.com/mrdbourke/pytorch-deep</a> -learning/blob/main/going_modular/going_modular/engine.py) función que creamos en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them">05. PyTorch Going Modular sección 4</a>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=51cfc5ec">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-13">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Optimizador de configuración</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1"># Función de pérdida de configuración</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Establezca semillas para la reproducibilidad y entrene el modelo.</span>
<span class="n">set_seeds</span><span class="p">()</span>
<span class="n">effnetb2_results</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2</span><span class="p">,</span>
                                <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader_effnetb2</span><span class="p">,</span>
                                <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader_effnetb2</span><span class="p">,</span>
                                <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-13">from going_modular.going_modular import engine

# Optimizador de configuración
optimizer = torch.optim.Adam(params=effnetb2.parameters(),
                             lr=1e-3)
# Función de pérdida de configuración
loss_fn = torch.nn.CrossEntropyLoss()

# Establezca semillas para la reproducibilidad y entrene el modelo.
set_seeds()
effnetb2_results = engine.train(model=effnetb2,
                                train_dataloader=train_dataloader_effnetb2,
                                test_dataloader=test_dataloader_effnetb2,
                                epochs=10,
                                optimizer=optimizer,
                                loss_fn=loss_fn,
                                device=device)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3d7877ba">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="34-inspeccionando-las-curvas-de-perdida-de-effnetb2">3.4 Inspeccionando las curvas de pérdida de EffNetB2<a class="anchor-link" href="#34-inspeccionando-las-curvas-de-perdida-de-effnetb2">¶</a></h3><p>¡Lindo!</p>
<p>Como vimos en 07. Seguimiento de experimentos de PyTorch, el modelo de extracción de características EffNetB2 funciona bastante bien con nuestros datos.</p>
<p>Convirtamos sus resultados en curvas de pérdidas para inspeccionarlos más a fondo.</p>
<blockquote>
<p><strong>Nota:</strong> Las curvas de pérdida son una de las mejores formas de visualizar el rendimiento de su modelo. Para obtener más información sobre las curvas de pérdidas, consulte <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#8-what-should-an-ideal-loss-curve-look-like">04. Sección 8 de conjuntos de datos personalizados de PyTorch: ¿Cómo debería ser una curva de pérdida ideal?</a></p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3305c213">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-14">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">plot_loss_curves</span>

<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">effnetb2_results</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-14">from helper_functions import plot_loss_curves

plot_loss_curves(effnetb2_results)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=47482f5e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Guau!</p>
<p>Esas son algunas curvas de pérdidas bonitas.</p>
<p>Parece que nuestro modelo está funcionando bastante bien y tal vez se beneficiaría de un entrenamiento un poco más largo y potencialmente de algo de [aumento de datos](<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data">https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data</a> -aumento) (para ayudar a prevenir un posible sobreajuste que se produzca debido a un entrenamiento más prolongado).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bdb3a937">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="35-guardar-el-extractor-de-funciones-de-effnetb2">3.5 Guardar el extractor de funciones de EffNetB2<a class="anchor-link" href="#35-guardar-el-extractor-de-funciones-de-effnetb2">¶</a></h3><p>Ahora que tenemos un modelo entrenado con buen rendimiento, guardémoslo en un archivo para poder importarlo y usarlo más tarde.</p>
<p>Para guardar nuestro modelo podemos usar la función <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/utils.py"><code>utils.save_model()</code></a> que creamos en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#5-creating-a-function-to-save-the-model-utilspy">05. PyTorch Going Modular sección 5</a>.</p>
<p>Estableceremos <code>target_dir</code> en <code>"models"</code> y <code>model_name</code> en <code>"09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"</code> (un poco completo, pero al menos sabemos lo que está pasando).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7a413d5e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-15">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="c1"># guardar el modelo</span>
<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">"models"</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="s2">"09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-15">from going_modular.going_modular import utils

# guardar el modelo
utils.save_model(model=effnetb2,
                 target_dir="models",
                 model_name="09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bcdd1230">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="36-comprobar-el-tamano-del-extractor-de-funciones-effnetb2">3.6 Comprobar el tamaño del extractor de funciones EffNetB2<a class="anchor-link" href="#36-comprobar-el-tamano-del-extractor-de-funciones-effnetb2">¶</a></h3><p>Dado que uno de nuestros criterios para implementar un modelo que impulse FoodVision Mini es la <strong>velocidad</strong> (~30 FPS o mejor), verifiquemos el tamaño de nuestro modelo.</p>
<p>¿Por qué comprobar el tamaño?</p>
<p>Bueno, aunque no siempre es así, el tamaño de un modelo puede influir en su velocidad de inferencia.</p>
<p>Es decir, si un modelo tiene más parámetros, generalmente realiza más operaciones y cada una de estas operaciones requiere cierta potencia informática.</p>
<p>Y como nos gustaría que nuestro modelo funcione en dispositivos con potencia informática limitada (por ejemplo, en un dispositivo móvil o en un navegador web), generalmente, cuanto más pequeño sea el tamaño, mejor (siempre que siga funcionando bien en términos de precisión). .</p>
<p>Para verificar el tamaño de nuestro modelo en bytes, podemos usar <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path"><code>pathlib.Path.stat("path_to_model").st_size</code></a> de Python .stat) y luego podemos convertirlo (aproximadamente) a megabytes dividiéndolo por <code>(1024*1024)</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=f2de175f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-16">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes</span>
<span class="n">pretrained_effnetb2_model_size</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"</span><span class="p">)</span><span class="o">.</span><span class="n">stat</span><span class="p">()</span><span class="o">.</span><span class="n">st_size</span> <span class="o">//</span> <span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> <span class="c1"># division converts bytes to megabytes (roughly) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Pretrained EffNetB2 feature extractor model size: </span><span class="si">{</span><span class="n">pretrained_effnetb2_model_size</span><span class="si">}</span><span class="s2"> MB"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-16">from pathlib import Path

# Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes
pretrained_effnetb2_model_size = Path("models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) 
print(f"Pretrained EffNetB2 feature extractor model size: {pretrained_effnetb2_model_size} MB")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=741e0e07">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="37-recopilacion-de-estadisticas-del-extractor-de-funciones-de-effnetb2">3.7 Recopilación de estadísticas del extractor de funciones de EffNetB2<a class="anchor-link" href="#37-recopilacion-de-estadisticas-del-extractor-de-funciones-de-effnetb2">¶</a></h3><p>Tenemos algunas estadísticas sobre nuestro modelo de extractor de funciones EffNetB2, como pérdida de prueba, precisión de la prueba y tamaño del modelo. ¿Qué tal si las recopilamos todas en un diccionario para poder compararlas con el próximo extractor de funciones ViT?</p>
<p>Y calcularemos uno extra por diversión, el número total de parámetros.</p>
<p>Podemos hacerlo contando el número de elementos (o patrones/pesos) en <code>effnetb2.parameters()</code>. Accederemos al número de elementos en cada parámetro usando <a href="https://pytorch.org/docs/stable/generated/torch.numel.html"><code>torch.numel()</code></a> (abreviatura de "número de elementos ") método.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3be32bff">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-17">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Cuente el número de parámetros en EffNetB2</span>
<span class="n">effnetb2_total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">effnetb2_total_params</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-17"># Cuente el número de parámetros en EffNetB2
effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())
effnetb2_total_params</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=22ada7f9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Excelente!</p>
<p>Ahora pongamos todo en un diccionario para poder hacer comparaciones más adelante.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c4d1e397">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-18">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Crear un diccionario con estadísticas de EffNetB2</span>
<span class="n">effnetb2_stats</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"test_loss"</span><span class="p">:</span> <span class="n">effnetb2_results</span><span class="p">[</span><span class="s2">"test_loss"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                  <span class="s2">"test_acc"</span><span class="p">:</span> <span class="n">effnetb2_results</span><span class="p">[</span><span class="s2">"test_acc"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                  <span class="s2">"number_of_parameters"</span><span class="p">:</span> <span class="n">effnetb2_total_params</span><span class="p">,</span>
                  <span class="s2">"model_size (MB)"</span><span class="p">:</span> <span class="n">pretrained_effnetb2_model_size</span><span class="p">}</span>
<span class="n">effnetb2_stats</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-18"># Crear un diccionario con estadísticas de EffNetB2
effnetb2_stats = {"test_loss": effnetb2_results["test_loss"][-1],
                  "test_acc": effnetb2_results["test_acc"][-1],
                  "number_of_parameters": effnetb2_total_params,
                  "model_size (MB)": pretrained_effnetb2_model_size}
effnetb2_stats</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7a0aa115">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Épico!</p>
<p>¡Parece que nuestro modelo EffNetB2 funciona con más del 95% de precisión!</p>
<p>Criterio número 1: actuar con una precisión superior al 95%, ¡marca!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3bf608cd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="4-creacion-de-un-extractor-de-funciones-vit">4. Creación de un extractor de funciones ViT<a class="anchor-link" href="#4-creacion-de-un-extractor-de-funciones-vit">¶</a></h2><p>Es hora de continuar con nuestros experimentos de modelado de FoodVision Mini.</p>
<p>Esta vez vamos a crear un extractor de funciones de ViT.</p>
<p>Y lo haremos de la misma manera que el extractor de funciones EffNetB2, excepto que esta vez con [<code>torchvision.models.vit_b_16()</code>](<a href="https://pytorch.org/vision/stable/models/generated/torchvision">https://pytorch.org/vision/stable/models/generated/torchvision</a>. models.vit_b_16.html#torchvision.models.vit_b_16) en lugar de <code>torchvision.models.ficientnet_b2()</code>.</p>
<p>Comenzaremos creando una función llamada <code>create_vit_model()</code> que será muy similar a <code>create_effnetb2_model()</code> excepto, por supuesto, que devolverá un modelo extractor de características ViT y transformaciones en lugar de EffNetB2.</p>
<p>Otra pequeña diferencia es que la capa de salida de <code>torchvision.models.vit_b_16()</code> se llama <code>cabezas</code> en lugar de <code>clasificador</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3412ae34">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-19">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Consulte la capa de cabezales ViT</span>
<span class="n">vit</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vit_b_16</span><span class="p">()</span>
<span class="n">vit</span><span class="o">.</span><span class="n">heads</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-19"># Consulte la capa de cabezales ViT
vit = torchvision.models.vit_b_16()
vit.heads</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=638f102e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Sabiendo esto, tenemos todas las piezas del rompecabezas que necesitamos.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=170c8292">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-20">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="k">def</span> <span class="nf">create_vit_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                     <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Creates a ViT-B/16 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of target classes. Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value for output layer. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): ViT-B/16 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): ViT-B/16 image transforms.</span>
<span class="sd">    """</span>
    <span class="c1"># Create ViT_B_16 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">ViT_B_16_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vit_b_16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Freeze all layers in model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Change classifier head to suit our needs (this will be trainable)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">768</span><span class="p">,</span> <span class="c1"># keep this the same as original model</span>
                                          <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">))</span> <span class="c1"># update to reflect target number of classes</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-20">def create_vit_model(num_classes:int=3, 
                     seed:int=42):
    """Creates a ViT-B/16 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of target classes. Defaults to 3.
        seed (int, optional): random seed value for output layer. Defaults to 42.

    Returns:
        model (torch.nn.Module): ViT-B/16 feature extractor model. 
        transforms (torchvision.transforms): ViT-B/16 image transforms.
    """
    # Create ViT_B_16 pretrained weights, transforms and model
    weights = torchvision.models.ViT_B_16_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.vit_b_16(weights=weights)

    # Freeze all layers in model
    for param in model.parameters():
        param.requires_grad = False

    # Change classifier head to suit our needs (this will be trainable)
    torch.manual_seed(seed)
    model.heads = nn.Sequential(nn.Linear(in_features=768, # keep this the same as original model
                                          out_features=num_classes)) # update to reflect target number of classes
    
    return model, transforms</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=722ea0d8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡La función de creación de modelos de extracción de características ViT está lista!</p>
<p>Probémoslo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=815a1224">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-21">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Crear modelo ViT y transformaciones.</span>
<span class="n">vit</span><span class="p">,</span> <span class="n">vit_transforms</span> <span class="o">=</span> <span class="n">create_vit_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                       <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-21"># Crear modelo ViT y transformaciones.
vit, vit_transforms = create_vit_model(num_classes=3,
                                       seed=42)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2f7702cc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Sin errores, ¡es encantador verlo!</p>
<p>Ahora obtengamos un resumen atractivo de nuestro modelo ViT usando <code>torchinfo.summary()</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=86d41dda">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-22">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># # Imprimir resumen del modelo del extractor de funciones de ViT (descomentar para obtener un resultado completo)</span>
<span class="c1"># resumen(vit,</span>
<span class="c1"># tamaño_entrada=(1, 3, 224, 224),</span>
<span class="c1"># col_names=["input_size", "output_size", "num_params", "entrenable"],</span>
<span class="c1"># ancho_columna=20,</span>
<span class="c1"># row_settings=["var_names"])</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-22">from torchinfo import summary

# # Imprimir resumen del modelo del extractor de funciones de ViT (descomentar para obtener un resultado completo)
# resumen(vit,
# tamaño_entrada=(1, 3, 224, 224),
# col_names=["input_size", "output_size", "num_params", "entrenable"],
# ancho_columna=20,
# row_settings=["var_names"])</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ab1fae70">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><img alt="extractor de funciones vit con 3 clases de salida" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-vit-feature-extractor-3-classes.png" width="900"/></p>
<p>Al igual que nuestro modelo de extracción de funciones EffNetB2, las capas base de nuestro modelo ViT están congeladas y la capa de salida se personaliza según nuestras necesidades.</p>
<p>¿Notas la gran diferencia?</p>
<p>Nuestro modelo ViT tiene <em>muchos</em> más parámetros que nuestro modelo EffNetB2. Quizás esto entre en juego cuando comparemos nuestros modelos en cuanto a velocidad y rendimiento más adelante.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=da3a43d6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="41-crear-cargadores-de-datos-para-vit">4.1 Crear cargadores de datos para ViT<a class="anchor-link" href="#41-crear-cargadores-de-datos-para-vit">¶</a></h3><p>Tenemos nuestro modelo ViT listo, ahora creemos algunos <code>DataLoader</code>s para él.</p>
<p>Haremos esto de la misma manera que hicimos para EffNetB2 excepto que usaremos <code>vit_transforms</code> para transformar nuestras imágenes al mismo formato en el que se entrenó el modelo ViT.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=689e8883">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-23">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Configurar cargadores de datos ViT</span>
<span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span>
<span class="n">train_dataloader_vit</span><span class="p">,</span> <span class="n">test_dataloader_vit</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="n">data_setup</span><span class="o">.</span><span class="n">create_dataloaders</span><span class="p">(</span><span class="n">train_dir</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
                                                                                       <span class="n">test_dir</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
                                                                                       <span class="n">transform</span><span class="o">=</span><span class="n">vit_transforms</span><span class="p">,</span>
                                                                                       <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-23"># Configurar cargadores de datos ViT
from going_modular.going_modular import data_setup
train_dataloader_vit, test_dataloader_vit, class_names = data_setup.create_dataloaders(train_dir=train_dir,
                                                                                       test_dir=test_dir,
                                                                                       transform=vit_transforms,
                                                                                       batch_size=32)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=dd28c6e4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="42-extractor-de-funciones-de-vit-de-entrenamiento">4.2 Extractor de funciones de ViT de entrenamiento<a class="anchor-link" href="#42-extractor-de-funciones-de-vit-de-entrenamiento">¶</a></h3><p>Sabes que hora es...</p>
<p>...es hora de entrenargggggg (cantado con la misma melodía que la canción <a href="https://youtu.be/xGytDsqkQY8">Closing Time</a>).</p>
<p>Entrenemos nuestro modelo de extracción de características ViT durante 10 épocas usando nuestra función <code>engine.train()</code> con <code>torch.optim.Adam()</code> y una tasa de aprendizaje de <code>1e-3</code> como nuestro optimizador y <code>torch.nn.CrossEntropyLoss ()</code> como nuestra función de pérdida.</p>
<p>Usaremos nuestra función <code>set_seeds()</code> antes del entrenamiento para intentar que nuestros resultados sean lo más reproducibles posible.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c022a5ed">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-24">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Optimizador de configuración</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">vit</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="c1"># Función de pérdida de configuración</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Entrene el modelo ViT con semillas configuradas para lograr reproducibilidad</span>
<span class="n">set_seeds</span><span class="p">()</span>
<span class="n">vit_results</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">vit</span><span class="p">,</span>
                           <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader_vit</span><span class="p">,</span>
                           <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader_vit</span><span class="p">,</span>
                           <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                           <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                           <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                           <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-24">from going_modular.going_modular import engine

# Optimizador de configuración
optimizer = torch.optim.Adam(params=vit.parameters(),
                             lr=1e-3)
# Función de pérdida de configuración
loss_fn = torch.nn.CrossEntropyLoss()

# Entrene el modelo ViT con semillas configuradas para lograr reproducibilidad
set_seeds()
vit_results = engine.train(model=vit,
                           train_dataloader=train_dataloader_vit,
                           test_dataloader=test_dataloader_vit,
                           epochs=10,
                           optimizer=optimizer,
                           loss_fn=loss_fn,
                           device=device)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4c3abbd9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="43-inspeccionando-las-curvas-de-perdidas-de-vit">4.3 Inspeccionando las curvas de pérdidas de ViT<a class="anchor-link" href="#43-inspeccionando-las-curvas-de-perdidas-de-vit">¶</a></h3><p>Muy bien, está bien, está bien, modelo ViT entrenado, seamos visuales y veamos algunas curvas de pérdida.</p>
<blockquote>
<p><strong>Nota:</strong> No olvide que puede ver cómo debería verse un conjunto ideal de curvas de pérdida en [04. Sección 8 de conjuntos de datos personalizados de PyTorch] (<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#8-what-should-an-ideal-loss-curve-look-like">https://www.learnpytorch.io/04_pytorch_custom_datasets/#8-what-should-an-ideal-loss-curve-look-like</a>).</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ad26bbcb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-25">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">plot_loss_curves</span>

<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">vit_results</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-25">from helper_functions import plot_loss_curves

plot_loss_curves(vit_results)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ca2970a1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Ohh si!</p>
<p>Esas son algunas curvas de pérdidas bonitas. Al igual que nuestro modelo de extracción de funciones EffNetB2, parece que nuestro modelo ViT podría beneficiarse de un tiempo de entrenamiento un poco más largo y tal vez algo de [aumento de datos](<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-">https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-</a> transforma-datos-aumento) (para ayudar a prevenir el sobreajuste).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=bbc635d6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="44-guardar-el-extractor-de-funciones-de-vit">4.4 Guardar el extractor de funciones de ViT<a class="anchor-link" href="#44-guardar-el-extractor-de-funciones-de-vit">¶</a></h3><p>¡Nuestro modelo ViT está funcionando de manera excelente!</p>
<p>Así que guardémoslo en un archivo para poder importarlo y usarlo más tarde si lo deseamos.</p>
<p>Podemos hacerlo usando la función <code>utils.save_model()</code> que creamos en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#5-creating-a-function-to-save-the-model-utilspy">05. PyTorch Going Modular sección 5</a>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c99e2879">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-26">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># guardar el modelo</span>
<span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">vit</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">"models"</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="s2">"09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-26"># guardar el modelo
from going_modular.going_modular import utils

utils.save_model(model=vit,
                 target_dir="models",
                 model_name="09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1c5cf52c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="45-comprobar-el-tamano-del-extractor-de-funciones-vit">4.5 Comprobar el tamaño del extractor de funciones ViT<a class="anchor-link" href="#45-comprobar-el-tamano-del-extractor-de-funciones-vit">¶</a></h3><p>Y como queremos comparar nuestro modelo EffNetB2 con nuestro modelo ViT en función de una serie de características, averigüemos su tamaño.</p>
<p>Para verificar el tamaño de nuestro modelo en bytes, podemos usar <code>pathlib.Path.stat("path_to_model").st_size</code> de Python y luego podemos convertirlo (aproximadamente) a megabytes dividiéndolo por <code>(1024*1024)</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e34c8d1a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-27">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes</span>
<span class="n">pretrained_vit_model_size</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"models/09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth"</span><span class="p">)</span><span class="o">.</span><span class="n">stat</span><span class="p">()</span><span class="o">.</span><span class="n">st_size</span> <span class="o">//</span> <span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> <span class="c1"># division converts bytes to megabytes (roughly) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Pretrained ViT feature extractor model size: </span><span class="si">{</span><span class="n">pretrained_vit_model_size</span><span class="si">}</span><span class="s2"> MB"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-27">from pathlib import Path

# Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes
pretrained_vit_model_size = Path("models/09_pretrained_vit_feature_extractor_pizza_steak_sushi_20_percent.pth").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) 
print(f"Pretrained ViT feature extractor model size: {pretrained_vit_model_size} MB")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=21c02a80">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Hmm, ¿cómo se compara el tamaño del modelo del extractor de funciones ViT con el tamaño de nuestro modelo EffNetB2?</p>
<p>Lo descubriremos en breve cuando comparemos todas las características de nuestro modelo.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c2a22783">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="46-recopilacion-de-estadisticas-del-extractor-de-funciones-de-vit">4.6 Recopilación de estadísticas del extractor de funciones de ViT<a class="anchor-link" href="#46-recopilacion-de-estadisticas-del-extractor-de-funciones-de-vit">¶</a></h3><p>Reunamos todas las estadísticas del modelo de extracción de funciones de ViT.</p>
<p>Lo vimos en el resumen anterior, pero calcularemos su número total de parámetros.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ddb262e5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-28">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Contar el número de parámetros en ViT</span>
<span class="n">vit_total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">vit</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">vit_total_params</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-28"># Contar el número de parámetros en ViT
vit_total_params = sum(torch.numel(param) for param in vit.parameters())
vit_total_params</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c9deebcb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Vaya, eso parece bastante más que nuestro EffNetB2!</p>
<blockquote>
<p><strong>Nota:</strong> Una mayor cantidad de parámetros (o pesos/patrones) generalmente significa que un modelo tiene una mayor <em>capacidad</em> de aprender; si realmente utiliza esta capacidad adicional es otra historia. A la luz de esto, nuestro modelo EffNetB2 tiene 7.705.221 parámetros, mientras que nuestro modelo ViT tiene 85.800.963 (11,1 veces más), por lo que podríamos suponer que nuestro modelo ViT tiene más capacidad de aprender, si se le dan más datos (más oportunidades de aprender). Sin embargo, esta mayor capacidad de aprender a menudo viene acompañada de un mayor tamaño del modelo y un mayor tiempo para realizar la inferencia.</p>
</blockquote>
<p>Ahora creemos un diccionario con algunas características importantes de nuestro modelo ViT.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=49f32762">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-29">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Crear diccionario de estadísticas de ViT</span>
<span class="n">vit_stats</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"test_loss"</span><span class="p">:</span> <span class="n">vit_results</span><span class="p">[</span><span class="s2">"test_loss"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
             <span class="s2">"test_acc"</span><span class="p">:</span> <span class="n">vit_results</span><span class="p">[</span><span class="s2">"test_acc"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
             <span class="s2">"number_of_parameters"</span><span class="p">:</span> <span class="n">vit_total_params</span><span class="p">,</span>
             <span class="s2">"model_size (MB)"</span><span class="p">:</span> <span class="n">pretrained_vit_model_size</span><span class="p">}</span>

<span class="n">vit_stats</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-29"># Crear diccionario de estadísticas de ViT
vit_stats = {"test_loss": vit_results["test_loss"][-1],
             "test_acc": vit_results["test_acc"][-1],
             "number_of_parameters": vit_total_params,
             "model_size (MB)": pretrained_vit_model_size}

vit_stats</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7fce72f1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Lindo! Parece que nuestro modelo ViT también logra una precisión superior al 95%.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4d27add0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="5-hacer-predicciones-con-nuestros-modelos-entrenados-y-cronometrarlas">5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas<a class="anchor-link" href="#5-hacer-predicciones-con-nuestros-modelos-entrenados-y-cronometrarlas">¶</a></h2><p>Tenemos un par de modelos entrenados y ambos funcionan bastante bien.</p>
<p>Ahora, ¿qué tal si los probamos haciendo lo que nos gustaría que hicieran?</p>
<p>Es decir, veamos cómo hacen predicciones (realizando inferencias).</p>
<p>Sabemos que nuestros dos modelos funcionan con una precisión superior al 95 % en el conjunto de datos de prueba, pero ¿qué tan rápidos son?</p>
<p>Idealmente, si implementamos nuestro modelo FoodVision Mini en un dispositivo móvil para que las personas puedan tomar fotografías de sus alimentos e identificarlos, nos gustaría que las predicciones se realicen en tiempo real (~30 fotogramas por segundo).</p>
<p>Por eso nuestro segundo criterio es: un modelo rápido.</p>
<p>Para saber cuánto tiempo tarda cada uno de nuestros modelos en inferir el rendimiento, creemos una función llamada <code>pred_and_store()</code> para iterar sobre cada una de las imágenes del conjunto de datos de prueba una por una y realizar una predicción.</p>
<p>Calcularemos el tiempo de cada una de las predicciones y almacenaremos los resultados en un formato de predicción común: una lista de diccionarios (donde cada elemento de la lista es una predicción única y cada predicción única es un diccionario).</p>
<blockquote>
<p><strong>Nota:</strong> Calculamos las predicciones una por una en lugar de por lotes porque cuando se implementa nuestro modelo, probablemente solo hará una predicción en una imagen a la vez. Es decir, alguien toma una foto y nuestro modelo predice sobre esa única imagen.</p>
</blockquote>
<p>Como nos gustaría hacer predicciones en todas las imágenes del conjunto de prueba, primero obtengamos una lista de todas las rutas de las imágenes de prueba para que podamos iterar sobre ellas.</p>
<p>Para hacerlo, usaremos <a href="https://docs.python.org/3/library/pathlib"><code>pathlib.Path("target_dir").glob("*/*.jpg"))</code></a> de Python. html#basic-use) para encontrar todas las rutas de archivos en un directorio de destino con la extensión <code>.jpg</code> (todas nuestras imágenes de prueba).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=313adfb4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-30">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Obtenga todas las rutas de datos de prueba</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Finding all filepaths ending with '.jpg' in directory: </span><span class="si">{</span><span class="n">test_dir</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="n">test_data_paths</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">test_dir</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">"*/*.jpg"</span><span class="p">))</span>
<span class="n">test_data_paths</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-30">from pathlib import Path

# Obtenga todas las rutas de datos de prueba
print(f"[INFO] Finding all filepaths ending with '.jpg' in directory: {test_dir}")
test_data_paths = list(Path(test_dir).glob("*/*.jpg"))
test_data_paths[:5]</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=23ca242a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="51-crear-una-funcion-para-hacer-predicciones-en-todo-el-conjunto-de-datos-de-prueba">5.1 Crear una función para hacer predicciones en todo el conjunto de datos de prueba<a class="anchor-link" href="#51-crear-una-funcion-para-hacer-predicciones-en-todo-el-conjunto-de-datos-de-prueba">¶</a></h3><p>Ahora que tenemos una lista de nuestras rutas de imágenes de prueba, comencemos a trabajar en nuestra función <code>pred_and_store()</code>:</p>
<ol>
<li>Cree una función que tome una lista de rutas, un modelo PyTorch entrenado, una serie de transformaciones (para preparar imágenes), una lista de nombres de clases de destino y un dispositivo de destino.</li>
<li>Cree una lista vacía para almacenar diccionarios de predicción (queremos que la función devuelva una lista de diccionarios, uno para cada predicción).</li>
<li>Recorra las rutas de entrada de destino (los pasos 4 a 14 se realizarán dentro del bucle).</li>
<li>Cree un diccionario vacío para cada iteración del bucle para almacenar los valores de predicción por muestra.</li>
<li>Obtenga la ruta de muestra y el nombre de la clase de verdad fundamental (podemos hacer esto infiriendo la clase a partir de la ruta).</li>
<li>Inicie el temporizador de predicción usando <a href="https://docs.python.org/3/library/timeit.html#timeit.default_timer"><code>timeit.default_timer()</code></a> de Python.</li>
<li>Abra la imagen usando <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#functions"><code>PIL.Image.open(path)</code></a>.</li>
<li>Transforme la imagen para que pueda usarse con el modelo de destino, así como agregue una dimensión por lotes y envíe la imagen al dispositivo de destino.</li>
<li>Prepare el modelo para la inferencia enviándolo al dispositivo de destino y activando el modo <code>eval()</code>.</li>
<li>Active <a href="https://pytorch.org/docs/stable/generated/torch.inference_mode.html"><code>torch.inference_mode()</code></a> y pase la imagen transformada de destino al modelo y calcule la probabilidad de predicción usando <code> torch.softmax()</code> y la etiqueta de destino usando <code>torch.argmax()</code>.</li>
<li>Agregue la probabilidad de predicción y la clase de predicción al diccionario de predicción creado en el paso 4. También asegúrese de que la probabilidad de predicción esté en la CPU para que pueda usarse con bibliotecas que no son de GPU, como NumPy y pandas, para una inspección posterior.</li>
<li>Finalice el temporizador de predicción iniciado en el paso 6 y agregue el tiempo al diccionario de predicción creado en el paso 4.</li>
<li>Vea si la clase predicha coincide con la clase de verdad fundamental del paso 5 y agregue el resultado al diccionario de predicción creado en el paso 4.</li>
<li>Agregue el diccionario de predicciones actualizado a la lista vacía de predicciones creada en el paso 2.</li>
<li>Devuelve la lista de diccionarios de predicción.</li>
</ol>
<p>¡Muchos pasos, pero nada que no podamos manejar!</p>
<p>Vamos a hacerlo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=afc13260">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-31">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span> 
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span>

<span class="c1"># 1. Cree una función para devolver una lista de diccionarios con muestra, etiqueta de verdad, predicción, probabilidad de predicción y tiempo de predicción.</span>
<span class="k">def</span> <span class="nf">pred_and_store</span><span class="p">(</span><span class="n">paths</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">],</span> 
                   <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
                   <span class="n">transform</span><span class="p">:</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="p">,</span> 
                   <span class="n">class_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> 
                   <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]:</span>
    
    <span class="c1"># 2. Create an empty list to store prediction dictionaires</span>
    <span class="n">pred_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># 3. Loop through target paths</span>
    <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">paths</span><span class="p">):</span>
        
        <span class="c1"># 4. Create empty dictionary to store prediction information for each sample</span>
        <span class="n">pred_dict</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># 5. Get the sample path and ground truth class name</span>
        <span class="n">pred_dict</span><span class="p">[</span><span class="s2">"image_path"</span><span class="p">]</span> <span class="o">=</span> <span class="n">path</span>
        <span class="n">class_name</span> <span class="o">=</span> <span class="n">path</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">stem</span>
        <span class="n">pred_dict</span><span class="p">[</span><span class="s2">"class_name"</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_name</span>
        
        <span class="c1"># 6. Start the prediction timer</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
        
        <span class="c1"># 7. Open image path</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        
        <span class="c1"># 8. Transform the image, add batch dimension and put image on target device</span>
        <span class="n">transformed_image</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
        
        <span class="c1"># 9. Prepare model for inference by sending it to target device and turning on eval() mode</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># 10. Get prediction probability, predicition label and prediction class</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
            <span class="n">pred_logit</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">transformed_image</span><span class="p">)</span> <span class="c1"># perform inference on target sample </span>
            <span class="n">pred_prob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred_logit</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># turn logits into prediction probabilities</span>
            <span class="n">pred_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># turn prediction probabilities into prediction label</span>
            <span class="n">pred_class</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">pred_label</span><span class="o">.</span><span class="n">cpu</span><span class="p">()]</span> <span class="c1"># hardcode prediction class to be on CPU</span>

            <span class="c1"># 11. Make sure things in the dictionary are on CPU (required for inspecting predictions later on) </span>
            <span class="n">pred_dict</span><span class="p">[</span><span class="s2">"pred_prob"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">pred_prob</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
            <span class="n">pred_dict</span><span class="p">[</span><span class="s2">"pred_class"</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_class</span>
            
            <span class="c1"># 12. End the timer and calculate time per pred</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
            <span class="n">pred_dict</span><span class="p">[</span><span class="s2">"time_for_pred"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">end_time</span><span class="o">-</span><span class="n">start_time</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

        <span class="c1"># 13. Does the pred match the true label?</span>
        <span class="n">pred_dict</span><span class="p">[</span><span class="s2">"correct"</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_name</span> <span class="o">==</span> <span class="n">pred_class</span>

        <span class="c1"># 14. Add the dictionary to the list of preds</span>
        <span class="n">pred_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_dict</span><span class="p">)</span>
    
    <span class="c1"># 15. Return list of prediction dictionaries</span>
    <span class="k">return</span> <span class="n">pred_list</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-31">import pathlib
import torch

from PIL import Image
from timeit import default_timer as timer 
from tqdm.auto import tqdm
from typing import List, Dict

# 1. Cree una función para devolver una lista de diccionarios con muestra, etiqueta de verdad, predicción, probabilidad de predicción y tiempo de predicción.
def pred_and_store(paths: List[pathlib.Path], 
                   model: torch.nn.Module,
                   transform: torchvision.transforms, 
                   class_names: List[str], 
                   device: str = "cuda" if torch.cuda.is_available() else "cpu") -&gt; List[Dict]:
    
    # 2. Create an empty list to store prediction dictionaires
    pred_list = []
    
    # 3. Loop through target paths
    for path in tqdm(paths):
        
        # 4. Create empty dictionary to store prediction information for each sample
        pred_dict = {}

        # 5. Get the sample path and ground truth class name
        pred_dict["image_path"] = path
        class_name = path.parent.stem
        pred_dict["class_name"] = class_name
        
        # 6. Start the prediction timer
        start_time = timer()
        
        # 7. Open image path
        img = Image.open(path)
        
        # 8. Transform the image, add batch dimension and put image on target device
        transformed_image = transform(img).unsqueeze(0).to(device) 
        
        # 9. Prepare model for inference by sending it to target device and turning on eval() mode
        model.to(device)
        model.eval()
        
        # 10. Get prediction probability, predicition label and prediction class
        with torch.inference_mode():
            pred_logit = model(transformed_image) # perform inference on target sample 
            pred_prob = torch.softmax(pred_logit, dim=1) # turn logits into prediction probabilities
            pred_label = torch.argmax(pred_prob, dim=1) # turn prediction probabilities into prediction label
            pred_class = class_names[pred_label.cpu()] # hardcode prediction class to be on CPU

            # 11. Make sure things in the dictionary are on CPU (required for inspecting predictions later on) 
            pred_dict["pred_prob"] = round(pred_prob.unsqueeze(0).max().cpu().item(), 4)
            pred_dict["pred_class"] = pred_class
            
            # 12. End the timer and calculate time per pred
            end_time = timer()
            pred_dict["time_for_pred"] = round(end_time-start_time, 4)

        # 13. Does the pred match the true label?
        pred_dict["correct"] = class_name == pred_class

        # 14. Add the dictionary to the list of preds
        pred_list.append(pred_dict)
    
    # 15. Return list of prediction dictionaries
    return pred_list</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9b1e0706">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Ho, ho!</p>
<p>¡Qué función tan atractiva!</p>
<p>Y sabes qué, dado que nuestro <code>pred_and_store()</code> es una función de utilidad bastante buena para hacer y almacenar predicciones, podría almacenarse en [<code>going_modular.going_modular.predictions.py</code>](<a href="https://github.com/mrdbourke">https://github.com/mrdbourke</a> /pytorch-deep-learning/blob/main/going_modular/going_modular/predictions.py) para su uso posterior. Podría ser una extensión que le gustaría probar; consulte <a href="https://www.learnpytorch.io/05_pytorch_going_modular/">05. PyTorch Going Modular</a> para obtener ideas.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=075d53b8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="52-realizacion-y-sincronizacion-de-predicciones-con-effnetb2">5.2 Realización y sincronización de predicciones con EffNetB2<a class="anchor-link" href="#52-realizacion-y-sincronizacion-de-predicciones-con-effnetb2">¶</a></h3><p>¡Es hora de probar nuestra función <code>pred_and_store()</code>!</p>
<p>Comencemos usándolo para hacer predicciones en todo el conjunto de datos de prueba con nuestro modelo EffNetB2, prestando atención a dos detalles:</p>
<ol>
<li><strong>Dispositivo</strong>: codificaremos el parámetro "dispositivo" para usar "cpu" porque cuando implementemos nuestro modelo, no siempre tendremos acceso a un dispositivo "cuda" (GPU). .<ul>
<li>Hacer predicciones en la CPU también será un buen indicador de la velocidad de inferencia porque generalmente las predicciones en dispositivos con CPU son más lentas que las de los dispositivos con GPU.</li>
</ul>
</li>
<li><strong>Transformaciones</strong> - También nos aseguraremos de establecer el parámetro <code>transform</code> en <code>effnetb2_transforms</code> para asegurarnos de que las imágenes se abran y transformen de la misma manera en la que se entrenó nuestro modelo <code>effnetb2</code>.</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=59d81492">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-32">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Haga predicciones en todo el conjunto de datos de prueba con EffNetB2</span>
<span class="n">effnetb2_test_pred_dicts</span> <span class="o">=</span> <span class="n">pred_and_store</span><span class="p">(</span><span class="n">paths</span><span class="o">=</span><span class="n">test_data_paths</span><span class="p">,</span>
                                          <span class="n">model</span><span class="o">=</span><span class="n">effnetb2</span><span class="p">,</span>
                                          <span class="n">transform</span><span class="o">=</span><span class="n">effnetb2_transforms</span><span class="p">,</span>
                                          <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
                                          <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">)</span> <span class="c1"># make predictions on CPU</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-32"># Haga predicciones en todo el conjunto de datos de prueba con EffNetB2
effnetb2_test_pred_dicts = pred_and_store(paths=test_data_paths,
                                          model=effnetb2,
                                          transform=effnetb2_transforms,
                                          class_names=class_names,
                                          device="cpu") # make predictions on CPU </div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=257021bd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Lindo! ¡Mira esas predicciones volar!</p>
<p>Inspeccionemos la primera pareja y veamos cómo se ven.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=76d3c42f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-33">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Inspeccione los primeros 2 diccionarios de predicción.</span>
<span class="n">effnetb2_test_pred_dicts</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-33"># Inspeccione los primeros 2 diccionarios de predicción.
effnetb2_test_pred_dicts[:2]</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=94fab835">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Guau!</p>
<p>Parece que nuestra función <code>pred_and_store()</code> funcionó bien.</p>
<p>Gracias a nuestra lista de estructura de datos de diccionarios, tenemos mucha información útil que podemos inspeccionar más a fondo.</p>
<p>Para hacerlo, convierta nuestra lista de diccionarios en un DataFrame de pandas.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=686e62d3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-34">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Convierta test_pred_dicts en un DataFrame</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">effnetb2_test_pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">effnetb2_test_pred_dicts</span><span class="p">)</span>
<span class="n">effnetb2_test_pred_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-34"># Convierta test_pred_dicts en un DataFrame
import pandas as pd
effnetb2_test_pred_df = pd.DataFrame(effnetb2_test_pred_dicts)
effnetb2_test_pred_df.head()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=f80be4f0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Hermoso!</p>
<p>Mire con qué facilidad esos diccionarios de predicción se convierten en un formato estructurado sobre el que podemos realizar análisis.</p>
<p>Como encontrar cuántas predicciones nuestro modelo EffNetB2 se equivocó...</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=acde19ba">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-35">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Comprobar número de predicciones correctas</span>
<span class="n">effnetb2_test_pred_df</span><span class="o">.</span><span class="n">correct</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-35"># Comprobar número de predicciones correctas
effnetb2_test_pred_df.correct.value_counts()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6d2f0408">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Cinco predicciones erróneas de un total de 150, ¡nada mal!</p>
<p>¿Y qué tal el tiempo medio de predicción?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=085b7ac9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-36">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Encuentre el tiempo promedio por predicción</span>
<span class="n">effnetb2_average_time_per_pred</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">effnetb2_test_pred_df</span><span class="o">.</span><span class="n">time_for_pred</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"EffNetB2 average time per prediction: </span><span class="si">{</span><span class="n">effnetb2_average_time_per_pred</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-36"># Encuentre el tiempo promedio por predicción
effnetb2_average_time_per_pred = round(effnetb2_test_pred_df.time_for_pred.mean(), 4)
print(f"EffNetB2 average time per prediction: {effnetb2_average_time_per_pred} seconds")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=c551ca3f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Mmmm, ¿cómo cumple ese tiempo promedio de predicción con nuestros criterios de rendimiento de nuestro modelo en tiempo real (~30 FPS o 0,03 segundos por predicción)?</p>
<blockquote>
<p><strong>Nota:</strong> Los tiempos de predicción serán diferentes según los distintos tipos de hardware (por ejemplo, una CPU Intel i9 local frente a una CPU Google Colab). Cuanto mejor y más rápido sea el hardware, generalmente, más rápida será la predicción. Por ejemplo, en mi PC local de aprendizaje profundo con un chip Intel i9, mi tiempo promedio de predicción con EffNetB2 es de alrededor de 0,031 segundos (un poco menos que el tiempo real). Sin embargo, en Google Colab (no estoy seguro de qué hardware de CPU utiliza Colab, pero parece que podría ser un [Intel(R) Xeon(R)](<a href="https://stackoverflow.com/questions/47805170/whats-the">https://stackoverflow.com/questions/47805170/whats-the</a> -hardware-spec-for-google-colaboratory)), mi tiempo promedio de predicción con EffNetB2 es de aproximadamente 0,1396 segundos (3-4 veces más lento).</p>
</blockquote>
<p>Agreguemos nuestro tiempo promedio por predicción de EffNetB2 a nuestro diccionario <code>effnetb2_stats</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=cfb2bd24">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-37">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Agregue el tiempo de predicción promedio de EffNetB2 al diccionario de estadísticas</span>
<span class="n">effnetb2_stats</span><span class="p">[</span><span class="s2">"time_per_pred_cpu"</span><span class="p">]</span> <span class="o">=</span> <span class="n">effnetb2_average_time_per_pred</span>
<span class="n">effnetb2_stats</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-37"># Agregue el tiempo de predicción promedio de EffNetB2 al diccionario de estadísticas
effnetb2_stats["time_per_pred_cpu"] = effnetb2_average_time_per_pred
effnetb2_stats</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0d661174">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="53-realizar-y-cronometrar-predicciones-con-vit">5.3 Realizar y cronometrar predicciones con ViT<a class="anchor-link" href="#53-realizar-y-cronometrar-predicciones-con-vit">¶</a></h3><p>Hemos hecho predicciones con nuestro modelo EffNetB2, ahora hagamos lo mismo con nuestro modelo ViT.</p>
<p>Para hacerlo, podemos usar la función <code>pred_and_store()</code> que creamos anteriormente, excepto que esta vez pasaremos nuestro modelo <code>vit</code> así como <code>vit_transforms</code>.</p>
<p>Y mantendremos las predicciones en la CPU a través de <code>device="cpu"</code> (una extensión natural aquí sería probar los tiempos de predicción en la CPU y en la GPU).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=b6d693ac">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-38">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Haga una lista de diccionarios de predicción con el modelo de extracción de funciones de ViT en imágenes de prueba</span>
<span class="n">vit_test_pred_dicts</span> <span class="o">=</span> <span class="n">pred_and_store</span><span class="p">(</span><span class="n">paths</span><span class="o">=</span><span class="n">test_data_paths</span><span class="p">,</span>
                                     <span class="n">model</span><span class="o">=</span><span class="n">vit</span><span class="p">,</span>
                                     <span class="n">transform</span><span class="o">=</span><span class="n">vit_transforms</span><span class="p">,</span>
                                     <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
                                     <span class="n">device</span><span class="o">=</span><span class="s2">"cpu"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-38"># Haga una lista de diccionarios de predicción con el modelo de extracción de funciones de ViT en imágenes de prueba
vit_test_pred_dicts = pred_and_store(paths=test_data_paths,
                                     model=vit,
                                     transform=vit_transforms,
                                     class_names=class_names,
                                     device="cpu")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=5a5c65e9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Predicciones hechas!</p>
<p>Ahora echemos un vistazo a la primera pareja.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=55893a44">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-39">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Verifique las primeras predicciones de ViT en el conjunto de datos de prueba</span>
<span class="n">vit_test_pred_dicts</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-39"># Verifique las primeras predicciones de ViT en el conjunto de datos de prueba
vit_test_pred_dicts[:2]</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=dd650a52">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Maravilloso!</p>
<p>Y al igual que antes, dado que las predicciones de nuestro modelo ViT tienen la forma de una lista de diccionarios, podemos convertirlas fácilmente en un DataFrame de pandas para una inspección más detallada.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=81c3120a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-40">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Convierta vit_test_pred_dicts en un DataFrame</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">vit_test_pred_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">vit_test_pred_dicts</span><span class="p">)</span>
<span class="n">vit_test_pred_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-40"># Convierta vit_test_pred_dicts en un DataFrame
import pandas as pd
vit_test_pred_df = pd.DataFrame(vit_test_pred_dicts)
vit_test_pred_df.head()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a32273ad">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¿Cuántas predicciones acertó nuestro modelo ViT?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=7cb28af5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-41">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Cuente el número de predicciones correctas.</span>
<span class="n">vit_test_pred_df</span><span class="o">.</span><span class="n">correct</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-41"># Cuente el número de predicciones correctas.
vit_test_pred_df.correct.value_counts()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3f039f3a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Guau!</p>
<p>Nuestro modelo ViT funcionó un poco mejor que nuestro modelo EffNetB2 en términos de predicciones correctas, solo dos muestras incorrectas en todo el conjunto de datos de prueba.</p>
<p>Como extensión, es posible que desee visualizar las predicciones incorrectas del modelo ViT y ver si hay alguna razón por la cual podrían haberse equivocado.</p>
<p>¿Qué tal si calculamos cuánto tiempo tardó el modelo ViT en realizar cada predicción?</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=357bf678">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-42">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Calcular el tiempo promedio por predicción para el modelo ViT</span>
<span class="n">vit_average_time_per_pred</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">vit_test_pred_df</span><span class="o">.</span><span class="n">time_for_pred</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"ViT average time per prediction: </span><span class="si">{</span><span class="n">vit_average_time_per_pred</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-42"># Calcular el tiempo promedio por predicción para el modelo ViT
vit_average_time_per_pred = round(vit_test_pred_df.time_for_pred.mean(), 4)
print(f"ViT average time per prediction: {vit_average_time_per_pred} seconds")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3c238746">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Bueno, eso parece un poco más lento que el tiempo promedio por predicción de nuestro modelo EffNetB2, pero ¿cómo se ve en términos de nuestro segundo criterio: velocidad?</p>
<p>Por ahora, agreguemos el valor a nuestro diccionario <code>vit_stats</code> para que podamos compararlo con las estadísticas de nuestro modelo EffNetB2.</p>
<blockquote>
<p><strong>Nota:</strong> El tiempo promedio por valor de predicción dependerá en gran medida del hardware en el que los realice. Por ejemplo, para el modelo ViT, mi tiempo promedio por predicción (en la CPU) fue de 0,0693 a 0,0777 segundos en mi PC local de aprendizaje profundo con una CPU Intel i9. Mientras que en Google Colab, mi tiempo promedio por predicción con el modelo ViT fue de 0,6766 a 0,7113 segundos.</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4be77977">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-43">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Agregue el tiempo de predicción promedio para el modelo ViT en la CPU</span>
<span class="n">vit_stats</span><span class="p">[</span><span class="s2">"time_per_pred_cpu"</span><span class="p">]</span> <span class="o">=</span> <span class="n">vit_average_time_per_pred</span>
<span class="n">vit_stats</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-43"># Agregue el tiempo de predicción promedio para el modelo ViT en la CPU
vit_stats["time_per_pred_cpu"] = vit_average_time_per_pred
vit_stats</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=62926330">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="6-comparacion-de-resultados-de-modelos-tiempos-de-prediccion-y-tamano">6. Comparación de resultados de modelos, tiempos de predicción y tamaño<a class="anchor-link" href="#6-comparacion-de-resultados-de-modelos-tiempos-de-prediccion-y-tamano">¶</a></h2><p>Nuestros dos mejores modelos contendientes han sido capacitados y evaluados.</p>
<p>Ahora pongámoslos cara a cara y comparemos sus diferentes estadísticas.</p>
<p>Para hacerlo, convierta nuestros diccionarios <code>effnetb2_stats</code> y <code>vit_stats</code> en un DataFrame de pandas.</p>
<p>Agregaremos una columna para ver los nombres de los modelos y convertiremos la precisión de la prueba a un porcentaje completo en lugar de decimal.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=f60f2df0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-44">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Convierta los diccionarios de estadísticas en DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">effnetb2_stats</span><span class="p">,</span> <span class="n">vit_stats</span><span class="p">])</span>

<span class="c1"># Agregar columna para nombres de modelos</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"model"</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"EffNetB2"</span><span class="p">,</span> <span class="s2">"ViT"</span><span class="p">]</span>

<span class="c1"># Convertir precisión a porcentajes</span>
<span class="n">df</span><span class="p">[</span><span class="s2">"test_acc"</span><span class="p">]</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">"test_acc"</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">df</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-44"># Convierta los diccionarios de estadísticas en DataFrame
df = pd.DataFrame([effnetb2_stats, vit_stats])

# Agregar columna para nombres de modelos
df["model"] = ["EffNetB2", "ViT"]

# Convertir precisión a porcentajes
df["test_acc"] = round(df["test_acc"] * 100, 2)

df</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=f22e6f8e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Maravilloso!</p>
<p>Parece que nuestros modelos son bastante parecidos en términos de precisión general de las pruebas, pero ¿cómo se ven en otros campos?</p>
<p>Una forma de averiguarlo sería dividir las estadísticas del modelo ViT por las estadísticas del modelo EffNetB2 para descubrir las diferentes proporciones entre los modelos.</p>
<p>Creemos otro DataFrame para hacerlo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=da434fcd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-45">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Compare ViT con EffNetB2 según diferentes características</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"model"</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">"ViT"</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">"model"</span><span class="p">)</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">"EffNetB2"</span><span class="p">]),</span> <span class="c1"># divide ViT statistics by EffNetB2 statistics</span>
             <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">"ViT to EffNetB2 ratios"</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-45"># Compare ViT con EffNetB2 según diferentes características
pd.DataFrame(data=(df.set_index("model").loc["ViT"] / df.set_index("model").loc["EffNetB2"]), # divide ViT statistics by EffNetB2 statistics
             columns=["ViT to EffNetB2 ratios"]).T</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=dc14ef8e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Parece que nuestro modelo ViT supera al modelo EffNetB2 en todas las métricas de rendimiento (pérdida de prueba, donde menor es mejor y precisión de la prueba, donde mayor es mejor), pero a expensas de tener:</p>
<ul>
<li>11x+ el número de parámetros.</li>
<li>11x+ el tamaño del modelo.</li>
<li>2,5 veces más el tiempo de predicción por imagen.</li>
</ul>
<p>¿Valen la pena estas compensaciones?</p>
<p>Quizás si tuviéramos una potencia informática ilimitada, pero para nuestro caso de uso de implementar el modelo FoodVision Mini en un dispositivo más pequeño (por ejemplo, un teléfono móvil), probablemente comenzaríamos con el modelo EffNetB2 para realizar predicciones más rápidas con un rendimiento ligeramente reducido pero dramáticamente más pequeño. tamaño.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9746fdcb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="61-visualizacion-del-equilibrio-entre-velocidad-y-rendimiento">6.1 Visualización del equilibrio entre velocidad y rendimiento<a class="anchor-link" href="#61-visualizacion-del-equilibrio-entre-velocidad-y-rendimiento">¶</a></h3><p>Hemos visto que nuestro modelo ViT supera a nuestro modelo EffNetB2 en términos de métricas de rendimiento, como pérdida de prueba y precisión de prueba.</p>
<p>Sin embargo, nuestro modelo EffNetB2 realiza predicciones más rápido y tiene un tamaño de modelo mucho más pequeño.</p>
<blockquote>
<p><strong>Nota:</strong> El tiempo de rendimiento o inferencia también suele denominarse "latencia".</p>
</blockquote>
<p>¿Qué tal si hacemos que este hecho sea visual?</p>
<p>Podemos hacerlo creando un gráfico con matplotlib:</p>
<ol>
<li>Cree un diagrama de dispersión a partir del marco de datos de comparación para comparar los valores <code>time_per_pred_cpu</code> y <code>test_acc</code> de EffNetB2 y ViT.</li>
<li>Agregue títulos y etiquetas correspondientes a los datos y personalice el tamaño de fuente por motivos estéticos.</li>
<li>Anote las muestras en el diagrama de dispersión del paso 1 con sus etiquetas apropiadas (los nombres de los modelos).</li>
<li>Cree una leyenda basada en los tamaños del modelo (<code>model_size (MB)</code>).</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=791f8a56">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-46">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># 1. Cree un gráfico a partir del marco de datos de comparación de modelos.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> 
                     <span class="n">x</span><span class="o">=</span><span class="s2">"time_per_pred_cpu"</span><span class="p">,</span> 
                     <span class="n">y</span><span class="o">=</span><span class="s2">"test_acc"</span><span class="p">,</span> 
                     <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="s2">"blue"</span><span class="p">,</span> <span class="s2">"orange"</span><span class="p">],</span> <span class="c1"># what colours to use?</span>
                     <span class="n">s</span><span class="o">=</span><span class="s2">"model_size (MB)"</span><span class="p">)</span> <span class="c1"># size the dots by the model sizes</span>

<span class="c1"># 2. Agregue títulos, etiquetas y personalice el tamaño de fuente por motivos estéticos.</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">"FoodVision Mini Inference Speed vs Performance"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">"Prediction time per image (seconds)"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">"Test accuracy (%)"</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">'both'</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 3. Anotar con nombres de modelos</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">row</span><span class="p">[</span><span class="s2">"model"</span><span class="p">],</span> <span class="c1"># note: depending on your version of Matplotlib, you may need to use "s=..." or "text=...", see: https://github.com/faustomorales/keras-ocr/issues/183#issuecomment-977733270 </span>
                <span class="n">xy</span><span class="o">=</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s2">"time_per_pred_cpu"</span><span class="p">]</span><span class="o">+</span><span class="mf">0.0006</span><span class="p">,</span> <span class="n">row</span><span class="p">[</span><span class="s2">"test_acc"</span><span class="p">]</span><span class="o">+</span><span class="mf">0.03</span><span class="p">),</span>
                <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># 4. Crea una leyenda basada en los tamaños del modelo.</span>
<span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">scatter</span><span class="o">.</span><span class="n">legend_elements</span><span class="p">(</span><span class="n">prop</span><span class="o">=</span><span class="s2">"sizes"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">model_size_legend</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="p">,</span> 
                              <span class="n">labels</span><span class="p">,</span> 
                              <span class="n">loc</span><span class="o">=</span><span class="s2">"lower right"</span><span class="p">,</span> 
                              <span class="n">title</span><span class="o">=</span><span class="s2">"Model size (MB)"</span><span class="p">,</span>
                              <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># guarda la figura</span>
<span class="err">!</span><span class="n">mdkir</span> <span class="n">images</span><span class="o">/</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">"images/09-foodvision-mini-inference-speed-vs-performance.jpg"</span><span class="p">)</span>

<span class="c1"># mostrar la figura</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-46"># 1. Cree un gráfico a partir del marco de datos de comparación de modelos.
fig, ax = plt.subplots(figsize=(12, 8))
scatter = ax.scatter(data=df, 
                     x="time_per_pred_cpu", 
                     y="test_acc", 
                     c=["blue", "orange"], # what colours to use?
                     s="model_size (MB)") # size the dots by the model sizes

# 2. Agregue títulos, etiquetas y personalice el tamaño de fuente por motivos estéticos.
ax.set_title("FoodVision Mini Inference Speed vs Performance", fontsize=18)
ax.set_xlabel("Prediction time per image (seconds)", fontsize=14)
ax.set_ylabel("Test accuracy (%)", fontsize=14)
ax.tick_params(axis='both', labelsize=12)
ax.grid(True)

# 3. Anotar con nombres de modelos
for index, row in df.iterrows():
    ax.annotate(text=row["model"], # note: depending on your version of Matplotlib, you may need to use "s=..." or "text=...", see: https://github.com/faustomorales/keras-ocr/issues/183#issuecomment-977733270 
                xy=(row["time_per_pred_cpu"]+0.0006, row["test_acc"]+0.03),
                size=12)

# 4. Crea una leyenda basada en los tamaños del modelo.
handles, labels = scatter.legend_elements(prop="sizes", alpha=0.5)
model_size_legend = ax.legend(handles, 
                              labels, 
                              loc="lower right", 
                              title="Model size (MB)",
                              fontsize=12)

# guarda la figura
!mdkir images/
plt.savefig("images/09-foodvision-mini-inference-speed-vs-performance.jpg")

# mostrar la figura
plt.show()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4c6dd1f6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Guau!</p>
<p>La gráfica realmente visualiza la <strong>velocidad versus rendimiento</strong>; en otras palabras, cuando tienes un modelo profundo más grande y de mejor rendimiento (como nuestro modelo ViT), <em>generalmente</em> lleva más tiempo realizar la inferencia (mayor latencia).</p>
<p>Hay excepciones a la regla y constantemente se publican nuevas investigaciones para ayudar a que los modelos más grandes funcionen más rápido.</p>
<p>Y puede resultar tentador simplemente implementar el modelo de <em>mejor</em> rendimiento, pero también es bueno tener en cuenta dónde funcionará el modelo.</p>
<p>En nuestro caso, las diferencias entre los niveles de rendimiento de nuestro modelo (en la pérdida de prueba y la precisión de la prueba) no son demasiado extremas.</p>
<p>Pero como para empezar nos gustaría poner énfasis en la velocidad, seguiremos implementando EffNetB2 ya que es más rápido y ocupa mucho menos espacio.</p>
<blockquote>
<p><strong>Nota:</strong> Los tiempos de predicción serán diferentes según los diferentes tipos de hardware (por ejemplo, Intel i9 frente a CPU de Google Colab frente a GPU), por lo que es importante pensar y probar dónde terminará su modelo. Hacer preguntas como "¿dónde se ejecutará el modelo?" o "¿cuál es el escenario ideal para ejecutar el modelo?" y luego realizar experimentos para intentar proporcionar respuestas en el camino hacia la implementación es muy útil.</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9da51ad8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="7-dar-vida-a-foodvision-mini-creando-una-demostracion-de-gradio">7. Dar vida a FoodVision Mini creando una demostración de Gradio<a class="anchor-link" href="#7-dar-vida-a-foodvision-mini-creando-una-demostracion-de-gradio">¶</a></h2><p>Hemos decidido que nos gustaría implementar el modelo EffNetB2 (para empezar, esto siempre se puede cambiar más adelante).</p>
<p>Entonces, ¿cómo podemos hacer eso?</p>
<p>Hay varias formas de implementar un modelo de aprendizaje automático, cada una con casos de uso específicos (como se analizó anteriormente).</p>
<p>Nos centraremos en la que quizás sea la forma más rápida y ciertamente una de las más divertidas de implementar un modelo en Internet.</p>
<p>Y eso es usando <a href="https://gradio.app/">Gradio</a>.</p>
<p>¿Qué es Gradio?</p>
<p>La página de inicio lo describe maravillosamente:</p>
<blockquote>
<p>Gradio es la forma más rápida de hacer una demostración de su modelo de aprendizaje automático con una interfaz web amigable para que cualquiera pueda usarlo, ¡en cualquier lugar!</p>
</blockquote>
<p>¿Por qué crear una demostración de tus modelos?</p>
<p>Porque las métricas en el conjunto de prueba se ven bien, pero nunca se sabe realmente cómo se desempeña su modelo hasta que lo usa en la naturaleza.</p>
<p>¡Así que comencemos a implementar!</p>
<p>Comenzaremos importando Gradio con el alias común <code>gr</code> y, si no está presente, lo instalaremos.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=16950ef8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-47">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Importar/instalar Gradio</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
<span class="k">except</span><span class="p">:</span> 
    <span class="err">!</span><span class="n">pip</span> <span class="o">-</span><span class="n">q</span> <span class="n">install</span> <span class="n">gradio</span>
    <span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
    
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Gradio version: </span><span class="si">{</span><span class="n">gr</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-47"># Importar/instalar Gradio
try:
    import gradio as gr
except: 
    !pip -q install gradio
    import gradio as gr
    
print(f"Gradio version: {gr.__version__}")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=43ca4692">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Gradio listo!</p>
<p>Convirtamos FoodVision Mini en una aplicación de demostración.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2d8ecb68">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="71-descripcion-general-de-gradio">7.1 Descripción general de Gradio<a class="anchor-link" href="#71-descripcion-general-de-gradio">¶</a></h3><p>La premisa general de Gradio es muy similar a la que hemos ido repitiendo a lo largo del curso.</p>
<p>¿Cuáles son nuestras <strong>entradas</strong> y <strong>salidas</strong>?</p>
<p>¿Y cómo deberíamos llegar allí?</p>
<p>Bueno, eso es lo que hace nuestro modelo de aprendizaje automático.</p>
<pre><code>entradas -&gt; modelo ML -&gt; salidas
</code></pre>
<p>En nuestro caso, para FoodVision Mini, nuestras entradas son imágenes de comida, nuestro modelo ML es EffNetB2 y nuestras salidas son clases de comida (pizza, bistec o sushi).</p>
<pre><code>imágenes de alimentos -&gt; EffNetB2 -&gt; salidas
</code></pre>
<p>Aunque los conceptos de entradas y salidas pueden vincularse a casi cualquier otro tipo de problema de ML.</p>
<p>Sus entradas y salidas pueden ser cualquier combinación de lo siguiente:</p>
<ul>
<li>Imágenes</li>
<li>Texto</li>
<li>Video</li>
<li>Datos tabulados
*Audio</li>
<li>Números</li>
<li>&amp; más</li>
</ul>
<p>Y el modelo de ML que cree dependerá de sus entradas y salidas.</p>
<p>Gradio emula este paradigma creando una interfaz (<a href="https://gradio.app/docs/#interface-header"><code>gradio.Interface()</code></a>) desde las entradas hasta las salidas.</p>
<pre><code>gradio.Interface(fn, entradas, salidas)
</code></pre>
<p>Donde, "fn" es una función de Python para asignar las "entradas" a las "salidas".</p>
<img alt="flujo de trabajo de gradio de entradas que fluyen hacia algún tipo de modelo o función y luego producir resultados" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-gradio-workflow.png" width="900/"/>
<p><em>Gradio proporciona una clase <code>Interfaz</code> muy útil para crear fácilmente entradas -&gt; modelo/función -&gt; flujo de trabajo de salidas donde las entradas y salidas pueden ser casi cualquier cosa que desee. Por ejemplo, puede ingresar Tweets (texto) para ver si tratan sobre aprendizaje automático o no o <a href="https://huggingface.co/blog/stable_diffusion">ingrese un mensaje de texto para generar imágenes</a>.</em></p>
<blockquote>
<p><strong>Nota:</strong> Gradio tiene una gran cantidad de posibles opciones de "entradas" y "salidas" conocidas como "Componentes", desde imágenes hasta texto, números, audio, videos y más. Puede verlos todos en la [documentación de componentes de Gradio] (<a href="https://gradio.app/docs/#components">https://gradio.app/docs/#components</a>).</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cee313d1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="72-creando-una-funcion-para-mapear-nuestras-entradas-y-salidas">7.2 Creando una función para mapear nuestras entradas y salidas<a class="anchor-link" href="#72-creando-una-funcion-para-mapear-nuestras-entradas-y-salidas">¶</a></h3><p>Para crear nuestra demostración de FoodVision Mini con Gradio, necesitaremos una función para asignar nuestras entradas a nuestras salidas.</p>
<p>Anteriormente creamos una función llamada <code>pred_and_store()</code> para hacer predicciones con un modelo determinado en una lista de archivos de destino y almacenarlos en una lista de diccionarios.</p>
<p>¿Qué tal si creamos una función similar pero esta vez centrándonos en hacer una predicción en una sola imagen con nuestro modelo EffNetB2?</p>
<p>Más específicamente, queremos una función que tome una imagen como entrada, la preprocese (transforme), haga una predicción con EffNetB2 y luego devuelva la predicción (pred o etiqueta pred para abreviar), así como la probabilidad de predicción (pred prob).</p>
<p>Y ya que estamos aquí, retrocedamos el tiempo que nos llevó hacerlo también:</p>
<pre><code>entrada: imagen -&gt; transformar -&gt; predecir con EffNetB2 -&gt; salida: pred, pred prob, tiempo necesario
</code></pre>
<p>Este será nuestro parámetro <code>fn</code> para nuestra interfaz Gradio.</p>
<p>Primero, asegurémonos de que nuestro modelo EffNetB2 esté en la CPU (ya que nos atenemos a las predicciones solo de CPU, sin embargo, puedes cambiar esto si tienes acceso a una GPU).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4bed7038">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-48">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Ponga EffNetB2 en la CPU</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">)</span> 

<span class="c1"># Verifique el dispositivo</span>
<span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">effnetb2</span><span class="o">.</span><span class="n">parameters</span><span class="p">()))</span><span class="o">.</span><span class="n">device</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-48"># Ponga EffNetB2 en la CPU
effnetb2.to("cpu") 

# Verifique el dispositivo
next(iter(effnetb2.parameters())).device</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2d2e1f3f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Y ahora creemos una función llamada <code>predict()</code> para replicar el flujo de trabajo anterior.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=77bd31f1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-49">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Transforms and performs a prediction on img and returns prediction and time taken.</span>
<span class="sd">    """</span>
    <span class="c1"># Start the timer</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    
    <span class="c1"># Transform the target image and add a batch dimension</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">effnetb2_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put model into evaluation mode and turn on inference mode</span>
    <span class="n">effnetb2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="c1"># Pass the transformed image through the model and turn the prediction logits into prediction probabilities</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">effnetb2</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)</span>
    <span class="n">pred_labels_and_probs</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))}</span>
    
    <span class="c1"># Calculate the prediction time</span>
    <span class="n">pred_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Return the prediction dictionary and prediction time </span>
    <span class="k">return</span> <span class="n">pred_labels_and_probs</span><span class="p">,</span> <span class="n">pred_time</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-49">from typing import Tuple, Dict

def predict(img) -&gt; Tuple[Dict, float]:
    """Transforms and performs a prediction on img and returns prediction and time taken.
    """
    # Start the timer
    start_time = timer()
    
    # Transform the target image and add a batch dimension
    img = effnetb2_transforms(img).unsqueeze(0)
    
    # Put model into evaluation mode and turn on inference mode
    effnetb2.eval()
    with torch.inference_mode():
        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities
        pred_probs = torch.softmax(effnetb2(img), dim=1)
    
    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)
    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}
    
    # Calculate the prediction time
    pred_time = round(timer() - start_time, 5)
    
    # Return the prediction dictionary and prediction time 
    return pred_labels_and_probs, pred_time</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4eb99888">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Hermoso!</p>
<p>Ahora veamos nuestra función en acción realizando una predicción en una imagen aleatoria del conjunto de datos de prueba.</p>
<p>Comenzaremos obteniendo una lista de todas las rutas de imágenes del directorio de prueba y luego seleccionaremos una al azar.</p>
<p>Luego abriremos la imagen seleccionada al azar con <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#functions"><code>PIL.Image.open()</code></a>.</p>
<p>Finalmente, pasaremos la imagen a nuestra función <code>predict()</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3618b98e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-50">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="c1"># Obtenga una lista de todas las rutas de archivos de imágenes de prueba</span>
<span class="n">test_data_paths</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">test_dir</span><span class="p">)</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">"*/*.jpg"</span><span class="p">))</span>

<span class="c1"># Seleccione aleatoriamente una ruta de imagen de prueba</span>
<span class="n">random_image_path</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">test_data_paths</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Abra la imagen de destino</span>
<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">random_image_path</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Predicting on image at path: </span><span class="si">{</span><span class="n">random_image_path</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Predecir sobre la imagen de destino e imprimir los resultados.</span>
<span class="n">pred_dict</span><span class="p">,</span> <span class="n">pred_time</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">img</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction label and probability dictionary: </span><span class="se">\n</span><span class="si">{</span><span class="n">pred_dict</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Prediction time: </span><span class="si">{</span><span class="n">pred_time</span><span class="si">}</span><span class="s2"> seconds"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-50">import random
from PIL import Image

# Obtenga una lista de todas las rutas de archivos de imágenes de prueba
test_data_paths = list(Path(test_dir).glob("*/*.jpg"))

# Seleccione aleatoriamente una ruta de imagen de prueba
random_image_path = random.sample(test_data_paths, k=1)[0]

# Abra la imagen de destino
image = Image.open(random_image_path)
print(f"[INFO] Predicting on image at path: {random_image_path}\n")

# Predecir sobre la imagen de destino e imprimir los resultados.
pred_dict, pred_time = predict(img=image)
print(f"Prediction label and probability dictionary: \n{pred_dict}")
print(f"Prediction time: {pred_time} seconds")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=5db48bb9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Lindo!</p>
<p>Al ejecutar la celda de arriba varias veces, podemos ver diferentes probabilidades de predicción para cada etiqueta de nuestro modelo EffNetB2, así como el tiempo que tomó cada predicción.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a0d28a9c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="73-crear-una-lista-de-imagenes-de-ejemplo">7.3 Crear una lista de imágenes de ejemplo<a class="anchor-link" href="#73-crear-una-lista-de-imagenes-de-ejemplo">¶</a></h3><p>Nuestra función <code>predict()</code> nos permite ir desde entradas -&gt; transformar -&gt; modelo ML -&gt; salidas.</p>
<p>Que es exactamente lo que necesitamos para nuestra demostración de Graido.</p>
<p>Pero antes de crear la demostración, creemos una cosa más: una lista de ejemplos.</p>
<p>La clase <a href="https://gradio.app/docs/#interface"><code>Interface</code></a> de Gradio toma una lista de <code>ejemplos</code> como parámetro opcional (<code>gradio.Interface(examples=List[Any])</code>).</p>
<p>Y el formato del parámetro "ejemplos" es una lista de listas.</p>
<p>Entonces, creemos una lista de listas que contengan rutas de archivos aleatorias a nuestras imágenes de prueba.</p>
<p>Tres ejemplos deberían ser suficientes.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=3e6081d9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-51">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Cree una lista de entradas de ejemplo para nuestra demostración de Gradio</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">str</span><span class="p">(</span><span class="n">filepath</span><span class="p">)]</span> <span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">test_data_paths</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">example_list</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-51"># Cree una lista de entradas de ejemplo para nuestra demostración de Gradio
example_list = [[str(filepath)] for filepath in random.sample(test_data_paths, k=3)]
example_list</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=639cef4a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Perfecto!</p>
<p>Nuestra demostración de Gradio los mostrará como entradas de ejemplo para nuestra demostración para que las personas puedan probarlo y ver qué hace sin cargar ninguno de sus propios datos.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=30ccd91e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="74-construyendo-una-interfaz-gradio">7.4 Construyendo una interfaz Gradio<a class="anchor-link" href="#74-construyendo-una-interfaz-gradio">¶</a></h3><p>¡Es hora de juntar todo y darle vida a nuestra demostración de FoodVision Mini!</p>
<p>Creemos una interfaz Gradio para replicar el flujo de trabajo:</p>
<pre><code>entrada: imagen -&gt; transformar -&gt; predecir con EffNetB2 -&gt; salida: pred, pred prob, tiempo necesario
</code></pre>
<p>Lo podemos hacer con la clase <a href="https://gradio.app/docs/#interface"><code>gradio.Interface()</code></a> con los siguientes parámetros:</p>
<ul>
<li><code>fn</code> - una función de Python para asignar <code>entradas</code> a <code>salidas</code>; en nuestro caso, usaremos nuestra función <code>predict()</code>.</li>
<li><code>inputs</code>: la entrada a nuestra interfaz, como una imagen usando <a href="https://gradio.app/docs/#image"><code>gradio.Image()</code></a> o <code>"image"</code>.</li>
<li><code>outputs</code> - la salida de nuestra interfaz una vez que las <code>inputs</code> han pasado por <code>fn</code>, como una etiqueta usando <a href="https://gradio.app/docs/#label"><code>gradio.Label()</code></a> (para las etiquetas predichas de nuestro modelo) o número usando <a href="https://gradio.app/docs/#number"><code>gradio.Number()</code></a> (para el tiempo de predicción de nuestro modelo).<ul>
<li><strong>Nota:</strong> Gradio viene con muchas opciones integradas de <code>entradas</code> y <code>salidas</code> conocidas como <a href="https://gradio.app/docs/#components">"Componentes"</a>.</li>
</ul>
</li>
<li><code>ejemplos</code>: una lista de ejemplos para mostrar en la demostración.</li>
<li><code>title</code> - un título de cadena de la demostración.</li>
<li><code>descripción</code>: una cadena de descripción de la demostración.</li>
<li><code>artículo</code>: una nota de referencia al final de la demostración.</li>
</ul>
<p>Una vez que hayamos creado nuestra instancia de demostración de <code>gr.Interface()</code>, podemos darle vida usando [<code>gradio.Interface().launch()</code>](<a href="https://gradio.app/docs/#launch">https://gradio.app/docs/#launch</a> -header) o el comando <code>demo.launch()</code>.</p>
<p>¡Fácil!</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4c456b2a">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-52">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>

<span class="c1"># Crear cadenas de título, descripción y artículo.</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">"FoodVision Mini 🍕🥩🍣"</span>
<span class="n">description</span> <span class="o">=</span> <span class="s2">"An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi."</span>
<span class="n">article</span> <span class="o">=</span> <span class="s2">"Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."</span>

<span class="c1"># Crea la demostración de Gradio</span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span> <span class="c1"># mapping function from input to output</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"pil"</span><span class="p">),</span> <span class="c1"># what are the inputs?</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">gr</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">num_top_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Predictions"</span><span class="p">),</span> <span class="c1"># what are the outputs?</span>
                             <span class="n">gr</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">"Prediction time (s)"</span><span class="p">)],</span> <span class="c1"># our fn has two outputs, therefore we have two outputs</span>
                    <span class="n">examples</span><span class="o">=</span><span class="n">example_list</span><span class="p">,</span> 
                    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
                    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
                    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">)</span>

<span class="c1"># ¡Lanza la demostración!</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># print errors locally?</span>
            <span class="n">share</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># generate a publically shareable URL?</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-52">import gradio as gr

# Crear cadenas de título, descripción y artículo.
title = "FoodVision Mini 🍕🥩🍣"
description = "An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi."
article = "Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."

# Crea la demostración de Gradio
demo = gr.Interface(fn=predict, # mapping function from input to output
                    inputs=gr.Image(type="pil"), # what are the inputs?
                    outputs=[gr.Label(num_top_classes=3, label="Predictions"), # what are the outputs?
                             gr.Number(label="Prediction time (s)")], # our fn has two outputs, therefore we have two outputs
                    examples=example_list, 
                    title=title,
                    description=description,
                    article=article)

# ¡Lanza la demostración!
demo.launch(debug=False, # print errors locally?
            share=True) # generate a publically shareable URL?</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2da65725">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<img alt=" Demostración de Gradio ejecutándose en Google Colab y en la web" src="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/09-gradio-running-in-google-colab-and-in-browser.gif" width="750/"/>
<p><em>Demo de FoodVision Mini Gradio ejecutándose en Google Colab y en el navegador (el enlace cuando se ejecuta desde Google Colab solo dura 72 horas). Puedes ver la <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">demo permanente en vivo en Hugging Face Spaces</a>.</em></p>
<p>¡¡¡Guau!!! ¡¡¡Qué demostración tan épica!!!</p>
<p>FoodVision Mini ha cobrado vida oficialmente en una interfaz que alguien podría usar y probar.</p>
<p>Si configura el parámetro <code>share=True</code> en el método <code>launch()</code>, Gradio también le proporciona un enlace para compartir como <code>https://123XYZ.gradio.app</code> (este enlace es solo un ejemplo y probablemente esté vencido). ) que es válido por 72 horas.</p>
<p>El enlace proporciona un proxy a la interfaz de Gradio que inició.</p>
<p>Para un alojamiento más permanente, puede cargar su aplicación Gradio en <a href="https://huggingface.co/spaces">Hugging Face Spaces</a> o en cualquier lugar que ejecute código Python.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=895b8927">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="8-convertir-nuestra-demostracion-foodvision-mini-gradio-en-una-aplicacion-implementable">8. Convertir nuestra demostración FoodVision Mini Gradio en una aplicación implementable<a class="anchor-link" href="#8-convertir-nuestra-demostracion-foodvision-mini-gradio-en-una-aplicacion-implementable">¶</a></h2><p>Hemos visto nuestro modelo FoodVision Mini cobrar vida a través de una demostración de Gradio.</p>
<p>Pero ¿y si quisiéramos compartirlo con nuestros amigos?</p>
<p>Bueno, podríamos usar el enlace de Gradio proporcionado, sin embargo, el enlace compartido solo dura 72 horas.</p>
<p>Para que nuestra demostración de FoodVision Mini sea más permanente, podemos empaquetarla en una aplicación y cargarla en <a href="https://huggingface.co/spaces/launch">Hugging Face Spaces</a>.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=720ff935">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="81-que-es-abrazar-los-espacios-faciales">8.1 ¿Qué es abrazar los espacios faciales?<a class="anchor-link" href="#81-que-es-abrazar-los-espacios-faciales">¶</a></h3><p>Hugging Face Spaces es un recurso que le permite alojar y compartir aplicaciones de aprendizaje automático.</p>
<p>Crear una demostración es una de las mejores formas de mostrar y probar lo que ha hecho.</p>
<p>Y Spaces te permite hacer precisamente eso.</p>
<p>Puedes pensar en Hugging Face como el GitHub del aprendizaje automático.</p>
<p>Si tener un buen portafolio de GitHub muestra tus habilidades de codificación, tener un buen portafolio de Hugging Face puede mostrar tus habilidades de aprendizaje automático.</p>
<blockquote>
<p><strong>Nota:</strong> Hay muchos otros lugares donde podríamos cargar y alojar nuestra aplicación Gradio, como Google Cloud, AWS (Amazon Web Services) u otros proveedores de nube; sin embargo, usaremos Hugging Face Spaces debido a la facilidad de uso y la amplia adopción por parte de la comunidad de aprendizaje automático.</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=cc5a3777">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="82-estructura-de-la-aplicacion-gradio-implementada">8.2 Estructura de la aplicación Gradio implementada<a class="anchor-link" href="#82-estructura-de-la-aplicacion-gradio-implementada">¶</a></h3><p>Para cargar nuestra aplicación de demostración Gradio, queremos colocar todo lo relacionado con ella en un solo directorio.</p>
<p>Por ejemplo, nuestra demostración podría estar en la ruta <code>demos/foodvision_mini/</code> con la estructura de archivos:</p>
<pre><code>población/
└── comidavision_mini/
    ├── 09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth
    ├── aplicación.py
    ├── ejemplos/
    │ ├── ejemplo_1.jpg
    │ ├── ejemplo_2.jpg
    │ └── ejemplo_3.jpg
    ├── modelo.py
    └── requisitos.txt
</code></pre>
<p>Dónde:</p>
<ul>
<li><code>09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth</code> es nuestro archivo modelo PyTorch entrenado.</li>
<li><code>app.py</code> contiene nuestra aplicación Gradio (similar al código que inició la aplicación).<ul>
<li><strong>Nota:</strong> <code>app.py</code> es el nombre de archivo predeterminado utilizado para Hugging Face Spaces. Si implementas tu aplicación allí, Spaces buscará de manera predeterminada un archivo llamado <code>app.py</code> para ejecutar. Esto se puede cambiar en la configuración.</li>
</ul>
</li>
<li><code>examples/</code> contiene imágenes de ejemplo para usar con nuestra aplicación Gradio.</li>
<li><code>model.py</code> contiene la definición del modelo, así como cualquier transformación asociada con el modelo.</li>
<li><code>requirements.txt</code> contiene las dependencias para ejecutar nuestra aplicación, como <code>torch</code>, <code>torchvision</code> y <code>gradio</code>.</li>
</ul>
<p>¿Por qué de esta manera?</p>
<p>Porque es uno de los diseños más simples con los que podríamos empezar.</p>
<p>Nuestro enfoque es: <em>¡experimentar, experimentar, experimentar!</em></p>
<p>Cuanto más rápido podamos realizar experimentos más pequeños, mejores serán los más grandes.</p>
<p>Vamos a trabajar para recrear la estructura anterior, pero puedes ver una aplicación de demostración en vivo ejecutándose en Hugging Face Spaces, así como la estructura de archivos:</p>
<ul>
<li><a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">Demostración en vivo de Gradio de FoodVision Mini 🍕🥩🍣</a>.</li>
<li><a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini/tree/main">Estructura de archivos FoodVision Mini en Hugging Face Spaces</a>.</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=88a284c2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="83-creando-una-carpeta-demos-para-almacenar-los-archivos-de-nuestra-aplicacion-foodvision-mini">8.3 Creando una carpeta <code>demos</code> para almacenar los archivos de nuestra aplicación FoodVision Mini<a class="anchor-link" href="#83-creando-una-carpeta-demos-para-almacenar-los-archivos-de-nuestra-aplicacion-foodvision-mini">¶</a></h3><p>Para comenzar, primero creemos un directorio <code>demos/</code> para almacenar todos los archivos de nuestra aplicación FoodVision Mini.</p>
<p>Podemos hacerlo con <a href="https://docs.python.org/3/library/pathlib.html#basic-use"><code>pathlib.Path("path_to_dir")</code></a> de Python para establecer la ruta del directorio y <a href="https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir"><code>pathlib. Path("path_to_dir").mkdir()</code></a> para crearlo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a9d63c66">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-53">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Crear una mini ruta de demostración de FoodVision</span>
<span class="n">foodvision_mini_demo_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"demos/foodvision_mini/"</span><span class="p">)</span>

<span class="c1"># Elimine los archivos que ya puedan existir allí y cree un nuevo directorio</span>
<span class="k">if</span> <span class="n">foodvision_mini_demo_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">foodvision_mini_demo_path</span><span class="p">)</span>
    <span class="n">foodvision_mini_demo_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># make the parent folders?</span>
                                    <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># create it even if it already exists?</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># If the file doesn't exist, create it anyway</span>
    <span class="n">foodvision_mini_demo_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                    <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="c1"># Comprueba lo que hay en la carpeta.</span>
<span class="err">!</span><span class="n">ls</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-53">import shutil
from pathlib import Path

# Crear una mini ruta de demostración de FoodVision
foodvision_mini_demo_path = Path("demos/foodvision_mini/")

# Elimine los archivos que ya puedan existir allí y cree un nuevo directorio
if foodvision_mini_demo_path.exists():
    shutil.rmtree(foodvision_mini_demo_path)
    foodvision_mini_demo_path.mkdir(parents=True, # make the parent folders?
                                    exist_ok=True) # create it even if it already exists?
else:
    # If the file doesn't exist, create it anyway
    foodvision_mini_demo_path.mkdir(parents=True, 
                                    exist_ok=True)
    
# Comprueba lo que hay en la carpeta.
!ls demos/foodvision_mini/</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=39c75470">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="84-crear-una-carpeta-de-imagenes-de-ejemplo-para-usar-con-nuestra-demostracion-de-foodvision-mini">8.4 Crear una carpeta de imágenes de ejemplo para usar con nuestra demostración de FoodVision Mini<a class="anchor-link" href="#84-crear-una-carpeta-de-imagenes-de-ejemplo-para-usar-con-nuestra-demostracion-de-foodvision-mini">¶</a></h3><p>Ahora que tenemos un directorio para almacenar nuestros archivos de demostración de FoodVision Mini, agreguemos algunos ejemplos.</p>
<p>Tres imágenes de ejemplo del conjunto de datos de prueba deberían ser suficientes.</p>
<p>Para hacerlo haremos:</p>
<ol>
<li>Cree un directorio <code>examples/</code> dentro del directorio <code>demos/foodvision_mini</code>.</li>
<li>Elija tres imágenes aleatorias del conjunto de datos de prueba y recopile sus rutas de archivo en una lista.</li>
<li>Copie las tres imágenes aleatorias del conjunto de datos de prueba al directorio <code>demos/foodvision_mini/examples/</code>.</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a2ea4b50">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-54">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># 1. Cree un directorio de ejemplos</span>
<span class="n">foodvision_mini_examples_path</span> <span class="o">=</span> <span class="n">foodvision_mini_demo_path</span> <span class="o">/</span> <span class="s2">"examples"</span>
<span class="n">foodvision_mini_examples_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># 2. Recopile tres rutas de imágenes de conjuntos de datos de prueba aleatorias</span>
<span class="n">foodvision_mini_examples</span> <span class="o">=</span> <span class="p">[</span><span class="n">Path</span><span class="p">(</span><span class="s1">'data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg'</span><span class="p">),</span>
                            <span class="n">Path</span><span class="p">(</span><span class="s1">'data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg'</span><span class="p">),</span>
                            <span class="n">Path</span><span class="p">(</span><span class="s1">'data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg'</span><span class="p">)]</span>

<span class="c1"># 3. Copie las tres imágenes aleatorias al directorio de ejemplos.</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">foodvision_mini_examples</span><span class="p">:</span>
    <span class="n">destination</span> <span class="o">=</span> <span class="n">foodvision_mini_examples_path</span> <span class="o">/</span> <span class="n">example</span><span class="o">.</span><span class="n">name</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Copying </span><span class="si">{</span><span class="n">example</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">destination</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">copy2</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">example</span><span class="p">,</span> <span class="n">dst</span><span class="o">=</span><span class="n">destination</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-54">import shutil
from pathlib import Path

# 1. Cree un directorio de ejemplos
foodvision_mini_examples_path = foodvision_mini_demo_path / "examples"
foodvision_mini_examples_path.mkdir(parents=True, exist_ok=True)

# 2. Recopile tres rutas de imágenes de conjuntos de datos de prueba aleatorias
foodvision_mini_examples = [Path('data/pizza_steak_sushi_20_percent/test/sushi/592799.jpg'),
                            Path('data/pizza_steak_sushi_20_percent/test/steak/3622237.jpg'),
                            Path('data/pizza_steak_sushi_20_percent/test/pizza/2582289.jpg')]

# 3. Copie las tres imágenes aleatorias al directorio de ejemplos.
for example in foodvision_mini_examples:
    destination = foodvision_mini_examples_path / example.name
    print(f"[INFO] Copying {example} to {destination}")
    shutil.copy2(src=example, dst=destination)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ea6f0701">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Ahora, para verificar que nuestros ejemplos estén presentes, enumeremos el contenido de nuestro directorio <code>demos/foodvision_mini/examples/</code> con [<code>os.listdir()</code>](<a href="https://docs.python.org/3/library/os">https://docs.python.org/3/library/os</a>. html#os.listdir) y luego formatee las rutas de archivo en una lista de listas (para que sea compatible con el parámetro <code>example</code> <a href="https://gradio.app/docs/#interface"><code>gradio.Interface()</code></a> de Gradio) .</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a7af12c8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-55">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># Obtenga rutas de archivos de ejemplo en una lista de listas</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"examples/"</span> <span class="o">+</span> <span class="n">example</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">foodvision_mini_examples_path</span><span class="p">)]</span>
<span class="n">example_list</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-55">import os

# Obtenga rutas de archivos de ejemplo en una lista de listas
example_list = [["examples/" + example] for example in os.listdir(foodvision_mini_examples_path)]
example_list</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=192f8473">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="85-mover-nuestro-modelo-effnetb2-entrenado-a-nuestro-directorio-de-demostracion-foodvision-mini">8.5 Mover nuestro modelo EffNetB2 entrenado a nuestro directorio de demostración FoodVision Mini<a class="anchor-link" href="#85-mover-nuestro-modelo-effnetb2-entrenado-a-nuestro-directorio-de-demostracion-foodvision-mini">¶</a></h3><p>Anteriormente guardamos nuestro modelo de extractor de funciones FoodVision Mini EffNetB2 en <code>models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth</code>.</p>
<p>Y en lugar de duplicar los archivos de modelo guardados, muevamos nuestro modelo a nuestro directorio <code>demos/foodvision_mini</code>.</p>
<p>Podemos hacerlo usando el método <a href="https://docs.python.org/3/library/shutil.html#shutil.move"><code>shutil.move()</code></a> de Python y pasando <code>src</code> (la ruta fuente de el archivo de destino) y <code>dst</code> (la ruta de destino del archivo de destino al que se va a mover).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=a9d0b11e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-56">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">shutil</span>

<span class="c1"># Crear una ruta de origen para nuestro modelo de destino.</span>
<span class="n">effnetb2_foodvision_mini_model_path</span> <span class="o">=</span> <span class="s2">"models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"</span>

<span class="c1"># Crear una ruta de destino para nuestro modelo objetivo.</span>
<span class="n">effnetb2_foodvision_mini_model_destination</span> <span class="o">=</span> <span class="n">foodvision_mini_demo_path</span> <span class="o">/</span> <span class="n">effnetb2_foodvision_mini_model_path</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"/"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Intenta mover el archivo</span>
<span class="k">try</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Attempting to move </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_path</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    
    <span class="c1"># Move the model</span>
    <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="n">effnetb2_foodvision_mini_model_path</span><span class="p">,</span> 
                <span class="n">dst</span><span class="o">=</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Model move complete."</span><span class="p">)</span>

<span class="c1"># Si el modelo ya ha sido movido, verifique si existe.</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] No model found at </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_path</span><span class="si">}</span><span class="s2">, perhaps its already been moved?"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Model exists at </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">effnetb2_foodvision_mini_model_destination</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-56">import shutil

# Crear una ruta de origen para nuestro modelo de destino.
effnetb2_foodvision_mini_model_path = "models/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"

# Crear una ruta de destino para nuestro modelo objetivo.
effnetb2_foodvision_mini_model_destination = foodvision_mini_demo_path / effnetb2_foodvision_mini_model_path.split("/")[1]

# Intenta mover el archivo
try:
    print(f"[INFO] Attempting to move {effnetb2_foodvision_mini_model_path} to {effnetb2_foodvision_mini_model_destination}")
    
    # Move the model
    shutil.move(src=effnetb2_foodvision_mini_model_path, 
                dst=effnetb2_foodvision_mini_model_destination)
    
    print(f"[INFO] Model move complete.")

# Si el modelo ya ha sido movido, verifique si existe.
except:
    print(f"[INFO] No model found at {effnetb2_foodvision_mini_model_path}, perhaps its already been moved?")
    print(f"[INFO] Model exists at {effnetb2_foodvision_mini_model_destination}: {effnetb2_foodvision_mini_model_destination.exists()}")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=56a414e8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="86-convirtiendo-nuestro-modelo-effnetb2-en-un-script-python-modelpy">8.6 Convirtiendo nuestro modelo EffNetB2 en un script Python (<code>model.py</code>)<a class="anchor-link" href="#86-convirtiendo-nuestro-modelo-effnetb2-en-un-script-python-modelpy">¶</a></h3><p>El <code>state_dict</code> de nuestro modelo actual se guarda en <code>demos/foodvision_mini/09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth</code>.</p>
<p>Para cargarlo podemos usar <code>model.load_state_dict()</code> junto con <code>torch.load()</code>.</p>
<blockquote>
<p><strong>Nota:</strong> Para obtener una actualización sobre cómo guardar y cargar un modelo (o el <code>state_dict</code> de un modelo en PyTorch, consulte [01. Fundamentos del flujo de trabajo de PyTorch, sección 5: Guardar y cargar un modelo de PyTorch](<a href="https://www">https://www</a>. learnpytorch.io/01_pytorch_workflow/#5-served-and-loading-a-pytorch-model) o consulte la receta de PyTorch para [¿Qué es un <code>state_dict</code> en PyTorch?](<a href="https://pytorch.org/tutorials/recipes">https://pytorch.org/tutorials/recipes</a> /recetas/what_is_state_dict.html)</p>
</blockquote>
<p>Pero antes de que podamos hacer esto, primero necesitamos una forma de crear una instancia de un "modelo".</p>
<p>Para hacer esto de forma modular, crearemos un script llamado <code>model.py</code> que contiene nuestra función <code>create_effnetb2_model()</code> que creamos en [sección 3.1: <em>Creación de una función para crear un extractor de funciones EffNetB2</em>](https: //www.learnpytorch.io/09_pytorch_model_deployment/#31-creating-a-function-to-make-an-effnetb2-feature-extractor).</p>
<p>De esa manera podemos importar la función en <em>otro</em> script (ver <code>app.py</code> a continuación) y luego usarla para crear nuestra instancia de <code>modelo</code> EffNetB2, así como obtener sus transformaciones apropiadas.</p>
<p>Al igual que en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/">05. PyTorch Going Modular</a>, usaremos el comando mágico <code>%%writefile path/to/file</code> para convertir una celda de código en un archivo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=4bd53a8d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-57">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">def</span> <span class="nf">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Creates an EfficientNetB2 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of classes in the classifier head. </span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): EffNetB2 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): EffNetB2 image transforms.</span>
<span class="sd">    """</span>
    <span class="c1"># Create EffNetB2 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Freeze all layers in base model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Change classifier head with random seed for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-57">%%writefile demos/foodvision_mini/model.py
import torch
import torchvision

from torch import nn


def create_effnetb2_model(num_classes:int=3, 
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head. 
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model. 
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )
    
    return model, transforms</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=ca2b6267">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="87-convirtiendo-nuestra-aplicacion-foodvision-mini-gradio-en-un-script-python-apppy">8.7 Convirtiendo nuestra aplicación FoodVision Mini Gradio en un script Python (<code>app.py</code>)<a class="anchor-link" href="#87-convirtiendo-nuestra-aplicacion-foodvision-mini-gradio-en-un-script-python-apppy">¶</a></h3><p>Ahora tenemos un script <code>model.py</code> así como una ruta a un modelo guardado <code>state_dict</code> que podemos cargar.</p>
<p>Es hora de construir <code>app.py</code>.</p>
<p>Lo llamamos <code>app.py</code> porque, de forma predeterminada, cuando creas un espacio HuggingFace, busca un archivo llamado <code>app.py</code> para ejecutarlo y alojarlo (aunque puedes cambiar esto en la configuración).</p>
<p>Nuestro script <code>app.py</code> juntará todas las piezas del rompecabezas para crear nuestra demostración de Gradio y tendrá cuatro partes principales:</p>
<ol>
<li><strong>Configuración de importaciones y nombres de clases</strong> - Aquí importaremos las diversas dependencias para nuestra demostración, incluida la función <code>create_effnetb2_model()</code> de <code>model.py</code>, así como también configuraremos los diferentes nombres de clases para nuestra aplicación FoodVision Mini. .</li>
<li><strong>Preparación de modelos y transformaciones</strong>: aquí crearemos una instancia de modelo EffNetB2 junto con las transformaciones que la acompañan y luego cargaremos los pesos/<code>state_dict</code> del modelo guardado. Cuando cargamos el modelo, también configuraremos <code>map_location=torch.device("cpu")</code> en [<code>torch.load()</code>](<a href="https://pytorch.org/docs/stable/generated/torch.load">https://pytorch.org/docs/stable/generated/torch.load</a> .html) para que nuestro modelo se cargue en la CPU independientemente del dispositivo en el que se entrenó (hacemos esto porque no necesariamente tendremos una GPU cuando implementemos y obtendremos un error si nuestro modelo está entrenado en GPU pero intente implementarlo en la CPU sin decirlo explícitamente).</li>
<li><strong>Función de predicción</strong> - <code>gradio.Interface()</code> de Gradio toma un parámetro <code>fn</code> para asignar entradas a salidas, nuestra función <code>predict()</code> será la misma que definimos anteriormente en la <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#72-creating-a-function-to-map-our-inputs-and-outputs">sección 7.2 : <em>Creando una función para mapear nuestras entradas y salidas</em></a>, lo hará tome una imagen y luego use las transformaciones cargadas para preprocesarla antes de usar el modelo cargado para hacer una predicción sobre ella.<ul>
<li><strong>Nota:</strong> Tendremos que crear la lista de ejemplo sobre la marcha mediante el parámetro <code>examples</code>. Podemos hacerlo creando una lista de archivos dentro del directorio <code>examples/</code> con: <code>[["examples/" + example] por ejemplo en os.listdir("examples")]</code>.</li>
</ul>
</li>
<li><strong>Aplicación Gradio</strong> - Aquí es donde vivirá la lógica principal de nuestra demostración, crearemos una instancia <code>gradio.Interface()</code> llamada <code>demo</code> para juntar nuestras entradas, función <code>predict()</code> y salidas. ¡Y terminaremos el script llamando a <code>demo.launch()</code> para iniciar nuestra demostración de FoodVision Mini!</li>
</ol>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e87fced3">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-58">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span><span class="n">app</span><span class="o">.</span><span class="n">py</span>
<span class="c1"># ## 1. Configuración de importaciones y nombres de clases ###</span>
<span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">create_effnetb2_model</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="c1"># Configurar nombres de clases</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"pizza"</span><span class="p">,</span> <span class="s2">"steak"</span><span class="p">,</span> <span class="s2">"sushi"</span><span class="p">]</span>

<span class="c1"># ## 2. Preparación del modelo y transforma ###</span>

<span class="c1"># Crear modelo EffNetB2</span>
<span class="n">effnetb2</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># len(class_names) would also work</span>
<span class="p">)</span>

<span class="c1"># Cargar pesos guardados</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">f</span><span class="o">=</span><span class="s2">"09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"</span><span class="p">,</span>
        <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">),</span>  <span class="c1"># load to CPU</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># ## 3. Función de predicción ###</span>

<span class="c1"># Crear función de predicción</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Transforms and performs a prediction on img and returns prediction and time taken.</span>
<span class="sd">    """</span>
    <span class="c1"># Start the timer</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    
    <span class="c1"># Transform the target image and add a batch dimension</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">effnetb2_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put model into evaluation mode and turn on inference mode</span>
    <span class="n">effnetb2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="c1"># Pass the transformed image through the model and turn the prediction logits into prediction probabilities</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">effnetb2</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)</span>
    <span class="n">pred_labels_and_probs</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))}</span>
    
    <span class="c1"># Calculate the prediction time</span>
    <span class="n">pred_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Return the prediction dictionary and prediction time </span>
    <span class="k">return</span> <span class="n">pred_labels_and_probs</span><span class="p">,</span> <span class="n">pred_time</span>

<span class="c1"># ## 4. Aplicación Gradio ###</span>

<span class="c1"># Crear cadenas de título, descripción y artículo.</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">"FoodVision Mini 🍕🥩🍣"</span>
<span class="n">description</span> <span class="o">=</span> <span class="s2">"An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi."</span>
<span class="n">article</span> <span class="o">=</span> <span class="s2">"Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."</span>

<span class="c1"># Crear una lista de ejemplos desde el directorio "examples/"</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"examples/"</span> <span class="o">+</span> <span class="n">example</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">"examples"</span><span class="p">)]</span>

<span class="c1"># Crea la demostración de Gradio</span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span> <span class="c1"># mapping function from input to output</span>
                    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"pil"</span><span class="p">),</span> <span class="c1"># what are the inputs?</span>
                    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">gr</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">num_top_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Predictions"</span><span class="p">),</span> <span class="c1"># what are the outputs?</span>
                             <span class="n">gr</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">"Prediction time (s)"</span><span class="p">)],</span> <span class="c1"># our fn has two outputs, therefore we have two outputs</span>
                    <span class="c1"># Create examples list from "examples/" directory</span>
                    <span class="n">examples</span><span class="o">=</span><span class="n">example_list</span><span class="p">,</span> 
                    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
                    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
                    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">)</span>

<span class="c1"># ¡Lanza la demostración!</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-58">%%writefile demos/foodvision_mini/app.py
# ## 1. Configuración de importaciones y nombres de clases ###
import gradio as gr
import os
import torch

from model import create_effnetb2_model
from timeit import default_timer as timer
from typing import Tuple, Dict

# Configurar nombres de clases
class_names = ["pizza", "steak", "sushi"]

# ## 2. Preparación del modelo y transforma ###

# Crear modelo EffNetB2
effnetb2, effnetb2_transforms = create_effnetb2_model(
    num_classes=3, # len(class_names) would also work
)

# Cargar pesos guardados
effnetb2.load_state_dict(
    torch.load(
        f="09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth",
        map_location=torch.device("cpu"),  # load to CPU
    )
)

# ## 3. Función de predicción ###

# Crear función de predicción
def predict(img) -&gt; Tuple[Dict, float]:
    """Transforms and performs a prediction on img and returns prediction and time taken.
    """
    # Start the timer
    start_time = timer()
    
    # Transform the target image and add a batch dimension
    img = effnetb2_transforms(img).unsqueeze(0)
    
    # Put model into evaluation mode and turn on inference mode
    effnetb2.eval()
    with torch.inference_mode():
        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities
        pred_probs = torch.softmax(effnetb2(img), dim=1)
    
    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)
    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}
    
    # Calculate the prediction time
    pred_time = round(timer() - start_time, 5)
    
    # Return the prediction dictionary and prediction time 
    return pred_labels_and_probs, pred_time

# ## 4. Aplicación Gradio ###

# Crear cadenas de título, descripción y artículo.
title = "FoodVision Mini 🍕🥩🍣"
description = "An EfficientNetB2 feature extractor computer vision model to classify images of food as pizza, steak or sushi."
article = "Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."

# Crear una lista de ejemplos desde el directorio "examples/"
example_list = [["examples/" + example] for example in os.listdir("examples")]

# Crea la demostración de Gradio
demo = gr.Interface(fn=predict, # mapping function from input to output
                    inputs=gr.Image(type="pil"), # what are the inputs?
                    outputs=[gr.Label(num_top_classes=3, label="Predictions"), # what are the outputs?
                             gr.Number(label="Prediction time (s)")], # our fn has two outputs, therefore we have two outputs
                    # Create examples list from "examples/" directory
                    examples=example_list, 
                    title=title,
                    description=description,
                    article=article)

# ¡Lanza la demostración!
demo.launch()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7d79c5b9">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="88-creacion-de-un-archivo-de-requisitos-para-foodvision-mini-requirementstxt">8.8 Creación de un archivo de requisitos para FoodVision Mini (<code>requirements.txt</code>)<a class="anchor-link" href="#88-creacion-de-un-archivo-de-requisitos-para-foodvision-mini-requirementstxt">¶</a></h3><p>El último archivo que debemos crear para nuestra aplicación FoodVision Mini es un [archivo <code>requirements.txt</code>] (<a href="https://learnpython.com/blog/python-requirements-file/">https://learnpython.com/blog/python-requirements-file/</a>).</p>
<p>Este será un archivo de texto que contendrá todas las dependencias necesarias para nuestra demostración.</p>
<p>Cuando implementemos nuestra aplicación de demostración en Hugging Face Spaces, buscará en este archivo e instalará las dependencias que definimos para que nuestra aplicación pueda ejecutarse.</p>
<p>¡La buena noticia es que sólo hay tres!</p>
<ol>
<li><code>antorcha==1.12.0</code></li>
<li><code>torchvision==0.13.0</code></li>
<li><code>gradio==3.1.4</code></li>
</ol>
<p>"<code>==1.12.0</code>" indica el número de versión a instalar.</p>
<p>Definir el número de versión no es 100% obligatorio, pero lo haremos por ahora, de modo que si se producen actualizaciones importantes en futuras versiones, nuestra aplicación aún se ejecuta (PD: si encuentra algún error, no dude en publicarlo en el curso [Problemas de GitHub](https: //github.com/mrdbourke/pytorch-deep-learning/issues)).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=f9557950">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-59">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span><span class="o">/</span><span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">torch</span><span class="o">==</span><span class="mf">1.12.0</span>
<span class="n">torchvision</span><span class="o">==</span><span class="mf">0.13.0</span>
<span class="n">gradio</span><span class="o">==</span><span class="mf">3.1.4</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-59">%%writefile demos/foodvision_mini/requirements.txt
torch==1.12.0
torchvision==0.13.0
gradio==3.1.4</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d7ec66e0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Lindo!</p>
<p>¡Tenemos oficialmente todos los archivos que necesitamos para implementar nuestra demostración de FoodVision Mini!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3a3a2223">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="9-implementacion-de-nuestra-aplicacion-foodvision-mini-en-huggingface-spaces">9. Implementación de nuestra aplicación FoodVision Mini en HuggingFace Spaces<a class="anchor-link" href="#9-implementacion-de-nuestra-aplicacion-foodvision-mini-en-huggingface-spaces">¶</a></h2><p>Tenemos un archivo que contiene nuestra demostración de FoodVision Mini. Ahora, ¿cómo hacemos para que se ejecute en Hugging Face Spaces?</p>
<p>Hay dos opciones principales para cargar en un Hugging Face Space (también llamado <a href="https://huggingface.co/docs/hub/repositories-getting-started#getting-started-with-repositories">Repositorio de Hugging Face</a>, similares a un repositorio de git):</p>
<ol>
<li><a href="https://huggingface.co/docs/hub/repositories-getting-started#adding-files-to-a-repository-web-ui">Carga a través de la interfaz web de Hugging Face (más fácil)</a>.</li>
<li>[Carga a través de la línea de comando o terminal] (<a href="https://huggingface.co/docs/hub/repositories-getting-started#terminal">https://huggingface.co/docs/hub/repositories-getting-started#terminal</a>).<ul>
<li><strong>Bonificación:</strong> También puedes usar la <a href="https://huggingface.co/docs/huggingface_hub/index">biblioteca <code>huggingface_hub</code></a> para interactuar con Hugging Face, esta sería una buena extensión de las dos opciones anteriores. .</li>
</ul>
</li>
</ol>
<p>No dude en leer la documentación sobre ambas opciones, pero optaremos por la opción dos.</p>
<blockquote>
<p><strong>Nota:</strong> Para alojar cualquier cosa en Hugging Face, deberás <a href="https://huggingface.co/join">registrarte para obtener una cuenta gratuita de Hugging Face</a>.</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9155f6d8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="91-descarga-de-los-archivos-de-nuestra-aplicacion-foodvision-mini">9.1 Descarga de los archivos de nuestra aplicación FoodVision Mini<a class="anchor-link" href="#91-descarga-de-los-archivos-de-nuestra-aplicacion-foodvision-mini">¶</a></h3><p>Veamos los archivos de demostración que tenemos dentro de <code>demos/foodvision_mini</code>.</p>
<p>Para hacerlo, podemos usar el comando <code>!ls</code> seguido de la ruta del archivo de destino.</p>
<p><code>ls</code> significa "lista" y <code>!</code> significa que queremos ejecutar el comando en el nivel de shell.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2b068e01">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-60">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="err">!</span><span class="n">ls</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-60">!ls demos/foodvision_mini</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1edd4675">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Estos son todos los archivos que hemos creado!</p>
<p>Para comenzar a cargar nuestros archivos en Hugging Face, descarguémoslos ahora desde Google Colab (o dondequiera que esté ejecutando este cuaderno).</p>
<p>Para hacerlo, primero comprimiremos los archivos en una única carpeta zip mediante el comando:</p>
<pre><code>zip -r ../foodvision_mini.zip * -x "*.pyc" "*.ipynb" "*__pycache__*" "*ipynb_checkpoints*"
</code></pre>
<p>Dónde:</p>
<ul>
<li><code>zip</code> significa "zip", como en "comprima los archivos en el siguiente directorio".</li>
<li><code>-r</code> significa "recursivo", como en "revisar todos los archivos en el directorio de destino".</li>
<li><code>../foodvision_mini.zip</code> es el directorio de destino donde nos gustaría comprimir nuestros archivos.</li>
<li><code>*</code> significa "todos los archivos en el directorio actual".</li>
<li><code>-x</code> significa "excluir estos archivos".</li>
</ul>
<p>Podemos descargar nuestro archivo zip de Google Colab usando <a href="https://colab.research.google.com/notebooks/io.ipynb"><code>google.colab.files.download("demos/foodvision_mini.zip")</code></a> ( Pondremos esto dentro de un bloque <code>try</code> y <code>except</code> en caso de que no estemos ejecutando el código dentro de Google Colab y, de ser así, imprimiremos un mensaje que indicará que descarguemos los archivos manualmente).</p>
<p>¡Probémoslo!</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=e74040c6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-61">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Cambie y luego comprima la carpeta foodvision_mini pero excluya ciertos archivos</span>
<span class="err">!</span><span class="n">cd</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_mini</span> <span class="o">&amp;&amp;</span> <span class="nb">zip</span> <span class="o">-</span><span class="n">r</span> <span class="o">../</span><span class="n">foodvision_mini</span><span class="o">.</span><span class="n">zip</span> <span class="o">*</span> <span class="o">-</span><span class="n">x</span> <span class="s2">"*.pyc"</span> <span class="s2">"*.ipynb"</span> <span class="s2">"*__pycache__*"</span> <span class="s2">"*ipynb_checkpoints*"</span>

<span class="c1"># Descargue la aplicación FoodVision Mini comprimida (si se ejecuta en Google Colab)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"demos/foodvision_mini.zip"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Not running in Google Colab, can't use google.colab.files.download(), please manually download."</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-61"># Cambie y luego comprima la carpeta foodvision_mini pero excluya ciertos archivos
!cd demos/foodvision_mini &amp;&amp; zip -r ../foodvision_mini.zip * -x "*.pyc" "*.ipynb" "*__pycache__*" "*ipynb_checkpoints*"

# Descargue la aplicación FoodVision Mini comprimida (si se ejecuta en Google Colab)
try:
    from google.colab import files
    files.download("demos/foodvision_mini.zip")
except:
    print("Not running in Google Colab, can't use google.colab.files.download(), please manually download.")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d54495e0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Guau!</p>
<p>Parece que nuestro comando <code>zip</code> fue exitoso.</p>
<p>Si está ejecutando este cuaderno en Google Colab, debería ver que un archivo comienza a descargarse en su navegador.</p>
<p>De lo contrario, puede ver la carpeta <code>foodvision_mini.zip</code> (y más) en el [curso GitHub en el directorio <code>demos/</code>](<a href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/">https://github.com/mrdbourke/pytorch-deep-learning/tree/main/</a> población).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=da63f0e4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="92-ejecucion-de-nuestra-demostracion-foodvision-mini-localmente">9.2 Ejecución de nuestra demostración FoodVision Mini localmente<a class="anchor-link" href="#92-ejecucion-de-nuestra-demostracion-foodvision-mini-localmente">¶</a></h3><p>Si descarga el archivo <code>foodvision_mini.zip</code>, puede probarlo localmente de la siguiente manera:</p>
<ol>
<li>Descomprimiendo el archivo.</li>
<li>Abrir la terminal o una línea de comando.</li>
<li>Cambiar al directorio <code>foodvision_mini</code> (<code>cd foodvision_mini</code>).</li>
<li>Crear un entorno (<code>python3 -m venv env</code>).</li>
<li>Activar el entorno (<code>source env/bin/activate</code>).</li>
<li>Instalar los requisitos (<code>pip install -r requisitos.txt</code>, "<code>-r</code>" es para recursivo).<ul>
<li><strong>Nota:</strong> Este paso puede tardar entre 5 y 10 minutos dependiendo de tu conexión a Internet. Y si enfrenta errores, es posible que primero necesite actualizar <code>pip</code>: <code>pip install --upgrade pip</code>.</li>
</ul>
</li>
<li>Ejecute la aplicación (<code>python3 app.py</code>).</li>
</ol>
<p>Esto debería dar como resultado una demostración de Gradio como la que creamos anteriormente ejecutándose localmente en su máquina en una URL como <code>http://127.0.0.1:7860/</code>.</p>
<blockquote>
<p><strong>Nota:</strong> Si ejecuta la aplicación localmente y observa que aparece un directorio <code>marcado/</code>, contiene muestras que han sido "marcadas".</p>
<p>Por ejemplo, si alguien prueba la demostración y el modelo produce un resultado incorrecto, la muestra se puede "marcar" y revisar para más adelante.</p>
<p>Para obtener más información sobre cómo marcar en Gradio, consulte la <a href="https://gradio.app/docs/#flagging">documentación sobre cómo marcar</a>.</p>
</blockquote>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=177828a4">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="93-subir-a-hugging-face">9.3 Subir a Hugging Face<a class="anchor-link" href="#93-subir-a-hugging-face">¶</a></h3><p>Hemos verificado que nuestra aplicación FoodVision Mini funciona localmente; sin embargo, lo divertido de crear una demostración de aprendizaje automático es mostrársela a otras personas y permitirles usarla.</p>
<p>Para hacerlo, cargaremos nuestra demostración de FoodVision Mini en Hugging Face.</p>
<blockquote>
<p><strong>Nota:</strong> La siguiente serie de pasos utiliza un flujo de trabajo Git (un sistema de seguimiento de archivos). Para obtener más información sobre cómo funciona Git, recomiendo consultar el <a href="https://youtu.be/RGOj5yH7evk">tutorial de Git y GitHub para principiantes</a> en freeCodeCamp.</p>
</blockquote>
<ol>
<li><a href="https://huggingface.co/join">Regístrese</a> para obtener una cuenta de Hugging Face.</li>
<li>Inicie un nuevo Hugging Face Space yendo a su perfil y luego <a href="https://huggingface.co/new-space">haciendo clic en "Nuevo espacio"</a>.<ul>
<li><strong>Nota:</strong> Un espacio en Hugging Face también se conoce como "repositorio de códigos" (un lugar para almacenar su código/archivos) o "repositorio" para abreviar.</li>
</ul>
</li>
<li>Dale un nombre al Espacio, por ejemplo, el mío se llama <code>mrdbourke/foodvision_mini</code>, puedes verlo aquí: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">https://huggingface.co/spaces/mrdbourke/foodvision_mini</a></li>
<li>Seleccione una licencia (yo usé <a href="https://opensource.org/licenses/MIT">MIT</a>).</li>
<li>Seleccione Gradio como Space SDK (kit de desarrollo de software).<ul>
<li><strong>Nota:</strong> Puedes usar otras opciones como Streamlit, pero como nuestra aplicación está construida con Gradio, nos quedaremos con eso.</li>
</ul>
</li>
<li>Elija si su Espacio es público o privado (seleccioné público porque me gustaría que mi Espacio esté disponible para otros).</li>
<li>Haga clic en "Crear espacio".</li>
<li>Clone el repositorio localmente ejecutando algo como: <code>git clone https://huggingface.co/spaces/[YOUR_USERNAME]/[YOUR_SPACE_NAME]</code> en la terminal o en el símbolo del sistema.<ul>
<li><strong>Nota:</strong> También puedes agregar archivos cargándolos en la pestaña "Archivos y versiones".</li>
</ul>
</li>
<li>Copie/mueva el contenido de la carpeta <code>foodvision_mini</code> descargada a la carpeta del repositorio clonado.</li>
<li>Para cargar y rastrear archivos más grandes (por ejemplo, archivos de más de 10 MB o, en nuestro caso, nuestro archivo modelo PyTorch), necesitará <a href="https://git-lfs.github.com/">instalar Git LFS</a> (que significa para "almacenamiento de archivos grandes de git").</li>
<li>Después de haber instalado Git LFS, puedes activarlo ejecutando <code>git lfs install</code>.</li>
<li>En el directorio <code>foodvision_mini</code>, realice un seguimiento de los archivos de más de 10 MB con Git LFS con <code>git lfs track "*.file_extension"</code>.<ul>
<li>Realice un seguimiento del archivo de modelo EffNetB2 PyTorch con <code>git lfs track "09_pretrained_effnetb2_feature_extractor_pizza_steak_sushi_20_percent.pth"</code>.</li>
</ul>
</li>
<li>Seguimiento de <code>.gitattributes</code> (creado automáticamente al clonar desde HuggingFace; este archivo ayudará a garantizar que nuestros archivos más grandes sean rastreados con Git LFS). Puede ver un archivo <code>.gitattributes</code> de ejemplo en [FoodVision Mini Hugging Face Space] (<a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini/blob/main/.gitattributes">https://huggingface.co/spaces/mrdbourke/foodvision_mini/blob/main/.gitattributes</a>).<ul>
<li><code>git agregar .gitattributes</code></li>
</ul>
</li>
<li>Agregue el resto de los archivos de la aplicación <code>foodvision_mini</code> y confírmelos con:<ul>
<li><code>git agregar *</code></li>
<li><code>git commit -m "primer compromiso"</code></li>
</ul>
</li>
<li>Envíe (cargue) los archivos a Hugging Face:
*<code>git push</code></li>
<li>Espere de 3 a 5 minutos hasta que se complete la compilación (las compilaciones futuras serán más rápidas) y su aplicación estará activa.</li>
</ol>
<p>Si todo funcionó, debería ver un ejemplo en vivo de nuestra demostración de FoodVision Mini Gradio como este: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_mini">https://huggingface.co/spaces/mrdbourke/foodvision_mini</a></p>
<p>E incluso podemos insertar nuestra demostración de FoodVision Mini Gradio en nuestra computadora portátil como un <a href="https://gradio.app/sharing_your_app/#embedding-with-iframes">iframe</a> con [<code>IPython.display.IFrame</code>](https:/ /ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.IFrame) y un enlace a nuestro espacio en el formato <code>https://hf.space/embed/[YOUR_USERNAME] /[TU_NOMBRE_ESPACIO]/+</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=93c08623">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-62">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># IPython es una biblioteca para ayudar a que Python sea interactivo</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>

<span class="c1"># Incrustar la demostración de FoodVision Mini Gradio</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">"https://hf.space/embed/mrdbourke/foodvision_mini/+"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-62"># IPython es una biblioteca para ayudar a que Python sea interactivo
from IPython.display import IFrame

# Incrustar la demostración de FoodVision Mini Gradio
IFrame(src="https://hf.space/embed/mrdbourke/foodvision_mini/+", width=900, height=750)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0d5335d8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="10-creando-foodvision-a-lo-grande">10. Creando FoodVision a lo grande<a class="anchor-link" href="#10-creando-foodvision-a-lo-grande">¶</a></h2><p>Hemos pasado las últimas secciones y capítulos trabajando para darle vida a FoodVision Mini.</p>
<p>Y ahora que lo hemos visto funcionar en una demostración en vivo, ¿qué tal si damos un paso más?</p>
<p>¿Cómo?</p>
<p>¡Visión alimentaria a lo grande!</p>
<p>Dado que FoodVision Mini está entrenado con imágenes de pizza, bistec y sushi del [conjunto de datos Food101] (<a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html">https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html</a>) (101 clases de alimentos x 1000 imágenes cada una ), ¿qué tal si hacemos FoodVision Big entrenando un modelo en las 101 clases?</p>
<p>¡Pasaremos de tres clases a 101!</p>
<p>¡Desde pizza, bistec, sushi hasta pizza, bistec, sushi, hot dog, tarta de manzana, pastel de zanahoria, pastel de chocolate, fuegos franceses, pan de ajo, ramen, nachos, tacos y más!</p>
<p>¿Cómo?</p>
<p>Bueno, tenemos todos los pasos implementados, todo lo que tenemos que hacer es modificar ligeramente nuestro modelo EffNetB2 y preparar un conjunto de datos diferente.</p>
<p>Para finalizar Milestone Project 3, recreemos una demostración de Gradio similar a FoodVision Mini (tres clases) pero para FoodVision Big (101 clases).</p>
<img alt="foodvision mini modele en tres clases: pizza, bistec, sushi y foodvision big en las 101 clases del conjunto de datos food101" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-model-deployment-foodvision-mini-to-foodvision-big.png" width="900/"/>
<p><em>FoodVision Mini funciona con tres clases de alimentos: pizza, bistec y sushi. Y FoodVision Big va un paso más allá para trabajar en 101 clases de alimentos: todas las [clases en el conjunto de datos Food101](<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names">https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names</a>. TXT).</em></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=781a8045">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="101-creando-un-modelo-y-transformaciones-para-foodvision-big">10.1 Creando un modelo y transformaciones para FoodVision Big<a class="anchor-link" href="#101-creando-un-modelo-y-transformaciones-para-foodvision-big">¶</a></h3><p>Al crear FoodVision Mini vimos que el modelo EffNetB2 era un buen equilibrio entre velocidad y rendimiento (funcionó bien a alta velocidad).</p>
<p>Así que continuaremos usando el mismo modelo para FoodVision Big.</p>
<p>Podemos crear un extractor de funciones EffNetB2 para Food101 usando nuestra función <code>create_effnetb2_model()</code> que creamos anteriormente, en la [sección 3.1](<a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#31-creating-a-function-to">https://www.learnpytorch.io/09_pytorch_model_deployment/#31-creating-a-function-to</a> -make-an-effnetb2-feature-extractor), y pasándole el parámetro <code>num_classes=101</code> (ya que Food101 tiene 101 clases).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=0b8c3ee8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-63">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Cree un modelo EffNetB2 capaz de adaptarse a 101 clases para Food101</span>
<span class="n">effnetb2_food101</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-63"># Cree un modelo EffNetB2 capaz de adaptarse a 101 clases para Food101
effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=3b20507f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Hermoso!</p>
<p>Ahora obtengamos un resumen de nuestro modelo.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=d11fcfbd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-64">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">torchinfo</span> <span class="kn">import</span> <span class="n">summary</span>

<span class="c1"># # Obtenga un resumen del extractor de funciones EffNetB2 para Food101 con 101 clases de salida (descomentar para obtener una salida completa)</span>
<span class="c1"># resumen(effnetb2_food101,</span>
<span class="c1"># tamaño_entrada=(1, 3, 224, 224),</span>
<span class="c1"># col_names=["input_size", "output_size", "num_params", "entrenable"],</span>
<span class="c1"># ancho_columna=20,</span>
<span class="c1"># row_settings=["var_names"])</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-64">from torchinfo import summary

# # Obtenga un resumen del extractor de funciones EffNetB2 para Food101 con 101 clases de salida (descomentar para obtener una salida completa)
# resumen(effnetb2_food101,
# tamaño_entrada=(1, 3, 224, 224),
# col_names=["input_size", "output_size", "num_params", "entrenable"],
# ancho_columna=20,
# row_settings=["var_names"])</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=b1032ad1">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p><img alt="extractor de funciones effnetb2 con resumen del modelo de 100 clases de salida" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/09-effnetb2-feature-extractor-101-classes.png" width="900">
¡Lindo!</img></p>
<p>Vea cómo, al igual que nuestro modelo EffNetB2 para FoodVision Mini, las capas base están congeladas (éstas están previamente entrenadas en ImageNet) y las capas externas (las capas <code>clasificadoras</code>) se pueden entrenar con una forma de salida de <code>[batch_size, 101]</code> (<code>101 </code> para 101 clases en Food101).</p>
<p>Ahora que vamos a tratar con bastante más datos de lo habitual, ¿qué tal si agregamos un poco de aumento de datos a nuestras transformaciones (<code>effnetb2_transforms</code>) para aumentar los datos de entrenamiento?</p>
<blockquote>
<p><strong>Nota:</strong> El aumento de datos es una técnica que se utiliza para alterar la apariencia de una muestra de entrenamiento de entrada (por ejemplo, rotar una imagen o sesgarla ligeramente) para aumentar artificialmente la diversidad de un conjunto de datos de entrenamiento y, con suerte, evitar el sobreajuste. Puede ver más sobre el aumento de datos en [04. Sección 6 de conjuntos de datos personalizados de PyTorch] (<a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation">https://www.learnpytorch.io/04_pytorch_custom_datasets/#6-other-forms-of-transforms-data-augmentation</a>).</p>
</blockquote>
<p>Compongamos una canalización <code>torchvision.transforms</code> para usar <a href="https://pytorch.org/vision/main/generated/torchvision.transforms.TrivialAugmentWide.html"><code>torchvision.transforms.TrivialAugmentWide()</code></a> (el mismo aumento de datos utilizado por el equipo de PyTorch en sus [recetas de visión por computadora] (<a href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#break-">https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#break-</a> mejoras de precisión de clave)) así como <code>effnetb2_transforms</code> para transformar nuestras imágenes de entrenamiento.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=aecfdd2d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-65">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Cree transformaciones de datos de entrenamiento de Food101 (realice solo aumento de datos en las imágenes de entrenamiento)</span>
<span class="n">food101_train_transforms</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">TrivialAugmentWide</span><span class="p">(),</span>
    <span class="n">effnetb2_transforms</span><span class="p">,</span>
<span class="p">])</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-65"># Cree transformaciones de datos de entrenamiento de Food101 (realice solo aumento de datos en las imágenes de entrenamiento)
food101_train_transforms = torchvision.transforms.Compose([
    torchvision.transforms.TrivialAugmentWide(),
    effnetb2_transforms,
])</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=08085acd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Épico!</p>
<p>Ahora comparemos <code>food101_train_transforms</code> (para los datos de entrenamiento) y <code>effnetb2_transforms</code> (para los datos de prueba/inferencia).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=ae95b4c8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-66">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training transforms:</span><span class="se">\n</span><span class="si">{</span><span class="n">food101_train_transforms</span><span class="si">}</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing transforms:</span><span class="se">\n</span><span class="si">{</span><span class="n">effnetb2_transforms</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-66">print(f"Training transforms:\n{food101_train_transforms}\n") 
print(f"Testing transforms:\n{effnetb2_transforms}")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e3a0be74">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="102-obtencion-de-datos-para-foodvision-big">10.2 Obtención de datos para FoodVision Big<a class="anchor-link" href="#102-obtencion-de-datos-para-foodvision-big">¶</a></h3><p>Para FoodVision Mini, creamos nuestras propias <a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb">divisiones de datos personalizadas</a> de todo el conjunto de datos de Food101.</p>
<p>Para obtener el conjunto de datos completo de Food101, podemos usar <a href="https://pytorch.org/vision/main/generated/torchvision.datasets.Food101.html"><code>torchvision.datasets.Food101()</code></a>.</p>
<p>Primero configuraremos una ruta al directorio <code>data/</code> para almacenar las imágenes.</p>
<p>Luego descargaremos y transformaremos las divisiones del conjunto de datos de entrenamiento y prueba usando <code>food101_train_transforms</code> y <code>effnetb2_transforms</code> para transformar cada conjunto de datos respectivamente.</p>
<blockquote>
<p><strong>Nota:</strong> Si está utilizando Google Colab, la siguiente celda tardará entre 3 y 5 minutos en ejecutarse por completo y descargar las imágenes de Food101 desde PyTorch.</p>
<p>Esto se debe a que se están descargando más de 100.000 imágenes (101 clases x 1000 imágenes por clase). Si reinicia el tiempo de ejecución de Google Colab y regresa a esta celda, las imágenes deberán volver a descargarse. Alternativamente, si está ejecutando este cuaderno localmente, las imágenes se almacenarán en caché y se almacenarán en el directorio especificado por el parámetro <code>root</code> de <code>torchvision.datasets.Food101()</code>.</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=9e7113f6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-67">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="c1"># Directorio de datos de configuración</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"data"</span><span class="p">)</span>

<span class="c1"># Obtenga datos de entrenamiento (~750 imágenes x 101 clases de alimentos)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Food101</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span> <span class="c1"># path to download data to</span>
                              <span class="n">split</span><span class="o">=</span><span class="s2">"train"</span><span class="p">,</span> <span class="c1"># dataset split to get</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">food101_train_transforms</span><span class="p">,</span> <span class="c1"># perform data augmentation on training data</span>
                              <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># want to download?</span>

<span class="c1"># Obtenga datos de prueba (~250 imágenes x 101 clases de alimentos)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Food101</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="n">data_dir</span><span class="p">,</span>
                             <span class="n">split</span><span class="o">=</span><span class="s2">"test"</span><span class="p">,</span>
                             <span class="n">transform</span><span class="o">=</span><span class="n">effnetb2_transforms</span><span class="p">,</span> <span class="c1"># perform normal EffNetB2 transforms on test data</span>
                             <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-67">from torchvision import datasets

# Directorio de datos de configuración
from pathlib import Path
data_dir = Path("data")

# Obtenga datos de entrenamiento (~750 imágenes x 101 clases de alimentos)
train_data = datasets.Food101(root=data_dir, # path to download data to
                              split="train", # dataset split to get
                              transform=food101_train_transforms, # perform data augmentation on training data
                              download=True) # want to download?

# Obtenga datos de prueba (~250 imágenes x 101 clases de alimentos)
test_data = datasets.Food101(root=data_dir,
                             split="test",
                             transform=effnetb2_transforms, # perform normal EffNetB2 transforms on test data
                             download=True)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e535c3b6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Datos descargados!</p>
<p>Ahora podemos obtener una lista de todos los nombres de clases usando <code>train_data.classes</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2825a280">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-68">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Obtener nombres de clases de Food101</span>
<span class="n">food101_class_names</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">classes</span>

<span class="c1"># Ver los primeros 10</span>
<span class="n">food101_class_names</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-68"># Obtener nombres de clases de Food101
food101_class_names = train_data.classes

# Ver los primeros 10
food101_class_names[:10]</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=9361d8f5">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Ho, ho! Esas son algunas comidas que suenan deliciosas (aunque nunca he oído hablar de los "buñuelos"... actualización: después de una búsqueda rápida en Google, los buñuelos también se ven deliciosos).
Puede ver una lista completa de los nombres de las clases Food101 en el curso GitHub en [<code>extras/food101_class_names.txt</code>](<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names">https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names</a>. TXT).</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4d7227c6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="103-creacion-de-un-subconjunto-del-conjunto-de-datos-food101-para-experimentar-mas-rapido">10.3 Creación de un subconjunto del conjunto de datos Food101 para experimentar más rápido<a class="anchor-link" href="#103-creacion-de-un-subconjunto-del-conjunto-de-datos-food101-para-experimentar-mas-rapido">¶</a></h3><p>Esto es opcional.</p>
<p>No <em>necesitamos</em> crear otro subconjunto del conjunto de datos de Food101, podríamos entrenar y evaluar un modelo en las 101.000 imágenes completas.</p>
<p>Pero para seguir entrenando rápido, creemos una división del 20 % de los conjuntos de datos de entrenamiento y prueba.</p>
<p>Nuestro objetivo será ver si podemos superar los mejores resultados del [documento Food101] original (<a href="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/">https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/</a>) con solo el 20 % de los datos.</p>
<p>Para desglosar los conjuntos de datos que hemos utilizado/utilizaremos:</p>
<table>
<thead>
<tr>
<th><strong>Cuadernos(s)</strong></th>
<th><strong>Nombre del proyecto</strong></th>
<th><strong>Conjunto de datos</strong></th>
<th><strong>Número de clases</strong></th>
<th><strong>Imágenes de entrenamiento</strong></th>
<th><strong>Imágenes de prueba</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>04, 05, 06, 07, 08</td>
<td>FoodVision Mini (10% de datos)</td>
<td>Food101 división personalizada</td>
<td>3 (pizza, bistec, sushi)</td>
<td>225</td>
<td>75</td>
</tr>
<tr>
<td>07, 08, 09</td>
<td>FoodVision Mini (20% de datos)</td>
<td>Food101 división personalizada</td>
<td>3 (pizza, bistec, sushi)</td>
<td>450</td>
<td>150</td>
</tr>
<tr>
<td><strong>09 (este)</strong></td>
<td>FoodVision Big (20% de datos)</td>
<td>Food101 división personalizada</td>
<td>101 (todas las clases de Food101)</td>
<td>15150</td>
<td>5050</td>
</tr>
<tr>
<td>Ampliación</td>
<td>FoodVision grande</td>
<td>Food101 todos los datos</td>
<td>101</td>
<td>75750</td>
<td>25250</td>
</tr>
</tbody>
</table>
<p>¿Puedes ver la tendencia?</p>
<p>Así como el tamaño de nuestro modelo aumentó lentamente con el tiempo, también lo hizo el tamaño del conjunto de datos que hemos estado usando para los experimentos.</p>
<blockquote>
<p><strong>Nota:</strong> Para superar realmente los resultados del artículo original de Food101 con el 20 % de los datos, tendríamos que entrenar un modelo con el 20 % de los datos de entrenamiento y luego evaluar nuestro modelo en el conjunto de pruebas <em>completo</em> en lugar de que la división que creamos. Dejaré esto como un ejercicio de extensión para que lo pruebes. También le recomiendo que intente entrenar un modelo en todo el conjunto de datos de entrenamiento de Food101.</p>
</blockquote>
<p>Para dividir nuestro FoodVision Big (20% de datos), creemos una función llamada <code>split_dataset()</code> para dividir un conjunto de datos determinado en ciertas proporciones.</p>
<p>Podemos usar <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split"><code>torch.utils.data.random_split()</code></a> para crear divisiones de tamaños determinados usando ` parámetro de longitudes.</p>
<p>El parámetro <code>longitudes</code> acepta una lista de longitudes divididas deseadas donde el total de la lista debe ser igual a la longitud total del conjunto de datos.</p>
<p>Por ejemplo, con un conjunto de datos de tamaño 100, podría pasar <code>longitudes=[20, 80]</code> para recibir una división del 20 % y del 80 %.</p>
<p>Querremos que nuestra función devuelva dos divisiones, una con la longitud objetivo (por ejemplo, el 20 % de los datos de entrenamiento) y la otra con la longitud restante (por ejemplo, el 80 % restante de los datos de entrenamiento).</p>
<p>Finalmente, estableceremos el parámetro <code>generador</code> en un valor <code>torch.manual_seed()</code> para mayor reproducibilidad.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=348192e8">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-69">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="k">def</span> <span class="nf">split_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="p">,</span> <span class="n">split_size</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Randomly splits a given dataset into two proportions based on split_size and seed.</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset (torchvision.datasets): A PyTorch Dataset, typically one from torchvision.datasets.</span>
<span class="sd">        split_size (float, optional): How much of the dataset should be split? </span>
<span class="sd">            E.g. split_size=0.2 means there will be a 20% split and an 80% split. Defaults to 0.2.</span>
<span class="sd">        seed (int, optional): Seed for random generator. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: (random_split_1, random_split_2) where random_split_1 is of size split_size*len(dataset) and </span>
<span class="sd">            random_split_2 is of size (1-split_size)*len(dataset).</span>
<span class="sd">    """</span>
    <span class="c1"># Create split lengths based on original dataset length</span>
    <span class="n">length_1</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">*</span> <span class="n">split_size</span><span class="p">)</span> <span class="c1"># desired length</span>
    <span class="n">length_2</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">length_1</span> <span class="c1"># remaining length</span>
        
    <span class="c1"># Print out info</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Splitting dataset of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="si">}</span><span class="s2"> into splits of size: </span><span class="si">{</span><span class="n">length_1</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">split_size</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">%), </span><span class="si">{</span><span class="n">length_2</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="nb">int</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">split_size</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s2">%)"</span><span class="p">)</span>
    
    <span class="c1"># Create splits with given random seed</span>
    <span class="n">random_split_1</span><span class="p">,</span> <span class="n">random_split_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 
                                                                   <span class="n">lengths</span><span class="o">=</span><span class="p">[</span><span class="n">length_1</span><span class="p">,</span> <span class="n">length_2</span><span class="p">],</span>
                                                                   <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span> <span class="c1"># set the random seed for reproducible splits</span>
    <span class="k">return</span> <span class="n">random_split_1</span><span class="p">,</span> <span class="n">random_split_2</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-69">def split_dataset(dataset:torchvision.datasets, split_size:float=0.2, seed:int=42):
    """Randomly splits a given dataset into two proportions based on split_size and seed.

    Args:
        dataset (torchvision.datasets): A PyTorch Dataset, typically one from torchvision.datasets.
        split_size (float, optional): How much of the dataset should be split? 
            E.g. split_size=0.2 means there will be a 20% split and an 80% split. Defaults to 0.2.
        seed (int, optional): Seed for random generator. Defaults to 42.

    Returns:
        tuple: (random_split_1, random_split_2) where random_split_1 is of size split_size*len(dataset) and 
            random_split_2 is of size (1-split_size)*len(dataset).
    """
    # Create split lengths based on original dataset length
    length_1 = int(len(dataset) * split_size) # desired length
    length_2 = len(dataset) - length_1 # remaining length
        
    # Print out info
    print(f"[INFO] Splitting dataset of length {len(dataset)} into splits of size: {length_1} ({int(split_size*100)}%), {length_2} ({int((1-split_size)*100)}%)")
    
    # Create splits with given random seed
    random_split_1, random_split_2 = torch.utils.data.random_split(dataset, 
                                                                   lengths=[length_1, length_2],
                                                                   generator=torch.manual_seed(seed)) # set the random seed for reproducible splits
    return random_split_1, random_split_2</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=6dcf24dd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Se creó la función de división del conjunto de datos!</p>
<p>Ahora probémoslo creando una división del 20% del conjunto de datos de prueba y capacitación de Food101.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6a8d0b13">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-70">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Crear capacitación División del 20% de Food101</span>
<span class="n">train_data_food101_20_percent</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                                                 <span class="n">split_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Crear pruebas con una división del 20% de Food101</span>
<span class="n">test_data_food101_20_percent</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">split_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                                                <span class="n">split_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">train_data_food101_20_percent</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_data_food101_20_percent</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-70"># Crear capacitación División del 20% de Food101
train_data_food101_20_percent, _ = split_dataset(dataset=train_data,
                                                 split_size=0.2)

# Crear pruebas con una división del 20% de Food101
test_data_food101_20_percent, _ = split_dataset(dataset=test_data,
                                                split_size=0.2)

len(train_data_food101_20_percent), len(test_data_food101_20_percent)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=e75737af">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Excelente!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=111bf184">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="104-convirtiendo-nuestros-conjuntos-de-datos-de-food101-en-dataloaders">10.4 Convirtiendo nuestros conjuntos de datos de Food101 en <code>DataLoader</code>s<a class="anchor-link" href="#104-convirtiendo-nuestros-conjuntos-de-datos-de-food101-en-dataloaders">¶</a></h3><p>Ahora conviertamos nuestras divisiones del conjunto de datos Food101 20% en <code>DataLoader</code> usando <code>torch.utils.data.DataLoader()</code>.</p>
<p>Estableceremos <code>shuffle=True</code> solo para los datos de entrenamiento y el tamaño del lote en <code>32</code> para ambos conjuntos de datos.</p>
<p>Y estableceremos <code>num_workers</code> en <code>4</code> si el recuento de CPU está disponible o <code>2</code> si no lo está (aunque el valor de <code>num_workers</code> es muy experimental y dependerá del hardware que estés usando, hay un <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813"> hilo de discusión activo sobre esto en los foros de PyTorch</a>).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=74f484ad">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-71">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">4</span> <span class="k">else</span> <span class="mi">4</span> <span class="c1"># this value is very experimental and will depend on the hardware you have available, Google Colab generally provides 2x CPUs</span>

<span class="c1"># Crear Food101 20 por ciento de entrenamiento DataLoader</span>
<span class="n">train_dataloader_food101_20_percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data_food101_20_percent</span><span class="p">,</span>
                                                                  <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                  <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
<span class="c1"># Crear Food101 20 por ciento de prueba DataLoader</span>
<span class="n">test_dataloader_food101_20_percent</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data_food101_20_percent</span><span class="p">,</span>
                                                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                                                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                                 <span class="n">num_workers</span><span class="o">=</span><span class="n">NUM_WORKERS</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-71">import os
import torch

BATCH_SIZE = 32
NUM_WORKERS = 2 if os.cpu_count() &lt;= 4 else 4 # this value is very experimental and will depend on the hardware you have available, Google Colab generally provides 2x CPUs

# Crear Food101 20 por ciento de entrenamiento DataLoader
train_dataloader_food101_20_percent = torch.utils.data.DataLoader(train_data_food101_20_percent,
                                                                  batch_size=BATCH_SIZE,
                                                                  shuffle=True,
                                                                  num_workers=NUM_WORKERS)
# Crear Food101 20 por ciento de prueba DataLoader
test_dataloader_food101_20_percent = torch.utils.data.DataLoader(test_data_food101_20_percent,
                                                                 batch_size=BATCH_SIZE,
                                                                 shuffle=False,
                                                                 num_workers=NUM_WORKERS)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=403df49c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="105-entrenamiento-foodvision-modelo-grande">10.5 Entrenamiento FoodVision Modelo grande<a class="anchor-link" href="#105-entrenamiento-foodvision-modelo-grande">¶</a></h3><p>¡El modelo FoodVision Big y <code>DataLoader</code>s están listos!</p>
<p>Hora de entrenar.</p>
<p>Crearemos un optimizador usando <code>torch.optim.Adam()</code> y una tasa de aprendizaje de <code>1e-3</code>.</p>
<p>Y debido a que tenemos tantas clases, también configuraremos una función de pérdida usando <code>torch.nn.CrossEntropyLoss()</code> con <code>label_smoothing=0.1</code>, en línea con la tecnología de punta de <a href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#label-smoothing"><code>torchvision</code> receta de entrenamiento</a>.</p>
<p>¿Qué es <a href="https://paperswithcode.com/method/label-smoothing"><strong>suavizado de etiquetas</strong></a>?</p>
<p>El suavizado de etiquetas es una técnica de regularización (regularización es otra palabra para describir el proceso de <a href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#81-how-to-deal-with-overfitting">prevención del sobreajuste</a>) que reduce la valor que un modelo le da a cualquier etiqueta y lo distribuye entre las demás etiquetas.</p>
<p>En esencia, en lugar de que un modelo se <em>demasiado confiado</em> en una sola etiqueta, el suavizado de etiquetas otorga un valor distinto de cero a otras etiquetas para ayudar en la generalización.</p>
<p>Por ejemplo, si un modelo <em>sin</em> suavizado de etiquetas tuviera los siguientes resultados para 5 clases:</p>
<pre><code>[0, 0, 0,99, 0,01, 0]
</code></pre>
<p>Un modelo <em>con</em> suavizado de etiquetas puede tener los siguientes resultados:</p>
<pre><code>[0,01, 0,01, 0,96, 0,01, 0,01]
</code></pre>
<p>El modelo todavía confía en su predicción de la clase 3, pero dar valores pequeños a las otras etiquetas obliga al modelo a considerar al menos otras opciones.</p>
<p>Finalmente, para agilizar las cosas, entrenaremos nuestro modelo durante cinco épocas usando la función <code>engine.train()</code> que creamos en <a href="https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them">05. PyTorch Going Modular sección 4</a> con el objetivo de superar al Food101 original resultado del artículo de 56,4% de precisión en el conjunto de prueba.</p>
<p>¡Entrenemos a nuestro modelo más grande hasta el momento!</p>
<blockquote>
<p><strong>Nota:</strong> La ejecución de la siguiente celda tardará entre 15 y 20 minutos en Google Colab. Esto se debe a que está entrenando el modelo más grande con la mayor cantidad de datos que hemos usado hasta ahora (15,150 imágenes de entrenamiento, 5050 imágenes de prueba). Y es una de las razones por las que antes decidimos dividir el 20% del conjunto de datos completo de Food101 (para que el entrenamiento no tomara más de una hora).</p>
</blockquote>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=62b1be2e">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-72">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Optimizador de configuración</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="n">effnetb2_food101</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># Función de pérdida de configuración</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="c1"># throw in a little label smoothing because so many classes</span>

<span class="c1"># Quiere superar el artículo original de Food101 con un 20 % de datos, necesita más del 56,4 % según el conjunto de datos de prueba</span>
<span class="n">set_seeds</span><span class="p">()</span>    
<span class="n">effnetb2_food101_results</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2_food101</span><span class="p">,</span>
                                        <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader_food101_20_percent</span><span class="p">,</span>
                                        <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader_food101_20_percent</span><span class="p">,</span>
                                        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                        <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                                        <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-72">from going_modular.going_modular import engine

# Optimizador de configuración
optimizer = torch.optim.Adam(params=effnetb2_food101.parameters(),
                             lr=1e-3)

# Función de pérdida de configuración
loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1) # throw in a little label smoothing because so many classes

# Quiere superar el artículo original de Food101 con un 20 % de datos, necesita más del 56,4 % según el conjunto de datos de prueba
set_seeds()    
effnetb2_food101_results = engine.train(model=effnetb2_food101,
                                        train_dataloader=train_dataloader_food101_20_percent,
                                        test_dataloader=test_dataloader_food101_20_percent,
                                        optimizer=optimizer,
                                        loss_fn=loss_fn,
                                        epochs=5,
                                        device=device)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=7788b8b2">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Woooo!!!!</p>
<p>Parece que superamos los resultados del artículo original de Food101 de 56,4% de precisión con solo el 20% de los datos de entrenamiento (aunque solo evaluamos el 20% de los datos de las pruebas también, para replicar completamente los resultados, podríamos evaluar el 100% de las pruebas). datos).</p>
<p>¡Ese es el poder del aprendizaje por transferencia!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=33d82425">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="106-inspeccionando-las-curvas-de-perdidas-del-modelo-foodvision-big">10.6 Inspeccionando las curvas de pérdidas del modelo FoodVision Big<a class="anchor-link" href="#106-inspeccionando-las-curvas-de-perdidas-del-modelo-foodvision-big">¶</a></h3><p>Hagamos visuales nuestras curvas de pérdidas de FoodVision Big.</p>
<p>Podemos hacerlo con la función <code>plot_loss_curves()</code> de <code>helper_functions.py</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=c533ebed">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-73">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">helper_functions</span> <span class="kn">import</span> <span class="n">plot_loss_curves</span>

<span class="c1"># Consulte las curvas de pérdidas de FoodVision Big</span>
<span class="n">plot_loss_curves</span><span class="p">(</span><span class="n">effnetb2_food101_results</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-73">from helper_functions import plot_loss_curves

# Consulte las curvas de pérdidas de FoodVision Big
plot_loss_curves(effnetb2_food101_results)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=805cb3eb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡¡¡Lindo!!!</p>
<p>Parece que nuestras técnicas de regularización (aumento de datos y suavizado de etiquetas) ayudaron a evitar que nuestro modelo se sobreajustara (la pérdida de entrenamiento sigue siendo mayor que la pérdida de prueba), lo que indica que nuestro modelo tiene un poco más de capacidad para aprender y podría mejorar con más entrenamiento.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=fff787e0">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="107-guardar-y-cargar-foodvision-big">10.7 Guardar y cargar FoodVision Big<a class="anchor-link" href="#107-guardar-y-cargar-foodvision-big">¶</a></h3><p>Ahora que hemos entrenado nuestro modelo más grande hasta el momento, guardémoslo para poder volver a cargarlo más tarde.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=1065cd2d">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-74">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">going_modular.going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="c1"># Crear una ruta modelo</span>
<span class="n">effnetb2_food101_model_path</span> <span class="o">=</span> <span class="s2">"09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"</span> 

<span class="c1"># Guardar modelo FoodVision Big</span>
<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">effnetb2_food101</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">"models"</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="n">effnetb2_food101_model_path</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-74">from going_modular.going_modular import utils

# Crear una ruta modelo
effnetb2_food101_model_path = "09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth" 

# Guardar modelo FoodVision Big
utils.save_model(model=effnetb2_food101,
                 target_dir="models",
                 model_name=effnetb2_food101_model_path)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d75f9cfa">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡Modelo guardado!</p>
<p>Antes de continuar, asegurémonos de poder volver a cargarlo.</p>
<p>Lo haremos creando primero una instancia de modelo con <code>create_effnetb2_model(num_classes=101)</code> (101 clases para todas las clases de Food101).</p>
<p>Y luego cargar el <code>state_dict()</code> guardado con [<code>torch.nn.Module.load_state_dict()</code>](<a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict">https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=load_state_dict</a> #torch.nn.Module.load_state_dict) y <a href="https://pytorch.org/docs/stable/generated/torch.load.html"><code>torch.load()</code></a>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=39b07130">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-75">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Crear una instancia EffNetB2 compatible con Food101</span>
<span class="n">loaded_effnetb2_food101</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">)</span>

<span class="c1"># Cargue el state_dict() del modelo guardado</span>
<span class="n">loaded_effnetb2_food101</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"</span><span class="p">))</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-75"># Crear una instancia EffNetB2 compatible con Food101
loaded_effnetb2_food101, effnetb2_transforms = create_effnetb2_model(num_classes=101)

# Cargue el state_dict() del modelo guardado
loaded_effnetb2_food101.load_state_dict(torch.load("models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"))</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=a6dc7fb7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="108-comprobacion-del-tamano-del-modelo-grande-de-foodvision">10.8 Comprobación del tamaño del modelo grande de FoodVision<a class="anchor-link" href="#108-comprobacion-del-tamano-del-modelo-grande-de-foodvision">¶</a></h3><p>Nuestro modelo FoodVision Big es capaz de clasificar 101 clases frente a las 3 clases de FoodVision Mini, ¡un aumento de 33,6 veces!</p>
<p>¿Cómo afecta esto al tamaño del modelo?</p>
<p>Vamos a averiguar.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2c406c66">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-76">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes</span>
<span class="n">pretrained_effnetb2_food101_model_size</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"models"</span><span class="p">,</span> <span class="n">effnetb2_food101_model_path</span><span class="p">)</span><span class="o">.</span><span class="n">stat</span><span class="p">()</span><span class="o">.</span><span class="n">st_size</span> <span class="o">//</span> <span class="p">(</span><span class="mi">1024</span><span class="o">*</span><span class="mi">1024</span><span class="p">)</span> <span class="c1"># division converts bytes to megabytes (roughly) </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Pretrained EffNetB2 feature extractor Food101 model size: </span><span class="si">{</span><span class="n">pretrained_effnetb2_food101_model_size</span><span class="si">}</span><span class="s2"> MB"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-76">from pathlib import Path

# Obtenga el tamaño del modelo en bytes y luego conviértalo a megabytes
pretrained_effnetb2_food101_model_size = Path("models", effnetb2_food101_model_path).stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly) 
print(f"Pretrained EffNetB2 feature extractor Food101 model size: {pretrained_effnetb2_food101_model_size} MB")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=f0d9978f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Mmm, parece que el tamaño del modelo se mantuvo prácticamente igual (30 MB para FoodVision Big y 29 MB para FoodVision Mini) a pesar del gran aumento en el número de clases.</p>
<p>Esto se debe a que todos los parámetros adicionales para FoodVision Big están <em>solo</em> en la última capa (el encabezado del clasificador).</p>
<p>Todas las capas base son iguales entre FoodVision Big y FoodVision Mini.</p>
<p>Volver arriba y comparar los resúmenes de los modelos dará más detalles.</p>
<table>
<thead>
<tr>
<th><strong>Modelo</strong></th>
<th><strong>Forma de salida (núm. de clases)</strong></th>
<th><strong>Parámetros entrenables</strong></th>
<th><strong>Parámetros totales</strong></th>
<th><strong>Tamaño del modelo (MB)</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>FoodVision Mini (extractor de funciones EffNetB2)</td>
<td>3</td>
<td>4.227</td>
<td>7.705.221</td>
<td>29</td>
</tr>
<tr>
<td>FoodVision Big (extractor de funciones EffNetB2)</td>
<td>101</td>
<td>142.309</td>
<td>7.843.303</td>
<td>30</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=840cc903">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="11-convertir-nuestro-modelo-foodvision-big-en-una-aplicacion-implementable">11. Convertir nuestro modelo FoodVision Big en una aplicación implementable<a class="anchor-link" href="#11-convertir-nuestro-modelo-foodvision-big-en-una-aplicacion-implementable">¶</a></h2><p>Tenemos un modelo EffNetB2 entrenado y guardado en el 20% del conjunto de datos de Food101.</p>
<p>Y en lugar de dejar que nuestro modelo viva en una carpeta toda su vida, ¡implementémoslo!</p>
<p>Implementaremos nuestro modelo FoodVision Big de la misma manera que implementamos nuestro modelo FoodVision Mini, como una demostración de Gradio en Hugging Face Spaces.</p>
<p>Para comenzar, creemos un directorio <code>demos/foodvision_big/</code> para almacenar nuestros archivos de demostración de FoodVision Big, así como un directorio <code>demos/foodvision_big/examples</code> para guardar una imagen de ejemplo con la que probar la demostración.</p>
<p>Cuando hayamos terminado tendremos la siguiente estructura de archivos:</p>
<pre><code>población/
  comidavision_big/
    09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth
    aplicación.py
    nombres_clase.txt
    ejemplos/
      ejemplo_1.jpg
    modelo.py
    requisitos.txt
</code></pre>
<p>Dónde:</p>
<ul>
<li><code>09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth</code> es nuestro archivo de modelo PyTorch entrenado.</li>
<li><code>app.py</code> contiene nuestra aplicación FoodVision Big Gradio.</li>
<li><code>class_names.txt</code> contiene todos los nombres de clases de FoodVision Big.</li>
<li><code>examples/</code> contiene imágenes de ejemplo para usar con nuestra aplicación Gradio.</li>
<li><code>model.py</code> contiene la definición del modelo, así como cualquier transformación asociada con el modelo.</li>
<li><code>requirements.txt</code> contiene las dependencias para ejecutar nuestra aplicación, como <code>torch</code>, <code>torchvision</code> y <code>gradio</code>.</li>
</ul>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=62622187">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-77">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Crear ruta de demostración de FoodVision Big</span>
<span class="n">foodvision_big_demo_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"demos/foodvision_big/"</span><span class="p">)</span>

<span class="c1"># Haga el directorio de demostración de FoodVision Big</span>
<span class="n">foodvision_big_demo_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Directorio de ejemplos de demostración de Make FoodVision Big</span>
<span class="p">(</span><span class="n">foodvision_big_demo_path</span> <span class="o">/</span> <span class="s2">"examples"</span><span class="p">)</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-77">from pathlib import Path

# Crear ruta de demostración de FoodVision Big
foodvision_big_demo_path = Path("demos/foodvision_big/")

# Haga el directorio de demostración de FoodVision Big
foodvision_big_demo_path.mkdir(parents=True, exist_ok=True)

# Directorio de ejemplos de demostración de Make FoodVision Big
(foodvision_big_demo_path / "examples").mkdir(parents=True, exist_ok=True)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=2522717c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="111-descargar-una-imagen-de-ejemplo-y-moverla-al-directorio-ejemplos">11.1 Descargar una imagen de ejemplo y moverla al directorio <code>ejemplos</code><a class="anchor-link" href="#111-descargar-una-imagen-de-ejemplo-y-moverla-al-directorio-ejemplos">¶</a></h3><p>Para nuestra imagen de ejemplo, usaremos la fiel [imagen <code>pizza-dad</code>] (<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad">https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad</a>. jpeg) (una foto de mi papá comiendo pizza).</p>
<p>Así que descarguémoslo del curso GitHub mediante el comando <code>!wget</code> y luego podemos moverlo a <code>demos/foodvision_big/examples</code> con el comando <code>!mv</code> (abreviatura de "mover").</p>
<p>Mientras estamos aquí, trasladaremos nuestro modelo Food101 EffNetB2 entrenado de <code>models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth</code> a <code>demos/foodvision_big</code> también.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=bff68aeb">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-78">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Descargar y mover una imagen de ejemplo</span>
<span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="o">.</span><span class="n">githubusercontent</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">mrdbourke</span><span class="o">/</span><span class="n">pytorch</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">/</span><span class="n">main</span><span class="o">/</span><span class="n">images</span><span class="o">/</span><span class="mi">04</span><span class="o">-</span><span class="n">pizza</span><span class="o">-</span><span class="n">dad</span><span class="o">.</span><span class="n">jpeg</span> 
<span class="err">!</span><span class="n">mv</span> <span class="mi">04</span><span class="o">-</span><span class="n">pizza</span><span class="o">-</span><span class="n">dad</span><span class="o">.</span><span class="n">jpeg</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="mi">04</span><span class="o">-</span><span class="n">pizza</span><span class="o">-</span><span class="n">dad</span><span class="o">.</span><span class="n">jpg</span>

<span class="c1"># Mueva el modelo entrenado a la carpeta de demostración de FoodVision Big (se producirá un error si el modelo ya se ha movido)</span>
<span class="err">!</span><span class="n">mv</span> <span class="n">models</span><span class="o">/</span><span class="mi">09</span><span class="n">_pretrained_effnetb2_feature_extractor_food101_20_percent</span><span class="o">.</span><span class="n">pth</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-78"># Descargar y mover una imagen de ejemplo
!wget https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg 
!mv 04-pizza-dad.jpeg demos/foodvision_big/examples/04-pizza-dad.jpg

# Mueva el modelo entrenado a la carpeta de demostración de FoodVision Big (se producirá un error si el modelo ya se ha movido)
!mv models/09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth demos/foodvision_big</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=04cac84b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="112-guardar-nombres-de-clases-de-food101-en-un-archivo-class_namestxt">11.2 Guardar nombres de clases de Food101 en un archivo (<code>class_names.txt</code>)<a class="anchor-link" href="#112-guardar-nombres-de-clases-de-food101-en-un-archivo-class_namestxt">¶</a></h3><p>Debido a que hay tantas clases en el conjunto de datos Food101, en lugar de almacenarlas como una lista en nuestro archivo <code>app.py</code>, guardémoslas en un archivo <code>.txt</code> y leámoslas cuando sea necesario.</p>
<p>Primero recordaremos cómo se ven revisando <code>food101_class_names</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=298853dc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-79">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Consulte los primeros 10 nombres de clases de Food101</span>
<span class="n">food101_class_names</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-79"># Consulte los primeros 10 nombres de clases de Food101
food101_class_names[:10]</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=088ee04f">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Maravilloso, ahora podemos escribirlos en un archivo de texto creando primero una ruta a <code>demos/foodvision_big/class_names.txt</code> y luego abriendo un archivo con <code>open()</code> de Python y luego escribiendo en él dejando una nueva línea para cada clase. .</p>
<p>Idealmente, queremos que los nombres de nuestras clases se guarden como:</p>
<pre><code>tarta de manzana
Costillitas
baklava
Carpaccio de carne
tartar_de_carne
...
</code></pre>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=2b858df6">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-80">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Crear ruta a los nombres de clases de Food101</span>
<span class="n">foodvision_big_class_names_path</span> <span class="o">=</span> <span class="n">foodvision_big_demo_path</span> <span class="o">/</span> <span class="s2">"class_names.txt"</span>

<span class="c1"># Escriba la lista de nombres de clases de Food101 en el archivo</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">foodvision_big_class_names_path</span><span class="p">,</span> <span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[INFO] Saving Food101 class names to </span><span class="si">{</span><span class="n">foodvision_big_class_names_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">food101_class_names</span><span class="p">))</span> <span class="c1"># leave a new line between each class</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-80"># Crear ruta a los nombres de clases de Food101
foodvision_big_class_names_path = foodvision_big_demo_path / "class_names.txt"

# Escriba la lista de nombres de clases de Food101 en el archivo
with open(foodvision_big_class_names_path, "w") as f:
    print(f"[INFO] Saving Food101 class names to {foodvision_big_class_names_path}")
    f.write("\n".join(food101_class_names)) # leave a new line between each class</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=1ce674ce">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Excelente, ahora asegurémonos de poder leerlos.</p>
<p>Para hacerlo usaremos <a href="https://www.w3schools.com/python/ref_func_open.asp"><code>open()</code></a> de Python en modo lectura (<code>"r"</code>) y luego usaremos <a href="https://www.w3schools.com/python/ref_file_readlines.asp"><code>readlines( )</code></a> método para leer cada línea de nuestro archivo <code>class_names.txt</code>.</p>
<p>Y podemos guardar los nombres de las clases en una lista eliminando el valor de nueva línea de cada uno de ellos con una lista de comprensión y <a href="https://www.w3schools.com/python/ref_string_strip.asp"><code>strip()</code></a>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6a7f8b62">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-81">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Abra el archivo de nombres de clases Food101 y lea cada línea en una lista</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">foodvision_big_class_names_path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">food101_class_names_loaded</span> <span class="o">=</span> <span class="p">[</span><span class="n">food</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">food</span> <span class="ow">in</span>  <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
    
<span class="c1"># Ver los primeros 5 nombres de clases cargados nuevamente en</span>
<span class="n">food101_class_names_loaded</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-81"># Abra el archivo de nombres de clases Food101 y lea cada línea en una lista
with open(foodvision_big_class_names_path, "r") as f:
    food101_class_names_loaded = [food.strip() for food in  f.readlines()]
    
# Ver los primeros 5 nombres de clases cargados nuevamente en
food101_class_names_loaded[:5]</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=76d75617">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="113-convirtiendo-nuestro-modelo-foodvision-big-en-un-script-de-python-modelpy">11.3 Convirtiendo nuestro modelo FoodVision Big en un script de Python (<code>model.py</code>)<a class="anchor-link" href="#113-convirtiendo-nuestro-modelo-foodvision-big-en-un-script-de-python-modelpy">¶</a></h3><p>Al igual que en la demostración de FoodVision Mini, creemos un script que sea capaz de crear una instancia de un modelo de extracción de características EffNetB2 junto con sus transformaciones necesarias.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=6c460542">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-82">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">model</span><span class="o">.</span><span class="n">py</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">def</span> <span class="nf">create_effnetb2_model</span><span class="p">(</span><span class="n">num_classes</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                          <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Creates an EfficientNetB2 feature extractor model and transforms.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_classes (int, optional): number of classes in the classifier head. </span>
<span class="sd">            Defaults to 3.</span>
<span class="sd">        seed (int, optional): random seed value. Defaults to 42.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model (torch.nn.Module): EffNetB2 feature extractor model. </span>
<span class="sd">        transforms (torchvision.transforms): EffNetB2 image transforms.</span>
<span class="sd">    """</span>
    <span class="c1"># Create EffNetB2 pretrained weights, transforms and model</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">EfficientNet_B2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span>
    <span class="n">transforms</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">transforms</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>

    <span class="c1"># Freeze all layers in base model</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Change classifier head with random seed for reproducibility</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1408</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">),</span>
    <span class="p">)</span>
    
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">transforms</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-82">%%writefile demos/foodvision_big/model.py
import torch
import torchvision

from torch import nn


def create_effnetb2_model(num_classes:int=3, 
                          seed:int=42):
    """Creates an EfficientNetB2 feature extractor model and transforms.

    Args:
        num_classes (int, optional): number of classes in the classifier head. 
            Defaults to 3.
        seed (int, optional): random seed value. Defaults to 42.

    Returns:
        model (torch.nn.Module): EffNetB2 feature extractor model. 
        transforms (torchvision.transforms): EffNetB2 image transforms.
    """
    # Create EffNetB2 pretrained weights, transforms and model
    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT
    transforms = weights.transforms()
    model = torchvision.models.efficientnet_b2(weights=weights)

    # Freeze all layers in base model
    for param in model.parameters():
        param.requires_grad = False

    # Change classifier head with random seed for reproducibility
    torch.manual_seed(seed)
    model.classifier = nn.Sequential(
        nn.Dropout(p=0.3, inplace=True),
        nn.Linear(in_features=1408, out_features=num_classes),
    )
    
    return model, transforms</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4a0f960c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="114-convirtiendo-nuestra-aplicacion-foodvision-big-gradio-en-un-script-python-apppy">11.4 Convirtiendo nuestra aplicación FoodVision Big Gradio en un script Python (<code>app.py</code>)<a class="anchor-link" href="#114-convirtiendo-nuestra-aplicacion-foodvision-big-gradio-en-un-script-python-apppy">¶</a></h3><p>Tenemos un script <code>model.py</code> de FoodVision Big, ahora creemos un script <code>app.py</code> de FoodVision Big.</p>
<p>De nuevo, esto será prácticamente igual que el script <code>app.py</code> de FoodVision Mini, excepto que cambiaremos:</p>
<ol>
<li><strong>Configuración de importaciones y nombres de clases</strong> - La variable <code>class_names</code> será una lista para todas las clases de Food101 en lugar de pizza, bistec o sushi. Podemos acceder a ellos a través de <code>demos/foodvision_big/class_names.txt</code>.</li>
<li><strong>Preparación de modelos y transformaciones</strong> - El <code>modelo</code> tendrá <code>num_classes=101</code> en lugar de <code>num_classes=3</code>. También nos aseguraremos de cargar los pesos de <code>"09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"</code> (nuestra ruta del modelo FoodVision Big).</li>
<li><strong>Función de predicción</strong>: seguirá siendo la misma que <code>app.py</code> de FoodVision Mini.</li>
<li><strong>Aplicación Gradio</strong>: la interfaz de Gradio tendrá diferentes parámetros de "título", "descripción" y "artículo" para reflejar los detalles de FoodVision Big.</li>
</ol>
<p>También nos aseguraremos de guardarlo en <code>demos/foodvision_big/app.py</code> usando el comando mágico <code>%%writefile</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=61a955bc">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-83">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">app</span><span class="o">.</span><span class="n">py</span>
<span class="c1"># ## 1. Configuración de importaciones y nombres de clases ###</span>
<span class="kn">import</span> <span class="nn">gradio</span> <span class="k">as</span> <span class="nn">gr</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">model</span> <span class="kn">import</span> <span class="n">create_effnetb2_model</span>
<span class="kn">from</span> <span class="nn">timeit</span> <span class="kn">import</span> <span class="n">default_timer</span> <span class="k">as</span> <span class="n">timer</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Dict</span>

<span class="c1"># Configurar nombres de clases</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"class_names.txt"</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># reading them in from class_names.txt</span>
    <span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">food_name</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">food_name</span> <span class="ow">in</span>  <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()]</span>
    
<span class="c1"># ## 2. Preparación del modelo y transforma ###</span>

<span class="c1"># Crear modelo</span>
<span class="n">effnetb2</span><span class="p">,</span> <span class="n">effnetb2_transforms</span> <span class="o">=</span> <span class="n">create_effnetb2_model</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span> <span class="c1"># could also use len(class_names)</span>
<span class="p">)</span>

<span class="c1"># Cargar pesos guardados</span>
<span class="n">effnetb2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
        <span class="n">f</span><span class="o">=</span><span class="s2">"09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"</span><span class="p">,</span>
        <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">"cpu"</span><span class="p">),</span>  <span class="c1"># load to CPU</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># ## 3. Función de predicción ###</span>

<span class="c1"># Crear función de predicción</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Transforms and performs a prediction on img and returns prediction and time taken.</span>
<span class="sd">    """</span>
    <span class="c1"># Start the timer</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">timer</span><span class="p">()</span>
    
    <span class="c1"># Transform the target image and add a batch dimension</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">effnetb2_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    
    <span class="c1"># Put model into evaluation mode and turn on inference mode</span>
    <span class="n">effnetb2</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
        <span class="c1"># Pass the transformed image through the model and turn the prediction logits into prediction probabilities</span>
        <span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">effnetb2</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)</span>
    <span class="n">pred_labels_and_probs</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="nb">float</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))}</span>
    
    <span class="c1"># Calculate the prediction time</span>
    <span class="n">pred_time</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">timer</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># Return the prediction dictionary and prediction time </span>
    <span class="k">return</span> <span class="n">pred_labels_and_probs</span><span class="p">,</span> <span class="n">pred_time</span>

<span class="c1"># ## 4. Aplicación Gradio ###</span>

<span class="c1"># Crear cadenas de título, descripción y artículo.</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">"FoodVision Big 🍔👁"</span>
<span class="n">description</span> <span class="o">=</span> <span class="s2">"An EfficientNetB2 feature extractor computer vision model to classify images of food into [101 different classes](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt)."</span>
<span class="n">article</span> <span class="o">=</span> <span class="s2">"Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."</span>

<span class="c1"># Crear una lista de ejemplos desde el directorio "examples/"</span>
<span class="n">example_list</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">"examples/"</span> <span class="o">+</span> <span class="n">example</span><span class="p">]</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="s2">"examples"</span><span class="p">)]</span>

<span class="c1"># Crear interfaz Gradio</span>
<span class="n">demo</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Interface</span><span class="p">(</span>
    <span class="n">fn</span><span class="o">=</span><span class="n">predict</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s2">"pil"</span><span class="p">),</span>
    <span class="n">outputs</span><span class="o">=</span><span class="p">[</span>
        <span class="n">gr</span><span class="o">.</span><span class="n">Label</span><span class="p">(</span><span class="n">num_top_classes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Predictions"</span><span class="p">),</span>
        <span class="n">gr</span><span class="o">.</span><span class="n">Number</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">"Prediction time (s)"</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">examples</span><span class="o">=</span><span class="n">example_list</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="n">title</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
    <span class="n">article</span><span class="o">=</span><span class="n">article</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># ¡Inicia la aplicación!</span>
<span class="n">demo</span><span class="o">.</span><span class="n">launch</span><span class="p">()</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-83">%%writefile demos/foodvision_big/app.py
# ## 1. Configuración de importaciones y nombres de clases ###
import gradio as gr
import os
import torch

from model import create_effnetb2_model
from timeit import default_timer as timer
from typing import Tuple, Dict

# Configurar nombres de clases
with open("class_names.txt", "r") as f: # reading them in from class_names.txt
    class_names = [food_name.strip() for food_name in  f.readlines()]
    
# ## 2. Preparación del modelo y transforma ###

# Crear modelo
effnetb2, effnetb2_transforms = create_effnetb2_model(
    num_classes=101, # could also use len(class_names)
)

# Cargar pesos guardados
effnetb2.load_state_dict(
    torch.load(
        f="09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth",
        map_location=torch.device("cpu"),  # load to CPU
    )
)

# ## 3. Función de predicción ###

# Crear función de predicción
def predict(img) -&gt; Tuple[Dict, float]:
    """Transforms and performs a prediction on img and returns prediction and time taken.
    """
    # Start the timer
    start_time = timer()
    
    # Transform the target image and add a batch dimension
    img = effnetb2_transforms(img).unsqueeze(0)
    
    # Put model into evaluation mode and turn on inference mode
    effnetb2.eval()
    with torch.inference_mode():
        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities
        pred_probs = torch.softmax(effnetb2(img), dim=1)
    
    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)
    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}
    
    # Calculate the prediction time
    pred_time = round(timer() - start_time, 5)
    
    # Return the prediction dictionary and prediction time 
    return pred_labels_and_probs, pred_time

# ## 4. Aplicación Gradio ###

# Crear cadenas de título, descripción y artículo.
title = "FoodVision Big 🍔👁"
description = "An EfficientNetB2 feature extractor computer vision model to classify images of food into [101 different classes](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt)."
article = "Created at [09. PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)."

# Crear una lista de ejemplos desde el directorio "examples/"
example_list = [["examples/" + example] for example in os.listdir("examples")]

# Crear interfaz Gradio
demo = gr.Interface(
    fn=predict,
    inputs=gr.Image(type="pil"),
    outputs=[
        gr.Label(num_top_classes=5, label="Predictions"),
        gr.Number(label="Prediction time (s)"),
    ],
    examples=example_list,
    title=title,
    description=description,
    article=article,
)

# ¡Inicia la aplicación!
demo.launch()</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=d5fb8012">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="115-creacion-de-un-archivo-de-requisitos-para-foodvision-big-requirementstxt">11.5 Creación de un archivo de requisitos para FoodVision Big (<code>requirements.txt</code>)<a class="anchor-link" href="#115-creacion-de-un-archivo-de-requisitos-para-foodvision-big-requirementstxt">¶</a></h3><p>Ahora todo lo que necesitamos es un archivo <code>requirements.txt</code> para indicarle a nuestro Hugging Face Space qué dependencias requiere nuestra aplicación FoodVision Big.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=74f6fc6b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-84">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span><span class="o">/</span><span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
<span class="n">torch</span><span class="o">==</span><span class="mf">1.12.0</span>
<span class="n">torchvision</span><span class="o">==</span><span class="mf">0.13.0</span>
<span class="n">gradio</span><span class="o">==</span><span class="mf">3.1.4</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-84">%%writefile demos/foodvision_big/requirements.txt
torch==1.12.0
torchvision==0.13.0
gradio==3.1.4</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=73ddcf8c">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="116-descarga-de-nuestros-archivos-de-la-aplicacion-foodvision-big">11.6 Descarga de nuestros archivos de la aplicación FoodVision Big<a class="anchor-link" href="#116-descarga-de-nuestros-archivos-de-la-aplicacion-foodvision-big">¶</a></h3><p>Tenemos todos los archivos que necesitamos para implementar nuestra aplicación FoodVision Big en Hugging Face, ahora comprimámoslos y descargámoslos.</p>
<p>Usaremos el mismo proceso que usamos para la aplicación FoodVision Mini anterior en la [sección 9.1: <em>Descarga de los archivos de nuestra aplicación Foodvision Mini</em>](<a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#91-downloading-our-foodvision">https://www.learnpytorch.io/09_pytorch_model_deployment/#91-downloading-our-foodvision</a> -archivos-mini-aplicación).</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=27b46e71">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-85">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># Comprima la carpeta foodvision_big pero excluya ciertos archivos</span>
<span class="err">!</span><span class="n">cd</span> <span class="n">demos</span><span class="o">/</span><span class="n">foodvision_big</span> <span class="o">&amp;&amp;</span> <span class="nb">zip</span> <span class="o">-</span><span class="n">r</span> <span class="o">../</span><span class="n">foodvision_big</span><span class="o">.</span><span class="n">zip</span> <span class="o">*</span> <span class="o">-</span><span class="n">x</span> <span class="s2">"*.pyc"</span> <span class="s2">"*.ipynb"</span> <span class="s2">"*__pycache__*"</span> <span class="s2">"*ipynb_checkpoints*"</span>

<span class="c1"># Descargue la aplicación FoodVision Big comprimida (si se ejecuta en Google Colab)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">files</span>
    <span class="n">files</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">"demos/foodvision_big.zip"</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Not running in Google Colab, can't use google.colab.files.download()"</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-85"># Comprima la carpeta foodvision_big pero excluya ciertos archivos
!cd demos/foodvision_big &amp;&amp; zip -r ../foodvision_big.zip * -x "*.pyc" "*.ipynb" "*__pycache__*" "*ipynb_checkpoints*"

# Descargue la aplicación FoodVision Big comprimida (si se ejecuta en Google Colab)
try:
    from google.colab import files
    files.download("demos/foodvision_big.zip")
except:
    print("Not running in Google Colab, can't use google.colab.files.download()")</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=4ed84eee">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="117-implementacion-de-nuestra-aplicacion-foodvision-big-en-huggingface-spaces">11.7 Implementación de nuestra aplicación FoodVision Big en HuggingFace Spaces<a class="anchor-link" href="#117-implementacion-de-nuestra-aplicacion-foodvision-big-en-huggingface-spaces">¶</a></h3><p>¡Hermoso!</p>
<p>¡Es hora de darle vida a nuestro modelo más grande de todo el curso!</p>
<p>Implementemos nuestra demostración de FoodVision Big Gradio en Hugging Face Spaces para que podamos probarla de forma interactiva y permitir que otros experimenten la magia de nuestros esfuerzos de aprendizaje automático.</p>
<blockquote>
<p><strong>Nota:</strong> Hay <a href="https://huggingface.co/docs/hub/repositories-getting-started#getting-started-with-repositories">varias formas de cargar archivos en Hugging Face Spaces</a>. Los siguientes pasos tratan a Hugging Face como un repositorio git para rastrear archivos. Sin embargo, también puede cargar directamente en Hugging Face Spaces a través de la <a href="https://huggingface.co/docs/hub/repositories-getting-started#adding-files-to-a-repository-web-ui">interfaz web</a> o por la <a href="https://huggingface.co/docs/huggingface_hub/index">biblioteca<code>huggingface_hub</code></a>.</p>
</blockquote>
<p>La buena noticia es que ya hemos realizado los pasos para hacerlo con FoodVision Mini, así que ahora todo lo que tenemos que hacer es personalizarlos para que se adapten a FoodVision Big:</p>
<ol>
<li><a href="https://huggingface.co/join">Regístrese</a> para obtener una cuenta de Hugging Face.</li>
<li>Inicie un nuevo Hugging Face Space yendo a su perfil y luego <a href="https://huggingface.co/new-space">haciendo clic en "Nuevo espacio"</a>.<ul>
<li><strong>Nota:</strong> Un espacio en Hugging Face también se conoce como "repositorio de códigos" (un lugar para almacenar su código/archivos) o "repositorio" para abreviar.</li>
</ul>
</li>
<li>Dale un nombre al Espacio, por ejemplo, el mío se llama <code>mrdbourke/foodvision_big</code>, puedes verlo aquí: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_big">https://huggingface.co/spaces/mrdbourke/foodvision_big</a></li>
<li>Seleccione una licencia (yo usé <a href="https://opensource.org/licenses/MIT">MIT</a>).</li>
<li>Seleccione Gradio como Space SDK (kit de desarrollo de software).<ul>
<li><strong>Nota:</strong> Puedes usar otras opciones como Streamlit, pero como nuestra aplicación está construida con Gradio, nos quedaremos con eso.</li>
</ul>
</li>
<li>Elija si su Espacio es público o privado (seleccioné público porque me gustaría que mi Espacio esté disponible para otros).</li>
<li>Haga clic en "Crear espacio".</li>
<li>Clone el repositorio localmente ejecutando: <code>git clone https://huggingface.co/spaces/[YOUR_USERNAME]/[YOUR_SPACE_NAME]</code> en la terminal o en el símbolo del sistema.<ul>
<li><strong>Nota:</strong> También puedes agregar archivos cargándolos en la pestaña "Archivos y versiones".</li>
</ul>
</li>
<li>Copie/mueva el contenido de la carpeta <code>foodvision_big</code> descargada a la carpeta del repositorio clonado.</li>
<li>Para cargar y rastrear archivos más grandes (por ejemplo, archivos de más de 10 MB o, en nuestro caso, nuestro archivo modelo PyTorch), necesitará <a href="https://git-lfs.github.com/">instalar Git LFS</a> (que significa para "almacenamiento de archivos grandes de git").</li>
<li>Después de haber instalado Git LFS, puedes activarlo ejecutando <code>git lfs install</code>.</li>
<li>En el directorio <code>foodvision_big</code>, realice un seguimiento de los archivos de más de 10 MB con Git LFS con <code>git lfs track "*.file_extension"</code>.<ul>
<li>Realice un seguimiento del archivo de modelo EffNetB2 PyTorch con <code>git lfs track "09_pretrained_effnetb2_feature_extractor_food101_20_percent.pth"</code>.</li>
<li><strong>Nota:</strong> Si recibe algún error al cargar imágenes, es posible que también deba rastrearlas con <code>git lfs</code>, por ejemplo, <code>git lfs track "examples/04-pizza-dad.jpg"</code></li>
</ul>
</li>
<li>Seguimiento de <code>.gitattributes</code> (creado automáticamente al clonar desde HuggingFace; este archivo ayudará a garantizar que nuestros archivos más grandes sean rastreados con Git LFS). Puede ver un archivo <code>.gitattributes</code> de ejemplo en [FoodVision Big Hugging Face Space] (<a href="https://huggingface.co/spaces/mrdbourke/foodvision_big/blob/main/.gitattributes">https://huggingface.co/spaces/mrdbourke/foodvision_big/blob/main/.gitattributes</a>).<ul>
<li><code>git agregar .gitattributes</code></li>
</ul>
</li>
<li>Agregue el resto de los archivos de la aplicación <code>foodvision_big</code> y confírmelos con:<ul>
<li><code>git agregar *</code></li>
<li><code>git commit -m "primer compromiso"</code></li>
</ul>
</li>
<li>Envíe (cargue) los archivos a Hugging Face:
*<code>git push</code></li>
<li>Espere de 3 a 5 minutos hasta que se complete la compilación (las compilaciones futuras serán más rápidas) y su aplicación estará activa.</li>
</ol>
<p>Si todo funcionó correctamente, ¡nuestra demostración de FoodVision Big Gradio debería estar lista para clasificar!</p>
<p>Puedes ver mi versión aquí: <a href="https://huggingface.co/spaces/mrdbourke/foodvision_big/">https://huggingface.co/spaces/mrdbourke/foodvision_big/</a></p>
<p>O incluso podemos insertar nuestra demostración de FoodVision Big Gradio directamente en nuestro cuaderno como un <a href="https://gradio.app/sharing_your_app/#embedding-with-iframes">iframe</a> con [<code>IPython.display.IFrame</code>](https: //ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.IFrame) y un enlace a nuestro espacio en el formato <code>https://hf.space/embed/[YOUR_USERNAME ]/[TU_NOMBRE_ESPACIO]/+</code>.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs" id="cell-id=489ae0ee">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [ ]:</div><div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="CodeMirror cm-s-jupyter">
<div class="zeroclipboard-container">
<clipboard-copy for="cell-86">
<div>
<span class="notice" hidden="">Copied!</span>
<svg aria-hidden="true" class="clipboard-copy-icon" data-view-component="true" height="20" version="1.1" viewbox="0 0 16 16" width="20">
<path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 010 1.5h-1.5a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-1.5a.75.75 0 011.5 0v1.5A1.75 1.75 0 019.25 16h-7.5A1.75 1.75 0 010 14.25v-7.5z" fill="currentColor" fill-rule="evenodd"></path>
<path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0114.25 11h-7.5A1.75 1.75 0 015 9.25v-7.5zm1.75-.25a.25.25 0 00-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 00.25-.25v-7.5a.25.25 0 00-.25-.25h-7.5z" fill="currentColor" fill-rule="evenodd"></path>
</svg>
</div>
</clipboard-copy>
</div>
<div class="highlight-ipynb hl-python"><pre><span></span><span class="c1"># IPython es una biblioteca para ayudar a trabajar con Python de forma interactiva</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">IFrame</span>

<span class="c1"># Incruste la demostración de FoodVision Big Gradio como un iFrame</span>
<span class="n">IFrame</span><span class="p">(</span><span class="n">src</span><span class="o">=</span><span class="s2">"https://hf.space/embed/mrdbourke/foodvision_big/+"</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">900</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">750</span><span class="p">)</span>
</pre></div>
<div class="clipboard-copy-txt" id="cell-86"># IPython es una biblioteca para ayudar a trabajar con Python de forma interactiva
from IPython.display import IFrame

# Incruste la demostración de FoodVision Big Gradio como un iFrame
IFrame(src="https://hf.space/embed/mrdbourke/foodvision_big/+", width=900, height=750)</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=847534f7">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>¡¿¡Cuan genial es eso!?!</p>
<p>Hemos recorrido un largo camino desde la construcción de modelos PyTorch para predecir una línea recta... ¡ahora estamos construyendo modelos de visión por computadora accesibles para personas de todo el mundo!</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=0443bf2b">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="principales-conclusiones">Principales conclusiones<a class="anchor-link" href="#principales-conclusiones">¶</a></h2><ul>
<li><strong>La implementación es tan importante como la capacitación.</strong> Una vez que tenga un buen modelo de trabajo, su primera pregunta debería ser: ¿cómo puedo implementarlo y hacerlo accesible para otros? La implementación le permite probar su modelo en el mundo real en lugar de en conjuntos de prueba y capacitación privados.</li>
<li><strong>Tres preguntas para la implementación del modelo de aprendizaje automático:</strong><ol>
<li>¿Cuál es el caso de uso más ideal para el modelo (qué tan bien y qué tan rápido funciona)?</li>
<li>¿A dónde irá el modelo (en el dispositivo o en la nube)?</li>
<li>¿Cómo funcionará el modelo (las predicciones están en línea o fuera de línea)?</li>
</ol>
</li>
<li><strong>Las opciones de implementación son abundantes.</strong> Pero es mejor empezar de forma sencilla. Una de las mejores formas actuales (digo actual porque estas cosas siempre están cambiando) es usar Gradio para crear una demostración y alojarla en Hugging Face Spaces. Comience de manera simple y amplíelo cuando sea necesario.</li>
<li><strong>Nunca dejes de experimentar.</strong> Las necesidades de tu modelo de aprendizaje automático probablemente cambiarán con el tiempo, por lo que implementar un único modelo no es el último paso. Es posible que encuentre cambios en el conjunto de datos, por lo que tendrá que actualizar su modelo. O se publica una nueva investigación y hay una mejor arquitectura para usar.<ul>
<li>Por lo tanto, implementar un modelo es un paso excelente, pero probablemente querrás actualizarlo con el tiempo.</li>
</ul>
</li>
<li><strong>La implementación del modelo de aprendizaje automático es parte de la práctica de ingeniería de MLOps (operaciones de aprendizaje automático).</strong> MLOps es una extensión de DevOps (operaciones de desarrollo) e involucra todas las partes de ingeniería relacionadas con el entrenamiento de un modelo: recopilación y almacenamiento de datos, datos preprocesamiento, implementación de modelos, monitoreo de modelos, control de versiones y más. Es un campo que evoluciona rápidamente, pero existen algunos recursos sólidos para aprender más, muchos de los cuales se encuentran en [Recursos adicionales de PyTorch](<a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and">https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning-and</a> -ingeniería-de-aprendizaje-profundo).</li>
</ul>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=762b33cd">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="ejercicios">Ejercicios<a class="anchor-link" href="#ejercicios">¶</a></h2><p>Todos los ejercicios se centran en practicar el código anterior.</p>
<p>Debería poder completarlos haciendo referencia a cada sección o siguiendo los recursos vinculados.</p>
<p><strong>Recursos:</strong></p>
<ul>
<li>[Cuaderno de plantilla de ejercicios para 09] (<a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/09_pytorch_model_deployment_exercises.ipynb">https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/09_pytorch_model_deployment_exercises.ipynb</a>).</li>
<li><a href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/09_pytorch_model_deployment_exercise_solutions.ipynb">Cuaderno de soluciones de ejemplo para 09</a> pruebe los ejercicios <em>antes</em> de mirar esto.<ul>
<li>Vea un [video tutorial de las soluciones en YouTube] en vivo (<a href="https://youtu.be/jOX5ZCkWO-0">https://youtu.be/jOX5ZCkWO-0</a>) (errores y todo).</li>
</ul>
</li>
</ul>
<ol>
<li>Realice y programe predicciones con ambos modelos de extracción de características en el conjunto de datos de prueba utilizando la GPU (<code>device="cuda"</code>). Compare los tiempos de predicción del modelo en GPU y CPU: ¿esto cierra la brecha entre ellos? Por ejemplo, ¿hacer predicciones en la GPU hace que los tiempos de predicción del extractor de funciones de ViT se acerquen más a los tiempos de predicción del extractor de funciones de EffNetB2?<ul>
<li>Encontrarás el código para realizar estos pasos en la [sección 5. Hacer predicciones con nuestros modelos entrenados y cronometrarlas](<a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#5-making-predictions-with-our-trained">https://www.learnpytorch.io/09_pytorch_model_deployment/#5-making-predictions-with-our-trained</a> -models-and-timing-them) y [sección 6. Comparación de resultados de modelos, tiempos de predicción y tamaño](<a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#6-comparing-model-results-prediction-times-and">https://www.learnpytorch.io/09_pytorch_model_deployment/#6-comparing-model-results-prediction-times-and</a> -tamaño).</li>
</ul>
</li>
<li>El extractor de funciones de ViT parece tener más capacidad de aprendizaje (debido a más parámetros) que EffNetB2. ¿Cómo le va en la división más grande del 20 % de todo el conjunto de datos de Food101?<ul>
<li>Entrene un extractor de funciones ViT en el conjunto de datos 20% Food101 durante 5 épocas, tal como lo hicimos con EffNetB2 en la sección <a href="https://www.learnpytorch.io/09_pytorch_model_deployment/#10-creating-foodvision-big">10. Creando FoodVision Big</a>.</li>
</ul>
</li>
<li>Haga predicciones en el conjunto de datos de prueba 20 % de Food101 con el extractor de funciones ViT del ejercicio 2 y encuentre las predicciones "más incorrectas".<ul>
<li>Las predicciones serán las que tengan mayor probabilidad de predicción pero con la etiqueta de predicción incorrecta.</li>
<li>Escribe una oración o dos sobre por qué crees que el modelo se equivocó en estas predicciones.</li>
</ul>
</li>
<li>Evalúe el extractor de funciones de ViT en todo el conjunto de datos de prueba de Food101 en lugar de solo la versión del 20 %, ¿cómo funciona?<ul>
<li>¿Supera el mejor resultado del artículo original de Food101 con una precisión del 56,4%?</li>
</ul>
</li>
<li>Diríjase a <a href="https://paperswithcode.com/">Paperswithcode.com</a> y busque el modelo actual con mejor rendimiento en el conjunto de datos de Food101.<ul>
<li>¿Qué modelo de arquitectura utiliza?</li>
</ul>
</li>
<li>Escriba de 1 a 3 posibles puntos de falla de nuestros modelos FoodVision implementados y cuáles podrían ser algunas posibles soluciones.<ul>
<li>Por ejemplo, ¿qué pasaría si alguien subiera una foto que no fuera de comida a nuestro modelo FoodVision Mini?</li>
</ul>
</li>
<li>Elija cualquier conjunto de datos de <a href="https://pytorch.org/vision/stable/datasets.html"><code>torchvision.datasets</code></a> y entrene un modelo de extracción de características usando un modelo de <a href="https://pytorch.org/vision/stable/models.html"><code>torchvision.models</code></a> (puede usar uno de los modelos que ya hemos creado, por ejemplo, EffNetB2 o ViT) durante 5 épocas y luego implementar su modelo como una aplicación Gradio en Hugging Face Espacios.<ul>
<li>Es posible que desee elegir un conjunto de datos más pequeño/hacer una división más pequeña para que el entrenamiento no demore demasiado.</li>
<li>¡Me encantaría ver tus modelos implementados! Así que asegúrese de compartirlos en Discord o en la [página de debates de GitHub del curso] (<a href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">https://github.com/mrdbourke/pytorch-deep-learning/discussions</a>).</li>
</ul>
</li>
</ol>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell" id="cell-id=88587451">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="extracurricular">Extracurricular<a class="anchor-link" href="#extracurricular">¶</a></h2><ul>
<li>La implementación del modelo de aprendizaje automático es generalmente un desafío de ingeniería en lugar de un desafío de aprendizaje automático puro; consulte la [sección de ingeniería de aprendizaje automático de recursos adicionales de PyTorch] (<a href="https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning">https://www.learnpytorch.io/pytorch_extra_resources/#resources-for-machine-learning</a> -y-deep-learning-engineering) para obtener recursos sobre cómo aprender más.<ul>
<li>En el interior encontrará recomendaciones de recursos como el libro de Chip Huyen <a href="https://www.amazon.com/Designing-Machine-Learning-Systems-Production-Ready/dp/1098107969"><em>Designing Machine Learning Systems</em></a> ( especialmente el capítulo 7 sobre implementación de modelos) y el [curso Made with ML MLOps] de Goku Mohandas (<a href="https://madewithml.com/#mlops">https://madewithml.com/#mlops</a>).</li>
</ul>
</li>
<li>A medida que empieces a construir más y más proyectos propios, es probable que empieces a usar Git (y potencialmente GitHub) con bastante frecuencia. Para obtener más información sobre ambos, recomiendo el video <a href="https://youtu.be/RGOj5yH7evk"><em>Git y GitHub para principiantes: curso intensivo</em></a> en el canal de YouTube freeCodeCamp.</li>
<li>Sólo hemos arañado la superficie de lo que es posible con Gradio. Para obtener más información, recomiendo consultar la <a href="https://gradio.app/docs/">documentación completa</a>, especialmente:<ul>
<li>Todos los diferentes tipos de [componentes de entrada y salida] (<a href="https://gradio.app/docs/#components">https://gradio.app/docs/#components</a>).</li>
<li>La <a href="https://gradio.app/docs/#blocks">API de Gradio Blocks</a> para flujos de trabajo más avanzados.</li>
<li>El capítulo del curso Hugging Face sobre [cómo usar Gradio con Hugging Face] (<a href="https://huggingface.co/course/chapter9/1">https://huggingface.co/course/chapter9/1</a>).</li>
</ul>
</li>
<li>Los dispositivos Edge no se limitan a teléfonos móviles, incluyen computadoras pequeñas como Raspberry Pi y el equipo de PyTorch tiene un <a href="https://pytorch.org/tutorials/intermediate/realtime_rpi.html">fantástico tutorial de publicación de blog</a> sobre la implementación un modelo de PyTorch a uno.</li>
<li>Para obtener una guía fantástica sobre el desarrollo de aplicaciones basadas en inteligencia artificial y aprendizaje automático, consulte la [Guía de personas + inteligencia artificial de Google] (<a href="https://pair.withgoogle.com/guidebook">https://pair.withgoogle.com/guidebook</a>). Una de mis favoritas es la sección sobre [establecer las expectativas correctas] (<a href="https://pair.withgoogle.com/guidebook/patterns#set-the-right-expectations">https://pair.withgoogle.com/guidebook/patterns#set-the-right-expectations</a>).<ul>
<li>Cubrí más de este tipo de recursos, incluidas guías de Apple, Microsoft y más en la <a href="https://zerotomastery.io/blog/machine-learning-monthly-april-2021/">edición de abril de 2021 de Machine Learning Monthly</a> (un boletín mensual que envío con lo último y lo mejor del campo de ML).</li>
</ul>
</li>
<li>Si desea acelerar el tiempo de ejecución de su modelo en la CPU, debe conocer <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">TorchScript</a>, [ONNX](<a href="https://pytorch">https://pytorch</a> .org/docs/stable/onnx.html) (Open Neural Network Exchange) y [OpenVINO](<a href="https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output">https://docs.openvino.ai/latest/notebooks/102-pytorch-onnx-to-openvino-with-output</a>. HTML). Al pasar de PyTorch puro a modelos ONNX/OpenVINO, he visto un aumento de ~2x+ en el rendimiento.</li>
<li>Para convertir modelos en una API implementable y escalable, consulte la <a href="https://pytorch.org/serve/">biblioteca TorchServe</a>.</li>
<li>Para ver un excelente ejemplo y una justificación de por qué implementar un modelo de aprendizaje automático en el navegador (una forma de implementación perimetral) ofrece varios beneficios (sin retraso en la latencia de transferencia de red), consulte el artículo de Jo Kristian Bergum sobre <a href="https://bergum.medium.com/moving-ml-inference-from-the-cloud-to-the-edge-d6f98dbdb2e3"><em>Moving ML Inference from the Cloud hasta el borde</em></a>.</li>
</ul>
</div>
</div>
</div>
</div>
</div> <!-- jp-Notebook -->
</div> <!-- jupyter-wrapper -->

        <style>
        ['pre { line-height: 125%; }\ntd.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\nspan.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\ntd.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\nspan.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n.highlight-ipynb .hll { background-color: var(--jp-cell-editor-active-background) }\n.highlight-ipynb { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }\n.highlight-ipynb .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */\n.highlight-ipynb .err { color: var(--jp-mirror-editor-error-color) } /* Error */\n.highlight-ipynb .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */\n.highlight-ipynb .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */\n.highlight-ipynb .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */\n.highlight-ipynb .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */\n.highlight-ipynb .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */\n.highlight-ipynb .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */\n.highlight-ipynb .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */\n.highlight-ipynb .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */\n.highlight-ipynb .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */\n.highlight-ipynb .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */\n.highlight-ipynb .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */\n.highlight-ipynb .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */\n.highlight-ipynb .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */\n.highlight-ipynb .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */\n.highlight-ipynb .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */\n.highlight-ipynb .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */\n.highlight-ipynb .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */\n.highlight-ipynb .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */\n.highlight-ipynb .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */\n.highlight-ipynb .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */\n.highlight-ipynb .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */\n.highlight-ipynb .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */\n.highlight-ipynb .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */\n.highlight-ipynb .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */\n.highlight-ipynb .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */\n.highlight-ipynb .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */\n.highlight-ipynb .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */\n.highlight-ipynb .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */\n.highlight-ipynb .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */\n.highlight-ipynb .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */\n.highlight-ipynb .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */\n.highlight-ipynb .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */\n.highlight-ipynb .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */\n.highlight-ipynb .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */\n.highlight-ipynb .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */\n.highlight-ipynb .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */\n.highlight-ipynb .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */\n.highlight-ipynb .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */\n.highlight-ipynb .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */']
        </style>
        







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../12-08_pytorch_paper_replicating/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 08. Replicación de papel PyTorch">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                08. Replicación de papel PyTorch
              </div>
            </div>
          </a>
        
        
          
          <a href="../embeddings/" class="md-footer__link md-footer__link--next" aria-label="Next: Predicción de Características de Nodos Utilizando Node2Vec en Análisis de Grafos y Redes con Python">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Predicción de Características de Nodos Utilizando Node2Vec en Análisis de Grafos y Redes con Python
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/fernandocarazo/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/fernandocarazomelo" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.top", "navigation.footer"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>