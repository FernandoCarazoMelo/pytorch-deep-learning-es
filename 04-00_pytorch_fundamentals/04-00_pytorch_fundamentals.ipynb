{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdc3533",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https:// colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\"/></a> \n",
    "\n",
    "[Ver código fuente](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/00_pytorch_fundamentals.ipynb) | [Ver diapositivas](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/slides/00_pytorch_and_deep_learning_fundamentals.pdf) | [Ver vídeo tutorial](https://youtu.be/Z_ikDlimN6A?t=76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d767f8d",
   "metadata": {},
   "source": [
    "# 00. Fundamentos de PyTorch\n",
    "\n",
    "## ¿Qué es PyTorch?\n",
    "\n",
    "[PyTorch](https://pytorch.org/) es un marco de aprendizaje automático y aprendizaje profundo de código abierto.\n",
    "\n",
    "## ¿Para qué se puede utilizar PyTorch?\n",
    "\n",
    "PyTorch le permite manipular y procesar datos y escribir algoritmos de aprendizaje automático utilizando código Python.\n",
    "\n",
    "## ¿Quién usa PyTorch?\n",
    "\n",
    "Muchas de las empresas de tecnología más grandes del mundo, como [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/ ), Tesla y Microsoft, así como empresas de investigación de inteligencia artificial como [OpenAI utiliza PyTorch](https://openai.com/blog/openai-pytorch/) para impulsar la investigación y llevar el aprendizaje automático a sus productos.\n",
    "\n",
    "![pytorch se utiliza en la industria y la investigación](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png )\n",
    "\n",
    "Por ejemplo, Andrej Karpathy (director de IA de Tesla) ha dado varias charlas ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M ?t=2904)) sobre cómo Tesla usa PyTorch para impulsar sus modelos de visión por computadora autónomos.\n",
    "\n",
    "PyTorch también se utiliza en otras industrias, como la agricultura, para [impulsar la visión por computadora en tractores](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
    "\n",
    "## ¿Por qué utilizar PyTorch?\n",
    "\n",
    "A los investigadores de aprendizaje automático les encanta usar PyTorch. Y a partir de febrero de 2022, PyTorch es el [marco de aprendizaje profundo más utilizado en Papers With Code](https://paperswithcode.com/trends), un sitio web para realizar un seguimiento de los artículos de investigación sobre aprendizaje automático y los repositorios de código adjuntos a ellos.\n",
    "\n",
    "PyTorch también ayuda a encargarse de muchas cosas, como la aceleración de GPU (hacer que su código se ejecute más rápido) detrás de escena. \n",
    "\n",
    "Por lo tanto, puede concentrarse en manipular datos y escribir algoritmos y PyTorch se asegurará de que se ejecute rápidamente.\n",
    "\n",
    "Y si empresas como Tesla y Meta (Facebook) lo utilizan para construir modelos que implementan para impulsar cientos de aplicaciones, conducir miles de automóviles y entregar contenido a miles de millones de personas, es evidente que también es capaz en el frente del desarrollo.\n",
    "\n",
    "## Qué vamos a cubrir en este módulo\n",
    "\n",
    "Este curso se divide en diferentes secciones (cuadernos). \n",
    "\n",
    "Cada cuaderno cubre ideas y conceptos importantes dentro de PyTorch.\n",
    "\n",
    "Los cuadernos posteriores se basan en el conocimiento del anterior (la numeración comienza en 00, 01, 02 y continúa hasta donde termina).\n",
    "\n",
    "Este cuaderno trata sobre el componente básico del aprendizaje automático y el aprendizaje profundo, el tensor.\n",
    "\n",
    "Específicamente, cubriremos:\n",
    "\n",
    "| **Tema** | **Contenido** |\n",
    "| ----- | ----- |\n",
    "| **Introducción a los tensores** | Los tensores son el componente básico de todo el aprendizaje automático y el aprendizaje profundo. |\n",
    "| **Creando tensores** | Los tensores pueden representar casi cualquier tipo de datos (imágenes, palabras, tablas de números). |\n",
    "| **Obtener información de tensores** | Si puedes poner información en un tensor, también querrás sacarla. |\n",
    "| **Manipulación de tensores** | Los algoritmos de aprendizaje automático (como las redes neuronales) implican la manipulación de tensores de muchas formas diferentes, como sumar, multiplicar y combinar. | \n",
    "| **Tratando con formas tensoriales** | Uno de los problemas más comunes en el aprendizaje automático es lidiar con desajustes de formas (intentar mezclar tensores con formas incorrectas con otros tensores). |\n",
    "| **Indexación de tensores** | Si ha indexado en una lista de Python o una matriz NumPy, es muy similar con los tensores, excepto que pueden tener muchas más dimensiones. |\n",
    "| **Mezcla de tensores de PyTorch y NumPy** | PyTorch juega con tensores ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), a NumPy le gustan las matrices ([`np.ndarray`](https://numpy.org /doc/stable/reference/generated/numpy.ndarray.html)) a veces querrás mezclarlos y combinarlos. | \n",
    "| **Reproducibilidad** | El aprendizaje automático es muy experimental y dado que utiliza mucha *aleatoriedad* para funcionar, a veces querrás que esa *aleatoriedad* no sea tan aleatoria. |\n",
    "| **Ejecución de tensores en GPU** | Las GPU (Unidades de procesamiento de gráficos) hacen que su código sea más rápido, PyTorch facilita la ejecución de su código en las GPU. |\n",
    "\n",
    "## ¿Dónde puedes obtener ayuda?\n",
    "\n",
    "Todos los materiales de este curso [en vivo en GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
    "\n",
    "Y si tiene problemas, también puede hacer una pregunta en la [página de debates](https://github.com/mrdbourke/pytorch-deep-learning/discussions).\n",
    "\n",
    "También están los [foros de desarrolladores de PyTorch](https://discuss.pytorch.org/), un lugar muy útil para todo lo relacionado con PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283daaf0",
   "metadata": {},
   "source": [
    "## Importando PyTorch\n",
    "\n",
    "> **Nota:** Antes de ejecutar cualquier código de este cuaderno, debería haber seguido los [pasos de configuración de PyTorch](https://pytorch.org/get-started/locally/). \n",
    ">\n",
    "> Sin embargo, **si estás ejecutando Google Colab**, todo debería funcionar (Google Colab viene con PyTorch y otras bibliotecas instaladas).\n",
    "\n",
    "Comencemos importando PyTorch y verificando la versión que estamos usando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d8b5b5",
   "metadata": {},
   "source": [
    "Maravilloso, parece que tenemos PyTorch 1.10.0+. \n",
    "\n",
    "Esto significa que si está leyendo estos materiales, verá la mayor compatibilidad con PyTorch 1.10.0+; sin embargo, si su número de versión es mucho mayor, es posible que note algunas inconsistencias. \n",
    "\n",
    "Y si tiene algún problema, publíquelo en el curso [página de debates de GitHub] (https://github.com/mrdbourke/pytorch-deep-learning/discussions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eab8a5",
   "metadata": {},
   "source": [
    "## Introducción a los tensores \n",
    "\n",
    "Ahora que importamos PyTorch, es hora de aprender sobre los tensores.\n",
    "\n",
    "Los tensores son el componente fundamental del aprendizaje automático.\n",
    "\n",
    "Su trabajo es representar datos de forma numérica.\n",
    "\n",
    "Por ejemplo, podría representar una imagen como un tensor con la forma `[3, 224, 224]` que significaría `[color_channels, height, width]`, ya que en la imagen tiene `3` canales de color (rojo, verde, azul), una altura de `224` píxeles y una anchura de `224` píxeles.\n",
    "\n",
    "![ejemplo de pasar de una imagen de entrada a una representación tensorial de la imagen, la imagen se divide en 3 canales de color, así como números para representar la altura y el ancho](https://raw.githubusercontent.com/mrdbourke/pytorch -aprendizaje-deep/main/images/00-tensor-shape-example-of-image.png)\n",
    "\n",
    "En lenguaje tensorial (el lenguaje utilizado para describir tensores), el tensor tendría tres dimensiones, una para \"color_channels\", \"altura\" y \"ancho\".\n",
    "\n",
    "Pero nos estamos adelantando.\n",
    "\n",
    "Aprendamos más sobre los tensores codificándolos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aced01",
   "metadata": {},
   "source": [
    "### Creando tensores \n",
    "\n",
    "A PyTorch le encantan los tensores. Tanto es así que hay una página de documentación completa dedicada a la clase [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html).\n",
    "\n",
    "Su primera tarea es [leer la documentación en `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) durante 10 minutos. Pero puedes llegar a eso más tarde.\n",
    "\n",
    "Codifiquemos.\n",
    "\n",
    "Lo primero que vamos a crear es un **escalar**.\n",
    "\n",
    "Un escalar es un número único y en términos tensoriales es un tensor de dimensión cero.\n",
    "\n",
    "> **Nota:** Esa es una tendencia para este curso. Nos centraremos en escribir código específico. Pero a menudo establezco ejercicios que implican leer y familiarizarse con la documentación de PyTorch. Porque después de todo, una vez que hayas terminado este curso, sin duda querrás aprender más. Y la documentación está en algún lugar donde se encontrará con bastante frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11203085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f04a24",
   "metadata": {},
   "source": [
    "¿Ves cómo lo anterior imprimió `tensor (7)`?\n",
    "\n",
    "Eso significa que aunque \"escalar\" es un número único, es del tipo \"torch.Tensor\".\n",
    "\n",
    "Podemos verificar las dimensiones de un tensor usando el atributo `ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346886e",
   "metadata": {},
   "source": [
    "¿Qué pasaría si quisiéramos recuperar el número del tensor?\n",
    "\n",
    "Como en, ¿convertirlo de `torch.Tensor` a un entero de Python?\n",
    "\n",
    "Para hacerlo podemos usar el método `item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84438880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el número de Python dentro de un tensor (solo funciona con tensores de un elemento)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e6ba47",
   "metadata": {},
   "source": [
    "Bien, ahora veamos un **vector**.\n",
    "\n",
    "Un vector es un tensor de una sola dimensión pero puede contener muchos números.\n",
    "\n",
    "Por ejemplo, podría tener un vector `[3, 2]` para describir `[dormitorios, baños]` en su casa. O podría tener \"[3, 2, 2]\" para describir \"[dormitorios, baños, aparcamientos]\" en su casa.\n",
    "\n",
    "La tendencia importante aquí es que un vector es flexible en lo que puede representar (lo mismo ocurre con los tensores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ae4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bff6bf",
   "metadata": {},
   "source": [
    "Maravilloso, \"vector\" ahora contiene dos 7, mi número favorito.\n",
    "\n",
    "¿Cuántas dimensiones crees que tendrá?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique el número de dimensiones del vector.\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a268d9ea",
   "metadata": {},
   "source": [
    "Hmm, eso es extraño, \"vector\" contiene dos números pero solo tiene una dimensión.\n",
    "\n",
    "Te contaré un truco.\n",
    "\n",
    "Puede saber la cantidad de dimensiones que tiene un tensor en PyTorch por la cantidad de corchetes en el exterior (`[`) y solo necesita contar un lado.\n",
    "\n",
    "¿Cuántos corchetes tiene \"vector\"?\n",
    "\n",
    "Otro concepto importante para los tensores es su atributo de \"forma\". La forma te dice cómo están dispuestos los elementos dentro de ella.\n",
    "\n",
    "Veamos la forma del \"vector\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c4d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar la forma del vector\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727d5c36",
   "metadata": {},
   "source": [
    "Lo anterior devuelve `torch.Size([2])` lo que significa que nuestro vector tiene la forma `[2]`. Esto se debe a los dos elementos que colocamos entre corchetes (`[7, 7]`).\n",
    "\n",
    "Veamos ahora una **matriz**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f00abd",
   "metadata": {},
   "source": [
    "¡Guau! ¡Más números! Las matrices son tan flexibles como los vectores, excepto que tienen una dimensión extra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar número de dimensiones\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53111732",
   "metadata": {},
   "source": [
    "`MATRIX` tiene dos dimensiones (¿contaste el número de corchetes en el exterior de un lado?).\n",
    "¿Qué \"forma\" crees que tendrá?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307bd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894cb05",
   "metadata": {},
   "source": [
    "Obtenemos el resultado `torch.Size([2, 2])` porque `MATRIX` tiene dos elementos de profundidad y dos elementos de ancho.\n",
    "\n",
    "¿Qué tal si creamos un **tensor**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0083c",
   "metadata": {},
   "source": [
    "¡Guau! Que bonito tensor.\n",
    "\n",
    "Quiero enfatizar que los tensores pueden representar casi cualquier cosa. \n",
    "\n",
    "El que acabamos de crear podrían ser las cifras de ventas de una tienda de carnes y mantequilla de almendras (dos de mis comidas favoritas).\n",
    "\n",
    "![un tensor simple en hojas de Google que muestra el día de la semana, las ventas de bistec y las ventas de mantequilla de almendras](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_simple_tensor.png)\n",
    "\n",
    "¿Cuántas dimensiones crees que tiene? (pista: utilice el truco de contar corchetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bfccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar número de dimensiones para TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225df5a",
   "metadata": {},
   "source": [
    "¿Y qué pasa con su forma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ed4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar la forma del TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd69348",
   "metadata": {},
   "source": [
    "Muy bien, genera `torch.Size([1, 3, 3])`.\n",
    "\n",
    "Las dimensiones van de exterior a interior.\n",
    "\n",
    "Eso significa que hay 1 dimensión de 3 por 3.\n",
    "\n",
    "![ejemplo de diferentes dimensiones tensoriales](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch- Different-tensor-dimensions.png)\n",
    "\n",
    "> **Nota:** Es posible que hayas notado que uso letras minúsculas para `escalar` y `vector` y letras mayúsculas para `MATRIX` y `TENSOR`. Esto fue a propósito. En la práctica, a menudo verás escalares y vectores indicados con letras minúsculas como \"y\" o \"a\". Y matrices y tensores indicados con letras mayúsculas como \"X\" o \"W\".\n",
    ">\n",
    "> También puedes notar que los nombres matriz y tensor se usan indistintamente. Esto es común. Sin embargo, dado que en PyTorch a menudo se trata con `torch.Tensor`s (de ahí el nombre del tensor), la forma y las dimensiones de lo que hay dentro dictarán lo que realmente es.\n",
    "\n",
    "Resumamos.\n",
    "\n",
    "| Nombre | ¿Qué es? | Número de dimensiones | Inferior o superior (normalmente/ejemplo) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **escalar** | un solo número | 0 | Inferior (`a`) | \n",
    "| **vector** | un número con dirección (por ejemplo, velocidad del viento con dirección) pero también puede tener muchos otros números | 1 | Inferior (`y`) |\n",
    "| **matriz** | una matriz bidimensional de números | 2 | Superior (`Q`) |\n",
    "| **tensor** | una matriz de números n-dimensional | puede ser cualquier número, un tensor de dimensión 0 es un escalar, un tensor de dimensión 1 es un vector | Superior (`X`) | \n",
    "\n",
    "![tensor de matriz vectorial escalar y su apariencia](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a16e9",
   "metadata": {},
   "source": [
    "### Tensores aleatorios\n",
    "\n",
    "Hemos establecido que los tensores representan algún tipo de datos.\n",
    "\n",
    "Y los modelos de aprendizaje automático, como las redes neuronales, manipulan y buscan patrones dentro de los tensores.\n",
    "\n",
    "Pero al construir modelos de aprendizaje automático con PyTorch, es raro que crees tensores a mano (como lo que estamos haciendo nosotros).\n",
    "\n",
    "En cambio, un modelo de aprendizaje automático a menudo comienza con grandes tensores de números aleatorios y ajusta estos números aleatorios a medida que trabaja con datos para representarlos mejor.\n",
    "\n",
    "En esencia:\n",
    "\n",
    "`Comience con números aleatorios -> mire los datos -> actualice los números aleatorios -> mire los datos -> actualice los números aleatorios...`\n",
    "\n",
    "Como científico de datos, puede definir cómo se inicia el modelo de aprendizaje automático (inicialización), analiza los datos (representación) y actualiza (optimización) sus números aleatorios.\n",
    "\n",
    "Nos pondremos manos a la obra con estos pasos más adelante.\n",
    "\n",
    "Por ahora, veamos cómo crear un tensor de números aleatorios.\n",
    "\n",
    "Podemos hacerlo usando [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) y pasando el parámetro `size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor aleatorio de tamaño (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c880a2ee",
   "metadata": {},
   "source": [
    "La flexibilidad de `torch.rand()` es que podemos ajustar el `tamaño` para que sea lo que queramos.\n",
    "\n",
    "Por ejemplo, supongamos que desea un tensor aleatorio con la forma de imagen común de `[224, 224, 3]` (`[alto, ancho, color_channels`])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor aleatorio de tamaño (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa006f4",
   "metadata": {},
   "source": [
    "### Ceros y unos\n",
    "\n",
    "A veces simplemente querrás llenar los tensores con ceros o unos.\n",
    "\n",
    "Esto sucede mucho con el enmascaramiento (como enmascarar algunos de los valores en un tensor con ceros para que el modelo sepa que no debe aprenderlos).\n",
    "\n",
    "Creemos un tensor lleno de ceros con [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
    "\n",
    "Nuevamente entra en juego el parámetro \"tamaño\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7315aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor de todos ceros.\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dea04",
   "metadata": {},
   "source": [
    "Podemos hacer lo mismo para crear un tensor de todos unos excepto usar [`torch.ones()` ](https://pytorch.org/docs/stable/generated/torch.ones.html) en su lugar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d80f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor de todos unos.\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3dba66",
   "metadata": {},
   "source": [
    "### Creando un rango y tensores como\n",
    "\n",
    "A veces es posible que desees un rango de números, como del 1 al 10 o del 0 al 100.\n",
    "\n",
    "Puede utilizar `torch.arange(inicio, fin, paso)` para hacerlo.\n",
    "\n",
    "Dónde:\n",
    "* `start` = inicio del rango (por ejemplo, 0)\n",
    "* `end` = fin del rango (por ejemplo, 10)\n",
    "* `paso` = cuántos pasos hay entre cada valor (por ejemplo, 1)\n",
    "\n",
    "> **Nota:** En Python, puedes usar `range()` para crear un rango. Sin embargo, en PyTorch, `torch.range()` está en desuso y puede mostrar un error en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilice torch.arange(), torch.range() está en desuso\n",
    "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
    "\n",
    "# Crea un rango de valores del 0 al 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd5730",
   "metadata": {},
   "source": [
    "A veces es posible que desees un tensor de cierto tipo con la misma forma que otro tensor.\n",
    "\n",
    "Por ejemplo, un tensor de todos ceros con la misma forma que un tensor anterior. \n",
    "\n",
    "Para hacerlo, puede utilizar [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) o [`torch.ones_like(input)`](https ://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) que devuelven un tensor lleno de ceros o unos con la misma forma que la \"entrada\", respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# También puede crear un tensor de ceros similar a otro tensor.\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b289a81",
   "metadata": {},
   "source": [
    "### Tipos de datos tensoriales\n",
    "\n",
    "Hay muchos [tipos de datos tensoriales disponibles en PyTorch] diferentes (https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "Algunos son específicos para CPU y otros son mejores para GPU.\n",
    "\n",
    "Saber cuál es cuál puede llevar algún tiempo.\n",
    "\n",
    "Generalmente, si ve `torch.cuda` en cualquier lugar, el tensor se está usando para la GPU (ya que las GPU de Nvidia usan un conjunto de herramientas informáticas llamado CUDA).\n",
    "\n",
    "El tipo más común (y generalmente el predeterminado) es `torch.float32` o `torch.float`.\n",
    "\n",
    "Esto se conoce como \"coma flotante de 32 bits\".\n",
    "\n",
    "Pero también hay punto flotante de 16 bits (`torch.float16` o `torch.half`) y punto flotante de 64 bits (`torch.float64` o `torch.double`).\n",
    "\n",
    "Y para confundir aún más las cosas, también hay números enteros de 8, 16, 32 y 64 bits.\n",
    "\n",
    "¡Y mucho más!\n",
    "\n",
    "> **Nota:** Un número entero es un número plano y redondo como \"7\", mientras que un flotante tiene un decimal \"7.0\".\n",
    "\n",
    "La razón de todo esto tiene que ver con la **precisión en la informática**.\n",
    "\n",
    "La precisión es la cantidad de detalles utilizados para describir un número.\n",
    "\n",
    "Cuanto mayor sea el valor de precisión (8, 16, 32), más detalles y, por tanto, más datos se utilizarán para expresar un número.\n",
    "\n",
    "Esto es importante en el aprendizaje profundo y la computación numérica porque al realizar tantas operaciones, cuanto más detalles tenga para calcular, más computación tendrá que usar.\n",
    "\n",
    "Por lo tanto, los tipos de datos de menor precisión generalmente son más rápidos de calcular, pero sacrifican algo de rendimiento en métricas de evaluación como la precisión (más rápido de calcular pero menos preciso).\n",
    "\n",
    "> **Recursos:** \n",
    "  * Consulte la [documentación de PyTorch para obtener una lista de todos los tipos de datos tensoriales disponibles] (https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Lea la [página de Wikipedia para obtener una descripción general de qué es la precisión en informática] (https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "Veamos cómo crear algunos tensores con tipos de datos específicos. Podemos hacerlo usando el parámetro `dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b366bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tipo de datos predeterminado para tensores es float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ab71f",
   "metadata": {},
   "source": [
    "Aparte de los problemas de forma (las formas de los tensores no coinciden), dos de los otros problemas más comunes que encontrará en PyTorch son problemas de tipo de datos y de dispositivo.\n",
    "\n",
    "Por ejemplo, uno de los tensores es `torch.float32` y el otro es `torch.float16` (a PyTorch a menudo le gusta que los tensores tengan el mismo formato).\n",
    "\n",
    "O uno de sus tensores está en la CPU y el otro en la GPU (a PyTorch le gusta que los cálculos entre tensores se realicen en el mismo dispositivo).\n",
    "\n",
    "Veremos más sobre este dispositivo más adelante.\n",
    "\n",
    "Por ahora creemos un tensor con `dtype=torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27610f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4e51d",
   "metadata": {},
   "source": [
    "## Obtener información de tensores\n",
    "\n",
    "Una vez que haya creado tensores (o alguien más o un módulo de PyTorch los haya creado para usted), es posible que desee obtener información de ellos.\n",
    "\n",
    "Ya los hemos visto antes, pero tres de los atributos más comunes que querrás conocer sobre los tensores son:\n",
    "* `forma` - ¿qué forma tiene el tensor? (algunas operaciones requieren reglas de forma específicas)\n",
    "* `dtype`: ¿en qué tipo de datos se almacenan los elementos dentro del tensor?\n",
    "* `dispositivo`: ¿en qué dispositivo está almacenado el tensor? (generalmente GPU o CPU)\n",
    "\n",
    "Creemos un tensor aleatorio y descubramos detalles al respecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Conoce detalles al respecto\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f26fd3",
   "metadata": {},
   "source": [
    "> **Nota:** Cuando tienes problemas en PyTorch, muy a menudo tiene que ver con uno de los tres atributos anteriores. Entonces, cuando aparezcan los mensajes de error, cante una pequeña canción llamada \"qué, qué, dónde\": \n",
    "  * \"*¿Qué forma tienen mis tensores? ¿Qué tipo de datos son y dónde se almacenan? ¿Qué forma, qué tipo de datos, dónde, dónde, dónde*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2928aa0b",
   "metadata": {},
   "source": [
    "## Manipulación de tensores (operaciones tensoriales)\n",
    "\n",
    "En el aprendizaje profundo, los datos (imágenes, texto, vídeo, audio, estructuras de proteínas, etc.) se representan como tensores.\n",
    "\n",
    "Un modelo aprende investigando esos tensores y realizando una serie de operaciones (podrían ser más de 1.000.000 de operaciones) en tensores para crear una representación de los patrones en los datos de entrada.\n",
    "\n",
    "Estas operaciones suelen ser un baile maravilloso entre:\n",
    "* Suma\n",
    "* Resta\n",
    "* Multiplicación (por elementos)\n",
    "* División\n",
    "* Multiplicación de matrices\n",
    "\n",
    "Y eso es. Seguro que hay algunos más aquí y allá, pero estos son los componentes básicos de las redes neuronales.\n",
    "\n",
    "Al apilar estos bloques de construcción de la manera correcta, puedes crear las redes neuronales más sofisticadas (¡como Lego!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1372fd",
   "metadata": {},
   "source": [
    "### Operaciones básicas\n",
    "\n",
    "Comencemos con algunas de las operaciones fundamentales, suma (`+`), resta (`-`), multiplicación (`*`).\n",
    "\n",
    "Funcionan tal como crees que lo harían."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd67655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor de valores y agrégale un número.\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18580c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicalo por 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2119311",
   "metadata": {},
   "source": [
    "Observe cómo los valores del tensor anteriores no terminaron siendo \"tensor ([110, 120, 130])\", esto se debe a que los valores dentro del tensor no cambian a menos que sean reasignados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los tensores no cambian a menos que se reasignen\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e96252",
   "metadata": {},
   "source": [
    "Restemos un número y esta vez reasignaremos la variable `tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d233ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restar y reasignar\n",
    "tensor = tensor - 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b82a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar y reasignar\n",
    "tensor = tensor + 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c6744",
   "metadata": {},
   "source": [
    "PyTorch también tiene un montón de funciones integradas como [`torch.mul()`](https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul) (abreviatura de multiplicación) y [`torch.add()`](https://pytorch.org/docs/stable/generated/torch.add.html) para realizar operaciones básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# También puede utilizar funciones de antorcha.\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbceba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El tensor original aún no ha cambiado.\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a952849",
   "metadata": {},
   "source": [
    "Sin embargo, es más común usar símbolos de operador como `*` en lugar de `torch.mul()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58df82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicación por elementos (cada elemento multiplica su equivalente, índice 0->0, 1->1, 2->2)\n",
    "print(tensor, \"*\", tensor)\n",
    "print(\"Equals:\", tensor * tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa965f1",
   "metadata": {},
   "source": [
    "### Multiplicación de matrices (es todo lo que necesitas)\n",
    "\n",
    "Una de las operaciones más comunes en los algoritmos de aprendizaje automático y aprendizaje profundo (como las redes neuronales) es la [multiplicación de matrices] (https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
    "\n",
    "PyTorch implementa la funcionalidad de multiplicación de matrices en el método [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n",
    "Las dos reglas principales que hay que recordar para la multiplicación de matrices son:\n",
    "\n",
    "1. Las **dimensiones interiores** deben coincidir:\n",
    "  * `(3, 2) @ (3, 2)` no funcionará\n",
    "  * `(2, 3) @ (3, 2)` funcionará\n",
    "  * `(3, 2) @ (2, 3)` funcionará\n",
    "2. La matriz resultante tiene la forma de **dimensiones exteriores**:\n",
    " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "> **Nota:** \"`@`\" en Python es el símbolo para la multiplicación de matrices.\n",
    "\n",
    "> **Recurso:** Puede ver todas las reglas para la multiplicación de matrices usando `torch.matmul()` [en la documentación de PyTorch](https://pytorch.org/docs/stable/generated/torch.matmul. HTML).\n",
    "\n",
    "Creemos un tensor y realicemos una multiplicación de elementos y una multiplicación de matrices en él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e13a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e1a3f8",
   "metadata": {},
   "source": [
    "La diferencia entre la multiplicación por elementos y la multiplicación de matrices es la suma de valores.\n",
    "\n",
    "Para nuestra variable `tensor` con valores `[1, 2, 3]`:\n",
    "\n",
    "| Operación | Cálculo | Código |\n",
    "| ----- | ----- | ----- |\n",
    "| **Multiplicación por elementos** | `[1*1, 2*2, 3*3]` = `[1, 4, 9]` | `tensor * tensor` |\n",
    "| **Multiplicación de matrices** | `[1*1 + 2*2 + 3*3]` = `[14]` | `tensor.matmul(tensor)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de103e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicación de matrices por elementos\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf7ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicación de matrices\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# También se puede utilizar el símbolo \"@\" para la multiplicación de matrices, aunque no se recomienda.\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b736b",
   "metadata": {},
   "source": [
    "Puedes hacer la multiplicación de matrices a mano, pero no es recomendable.\n",
    "\n",
    "El método incorporado `torch.matmul()` es más rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Multiplicación de matrices a mano.\n",
    "# (evite a toda costa realizar operaciones con bucles for, son computacionalmente costosos)\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a333c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d5c69",
   "metadata": {},
   "source": [
    "## Uno de los errores más comunes en el aprendizaje profundo (errores de forma)\n",
    "\n",
    "Debido a que gran parte del aprendizaje profundo consiste en multiplicar y realizar operaciones en matrices, y las matrices tienen una regla estricta sobre qué formas y tamaños se pueden combinar, uno de los errores más comunes con los que se encontrará en el aprendizaje profundo son las discrepancias de formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las formas deben estar en la forma correcta.\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c2d53",
   "metadata": {},
   "source": [
    "Podemos hacer que la multiplicación de matrices funcione entre `tensor_A` y `tensor_B` haciendo que sus dimensiones internas coincidan.\n",
    "\n",
    "Una de las formas de hacer esto es con una **transposición** (cambiar las dimensiones de un tensor determinado).\n",
    "\n",
    "Puede realizar transposiciones en PyTorch usando:\n",
    "* `torch.transpose(input, dim0, dim1)` - donde `input` es el tensor que se desea transponer y `dim0` y `dim1` son las dimensiones que se van a intercambiar.\n",
    "* `tensor.T` - donde `tensor` es el tensor que se desea transponer.\n",
    "\n",
    "Probemos esto último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver tensor_A y tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver tensor_A y tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d06bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La operación funciona cuando se transpone tensor_B\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape} (same as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebaa3a",
   "metadata": {},
   "source": [
    "También puede usar [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) que es una abreviatura de `torch.matmul()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29132597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mm es un atajo para matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e857b191",
   "metadata": {},
   "source": [
    "Sin la transpuesta, las reglas de multiplicación de matrices no se cumplen y obtenemos un error como el anterior.\n",
    "\n",
    "¿Qué tal una imagen? \n",
    "\n",
    "![demostración visual de multiplicación de matrices](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
    "\n",
    "Puede crear sus propios elementos visuales de multiplicación de matrices como este en http://matrixmultiplication.xyz/.\n",
    "\n",
    "> **Nota:** Una multiplicación de matrices como esta también se conoce como [**producto escalar**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) de dos matrices ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9e0e9",
   "metadata": {},
   "source": [
    "Las redes neuronales están llenas de multiplicaciones de matrices y productos escalares.\n",
    "\n",
    "El módulo [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) (lo veremos en acción más adelante), También conocida como capa de avance o capa completamente conectada, implementa una multiplicación de matrices entre una entrada \"x\" y una matriz de pesos \"A\".\n",
    "\n",
    "$$\n",
    "y = x\\cdot{A^T} + b\n",
    "$$\n",
    "\n",
    "Dónde:\n",
    "* `x` es la entrada a la capa (el aprendizaje profundo es una pila de capas como `torch.nn.Linear()` y otras una encima de la otra).\n",
    "* `A` es la matriz de pesos creada por la capa, esto comienza como números aleatorios que se ajustan a medida que una red neuronal aprende a representar mejor los patrones en los datos (observe la \"`T`\", eso se debe a que la matriz de pesos se transpone ).\n",
    "  * **Nota:** Es posible que también veas a menudo \"W\" u otra letra como \"X\" utilizada para mostrar la matriz de pesos.\n",
    "* `b` es el término de sesgo utilizado para compensar ligeramente los pesos y las entradas.\n",
    "* `y` es la salida (una manipulación de la entrada con la esperanza de descubrir patrones en ella).\n",
    "\n",
    "Esta es una función lineal (es posible que hayas visto algo como $y = mx+b$ en la escuela secundaria o en cualquier otro lugar) y se puede usar para dibujar una línea recta.\n",
    "\n",
    "Juguemos con una capa lineal.\n",
    "\n",
    "Intente cambiar los valores de `in_features` y `out_features` a continuación y vea qué sucede.\n",
    "\n",
    "¿Notas algo que ver con las formas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que la capa lineal comienza con una matriz de pesos aleatorios, hagámosla reproducible (más sobre esto más adelante)\n",
    "torch.manual_seed(42)\n",
    "# Esto usa la multiplicación de matrices.\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f60695",
   "metadata": {},
   "source": [
    "> **Pregunta:** ¿Qué sucede si cambia `in_features` del 2 al 3 anterior? ¿Tiene error? ¿Cómo podría cambiar la forma de la entrada (`x`) para adaptarse al error? Pista: ¿qué tuvimos que hacer con el `tensor_B` anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df977d4",
   "metadata": {},
   "source": [
    "Si nunca lo has hecho antes, la multiplicación de matrices puede ser un tema confuso al principio.\n",
    "\n",
    "Pero después de haber jugado con él unas cuantas veces e incluso haber abierto algunas redes neuronales, notarás que está en todas partes.\n",
    "\n",
    "Recuerde, la multiplicación de matrices es todo lo que necesita.\n",
    "\n",
    "![Todo lo que necesitas es multiplicación de matrices](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
    "\n",
    "*Cuando empieces a profundizar en las capas de la red neuronal y a construir la tuya propia, encontrarás multiplicaciones de matrices por todas partes. **Fuente:** https://marksaroufim.substack.com/p/working-class-deep-learner*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb03695c",
   "metadata": {},
   "source": [
    "### Encontrar el mínimo, máximo, media, suma, etc. (agregación)\n",
    "\n",
    "Ahora que hemos visto algunas formas de manipular tensores, veamos algunas formas de agregarlos (pasar de más valores a menos valores).\n",
    "\n",
    "Primero crearemos un tensor y luego encontraremos su máximo, mínimo, media y suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6280582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79552911",
   "metadata": {},
   "source": [
    "Ahora realicemos alguna agregación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79406e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # esto generará un error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efe2c2",
   "metadata": {},
   "source": [
    "> **Nota:** Es posible que algunos métodos como `torch.mean()` requieran que los tensores estén en `torch.float32` (el más común) u otro tipo de datos específico; de lo contrario, la operación fallará. \n",
    "\n",
    "También puedes hacer lo mismo que arriba con los métodos \"antorcha\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45fa46",
   "metadata": {},
   "source": [
    "### Posicional mín/máx\n",
    "\n",
    "También puede encontrar el índice de un tensor donde ocurre el máximo o el mínimo con [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) y [`torch .argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectivamente.\n",
    "\n",
    "Esto es útil en caso de que solo desee la posición donde está el valor más alto (o más bajo) y no el valor real en sí (veremos esto en una sección posterior cuando utilice la [función de activación softmax](https://pytorch.org /docs/stable/generated/torch.nn.Softmax.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Devuelve el índice de valores máximo y mínimo.\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d24ede0",
   "metadata": {},
   "source": [
    "### Cambiar el tipo de datos del tensor\n",
    "\n",
    "Como se mencionó, un problema común con las operaciones de aprendizaje profundo es tener tensores en diferentes tipos de datos.\n",
    "\n",
    "Si un tensor está en `torch.float64` y otro está en `torch.float32`, es posible que se encuentre con algunos errores.\n",
    "\n",
    "Pero hay una solución.\n",
    "\n",
    "Puede cambiar los tipos de datos de los tensores usando [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) donde el `dtype` El parámetro es el tipo de datos que desea utilizar.\n",
    "\n",
    "Primero crearemos un tensor y verificaremos su tipo de datos (el valor predeterminado es `torch.float32`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0bb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor y verifica su tipo de datos.\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69b781",
   "metadata": {},
   "source": [
    "Ahora crearemos otro tensor igual que antes pero cambiaremos su tipo de datos a `torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un tensor float16\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee26fd",
   "metadata": {},
   "source": [
    "Y podemos hacer algo similar para crear un tensor `torch.int8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor int8\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24207d81",
   "metadata": {},
   "source": [
    "> **Nota:** Para empezar, diferentes tipos de datos pueden resultar confusos. Pero piénselo así: cuanto menor es el número (por ejemplo, 32, 16, 8), menos precisa es la computadora que almacena el valor. Y con una menor cantidad de almacenamiento, esto generalmente resulta en un cálculo más rápido y un modelo general más pequeño. Las redes neuronales móviles a menudo operan con números enteros de 8 bits, más pequeños y más rápidos de ejecutar, pero menos precisos que sus contrapartes float32. Para obtener más información sobre esto, leí sobre [precisión en informática] (https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
    "\n",
    "> **Ejercicio:** Hasta ahora hemos cubierto algunos métodos tensoriales, pero hay muchos más en la [documentación `torch.Tensor`](https://pytorch.org/docs/stable/tensors.html) , recomendaría pasar 10 minutos desplazándose y mirando cualquiera que le llame la atención. Haga clic en ellos y luego escríbalos usted mismo en código para ver qué sucede."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfae91",
   "metadata": {},
   "source": [
    "### Remodelar, apilar, apretar y descomprimir\n",
    "\n",
    "Muchas veces querrás remodelar o cambiar las dimensiones de tus tensores sin cambiar realmente los valores dentro de ellos.\n",
    "\n",
    "Para hacerlo, algunos métodos populares son:\n",
    "\n",
    "| Método | Descripción de una línea |\n",
    "| ----- | ----- |\n",
    "| [`torch.reshape(entrada, forma)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Cambia la forma de `input` a `shape` (si es compatible), también puede usar `torch.Tensor.reshape()`. |\n",
    "| [`Tensor.view(forma)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Devuelve una vista del tensor original en una \"forma\" diferente pero comparte los mismos datos que el tensor original. |\n",
    "| [`torch.stack(tensores, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatena una secuencia de \"tensores\" a lo largo de una nueva dimensión (\"dim\"), todos los \"tensores\" deben tener el mismo tamaño. |\n",
    "| [`torch.squeeze(entrada)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Aprieta `input` para eliminar todas las dimensiones con valor `1`. |\n",
    "| [`torch.unsqueeze(entrada, tenue)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Devuelve \"entrada\" con un valor de dimensión de \"1\" agregado en \"tenue\". | \n",
    "| [`torch.permute(entrada, atenuaciones)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Devuelve una *vista* de la \"entrada\" original con sus dimensiones permutadas (reorganizadas) a \"atenuadas\". | \n",
    "\n",
    "¿Por qué hacer algo de esto?\n",
    "\n",
    "Porque los modelos de aprendizaje profundo (redes neuronales) tratan de manipular tensores de alguna manera. Y debido a las reglas de la multiplicación de matrices, si las formas no coinciden, se producirán errores. Estos métodos le ayudan a asegurarse de que los elementos correctos de sus tensores se mezclen con los elementos correctos de otros tensores. \n",
    "\n",
    "Probémoslos.\n",
    "\n",
    "Primero, crearemos un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "import torch\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f326b7",
   "metadata": {},
   "source": [
    "Ahora agreguemos una dimensión adicional con `torch.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6ad4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añade una dimensión extra\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d40c36",
   "metadata": {},
   "source": [
    "También podemos cambiar la vista con `torch.view()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06627de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar vista (mantiene los mismos datos que el original pero cambia la vista)\n",
    "# Ver más: https://stackoverflow.com/a/54507446/7900723\n",
    "z = x.view(1, 7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b469ab",
   "metadata": {},
   "source": [
    "Sin embargo, recuerde que cambiar la vista de un tensor con `torch.view()` en realidad solo crea una nueva vista del *mismo* tensor.\n",
    "\n",
    "Entonces, cambiar la vista también cambia el tensor original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ac03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar z cambia x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc965191",
   "metadata": {},
   "source": [
    "Si quisiéramos apilar nuestro nuevo tensor encima de sí mismo cinco veces, podríamos hacerlo con `torch.stack()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cf8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apilar tensores uno encima del otro\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf196f",
   "metadata": {},
   "source": [
    "¿Qué tal eliminar todas las dimensiones individuales de un tensor?\n",
    "\n",
    "Para hacerlo, puedes usar `torch.squeeze()` (recuerdo esto como *apretar* el tensor para que solo tenga dimensiones superiores a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7514f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Eliminar dimensión adicional de x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0f9ce",
   "metadata": {},
   "source": [
    "Y para hacer lo contrario de `torch.squeeze()` puedes usar `torch.unsqueeze()` para agregar un valor de dimensión de 1 en un índice específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# # Añade una dimensión extra con unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94d5972",
   "metadata": {},
   "source": [
    "También puede reorganizar el orden de los valores de los ejes con `torch.permute(input, dims)`, donde la `input` se convierte en una *vista* con nuevas `dims`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor con forma específica.\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permutar el tensor original para reorganizar el orden de los ejes.\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baccefd",
   "metadata": {},
   "source": [
    "> **Nota**: Debido a que la permutación devuelve una *vista* (comparte los mismos datos que el original), los valores en el tensor permutado serán los mismos que los del tensor original y si cambia los valores en la vista, también cambiar los valores del original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7a1f4",
   "metadata": {},
   "source": [
    "## Indexación (seleccionando datos de tensores)\n",
    "\n",
    "A veces querrás seleccionar datos específicos de los tensores (por ejemplo, solo la primera columna o la segunda fila).\n",
    "\n",
    "Para hacerlo, puede utilizar la indexación.\n",
    "\n",
    "Si alguna vez ha indexado en listas de Python o matrices NumPy, la indexación en PyTorch con tensores es muy similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5108d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un tensor\n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a59b3",
   "metadata": {},
   "source": [
    "Los valores de indexación van a la dimensión exterior -> dimensión interior (consulte los corchetes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb651e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexemos paréntesis por paréntesis\n",
    "print(f\"First square bracket:\\n{x[0]}\") \n",
    "print(f\"Second square bracket: {x[0][0]}\") \n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315cebc7",
   "metadata": {},
   "source": [
    "También puede usar `:` para especificar \"todos los valores en esta dimensión\" y luego usar una coma (`,`) para agregar otra dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenga todos los valores de la dimensión 0 y el índice 0 de la dimensión 1\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb75645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenga todos los valores de la 0.ª y la 1.ª dimensión, pero solo el índice 1 de la 2.ª dimensión\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenga todos los valores de la dimensión 0 pero solo el valor del índice 1 de la primera y segunda dimensión\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f89c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenga el índice 0 de la 0.ª y 1.ª dimensión y todos los valores de la 2.ª dimensión\n",
    "x[0, 0, :] # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd26d59",
   "metadata": {},
   "source": [
    "Para empezar, la indexación puede resultar bastante confusa, especialmente con tensores más grandes (todavía tengo que intentar indexar varias veces para hacerlo bien). Pero con un poco de práctica y siguiendo el lema del explorador de datos (***visualizar, visualizar, visualizar***), empezarás a cogerle el tranquillo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0a767",
   "metadata": {},
   "source": [
    "## Tensores de PyTorch y NumPy\n",
    "\n",
    "Dado que NumPy es una biblioteca de computación numérica popular de Python, PyTorch tiene una funcionalidad para interactuar bien con ella.  \n",
    "\n",
    "Los dos métodos principales que querrás usar para NumPy a PyTorch (y viceversa) son: \n",
    "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - Matriz NumPy -> tensor de PyTorch. \n",
    "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - Tensor de PyTorch -> Matriz NumPy.\n",
    "\n",
    "Probémoslos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29975c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz NumPy a tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbfda92",
   "metadata": {},
   "source": [
    "> **Nota:** De forma predeterminada, las matrices NumPy se crean con el tipo de datos `float64` y si lo convierte a un tensor de PyTorch, mantendrá el mismo tipo de datos (como arriba). \n",
    ">\n",
    "> Sin embargo, muchos cálculos de PyTorch utilizan de forma predeterminada `float32`. \n",
    "> \n",
    "> Entonces, si desea convertir su matriz NumPy (float64) -> tensor PyTorch (float64) -> tensor PyTorch (float32), puede usar `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
    "\n",
    "Debido a que reasignamos el \"tensor\" arriba, si cambia el tensor, la matriz permanece igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia la matriz, mantén el tensor.\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4120de00",
   "metadata": {},
   "source": [
    "Y si desea pasar del tensor de PyTorch a la matriz NumPy, puede llamar a `tensor.numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor a matriz NumPy\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66175351",
   "metadata": {},
   "source": [
    "Y se aplica la misma regla anterior, si cambia el `tensor` original, el nuevo `numpy_tensor` permanece igual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea712ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia el tensor, mantén la matriz igual\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e520b44",
   "metadata": {},
   "source": [
    "## Reproducibilidad (tratar de sacar lo aleatorio de lo aleatorio)\n",
    "\n",
    "A medida que aprenda más sobre las redes neuronales y el aprendizaje automático, comenzará a descubrir en qué medida influye la aleatoriedad.\n",
    "\n",
    "Bueno, pseudoaleatoriedad, eso es. Porque después de todo, tal como están diseñadas, una computadora es fundamentalmente determinista (cada paso es predecible), por lo que la aleatoriedad que crean es aleatoriedad simulada (aunque también hay debate sobre esto, pero como no soy un científico informático, no Te dejaremos descubrir más tú mismo).\n",
    "\n",
    "Entonces, ¿cómo se relaciona esto con las redes neuronales y el aprendizaje profundo?\n",
    "\n",
    "Hemos discutido que las redes neuronales comienzan con números aleatorios para describir patrones en los datos (estos números son descripciones deficientes) y tratamos de mejorar esos números aleatorios usando operaciones tensoriales (y algunas otras cosas que aún no hemos discutido) para describir mejor los patrones en datos.\n",
    "\n",
    "En breve: \n",
    "\n",
    "``comience con números aleatorios -> operaciones tensoriales -> intente hacerlo mejor (una y otra vez)``\n",
    "\n",
    "Aunque la aleatoriedad es agradable y poderosa, a veces te gustaría que hubiera un poco menos de aleatoriedad.\n",
    "\n",
    "¿Por qué?\n",
    "\n",
    "Para que pueda realizar experimentos repetibles.\n",
    "\n",
    "Por ejemplo, crea un algoritmo capaz de lograr un rendimiento X.\n",
    "\n",
    "Y luego tu amigo lo prueba para comprobar que no estás loco.\n",
    "\n",
    "¿Cómo pudieron hacer tal cosa?\n",
    "\n",
    "Ahí es donde entra en juego la **reproducibilidad**.\n",
    "\n",
    "En otras palabras, ¿puedes obtener los mismos resultados (o muy similares) en tu computadora ejecutando el mismo código que yo obtengo en la mía?\n",
    "\n",
    "Veamos un breve ejemplo de reproducibilidad en PyTorch.\n",
    "\n",
    "Comenzaremos creando dos tensores aleatorios, ya que son aleatorios, uno esperaría que fueran diferentes, ¿verdad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f806ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Crea dos tensores aleatorios\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(f\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae5b4d",
   "metadata": {},
   "source": [
    "Tal como era de esperar, los tensores salen con valores diferentes.\n",
    "\n",
    "Pero, ¿qué pasaría si quisieras crear dos tensores aleatorios con los *mismos* valores?\n",
    "\n",
    "Como en, los tensores aún contendrían valores aleatorios pero serían del mismo tipo.\n",
    "\n",
    "Ahí es donde entra [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html), donde `seed` es un número entero (como `42` pero podría ser cualquier cosa) que le dé sabor a la aleatoriedad.\n",
    "\n",
    "Probémoslo creando algunos tensores aleatorios más *con sabor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# # Establecer la semilla aleatoria\n",
    "RANDOM_SEED=42 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED) \n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Tienes que restablecer la semilla cada vez que se llama a un nuevo rand()\n",
    "# Sin esto, tensor_D sería diferente a tensor_C\n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ac4afb",
   "metadata": {},
   "source": [
    "¡Lindo!\n",
    "\n",
    "Parece que la semilla funcionó. \n",
    "\n",
    "> **Recurso:** Lo que acabamos de cubrir solo roza la superficie de la reproducibilidad en PyTorch. Para obtener más información sobre la reproducibilidad en general y las semillas aleatorias, consultaría:\n",
    "> * [La documentación de reproducibilidad de PyTorch](https://pytorch.org/docs/stable/notes/randomness.html) (un buen ejercicio sería leer esto durante 10 minutos e incluso si no lo entiendes ahora, ser consciente de ello es importante).\n",
    "> * [La página de semillas aleatorias de Wikipedia](https://en.wikipedia.org/wiki/Random_seed) (esto brindará una buena descripción general de las semillas aleatorias y la pseudoaleatoriedad en general)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c96a6",
   "metadata": {},
   "source": [
    "## Ejecutar tensores en GPU (y realizar cálculos más rápidos)\n",
    "\n",
    "Los algoritmos de aprendizaje profundo requieren muchas operaciones numéricas.\n",
    "\n",
    "Y, de forma predeterminada, estas operaciones suelen realizarse en una CPU (unidad de procesamiento de computadora).\n",
    "\n",
    "Sin embargo, existe otra pieza común de hardware llamada GPU (unidad de procesamiento de gráficos), que suele ser mucho más rápida a la hora de realizar los tipos específicos de operaciones que necesitan las redes neuronales (multiplicaciones de matrices) que las CPU.\n",
    "\n",
    "Es posible que su computadora tenga uno.\n",
    "\n",
    "Si es así, deberías intentar usarlo siempre que puedas para entrenar redes neuronales porque es probable que acelere drásticamente el tiempo de entrenamiento.\n",
    "\n",
    "Hay algunas formas de obtener acceso primero a una GPU y, en segundo lugar, hacer que PyTorch use la GPU.\n",
    "\n",
    "> **Nota:** Cuando hago referencia a \"GPU\" a lo largo de este curso, me refiero a una [GPU Nvidia con CUDA](https://developer.nvidia.com/cuda-gpus) habilitada (CUDA es una plataforma informática y API que ayuda a permitir que las GPU se utilicen para computación de propósito general y no solo para gráficos) a menos que se especifique lo contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d50cc1",
   "metadata": {},
   "source": [
    "### 1. Obtener una GPU\n",
    "\n",
    "Quizás ya sepas lo que pasa cuando digo GPU. Pero si no, hay algunas formas de acceder a uno.\n",
    "\n",
    "| **Método** | **Dificultad de configuración** | **Ventajas** | **Desventajas** | **Cómo configurar** |\n",
    "| ----- | ----- | ----- | ----- | ----- |\n",
    "| Colaboración de Google | Fácil | De uso gratuito, casi no requiere configuración, puede compartir el trabajo con otras personas tan fácilmente como un enlace | No guarda sus salidas de datos, cálculo limitado, sujeto a tiempos de espera | [Siga la guía de Google Colab](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
    "| Utilice el suyo propio | Medio | Ejecute todo localmente en su propia máquina | Las GPU no son gratuitas, requieren un costo inicial | Siga las [directrices de instalación de PyTorch](https://pytorch.org/get-started/locally/) |\n",
    "| Computación en la nube (AWS, GCP, Azure) | Medio-Duro | Pequeño costo inicial, acceso a computación casi infinita | Puede resultar costoso si se ejecuta continuamente, lleva algo de tiempo configurarlo correctamente | Siga las [directrices de instalación de PyTorch](https://pytorch.org/get-started/cloud-partners/) |\n",
    "\n",
    "Hay más opciones para usar GPU, pero las tres anteriores serán suficientes por ahora.\n",
    "\n",
    "Personalmente, uso una combinación de Google Colab y mi propia computadora personal para experimentos a pequeña escala (y para crear este curso) y recurro a recursos de la nube cuando necesito más potencia informática.\n",
    "\n",
    "> **Recurso:** Si está pensando en comprar su propia GPU pero no está seguro de qué comprar, [Tim Dettmers tiene una guía excelente](https://timdettmers.com/2020/09/07/ Which -gpu-para-aprendizaje-profundo/).\n",
    "\n",
    "Para verificar si tiene acceso a una GPU Nvidia, puede ejecutar `!nvidia-smi` donde `!` (también llamado bang) significa \"ejecutar esto en la línea de comando\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f579a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f877be",
   "metadata": {},
   "source": [
    "Si no tiene una GPU Nvidia accesible, lo anterior generará algo como:\n",
    "\n",
    "```\n",
    "NVIDIA-SMI falló porque no pudo comunicarse con el controlador NVIDIA. Asegúrese de que el controlador NVIDIA más reciente esté instalado y ejecutándose.\n",
    "```\n",
    "\n",
    "En ese caso, vuelva a subir y siga los pasos de instalación.\n",
    "\n",
    "Si tiene una GPU, la línea anterior generará algo como:\n",
    "\n",
    "```\n",
    "miércoles 19 de enero 22:09:08 2022       \n",
    "+------------------------------------------------- ----------------------------+\n",
    "| NVIDIA-SMI 495.46 Versión del controlador: 460.32.03 Versión CUDA: 11.2 |\n",
    "|-------------------------------+------------------ -----+----------------------+\n",
    "| Persistencia del nombre de GPU-M| Visualización de ID de bus A | Incorrección volátil. CEC |\n",
    "| Fan Temp Perf Pwr:Uso/Cap|         Uso de memoria | GPU-Util Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+================== =====+======================|\n",
    "|   0 Tesla P100-PCIE... Apagado | 00000000:00:04.0 Apagado |                    0 |\n",
    "| N/D 35C P0 27W / 250W |      0MiB/16280MiB |      0% Predeterminado |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+------------------ -----+----------------------+\n",
    "                                                                               \n",
    "+------------------------------------------------- ----------------------------+\n",
    "| Procesos: |\n",
    "|  GPU GI CI PID Tipo Nombre del proceso GPU Memoria |\n",
    "|        Uso de identificación |\n",
    "|=================================================== ============================|\n",
    "|  No se encontraron procesos en ejecución |\n",
    "+------------------------------------------------- ----------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326badcf",
   "metadata": {},
   "source": [
    "### 2. Hacer que PyTorch se ejecute en la GPU\n",
    "\n",
    "Una vez que tenga una GPU lista para acceder, el siguiente paso es utilizar PyTorch para almacenar datos (tensores) y calcular datos (realizar operaciones con tensores).\n",
    "\n",
    "Para hacerlo, puede utilizar el paquete [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html).\n",
    "\n",
    "En lugar de hablar de ello, probémoslo.\n",
    "\n",
    "Puede probar si PyTorch tiene acceso a una GPU usando [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bade310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710da645",
   "metadata": {},
   "source": [
    "Si lo anterior genera \"True\", PyTorch puede ver y usar la GPU, si genera \"False\", no puede ver la GPU y, en ese caso, tendrá que volver a realizar los pasos de instalación.\n",
    "\n",
    "Ahora, digamos que desea configurar su código para que se ejecute en la CPU *o* la GPU, si está disponible.\n",
    "\n",
    "De esa manera, si usted o alguien decide ejecutar su código, funcionará independientemente del dispositivo informático que esté utilizando. \n",
    "\n",
    "Creemos una variable \"dispositivo\" para almacenar qué tipo de dispositivo está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer tipo de dispositivo\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d231a6",
   "metadata": {},
   "source": [
    "Si el resultado anterior es `\"cuda\"`, significa que podemos configurar todo nuestro código PyTorch para usar el dispositivo CUDA disponible (una GPU) y si genera `\"cpu\"`, nuestro código PyTorch se quedará con la CPU.\n",
    "\n",
    "> **Nota:** En PyTorch, se recomienda escribir [**código independiente del dispositivo**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). Esto significa código que se ejecutará en la CPU (siempre disponible) o GPU (si está disponible).\n",
    "\n",
    "Si desea realizar una informática más rápida, puede utilizar una GPU, pero si desea realizar una informática *mucho* más rápida, puede utilizar varias GPU.\n",
    "\n",
    "Puede contar la cantidad de GPU a las que PyTorch tiene acceso usando [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda. recuento_dispositivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar el número de dispositivos\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8e6a2",
   "metadata": {},
   "source": [
    "Saber la cantidad de GPU a las que tiene acceso PyTorch es útil en caso de que desee ejecutar un proceso específico en una GPU y otro proceso en otra (PyTorch también tiene funciones que le permiten ejecutar un proceso en *todas* las GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ab2f78",
   "metadata": {},
   "source": [
    "### 2.1 Hacer que PyTorch se ejecute en Apple Silicon\n",
    "\n",
    "Para ejecutar PyTorch en las GPU M1/M2/M3 de Apple, puede utilizar el módulo [`torch.backends.mps`](https://pytorch.org/docs/stable/notes/mps.html).\n",
    "\n",
    "Asegúrese de que las versiones de macOS y Pytorch estén actualizadas.\n",
    "\n",
    "Puede probar si PyTorch tiene acceso a una GPU usando `torch.backends.mps.is_available()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec43d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compruebe si hay GPU Apple Silicon\n",
    "import torch\n",
    "torch.backends.mps.is_available() # Note this will print false if you're not running on a Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e2e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer tipo de dispositivo\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861e158",
   "metadata": {},
   "source": [
    "Como antes, si el resultado anterior es `\"mps\"`, significa que podemos configurar todo nuestro código PyTorch para usar la GPU Apple Silicon disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" # Use NVIDIA GPU (if available)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\" # Use Apple Silicon GPU (if available)\n",
    "else:\n",
    "    device = \"cpu\" # Default to CPU if no GPU is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39367caf",
   "metadata": {},
   "source": [
    "### 3. Poner tensores (y modelos) en la GPU\n",
    "\n",
    "Puede colocar tensores (y modelos, lo veremos más adelante) en un dispositivo específico llamando a [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to. html) en ellos. Donde \"dispositivo\" es el dispositivo de destino al que desea que vaya el tensor (o modelo).\n",
    "\n",
    "¿Por qué hacer esto?\n",
    "\n",
    "Las GPU ofrecen computación numérica mucho más rápida que las CPU y, si no hay una GPU disponible, debido a nuestro **código independiente del dispositivo** (ver arriba), se ejecutará en la CPU.\n",
    "\n",
    "> **Nota:** Poner un tensor en la GPU usando `to(dispositivo)` (por ejemplo, `some_tensor.to(device)`) devuelve una copia de ese tensor, p.ej. el mismo tensor estará en CPU y GPU. Para sobrescribir tensores, reasígnalos:\n",
    ">\n",
    "> `algún_tensor = algún_tensor.to(dispositivo)`\n",
    "\n",
    "Intentemos crear un tensor y ponerlo en la GPU (si está disponible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tensor (predeterminado en la CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor no en GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Mover tensor a GPU (si está disponible)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fd895",
   "metadata": {},
   "source": [
    "Si tiene una GPU disponible, el código anterior generará algo como:\n",
    "\n",
    "```\n",
    "tensor([1, 2, 3]) CPU\n",
    "tensor([1, 2, 3], dispositivo='cuda:0')\n",
    "```\n",
    "\n",
    "Observe que el segundo tensor tiene `'device='cuda:0'`, esto significa que está almacenado en la 0.ª GPU disponible (las GPU están indexadas a 0, si hubiera dos GPU disponibles, serían `'cuda:0'` y `' cuda:1'` respectivamente, hasta `'cuda:n'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac33972",
   "metadata": {},
   "source": [
    "### 4. Mover tensores de regreso a la CPU\n",
    "\n",
    "¿Qué pasaría si quisiéramos mover el tensor de nuevo a la CPU?\n",
    "\n",
    "Por ejemplo, querrás hacer esto si quieres interactuar con tus tensores con NumPy (NumPy no aprovecha la GPU).\n",
    "\n",
    "Intentemos usar el método [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) en nuestro `tensor_on_gpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si el tensor está en la GPU, no se puede transformar a NumPy (esto generará un error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb8546",
   "metadata": {},
   "source": [
    "En su lugar, para devolver un tensor a la CPU y poder usarlo con NumPy, podemos usar [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
    "\n",
    "Esto copia el tensor a la memoria de la CPU para que pueda usarse con CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fafe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En su lugar, copie el tensor nuevamente a la CPU.\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4fdfee",
   "metadata": {},
   "source": [
    "Lo anterior devuelve una copia del tensor de la GPU en la memoria de la CPU, por lo que el tensor original todavía está en la GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df864b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2108eb47",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "Todos los ejercicios se centran en practicar el código anterior.\n",
    "\n",
    "Debería poder completarlos haciendo referencia a cada sección o siguiendo los recursos vinculados.\n",
    "\n",
    "**Recursos:**\n",
    "\n",
    "* [Cuaderno de plantilla de ejercicios para 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
    "* [Cuaderno de soluciones de ejemplo para 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (pruebe los ejercicios *antes* de mirar esto).\n",
    "\n",
    "1. Lectura de documentación: una gran parte del aprendizaje profundo (y de aprender a codificar en general) es familiarizarse con la documentación de un marco determinado que estás utilizando. Usaremos mucho la documentación de PyTorch durante el resto de este curso. Así que recomendaría dedicar 10 minutos a leer lo siguiente (está bien si no entiendes algunas cosas por ahora, el enfoque aún no es la comprensión total, sino la conciencia). Consulte la documentación en [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) y para [`torch.cuda`](https://pytorch.org/ docs/master/notes/cuda.html#cuda-semantics).\n",
    "2. Crea un tensor aleatorio con forma `(7, 7)`.\n",
    "3. Realiza una multiplicación matricial del tensor de 2 con otro tensor aleatorio con forma `(1, 7)` (pista: es posible que tengas que transponer el segundo tensor).\n",
    "4. Establezca la semilla aleatoria en \"0\" y repita los ejercicios 2 y 3.\n",
    "5. Hablando de semillas aleatorias, vimos cómo configurarlas con `torch.manual_seed()` pero ¿existe una GPU equivalente? (Pista: necesitarás consultar la documentación de `torch.cuda` para este caso). Si es así, configure la semilla aleatoria de la GPU en \"1234\".\n",
    "6. Cree dos tensores aleatorios de forma `(2, 3)` y envíelos a la GPU (necesitará acceso a una GPU para esto). Configure `torch.manual_seed(1234)` al crear los tensores (no tiene que ser la semilla aleatoria de la GPU).\n",
    "7. Realiza una multiplicación de matrices en los tensores que creaste en 6 (nuevamente, es posible que tengas que ajustar las formas de uno de los tensores).\n",
    "8. Encuentre los valores máximo y mínimo de la salida de 7.\n",
    "9. Encuentre los valores de índice máximo y mínimo de la salida de 7.\n",
    "10. Haga un tensor aleatorio con forma `(1, 1, 1, 10)` y luego cree un nuevo tensor con todas las dimensiones `1` eliminadas para quedar con un tensor de forma `(10)`. Establezca la semilla en `7` cuando la cree e imprima el primer tensor y su forma, así como el segundo tensor y su forma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e5c105",
   "metadata": {},
   "source": [
    "## Extracurricular\n",
    "\n",
    "* Dedique 1 hora a leer el [tutorial básico de PyTorch](https://pytorch.org/tutorials/beginner/basics/intro.html) (recomiendo el [Inicio rápido](https://pytorch.org/ tutorials/beginner/basics/quickstart_tutorial.html) y [Tensores](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) secciones).\n",
    "* Para obtener más información sobre cómo un tensor puede representar datos, vea este vídeo: [¿Qué es un tensor?](https://youtu.be/f5liqUk0ZTw)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
